{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Almost Visual Inertial Odometry"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.models import MobileNetV2, mobilenet_v3_small, MobileNet_V3_Small_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from  matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 20197\n",
    "BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 32\n",
    "GAMMA = 0.1   # torch default\n",
    "LR=0.001 \n",
    "EPOCHS = 2000\n",
    "EARLY_STOPPING = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available cuda: True\n"
     ]
    }
   ],
   "source": [
    "available_cuda = torch.cuda.is_available()\n",
    "print(f\"Available cuda: {available_cuda}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if available_cuda else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvioDataset(torch.utils.data.Dataset):\n",
    "      def __init__(self, frames, inertials, labels, inertials_buffer, choose_split=None, split={'train':0.6, 'val':0.2, 'test':0.2}, shuffle=True):\n",
    "            if shuffle:\n",
    "                  shuffled_index = torch.randperm(frames.shape[0])\n",
    "                  frames = frames[shuffled_index]\n",
    "                  inertials = inertials[shuffled_index]\n",
    "                  labels = labels[shuffled_index]\n",
    "                  inertials_buffer = inertials_buffer[shuffled_index]\n",
    "\n",
    "            if choose_split is None:\n",
    "                  self.frames = frames\n",
    "                  self.inertials = inertials\n",
    "                  self.labels = labels\n",
    "                  self.inertials_buffer = inertials_buffer\n",
    "            else:\n",
    "                  assert split['train'] + split['val'] + split['test'] == 1\n",
    "                  length = frames.shape[0]\n",
    "                  if choose_split == \"train\":\n",
    "                        self.frames = frames[:round(split['train']*length)]\n",
    "                        self.inertials = inertials[:round(split['train']*length)]\n",
    "                        self.labels = labels[:round(split['train']*length)]\n",
    "                        self.inertials_buffer = inertials_buffer[:round(split['train']*length)]\n",
    "                  elif choose_split == \"val\":\n",
    "                        self.frames = frames[round(split['train']*length):-round(split['test']*length)]\n",
    "                        self.inertials = inertials[round(split['train']*length):-round(split['test']*length)]\n",
    "                        self.labels = labels[round(split['train']*length):-round(split['test']*length)]\n",
    "                        self.inertials_buffer = inertials_buffer[round(split['train']*length):-round(split['test']*length)]\n",
    "                  elif choose_split == \"test\":\n",
    "                        self.frames = frames[-round(split['test']*length):]\n",
    "                        self.inertials = inertials[-round(split['test']*length):]\n",
    "                        self.labels = labels[-round(split['test']*length):]\n",
    "                        self.inertials_buffer = inertials_buffer[-round(split['test']*length):]\n",
    "                  else:\n",
    "                        raise Exception(f\"The split name '{choose_split}' doesn't exists\")\n",
    "\n",
    "      def __len__(self):\n",
    "            return len(self.frames) - 1\n",
    "\n",
    "      def __getitem__(self, index):\n",
    "            # load sample of frames\n",
    "            frame_name = self.frames[index]\n",
    "            scene_name, frame_name = frame_name.split(\"_\")\n",
    "            frame_name, file_extension = frame_name.split(\".\")\n",
    "            sample_frame = torch.Tensor(np.load(f\"./data/{scene_name}/iphone/frames/{scene_name}_{frame_name}.npy\", allow_pickle=True))\n",
    "\n",
    "            # build buffer sample of inertials\n",
    "            sample_inertials_buffer = self.inertials_buffer[index]\n",
    "\n",
    "            # load labels\n",
    "            label_odometry = self.labels[index]\n",
    "\n",
    "            # load inertials\n",
    "            label_inertial = self.inertials[index]\n",
    "\n",
    "            return sample_frame, sample_inertials_buffer, label_odometry, label_inertial\n",
    "\n",
    "\n",
    "frames = np.load(\"dataset_frames.npy\", allow_pickle=True)\n",
    "inertials = torch.Tensor(np.load(\"dataset_inertials.npy\", allow_pickle=True))\n",
    "labels = torch.Tensor(np.load(\"dataset_labels.npy\", allow_pickle=True))\n",
    "buffer_inertials = torch.Tensor(np.load(\"dataset_buffer.npy\", allow_pickle=True))\n",
    "\n",
    "train_data = AdvioDataset(frames, inertials, labels, buffer_inertials, \"train\")\n",
    "val_data = AdvioDataset(frames, inertials, labels, buffer_inertials, \"val\")\n",
    "test_data = AdvioDataset(frames, inertials, labels, buffer_inertials, \"test\")\n",
    "\n",
    "del frames\n",
    "del inertials\n",
    "del labels\n",
    "del buffer_inertials\n",
    "\n",
    "params = {'batch_size': BATCH_SIZE,\n",
    "          'num_workers': 6,\n",
    "          'drop_last':True}\n",
    "\n",
    "train_loader = DataLoader(train_data, **params, shuffle=True)\n",
    "val_loader = DataLoader(val_data, **params, shuffle=True)\n",
    "test_loader = DataLoader(test_data, **params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet1D(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(ConvNet1D,self).__init__()\n",
    "    self.conv1 = nn.Conv1d(3,8,3,2)\n",
    "    torch.nn.init.kaiming_uniform_(self.conv1.weight)\n",
    "    \n",
    "    self.conv2 = nn.Conv1d(8,16,3,2)\n",
    "    torch.nn.init.kaiming_uniform_(self.conv2.weight)\n",
    "    \n",
    "    self.conv3 = nn.Conv1d(16,32,3,2)\n",
    "    torch.nn.init.kaiming_uniform_(self.conv3.weight)\n",
    "    \n",
    "    self.conv4 = nn.Conv1d(32,64,3,2)\n",
    "    torch.nn.init.kaiming_uniform_(self.conv4.weight)\n",
    "    \n",
    "    self.conv5 = nn.Conv1d(64,16,3,1)\n",
    "    torch.nn.init.kaiming_uniform_(self.conv5.weight)\n",
    "\n",
    "    self.conv6 = nn.Conv1d(16,3,3,1)\n",
    "    torch.nn.init.kaiming_uniform_(self.conv6.weight)\n",
    "\n",
    "    self.fc1 = nn.Linear(3,3)\n",
    "\n",
    "  def forward(self,x):\n",
    "    # adding uncertanty\n",
    "    # random_weights = torch.randn(x.shape)*2 + 1\n",
    "    # random_weights = random_weights.to(device)\n",
    "    # x = x * random_weights\n",
    "\n",
    "    x = F.silu(self.conv1(x))\n",
    "    x = F.silu(self.conv2(x))\n",
    "    x = F.silu(self.conv3(x))\n",
    "    x = F.silu(self.conv4(x))\n",
    "    x = F.silu(self.conv5(x))\n",
    "    x = F.silu(self.conv6(x))\n",
    "    x = x.reshape(x.shape[0], 3)\n",
    "    x = self.fc1(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InertialNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InertialNet, self).__init__()\n",
    "        \n",
    "        self.conv2d_odometry = MobileNetV2(num_classes=3)\n",
    "        self.conv2d_inertial = MobileNetV2(num_classes=3)\n",
    "        self.conv1d_inertial = ConvNet1D()\n",
    "\n",
    "        self.fc1 = nn.Linear(6,6)\n",
    "        self.fc2 = nn.Linear(6,3)\n",
    "        self.fc3 = nn.Linear(3,3)\n",
    "\n",
    "    def forward(self, x, inertial_buffer):\n",
    "        x_odometry = self.conv2d_odometry(x)\n",
    "        x_inertial = self.conv2d_inertial(x)\n",
    "\n",
    "        x_inertial_unsqueezed = torch.unsqueeze(x_inertial, axis=2)\n",
    "        x_inertial_buffer = torch.concat([inertial_buffer, x_inertial_unsqueezed], axis=2)\n",
    "        x_inertial_refined = self.conv1d_inertial(x_inertial_buffer)\n",
    "\n",
    "        x_odometry = x_odometry.reshape((x.shape[0], -1))\n",
    "        x_inertial_refined = x_inertial_refined.reshape((x.shape[0], -1))\n",
    "        x = torch.concat([x_odometry, x_inertial_refined], axis=1)\n",
    "\n",
    "        x = F.silu(self.fc1(x))\n",
    "        x = F.silu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x, x_inertial, x_inertial_refined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_head(model):\n",
    "    n_inputs = model.classifier[0].in_features\n",
    "    classifier = nn.Linear(n_inputs, 100)\n",
    "    model.classifier[0] = classifier\n",
    "\n",
    "    n_inputs = model.classifier[3].in_features\n",
    "    classifier = nn.Linear(100, 3)\n",
    "    model.classifier[3] = classifier\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InertialNet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InertialNet2, self).__init__()\n",
    "        \n",
    "        self.conv2d_odometry = mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1)\n",
    "        self.conv2d_odometry = replace_head(self.conv2d_odometry)\n",
    "        self.conv2d_inertial = mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1)\n",
    "        self.conv2d_odometry = replace_head(self.conv2d_inertial)\n",
    "        self.conv1d_inertial = ConvNet1D()\n",
    "\n",
    "        self.fc1 = nn.Linear(6,6)\n",
    "        self.fc2 = nn.Linear(6,3)\n",
    "        self.fc3 = nn.Linear(3,3)\n",
    "\n",
    "    def forward(self, x, inertial_buffer):\n",
    "        x_odometry = self.conv2d_odometry(x)\n",
    "        x_inertial = self.conv2d_inertial(x)\n",
    "\n",
    "        x_inertial_unsqueezed = torch.unsqueeze(x_inertial, axis=2)\n",
    "        x_inertial_buffer = torch.concat([inertial_buffer, x_inertial_unsqueezed], axis=2)\n",
    "        x_inertial_refined = self.conv1d_inertial(x_inertial_buffer)\n",
    "\n",
    "        x_odometry = x_odometry.reshape((x.shape[0], -1))\n",
    "        x_inertial_refined = x_inertial_refined.reshape((x.shape[0], -1))\n",
    "        x = torch.concat([x_odometry, x_inertial_refined], axis=1)\n",
    "\n",
    "        x = F.silu(self.fc1(x))\n",
    "        x = F.silu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x, x_inertial, x_inertial_refined"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "  data = data - data.min()\n",
    "  data = data / data.max()\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    history_loss = 0\n",
    "    history_loss=0\n",
    "    history_odometry_loss=0\n",
    "    history_inertial_loss=0\n",
    "    history_inertial_refined_loss=0\n",
    "\n",
    "    for batch_idx, (data, inertials_buffer, labels_odometry, labels_inertial) in enumerate(train_loader):\n",
    "        # data preparation\n",
    "        data = normalize(data)\n",
    "        labels_odometry = labels_odometry.mean(axis=1)\n",
    "        inertials_buffer = inertials_buffer.mean(axis=2)\n",
    "        inertials_buffer = torch.moveaxis(inertials_buffer, 2, 1)\n",
    "        labels_inertial = labels_inertial.mean(axis=1)\n",
    "\n",
    "        data = data.to(device)\n",
    "        inertials_buffer = inertials_buffer.to(device)\n",
    "        labels_odometry = labels_odometry.to(device)\n",
    "        labels_inertial = labels_inertial.to(device)\n",
    "\n",
    "        #forward\n",
    "        optimizer.zero_grad()\n",
    "        out, out_inertial, out_inertial_refined = model(data, inertials_buffer)\n",
    "\n",
    "        # loss\n",
    "        odometry_loss = torch.sqrt(F.mse_loss(out, labels_odometry))\n",
    "        inertial_loss = torch.sqrt(F.mse_loss(out_inertial, labels_inertial))\n",
    "        inertial_refined_loss = torch.sqrt(F.mse_loss(out_inertial_refined, labels_inertial))\n",
    "        loss = odometry_loss + inertial_loss + inertial_refined_loss\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #stats\n",
    "        history_loss += loss.item()\n",
    "        history_odometry_loss += odometry_loss.item()\n",
    "        history_inertial_loss += inertial_loss.item()\n",
    "        history_inertial_refined_loss += inertial_refined_loss.item()\n",
    "\n",
    "        if batch_idx%(len(train_loader)//5)==0:\n",
    "            print(f\"\\t[# {batch_idx: 4}] train_loss: {loss.item():.6f}, odo_loss: {odometry_loss.item():.6f}, ine_loss: {inertial_loss.item():.6f}, ref_loss: {inertial_refined_loss.item():.6f}\")\n",
    "    \n",
    "    history_loss /= len(train_loader) # average epoch loss\n",
    "    history_odometry_loss /= len(train_loader)\n",
    "    history_inertial_loss /= len(train_loader)\n",
    "    history_inertial_refined_loss /= len(train_loader)\n",
    "    print(f\"\\ttrain_loss: {history_loss:.6f}, odo_loss: {history_odometry_loss:.6f}, ine_loss: {history_inertial_loss:.6f}, ref_loss: {history_inertial_refined_loss:.6f}\")\n",
    "    \n",
    "    return history_loss, history_odometry_loss, history_inertial_loss, history_inertial_refined_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, device, val_loader, epoch):\n",
    "    model.train()\n",
    "    history_loss=0\n",
    "    history_odometry_loss=0\n",
    "    history_inertial_loss=0\n",
    "    history_inertial_refined_loss=0\n",
    "\n",
    "    for batch_idx, (data, inertials_buffer, labels_odometry, labels_inertial) in enumerate(val_loader):\n",
    "        # data preparation\n",
    "        data = normalize(data)\n",
    "        labels_odometry = labels_odometry.mean(axis=1)\n",
    "        inertials_buffer = inertials_buffer.mean(axis=2)\n",
    "        inertials_buffer = torch.moveaxis(inertials_buffer, 2, 1)\n",
    "        labels_inertial = labels_inertial.mean(axis=1)\n",
    "\n",
    "        data = data.to(device)\n",
    "        inertials_buffer = inertials_buffer.to(device)\n",
    "        labels_odometry = labels_odometry.to(device)\n",
    "        labels_inertial = labels_inertial.to(device)\n",
    "\n",
    "        # forward\n",
    "        out, out_inertial, out_inertial_refined = model(data, inertials_buffer)\n",
    "\n",
    "        # loss\n",
    "        odometry_loss = torch.sqrt(F.mse_loss(out, labels_odometry))\n",
    "        inertial_loss = torch.sqrt(F.mse_loss(out_inertial, labels_inertial))\n",
    "        inertial_refined_loss = torch.sqrt(F.mse_loss(out_inertial_refined, labels_inertial))\n",
    "        loss = odometry_loss + inertial_loss + inertial_refined_loss\n",
    "        \n",
    "        #stats\n",
    "        history_loss += loss.item()\n",
    "        history_odometry_loss += odometry_loss.item()\n",
    "        history_inertial_loss += inertial_loss.item()\n",
    "        history_inertial_refined_loss += inertial_refined_loss.item()\n",
    "\n",
    "    history_loss /= len(val_loader) # average epoch loss\n",
    "    history_odometry_loss /= len(val_loader)\n",
    "    history_inertial_loss /= len(val_loader)\n",
    "    history_inertial_refined_loss /= len(val_loader)\n",
    "    print(f\"\\tval_loss: {history_loss:.6f}, odo_loss: {history_odometry_loss:.6f}, ine_loss: {history_inertial_loss:.6f}, ref_loss: {history_inertial_refined_loss:.6f}\")\n",
    "\n",
    "    return history_loss, history_odometry_loss, history_inertial_loss, history_inertial_refined_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "\t[#    0] train_loss: 18.536900, odo_loss: 17.134748, ine_loss: 0.676264, ref_loss: 0.725888\n",
      "\t[#  180] train_loss: 22.863979, odo_loss: 22.201708, ine_loss: 0.369722, ref_loss: 0.292549\n",
      "\t[#  360] train_loss: 19.769011, odo_loss: 19.168858, ine_loss: 0.346896, ref_loss: 0.253257\n",
      "\t[#  540] train_loss: 18.706205, odo_loss: 17.558844, ine_loss: 0.912996, ref_loss: 0.234366\n",
      "\t[#  720] train_loss: 18.767729, odo_loss: 17.398020, ine_loss: 1.052042, ref_loss: 0.317667\n",
      "\t[#  900] train_loss: 15.692014, odo_loss: 13.762267, ine_loss: 1.651571, ref_loss: 0.278175\n",
      "\ttrain_loss: 19.050353, odo_loss: 18.034054, ine_loss: 0.725502, ref_loss: 0.290797\n",
      "\tval_loss: 15.358599, odo_loss: 13.592765, ine_loss: 1.504053, ref_loss: 0.261781\n",
      "\t*** Personal Best ***\n",
      "Epoch 2/2000\n",
      "\t[#    0] train_loss: 12.353523, odo_loss: 10.662315, ine_loss: 1.436039, ref_loss: 0.255169\n",
      "\t[#  180] train_loss: 14.736344, odo_loss: 13.179420, ine_loss: 1.286616, ref_loss: 0.270307\n",
      "\t[#  360] train_loss: 13.067213, odo_loss: 11.671004, ine_loss: 1.040468, ref_loss: 0.355741\n",
      "\t[#  540] train_loss: 9.883199, odo_loss: 8.713314, ine_loss: 0.954618, ref_loss: 0.215266\n",
      "\t[#  720] train_loss: 12.032157, odo_loss: 10.671142, ine_loss: 1.124445, ref_loss: 0.236571\n",
      "\t[#  900] train_loss: 10.256164, odo_loss: 8.999200, ine_loss: 0.934250, ref_loss: 0.322714\n",
      "\ttrain_loss: 12.281238, odo_loss: 10.874090, ine_loss: 1.142419, ref_loss: 0.264729\n",
      "\tval_loss: 10.462215, odo_loss: 9.301320, ine_loss: 0.906286, ref_loss: 0.254609\n",
      "\t*** Personal Best ***\n",
      "Epoch 3/2000\n",
      "\t[#    0] train_loss: 9.194778, odo_loss: 7.934384, ine_loss: 0.964498, ref_loss: 0.295897\n",
      "\t[#  180] train_loss: 10.708104, odo_loss: 9.650922, ine_loss: 0.796780, ref_loss: 0.260403\n",
      "\t[#  360] train_loss: 9.756662, odo_loss: 8.723392, ine_loss: 0.779450, ref_loss: 0.253821\n",
      "\t[#  540] train_loss: 8.778183, odo_loss: 7.688451, ine_loss: 0.859384, ref_loss: 0.230347\n",
      "\t[#  720] train_loss: 11.711359, odo_loss: 10.804787, ine_loss: 0.707574, ref_loss: 0.198998\n",
      "\t[#  900] train_loss: 9.740107, odo_loss: 8.818860, ine_loss: 0.689446, ref_loss: 0.231801\n",
      "\ttrain_loss: 10.275757, odo_loss: 9.231774, ine_loss: 0.789851, ref_loss: 0.254132\n",
      "\tval_loss: 10.063586, odo_loss: 9.120634, ine_loss: 0.683120, ref_loss: 0.259832\n",
      "\t*** Personal Best ***\n",
      "Epoch 4/2000\n",
      "\t[#    0] train_loss: 10.957258, odo_loss: 9.953724, ine_loss: 0.722488, ref_loss: 0.281046\n",
      "\t[#  180] train_loss: 9.621970, odo_loss: 8.632568, ine_loss: 0.689836, ref_loss: 0.299565\n",
      "\t[#  360] train_loss: 11.365837, odo_loss: 10.390323, ine_loss: 0.708299, ref_loss: 0.267214\n",
      "\t[#  540] train_loss: 8.987087, odo_loss: 7.976097, ine_loss: 0.770362, ref_loss: 0.240630\n",
      "\t[#  720] train_loss: 13.596936, odo_loss: 12.682624, ine_loss: 0.675582, ref_loss: 0.238731\n",
      "\t[#  900] train_loss: 9.385355, odo_loss: 8.492130, ine_loss: 0.669554, ref_loss: 0.223671\n",
      "\ttrain_loss: 9.569551, odo_loss: 8.639712, ine_loss: 0.680482, ref_loss: 0.249356\n",
      "\tval_loss: 9.359286, odo_loss: 8.462624, ine_loss: 0.652724, ref_loss: 0.243938\n",
      "\t*** Personal Best ***\n",
      "Epoch 5/2000\n",
      "\t[#    0] train_loss: 10.132417, odo_loss: 9.092463, ine_loss: 0.745166, ref_loss: 0.294788\n",
      "\t[#  180] train_loss: 6.082519, odo_loss: 5.288026, ine_loss: 0.554423, ref_loss: 0.240070\n",
      "\t[#  360] train_loss: 8.319532, odo_loss: 7.504124, ine_loss: 0.598742, ref_loss: 0.216667\n",
      "\t[#  540] train_loss: 10.191121, odo_loss: 9.203711, ine_loss: 0.746122, ref_loss: 0.241289\n",
      "\t[#  720] train_loss: 10.808357, odo_loss: 9.787296, ine_loss: 0.754900, ref_loss: 0.266161\n",
      "\t[#  900] train_loss: 5.920269, odo_loss: 5.134354, ine_loss: 0.541560, ref_loss: 0.244355\n",
      "\ttrain_loss: 9.223298, odo_loss: 8.320879, ine_loss: 0.655433, ref_loss: 0.246985\n",
      "\tval_loss: 9.089402, odo_loss: 8.185535, ine_loss: 0.659492, ref_loss: 0.244376\n",
      "\t*** Personal Best ***\n",
      "Epoch 6/2000\n",
      "\t[#    0] train_loss: 8.327546, odo_loss: 7.351549, ine_loss: 0.701188, ref_loss: 0.274810\n",
      "\t[#  180] train_loss: 9.733889, odo_loss: 8.823957, ine_loss: 0.712167, ref_loss: 0.197764\n",
      "\t[#  360] train_loss: 10.158897, odo_loss: 9.213580, ine_loss: 0.675733, ref_loss: 0.269584\n",
      "\t[#  540] train_loss: 8.715450, odo_loss: 7.824648, ine_loss: 0.658059, ref_loss: 0.232742\n",
      "\t[#  720] train_loss: 8.661216, odo_loss: 7.797935, ine_loss: 0.629790, ref_loss: 0.233490\n",
      "\t[#  900] train_loss: 8.700264, odo_loss: 7.739198, ine_loss: 0.697175, ref_loss: 0.263891\n",
      "\ttrain_loss: 8.967630, odo_loss: 8.041927, ine_loss: 0.680174, ref_loss: 0.245529\n",
      "\tval_loss: 9.206838, odo_loss: 8.249257, ine_loss: 0.712862, ref_loss: 0.244718\n",
      "Epoch 7/2000\n",
      "\t[#    0] train_loss: 13.357382, odo_loss: 12.432247, ine_loss: 0.663156, ref_loss: 0.261979\n",
      "\t[#  180] train_loss: 9.445082, odo_loss: 8.577137, ine_loss: 0.632920, ref_loss: 0.235026\n",
      "\t[#  360] train_loss: 9.020117, odo_loss: 8.195705, ine_loss: 0.587510, ref_loss: 0.236901\n",
      "\t[#  540] train_loss: 11.372373, odo_loss: 10.410378, ine_loss: 0.748190, ref_loss: 0.213805\n",
      "\t[#  720] train_loss: 8.105373, odo_loss: 7.250138, ine_loss: 0.606515, ref_loss: 0.248720\n",
      "\t[#  900] train_loss: 8.702615, odo_loss: 7.765017, ine_loss: 0.690839, ref_loss: 0.246759\n",
      "\ttrain_loss: 8.516491, odo_loss: 7.572662, ine_loss: 0.700448, ref_loss: 0.243380\n",
      "\tval_loss: 8.268491, odo_loss: 7.347103, ine_loss: 0.680754, ref_loss: 0.240634\n",
      "\t*** Personal Best ***\n",
      "Epoch 8/2000\n",
      "\t[#    0] train_loss: 8.739070, odo_loss: 7.852505, ine_loss: 0.663303, ref_loss: 0.223262\n",
      "\t[#  180] train_loss: 8.754222, odo_loss: 7.968280, ine_loss: 0.587696, ref_loss: 0.198246\n",
      "\t[#  360] train_loss: 8.153556, odo_loss: 7.343876, ine_loss: 0.616045, ref_loss: 0.193635\n",
      "\t[#  540] train_loss: 9.388226, odo_loss: 8.275331, ine_loss: 0.854816, ref_loss: 0.258079\n",
      "\t[#  720] train_loss: 6.471696, odo_loss: 5.578965, ine_loss: 0.683015, ref_loss: 0.209717\n",
      "\t[#  900] train_loss: 5.380644, odo_loss: 4.413701, ine_loss: 0.709904, ref_loss: 0.257040\n",
      "\ttrain_loss: 7.754729, odo_loss: 6.817992, ine_loss: 0.696547, ref_loss: 0.240190\n",
      "\tval_loss: 7.535313, odo_loss: 6.592647, ine_loss: 0.704307, ref_loss: 0.238359\n",
      "\t*** Personal Best ***\n",
      "Epoch 9/2000\n",
      "\t[#    0] train_loss: 8.352308, odo_loss: 7.481277, ine_loss: 0.693184, ref_loss: 0.177847\n",
      "\t[#  180] train_loss: 7.789990, odo_loss: 6.769415, ine_loss: 0.695525, ref_loss: 0.325050\n",
      "\t[#  360] train_loss: 6.929461, odo_loss: 5.873617, ine_loss: 0.774743, ref_loss: 0.281101\n",
      "\t[#  540] train_loss: 7.757362, odo_loss: 6.687256, ine_loss: 0.812284, ref_loss: 0.257823\n",
      "\t[#  720] train_loss: 10.198589, odo_loss: 9.385235, ine_loss: 0.596501, ref_loss: 0.216853\n",
      "\t[#  900] train_loss: 6.047962, odo_loss: 5.156493, ine_loss: 0.657688, ref_loss: 0.233781\n",
      "\ttrain_loss: 7.433611, odo_loss: 6.508623, ine_loss: 0.686537, ref_loss: 0.238451\n",
      "\tval_loss: 7.520280, odo_loss: 6.591977, ine_loss: 0.691363, ref_loss: 0.236941\n",
      "\t*** Personal Best ***\n",
      "Epoch 10/2000\n",
      "\t[#    0] train_loss: 5.749128, odo_loss: 4.956235, ine_loss: 0.556112, ref_loss: 0.236781\n",
      "\t[#  180] train_loss: 6.766576, odo_loss: 5.861307, ine_loss: 0.678319, ref_loss: 0.226949\n",
      "\t[#  360] train_loss: 7.273996, odo_loss: 6.354034, ine_loss: 0.731523, ref_loss: 0.188440\n",
      "\t[#  540] train_loss: 5.780386, odo_loss: 4.954399, ine_loss: 0.594192, ref_loss: 0.231796\n",
      "\t[#  720] train_loss: 7.193370, odo_loss: 6.274923, ine_loss: 0.714821, ref_loss: 0.203626\n",
      "\t[#  900] train_loss: 6.814597, odo_loss: 6.000398, ine_loss: 0.595867, ref_loss: 0.218331\n",
      "\ttrain_loss: 7.089424, odo_loss: 6.177204, ine_loss: 0.675018, ref_loss: 0.237201\n",
      "\tval_loss: 6.860111, odo_loss: 5.957102, ine_loss: 0.663491, ref_loss: 0.239518\n",
      "\t*** Personal Best ***\n",
      "Epoch 11/2000\n",
      "\t[#    0] train_loss: 6.528986, odo_loss: 5.745432, ine_loss: 0.558249, ref_loss: 0.225304\n",
      "\t[#  180] train_loss: 5.406953, odo_loss: 4.492779, ine_loss: 0.683688, ref_loss: 0.230486\n",
      "\t[#  360] train_loss: 6.198750, odo_loss: 5.290161, ine_loss: 0.633043, ref_loss: 0.275547\n",
      "\t[#  540] train_loss: 7.988686, odo_loss: 7.095327, ine_loss: 0.683892, ref_loss: 0.209466\n",
      "\t[#  720] train_loss: 8.957393, odo_loss: 8.088390, ine_loss: 0.687217, ref_loss: 0.181786\n",
      "\t[#  900] train_loss: 8.917792, odo_loss: 8.045157, ine_loss: 0.655059, ref_loss: 0.217575\n",
      "\ttrain_loss: 6.883053, odo_loss: 5.987701, ine_loss: 0.659868, ref_loss: 0.235484\n",
      "\tval_loss: 6.520933, odo_loss: 5.635100, ine_loss: 0.652141, ref_loss: 0.233691\n",
      "\t*** Personal Best ***\n",
      "Epoch 12/2000\n",
      "\t[#    0] train_loss: 7.768053, odo_loss: 6.738925, ine_loss: 0.779096, ref_loss: 0.250032\n",
      "\t[#  180] train_loss: 8.407838, odo_loss: 7.418554, ine_loss: 0.712912, ref_loss: 0.276372\n",
      "\t[#  360] train_loss: 5.666164, odo_loss: 4.736120, ine_loss: 0.640539, ref_loss: 0.289505\n",
      "\t[#  540] train_loss: 6.365957, odo_loss: 5.398656, ine_loss: 0.698666, ref_loss: 0.268634\n",
      "\t[#  720] train_loss: 6.223690, odo_loss: 5.259046, ine_loss: 0.701846, ref_loss: 0.262798\n",
      "\t[#  900] train_loss: 7.402888, odo_loss: 6.639515, ine_loss: 0.539625, ref_loss: 0.223748\n",
      "\ttrain_loss: 6.345842, odo_loss: 5.461525, ine_loss: 0.651341, ref_loss: 0.232976\n",
      "\tval_loss: 6.321737, odo_loss: 5.448174, ine_loss: 0.641431, ref_loss: 0.232133\n",
      "\t*** Personal Best ***\n",
      "Epoch 13/2000\n",
      "\t[#    0] train_loss: 5.078966, odo_loss: 4.389472, ine_loss: 0.493856, ref_loss: 0.195638\n",
      "\t[#  180] train_loss: 6.001128, odo_loss: 5.288752, ine_loss: 0.522458, ref_loss: 0.189919\n",
      "\t[#  360] train_loss: 7.754154, odo_loss: 6.966618, ine_loss: 0.593774, ref_loss: 0.193761\n",
      "\t[#  540] train_loss: 4.213093, odo_loss: 3.380085, ine_loss: 0.609713, ref_loss: 0.223295\n",
      "\t[#  720] train_loss: 5.624187, odo_loss: 4.816972, ine_loss: 0.599384, ref_loss: 0.207831\n",
      "\t[#  900] train_loss: 5.905665, odo_loss: 4.940082, ine_loss: 0.698424, ref_loss: 0.267160\n",
      "\ttrain_loss: 6.445821, odo_loss: 5.577230, ine_loss: 0.635463, ref_loss: 0.233128\n",
      "\tval_loss: 6.141915, odo_loss: 5.273783, ine_loss: 0.636067, ref_loss: 0.232064\n",
      "\t*** Personal Best ***\n",
      "Epoch 14/2000\n",
      "\t[#    0] train_loss: 7.510538, odo_loss: 6.473656, ine_loss: 0.746706, ref_loss: 0.290176\n",
      "\t[#  180] train_loss: 6.783783, odo_loss: 5.909711, ine_loss: 0.629415, ref_loss: 0.244657\n",
      "\t[#  360] train_loss: 8.212523, odo_loss: 7.443182, ine_loss: 0.562707, ref_loss: 0.206635\n",
      "\t[#  540] train_loss: 5.868741, odo_loss: 5.118063, ine_loss: 0.535448, ref_loss: 0.215230\n",
      "\t[#  720] train_loss: 6.491646, odo_loss: 5.665409, ine_loss: 0.608689, ref_loss: 0.217548\n",
      "\t[#  900] train_loss: 5.454621, odo_loss: 4.578601, ine_loss: 0.620661, ref_loss: 0.255359\n",
      "\ttrain_loss: 6.062572, odo_loss: 5.203012, ine_loss: 0.629214, ref_loss: 0.230345\n",
      "\tval_loss: 5.941136, odo_loss: 5.090067, ine_loss: 0.620808, ref_loss: 0.230261\n",
      "\t*** Personal Best ***\n",
      "Epoch 15/2000\n",
      "\t[#    0] train_loss: 5.202430, odo_loss: 4.458920, ine_loss: 0.552038, ref_loss: 0.191472\n",
      "\t[#  180] train_loss: 4.888828, odo_loss: 3.992490, ine_loss: 0.621975, ref_loss: 0.274363\n",
      "\t[#  360] train_loss: 6.092061, odo_loss: 5.349151, ine_loss: 0.552859, ref_loss: 0.190051\n",
      "\t[#  540] train_loss: 5.264983, odo_loss: 4.299977, ine_loss: 0.708650, ref_loss: 0.256356\n",
      "\t[#  720] train_loss: 6.529244, odo_loss: 5.686923, ine_loss: 0.664059, ref_loss: 0.178262\n",
      "\t[#  900] train_loss: 5.417450, odo_loss: 4.620286, ine_loss: 0.605330, ref_loss: 0.191834\n",
      "\ttrain_loss: 5.862109, odo_loss: 5.012264, ine_loss: 0.620384, ref_loss: 0.229461\n",
      "\tval_loss: 5.599638, odo_loss: 4.758656, ine_loss: 0.613527, ref_loss: 0.227456\n",
      "\t*** Personal Best ***\n",
      "Epoch 16/2000\n",
      "\t[#    0] train_loss: 5.622849, odo_loss: 4.735119, ine_loss: 0.677502, ref_loss: 0.210227\n",
      "\t[#  180] train_loss: 7.624539, odo_loss: 6.682749, ine_loss: 0.662579, ref_loss: 0.279210\n",
      "\t[#  360] train_loss: 7.151979, odo_loss: 6.354376, ine_loss: 0.591423, ref_loss: 0.206181\n",
      "\t[#  540] train_loss: 7.222722, odo_loss: 6.244027, ine_loss: 0.710966, ref_loss: 0.267728\n",
      "\t[#  720] train_loss: 3.927373, odo_loss: 3.116642, ine_loss: 0.588810, ref_loss: 0.221921\n",
      "\t[#  900] train_loss: 6.275033, odo_loss: 5.525008, ine_loss: 0.548091, ref_loss: 0.201934\n",
      "\ttrain_loss: 5.467758, odo_loss: 4.625860, ine_loss: 0.614436, ref_loss: 0.227463\n",
      "\tval_loss: 5.352495, odo_loss: 4.521091, ine_loss: 0.606688, ref_loss: 0.224716\n",
      "\t*** Personal Best ***\n",
      "Epoch 17/2000\n",
      "\t[#    0] train_loss: 4.093949, odo_loss: 3.244732, ine_loss: 0.660409, ref_loss: 0.188808\n",
      "\t[#  180] train_loss: 4.928240, odo_loss: 4.090579, ine_loss: 0.581769, ref_loss: 0.255893\n",
      "\t[#  360] train_loss: 5.748115, odo_loss: 4.833487, ine_loss: 0.639368, ref_loss: 0.275260\n",
      "\t[#  540] train_loss: 3.772478, odo_loss: 2.836352, ine_loss: 0.682035, ref_loss: 0.254091\n",
      "\t[#  720] train_loss: 5.776389, odo_loss: 4.927141, ine_loss: 0.604961, ref_loss: 0.244287\n",
      "\t[#  900] train_loss: 6.328370, odo_loss: 5.551951, ine_loss: 0.579751, ref_loss: 0.196669\n",
      "\ttrain_loss: 5.412135, odo_loss: 4.579851, ine_loss: 0.606078, ref_loss: 0.226206\n",
      "\tval_loss: 5.224358, odo_loss: 4.394805, ine_loss: 0.603509, ref_loss: 0.226044\n",
      "\t*** Personal Best ***\n",
      "Epoch 18/2000\n",
      "\t[#    0] train_loss: 5.328944, odo_loss: 4.352513, ine_loss: 0.657633, ref_loss: 0.318798\n",
      "\t[#  180] train_loss: 5.622846, odo_loss: 4.774190, ine_loss: 0.603201, ref_loss: 0.245455\n",
      "\t[#  360] train_loss: 4.972244, odo_loss: 4.142121, ine_loss: 0.607607, ref_loss: 0.222516\n",
      "\t[#  540] train_loss: 3.773103, odo_loss: 3.024423, ine_loss: 0.542754, ref_loss: 0.205926\n",
      "\t[#  720] train_loss: 3.595502, odo_loss: 2.932326, ine_loss: 0.472382, ref_loss: 0.190794\n",
      "\t[#  900] train_loss: 5.562701, odo_loss: 4.574731, ine_loss: 0.761423, ref_loss: 0.226547\n",
      "\ttrain_loss: 5.397657, odo_loss: 4.575181, ine_loss: 0.596899, ref_loss: 0.225577\n",
      "\tval_loss: 5.186832, odo_loss: 4.376298, ine_loss: 0.585551, ref_loss: 0.224983\n",
      "\t*** Personal Best ***\n",
      "Epoch 19/2000\n",
      "\t[#    0] train_loss: 5.357717, odo_loss: 4.526849, ine_loss: 0.619469, ref_loss: 0.211398\n",
      "\t[#  180] train_loss: 4.099600, odo_loss: 3.240033, ine_loss: 0.608279, ref_loss: 0.251288\n",
      "\t[#  360] train_loss: 5.308990, odo_loss: 4.615396, ine_loss: 0.491984, ref_loss: 0.201609\n",
      "\t[#  540] train_loss: 4.200995, odo_loss: 3.467058, ine_loss: 0.520783, ref_loss: 0.213155\n",
      "\t[#  720] train_loss: 5.485725, odo_loss: 4.690784, ine_loss: 0.587418, ref_loss: 0.207523\n",
      "\t[#  900] train_loss: 6.340807, odo_loss: 5.576050, ine_loss: 0.571220, ref_loss: 0.193538\n",
      "\ttrain_loss: 5.075841, odo_loss: 4.262426, ine_loss: 0.590150, ref_loss: 0.223265\n",
      "\tval_loss: 5.186694, odo_loss: 4.374941, ine_loss: 0.584699, ref_loss: 0.227055\n",
      "\t*** Personal Best ***\n",
      "Epoch 20/2000\n",
      "\t[#    0] train_loss: 5.277606, odo_loss: 4.569060, ine_loss: 0.509550, ref_loss: 0.198996\n",
      "\t[#  180] train_loss: 5.577865, odo_loss: 4.782474, ine_loss: 0.585455, ref_loss: 0.209936\n",
      "\t[#  360] train_loss: 4.744134, odo_loss: 3.884218, ine_loss: 0.613231, ref_loss: 0.246684\n",
      "\t[#  540] train_loss: 3.477873, odo_loss: 2.626263, ine_loss: 0.589347, ref_loss: 0.262263\n",
      "\t[#  720] train_loss: 3.569525, odo_loss: 2.830568, ine_loss: 0.570539, ref_loss: 0.168418\n",
      "\t[#  900] train_loss: 6.882624, odo_loss: 6.008239, ine_loss: 0.672740, ref_loss: 0.201644\n",
      "\ttrain_loss: 5.068145, odo_loss: 4.261808, ine_loss: 0.583438, ref_loss: 0.222899\n",
      "\tval_loss: 4.725792, odo_loss: 3.928842, ine_loss: 0.575862, ref_loss: 0.221087\n",
      "\t*** Personal Best ***\n",
      "Epoch 21/2000\n",
      "\t[#    0] train_loss: 5.681766, odo_loss: 4.895121, ine_loss: 0.582126, ref_loss: 0.204519\n",
      "\t[#  180] train_loss: 5.308265, odo_loss: 4.496950, ine_loss: 0.611297, ref_loss: 0.200018\n",
      "\t[#  360] train_loss: 5.803716, odo_loss: 5.003188, ine_loss: 0.586752, ref_loss: 0.213777\n",
      "\t[#  540] train_loss: 3.487541, odo_loss: 2.742137, ine_loss: 0.523465, ref_loss: 0.221939\n",
      "\t[#  720] train_loss: 5.782475, odo_loss: 4.953067, ine_loss: 0.620946, ref_loss: 0.208462\n",
      "\t[#  900] train_loss: 3.903640, odo_loss: 3.178227, ine_loss: 0.516864, ref_loss: 0.208548\n",
      "\ttrain_loss: 4.644635, odo_loss: 3.845095, ine_loss: 0.579007, ref_loss: 0.220533\n",
      "\tval_loss: 4.641598, odo_loss: 3.854369, ine_loss: 0.567987, ref_loss: 0.219242\n",
      "\t*** Personal Best ***\n",
      "Epoch 22/2000\n",
      "\t[#    0] train_loss: 3.703652, odo_loss: 2.937428, ine_loss: 0.541612, ref_loss: 0.224613\n",
      "\t[#  180] train_loss: 3.301471, odo_loss: 2.524171, ine_loss: 0.541282, ref_loss: 0.236018\n",
      "\t[#  360] train_loss: 5.224002, odo_loss: 4.446075, ine_loss: 0.593088, ref_loss: 0.184839\n",
      "\t[#  540] train_loss: 4.081224, odo_loss: 3.390148, ine_loss: 0.466944, ref_loss: 0.224132\n",
      "\t[#  720] train_loss: 4.429348, odo_loss: 3.642088, ine_loss: 0.552606, ref_loss: 0.234653\n",
      "\t[#  900] train_loss: 3.841785, odo_loss: 3.018236, ine_loss: 0.570125, ref_loss: 0.253424\n",
      "\ttrain_loss: 4.513497, odo_loss: 3.723474, ine_loss: 0.571565, ref_loss: 0.218458\n",
      "\tval_loss: 4.421867, odo_loss: 3.638615, ine_loss: 0.563735, ref_loss: 0.219517\n",
      "\t*** Personal Best ***\n",
      "Epoch 23/2000\n",
      "\t[#    0] train_loss: 4.742625, odo_loss: 3.880583, ine_loss: 0.639386, ref_loss: 0.222657\n",
      "\t[#  180] train_loss: 3.540656, odo_loss: 2.560063, ine_loss: 0.720012, ref_loss: 0.260581\n",
      "\t[#  360] train_loss: 5.697339, odo_loss: 4.981515, ine_loss: 0.533195, ref_loss: 0.182628\n",
      "\t[#  540] train_loss: 5.111115, odo_loss: 4.241602, ine_loss: 0.630147, ref_loss: 0.239366\n",
      "\t[#  720] train_loss: 4.412028, odo_loss: 3.599217, ine_loss: 0.608258, ref_loss: 0.204553\n",
      "\t[#  900] train_loss: 6.303791, odo_loss: 5.506882, ine_loss: 0.563055, ref_loss: 0.233854\n",
      "\ttrain_loss: 4.406800, odo_loss: 3.624594, ine_loss: 0.565452, ref_loss: 0.216754\n",
      "\tval_loss: 5.799534, odo_loss: 5.026097, ine_loss: 0.556536, ref_loss: 0.216900\n",
      "Epoch 24/2000\n",
      "\t[#    0] train_loss: 4.180007, odo_loss: 3.358115, ine_loss: 0.632700, ref_loss: 0.189192\n",
      "\t[#  180] train_loss: 5.136797, odo_loss: 4.303661, ine_loss: 0.597418, ref_loss: 0.235718\n",
      "\t[#  360] train_loss: 4.429636, odo_loss: 3.652343, ine_loss: 0.582012, ref_loss: 0.195281\n",
      "\t[#  540] train_loss: 3.348252, odo_loss: 2.537185, ine_loss: 0.596350, ref_loss: 0.214717\n",
      "\t[#  720] train_loss: 5.597198, odo_loss: 4.824460, ine_loss: 0.551745, ref_loss: 0.220992\n",
      "\t[#  900] train_loss: 3.356062, odo_loss: 2.568257, ine_loss: 0.562900, ref_loss: 0.224905\n",
      "\ttrain_loss: 4.892029, odo_loss: 4.113027, ine_loss: 0.559891, ref_loss: 0.219111\n",
      "\tval_loss: 4.387850, odo_loss: 3.617243, ine_loss: 0.552281, ref_loss: 0.218327\n",
      "\t*** Personal Best ***\n",
      "Epoch 25/2000\n",
      "\t[#    0] train_loss: 3.027941, odo_loss: 2.268952, ine_loss: 0.575808, ref_loss: 0.183181\n",
      "\t[#  180] train_loss: 3.983113, odo_loss: 3.245472, ine_loss: 0.532613, ref_loss: 0.205028\n",
      "\t[#  360] train_loss: 3.296282, odo_loss: 2.503251, ine_loss: 0.547079, ref_loss: 0.245952\n",
      "\t[#  540] train_loss: 3.752720, odo_loss: 2.838863, ine_loss: 0.689375, ref_loss: 0.224481\n",
      "\t[#  720] train_loss: 3.513300, odo_loss: 2.643559, ine_loss: 0.627296, ref_loss: 0.242445\n",
      "\t[#  900] train_loss: 2.683702, odo_loss: 2.004948, ine_loss: 0.466398, ref_loss: 0.212355\n",
      "\ttrain_loss: 4.306966, odo_loss: 3.534421, ine_loss: 0.557299, ref_loss: 0.215246\n",
      "\tval_loss: 4.112750, odo_loss: 3.356659, ine_loss: 0.542355, ref_loss: 0.213737\n",
      "\t*** Personal Best ***\n",
      "Epoch 26/2000\n",
      "\t[#    0] train_loss: 4.001339, odo_loss: 3.327677, ine_loss: 0.486669, ref_loss: 0.186995\n",
      "\t[#  180] train_loss: 4.042152, odo_loss: 3.316518, ine_loss: 0.513745, ref_loss: 0.211889\n",
      "\t[#  360] train_loss: 5.591993, odo_loss: 4.710123, ine_loss: 0.645132, ref_loss: 0.236738\n",
      "\t[#  540] train_loss: 4.291351, odo_loss: 3.574016, ine_loss: 0.549024, ref_loss: 0.168311\n",
      "\t[#  720] train_loss: 4.228462, odo_loss: 3.492874, ine_loss: 0.506970, ref_loss: 0.228617\n",
      "\t[#  900] train_loss: 5.262083, odo_loss: 4.451409, ine_loss: 0.618042, ref_loss: 0.192632\n",
      "\ttrain_loss: 4.089891, odo_loss: 3.327998, ine_loss: 0.548503, ref_loss: 0.213390\n",
      "\tval_loss: 4.093169, odo_loss: 3.337179, ine_loss: 0.543493, ref_loss: 0.212497\n",
      "\t*** Personal Best ***\n",
      "Epoch 27/2000\n",
      "\t[#    0] train_loss: 3.258864, odo_loss: 2.464611, ine_loss: 0.567229, ref_loss: 0.227024\n",
      "\t[#  180] train_loss: 4.248851, odo_loss: 3.535503, ine_loss: 0.500107, ref_loss: 0.213242\n",
      "\t[#  360] train_loss: 3.787509, odo_loss: 3.088624, ine_loss: 0.487410, ref_loss: 0.211475\n",
      "\t[#  540] train_loss: 4.884996, odo_loss: 4.101682, ine_loss: 0.566041, ref_loss: 0.217274\n",
      "\t[#  720] train_loss: 5.168022, odo_loss: 4.427512, ine_loss: 0.511887, ref_loss: 0.228623\n",
      "\t[#  900] train_loss: 5.613484, odo_loss: 4.905513, ine_loss: 0.490734, ref_loss: 0.217237\n",
      "\ttrain_loss: 4.328565, odo_loss: 3.569353, ine_loss: 0.545557, ref_loss: 0.213655\n",
      "\tval_loss: 4.815303, odo_loss: 4.053776, ine_loss: 0.540539, ref_loss: 0.220988\n",
      "Epoch 28/2000\n",
      "\t[#    0] train_loss: 3.560099, odo_loss: 2.686067, ine_loss: 0.629531, ref_loss: 0.244501\n",
      "\t[#  180] train_loss: 5.215311, odo_loss: 4.383394, ine_loss: 0.611790, ref_loss: 0.220127\n",
      "\t[#  360] train_loss: 3.954989, odo_loss: 3.209126, ine_loss: 0.538501, ref_loss: 0.207362\n",
      "\t[#  540] train_loss: 4.328205, odo_loss: 3.672982, ine_loss: 0.484920, ref_loss: 0.170304\n",
      "\t[#  720] train_loss: 3.055015, odo_loss: 2.388099, ine_loss: 0.499684, ref_loss: 0.167232\n",
      "\t[#  900] train_loss: 4.059193, odo_loss: 3.246722, ine_loss: 0.594207, ref_loss: 0.218265\n",
      "\ttrain_loss: 4.191395, odo_loss: 3.436658, ine_loss: 0.541942, ref_loss: 0.212795\n",
      "\tval_loss: 3.988597, odo_loss: 3.238395, ine_loss: 0.535263, ref_loss: 0.214939\n",
      "\t*** Personal Best ***\n",
      "Epoch 29/2000\n",
      "\t[#    0] train_loss: 2.913362, odo_loss: 2.350470, ine_loss: 0.382642, ref_loss: 0.180251\n",
      "\t[#  180] train_loss: 4.360992, odo_loss: 3.628974, ine_loss: 0.505920, ref_loss: 0.226098\n",
      "\t[#  360] train_loss: 5.382057, odo_loss: 4.629361, ine_loss: 0.575069, ref_loss: 0.177626\n",
      "\t[#  540] train_loss: 3.622263, odo_loss: 2.752689, ine_loss: 0.624281, ref_loss: 0.245293\n",
      "\t[#  720] train_loss: 3.990699, odo_loss: 3.314109, ine_loss: 0.497384, ref_loss: 0.179206\n",
      "\t[#  900] train_loss: 4.250663, odo_loss: 3.457667, ine_loss: 0.609177, ref_loss: 0.183819\n",
      "\ttrain_loss: 3.993078, odo_loss: 3.244195, ine_loss: 0.537942, ref_loss: 0.210941\n",
      "\tval_loss: 3.873114, odo_loss: 3.122845, ine_loss: 0.537548, ref_loss: 0.212722\n",
      "\t*** Personal Best ***\n",
      "Epoch 30/2000\n",
      "\t[#    0] train_loss: 3.024762, odo_loss: 2.354479, ine_loss: 0.477784, ref_loss: 0.192499\n",
      "\t[#  180] train_loss: 3.210803, odo_loss: 2.500094, ine_loss: 0.494111, ref_loss: 0.216598\n",
      "\t[#  360] train_loss: 4.072649, odo_loss: 3.359577, ine_loss: 0.511969, ref_loss: 0.201103\n",
      "\t[#  540] train_loss: 3.349848, odo_loss: 2.692641, ine_loss: 0.450979, ref_loss: 0.206228\n",
      "\t[#  720] train_loss: 3.317027, odo_loss: 2.574711, ine_loss: 0.565066, ref_loss: 0.177250\n",
      "\t[#  900] train_loss: 5.169974, odo_loss: 4.444390, ine_loss: 0.528165, ref_loss: 0.197419\n",
      "\ttrain_loss: 3.847023, odo_loss: 3.101693, ine_loss: 0.535892, ref_loss: 0.209438\n",
      "\tval_loss: 3.891664, odo_loss: 3.152635, ine_loss: 0.529449, ref_loss: 0.209580\n",
      "Epoch 31/2000\n",
      "\t[#    0] train_loss: 2.640538, odo_loss: 1.919106, ine_loss: 0.524660, ref_loss: 0.196772\n",
      "\t[#  180] train_loss: 3.220237, odo_loss: 2.541997, ine_loss: 0.445685, ref_loss: 0.232554\n",
      "\t[#  360] train_loss: 4.647674, odo_loss: 3.895762, ine_loss: 0.519686, ref_loss: 0.232226\n",
      "\t[#  540] train_loss: 3.087624, odo_loss: 2.432500, ine_loss: 0.451889, ref_loss: 0.203236\n",
      "\t[#  720] train_loss: 4.102224, odo_loss: 3.393641, ine_loss: 0.507604, ref_loss: 0.200978\n",
      "\t[#  900] train_loss: 4.721567, odo_loss: 4.008969, ine_loss: 0.512665, ref_loss: 0.199933\n",
      "\ttrain_loss: 4.137896, odo_loss: 3.394805, ine_loss: 0.533450, ref_loss: 0.209641\n",
      "\tval_loss: 4.822124, odo_loss: 4.067201, ine_loss: 0.536562, ref_loss: 0.218361\n",
      "Epoch 32/2000\n",
      "\t[#    0] train_loss: 4.497593, odo_loss: 3.667881, ine_loss: 0.557833, ref_loss: 0.271878\n",
      "\t[#  180] train_loss: 3.590136, odo_loss: 2.960095, ine_loss: 0.438293, ref_loss: 0.191747\n",
      "\t[#  360] train_loss: 3.474219, odo_loss: 2.757958, ine_loss: 0.505681, ref_loss: 0.210579\n",
      "\t[#  540] train_loss: 5.017135, odo_loss: 4.275510, ine_loss: 0.526677, ref_loss: 0.214948\n",
      "\t[#  720] train_loss: 4.765074, odo_loss: 3.909810, ine_loss: 0.604757, ref_loss: 0.250508\n",
      "\t[#  900] train_loss: 3.326459, odo_loss: 2.687487, ine_loss: 0.470371, ref_loss: 0.168601\n",
      "\ttrain_loss: 3.868081, odo_loss: 3.126521, ine_loss: 0.531826, ref_loss: 0.209734\n",
      "\tval_loss: 3.714389, odo_loss: 2.970277, ine_loss: 0.532889, ref_loss: 0.211223\n",
      "\t*** Personal Best ***\n",
      "Epoch 33/2000\n",
      "\t[#    0] train_loss: 3.012197, odo_loss: 2.221610, ine_loss: 0.568354, ref_loss: 0.222232\n",
      "\t[#  180] train_loss: 2.811625, odo_loss: 2.115338, ine_loss: 0.484985, ref_loss: 0.211303\n",
      "\t[#  360] train_loss: 4.115958, odo_loss: 3.352566, ine_loss: 0.557527, ref_loss: 0.205865\n",
      "\t[#  540] train_loss: 3.308900, odo_loss: 2.607256, ine_loss: 0.505948, ref_loss: 0.195696\n",
      "\t[#  720] train_loss: 3.547136, odo_loss: 2.805261, ine_loss: 0.535129, ref_loss: 0.206746\n",
      "\t[#  900] train_loss: 3.338128, odo_loss: 2.562791, ine_loss: 0.574612, ref_loss: 0.200725\n",
      "\ttrain_loss: 3.642079, odo_loss: 2.904258, ine_loss: 0.530702, ref_loss: 0.207119\n",
      "\tval_loss: 3.615055, odo_loss: 2.880211, ine_loss: 0.526775, ref_loss: 0.208069\n",
      "\t*** Personal Best ***\n",
      "Epoch 34/2000\n",
      "\t[#    0] train_loss: 3.270043, odo_loss: 2.597911, ine_loss: 0.453494, ref_loss: 0.218638\n",
      "\t[#  180] train_loss: 2.524667, odo_loss: 1.903213, ine_loss: 0.401315, ref_loss: 0.220140\n",
      "\t[#  360] train_loss: 3.134987, odo_loss: 2.443372, ine_loss: 0.480053, ref_loss: 0.211563\n",
      "\t[#  540] train_loss: 4.240605, odo_loss: 3.391156, ine_loss: 0.569058, ref_loss: 0.280390\n",
      "\t[#  720] train_loss: 3.422766, odo_loss: 2.613705, ine_loss: 0.616800, ref_loss: 0.192261\n",
      "\t[#  900] train_loss: 4.971028, odo_loss: 4.231754, ine_loss: 0.546610, ref_loss: 0.192664\n",
      "\ttrain_loss: 3.551781, odo_loss: 2.818757, ine_loss: 0.527614, ref_loss: 0.205410\n",
      "\tval_loss: 3.517460, odo_loss: 2.783950, ine_loss: 0.525303, ref_loss: 0.208208\n",
      "\t*** Personal Best ***\n",
      "Epoch 35/2000\n",
      "\t[#    0] train_loss: 4.303907, odo_loss: 3.553552, ine_loss: 0.567076, ref_loss: 0.183280\n",
      "\t[#  180] train_loss: 3.740439, odo_loss: 2.998831, ine_loss: 0.535258, ref_loss: 0.206351\n",
      "\t[#  360] train_loss: 3.794209, odo_loss: 3.110666, ine_loss: 0.490840, ref_loss: 0.192703\n",
      "\t[#  540] train_loss: 3.057843, odo_loss: 2.243830, ine_loss: 0.598418, ref_loss: 0.215594\n",
      "\t[#  720] train_loss: 2.937911, odo_loss: 2.244131, ine_loss: 0.472668, ref_loss: 0.221111\n",
      "\t[#  900] train_loss: 2.934948, odo_loss: 2.177907, ine_loss: 0.571054, ref_loss: 0.185987\n",
      "\ttrain_loss: 3.475874, odo_loss: 2.744863, ine_loss: 0.526592, ref_loss: 0.204419\n",
      "\tval_loss: 3.650464, odo_loss: 2.928696, ine_loss: 0.515117, ref_loss: 0.206651\n",
      "Epoch 36/2000\n",
      "\t[#    0] train_loss: 4.055325, odo_loss: 3.383395, ine_loss: 0.471989, ref_loss: 0.199940\n",
      "\t[#  180] train_loss: 3.464186, odo_loss: 2.807420, ine_loss: 0.481990, ref_loss: 0.174776\n",
      "\t[#  360] train_loss: 3.642109, odo_loss: 2.941633, ine_loss: 0.479375, ref_loss: 0.221101\n",
      "\t[#  540] train_loss: 3.037920, odo_loss: 2.397579, ine_loss: 0.454261, ref_loss: 0.186080\n",
      "\t[#  720] train_loss: 4.961801, odo_loss: 4.094250, ine_loss: 0.662582, ref_loss: 0.204969\n",
      "\t[#  900] train_loss: 3.570643, odo_loss: 2.645150, ine_loss: 0.701956, ref_loss: 0.223538\n",
      "\ttrain_loss: 3.441822, odo_loss: 2.712881, ine_loss: 0.526180, ref_loss: 0.202761\n",
      "\tval_loss: 3.579357, odo_loss: 2.848241, ine_loss: 0.525709, ref_loss: 0.205407\n",
      "Epoch 37/2000\n",
      "\t[#    0] train_loss: 3.941247, odo_loss: 3.127148, ine_loss: 0.599845, ref_loss: 0.214254\n",
      "\t[#  180] train_loss: 9.132352, odo_loss: 8.411183, ine_loss: 0.526585, ref_loss: 0.194584\n",
      "\t[#  360] train_loss: 3.357962, odo_loss: 2.672321, ine_loss: 0.475009, ref_loss: 0.210631\n",
      "\t[#  540] train_loss: 4.008525, odo_loss: 3.278064, ine_loss: 0.512190, ref_loss: 0.218271\n",
      "\t[#  720] train_loss: 3.529905, odo_loss: 2.627802, ine_loss: 0.654931, ref_loss: 0.247171\n",
      "\t[#  900] train_loss: 3.065924, odo_loss: 2.299148, ine_loss: 0.564023, ref_loss: 0.202753\n",
      "\ttrain_loss: 4.140288, odo_loss: 3.409846, ine_loss: 0.524382, ref_loss: 0.206060\n",
      "\tval_loss: 3.492671, odo_loss: 2.764292, ine_loss: 0.521469, ref_loss: 0.206910\n",
      "\t*** Personal Best ***\n",
      "Epoch 38/2000\n",
      "\t[#    0] train_loss: 3.432434, odo_loss: 2.779099, ine_loss: 0.476783, ref_loss: 0.176553\n",
      "\t[#  180] train_loss: 3.094958, odo_loss: 2.399291, ine_loss: 0.529019, ref_loss: 0.166649\n",
      "\t[#  360] train_loss: 3.012967, odo_loss: 2.331747, ine_loss: 0.478779, ref_loss: 0.202441\n",
      "\t[#  540] train_loss: 3.631032, odo_loss: 2.931113, ine_loss: 0.503162, ref_loss: 0.196757\n",
      "\t[#  720] train_loss: 2.873242, odo_loss: 2.164786, ine_loss: 0.456543, ref_loss: 0.251913\n",
      "\t[#  900] train_loss: 3.852143, odo_loss: 3.026450, ine_loss: 0.599482, ref_loss: 0.226212\n",
      "\ttrain_loss: 3.438205, odo_loss: 2.712817, ine_loss: 0.523100, ref_loss: 0.202289\n",
      "\tval_loss: 3.576426, odo_loss: 2.847199, ine_loss: 0.522561, ref_loss: 0.206666\n",
      "Epoch 39/2000\n",
      "\t[#    0] train_loss: 3.307375, odo_loss: 2.667907, ine_loss: 0.435622, ref_loss: 0.203846\n",
      "\t[#  180] train_loss: 3.743680, odo_loss: 2.998472, ine_loss: 0.525963, ref_loss: 0.219245\n",
      "\t[#  360] train_loss: 3.690005, odo_loss: 3.032649, ine_loss: 0.464977, ref_loss: 0.192379\n",
      "\t[#  540] train_loss: 4.221393, odo_loss: 3.511669, ine_loss: 0.504002, ref_loss: 0.205723\n",
      "\t[#  720] train_loss: 3.668894, odo_loss: 2.971983, ine_loss: 0.502387, ref_loss: 0.194524\n",
      "\t[#  900] train_loss: 2.875364, odo_loss: 2.132603, ine_loss: 0.505132, ref_loss: 0.237629\n",
      "\ttrain_loss: 3.350477, odo_loss: 2.626674, ine_loss: 0.522472, ref_loss: 0.201331\n",
      "\tval_loss: 3.292021, odo_loss: 2.572139, ine_loss: 0.514556, ref_loss: 0.205326\n",
      "\t*** Personal Best ***\n",
      "Epoch 40/2000\n",
      "\t[#    0] train_loss: 2.870949, odo_loss: 2.130578, ine_loss: 0.471590, ref_loss: 0.268781\n",
      "\t[#  180] train_loss: 2.744738, odo_loss: 1.983933, ine_loss: 0.568829, ref_loss: 0.191976\n",
      "\t[#  360] train_loss: 2.963168, odo_loss: 2.304773, ine_loss: 0.492115, ref_loss: 0.166279\n",
      "\t[#  540] train_loss: 2.815033, odo_loss: 2.229791, ine_loss: 0.387177, ref_loss: 0.198066\n",
      "\t[#  720] train_loss: 2.802346, odo_loss: 2.042157, ine_loss: 0.552681, ref_loss: 0.207508\n",
      "\t[#  900] train_loss: 4.028965, odo_loss: 3.243703, ine_loss: 0.538861, ref_loss: 0.246402\n",
      "\ttrain_loss: 3.302464, odo_loss: 2.581607, ine_loss: 0.521069, ref_loss: 0.199789\n",
      "\tval_loss: 3.396366, odo_loss: 2.665662, ine_loss: 0.526101, ref_loss: 0.204603\n",
      "Epoch 41/2000\n",
      "\t[#    0] train_loss: 3.216629, odo_loss: 2.429493, ine_loss: 0.564260, ref_loss: 0.222875\n",
      "\t[#  180] train_loss: 3.508414, odo_loss: 2.939981, ine_loss: 0.388988, ref_loss: 0.179444\n",
      "\t[#  360] train_loss: 2.687557, odo_loss: 1.965123, ine_loss: 0.547851, ref_loss: 0.174584\n",
      "\t[#  540] train_loss: 3.201114, odo_loss: 2.453691, ine_loss: 0.504767, ref_loss: 0.242657\n",
      "\t[#  720] train_loss: 2.370136, odo_loss: 1.702517, ine_loss: 0.505292, ref_loss: 0.162327\n",
      "\t[#  900] train_loss: 13.339328, odo_loss: 12.553165, ine_loss: 0.608164, ref_loss: 0.177999\n",
      "\ttrain_loss: 3.495811, odo_loss: 2.774904, ine_loss: 0.521208, ref_loss: 0.199699\n",
      "\tval_loss: 6.329439, odo_loss: 5.591256, ine_loss: 0.530934, ref_loss: 0.207249\n",
      "Epoch 42/2000\n",
      "\t[#    0] train_loss: 3.378731, odo_loss: 2.782416, ine_loss: 0.452896, ref_loss: 0.143419\n",
      "\t[#  180] train_loss: 3.194306, odo_loss: 2.345282, ine_loss: 0.657380, ref_loss: 0.191644\n",
      "\t[#  360] train_loss: 3.339632, odo_loss: 2.523485, ine_loss: 0.613440, ref_loss: 0.202707\n",
      "\t[#  540] train_loss: 4.135360, odo_loss: 3.523427, ine_loss: 0.426983, ref_loss: 0.184949\n",
      "\t[#  720] train_loss: 3.380871, odo_loss: 2.650665, ine_loss: 0.490024, ref_loss: 0.240181\n",
      "\t[#  900] train_loss: 2.548134, odo_loss: 1.903015, ine_loss: 0.466612, ref_loss: 0.178508\n",
      "\ttrain_loss: 3.650969, odo_loss: 2.928265, ine_loss: 0.521530, ref_loss: 0.201174\n",
      "\tval_loss: 3.328691, odo_loss: 2.610439, ine_loss: 0.513897, ref_loss: 0.204354\n",
      "Epoch 43/2000\n",
      "\t[#    0] train_loss: 3.267796, odo_loss: 2.461334, ine_loss: 0.586788, ref_loss: 0.219674\n",
      "\t[#  180] train_loss: 2.855715, odo_loss: 2.180740, ine_loss: 0.468624, ref_loss: 0.206352\n",
      "\t[#  360] train_loss: 3.787489, odo_loss: 3.033686, ine_loss: 0.556222, ref_loss: 0.197581\n",
      "\t[#  540] train_loss: 3.351810, odo_loss: 2.758842, ine_loss: 0.382483, ref_loss: 0.210485\n",
      "\t[#  720] train_loss: 2.798464, odo_loss: 2.123915, ine_loss: 0.499539, ref_loss: 0.175009\n",
      "\t[#  900] train_loss: 3.162312, odo_loss: 2.458156, ine_loss: 0.485859, ref_loss: 0.218297\n",
      "\ttrain_loss: 3.254294, odo_loss: 2.535709, ine_loss: 0.520592, ref_loss: 0.197992\n",
      "\tval_loss: 3.171528, odo_loss: 2.455341, ine_loss: 0.515881, ref_loss: 0.200305\n",
      "\t*** Personal Best ***\n",
      "Epoch 44/2000\n",
      "\t[#    0] train_loss: 3.351712, odo_loss: 2.654177, ine_loss: 0.524144, ref_loss: 0.173391\n",
      "\t[#  180] train_loss: 2.909688, odo_loss: 2.213971, ine_loss: 0.527646, ref_loss: 0.168072\n",
      "\t[#  360] train_loss: 3.918774, odo_loss: 3.137924, ine_loss: 0.573873, ref_loss: 0.206977\n",
      "\t[#  540] train_loss: 3.145501, odo_loss: 2.382182, ine_loss: 0.518572, ref_loss: 0.244748\n",
      "\t[#  720] train_loss: 3.274326, odo_loss: 2.577854, ine_loss: 0.478336, ref_loss: 0.218136\n",
      "\t[#  900] train_loss: 4.056024, odo_loss: 3.355930, ine_loss: 0.498319, ref_loss: 0.201774\n",
      "\ttrain_loss: 3.155654, odo_loss: 2.439855, ine_loss: 0.518949, ref_loss: 0.196850\n",
      "\tval_loss: 3.078129, odo_loss: 2.363905, ine_loss: 0.513846, ref_loss: 0.200378\n",
      "\t*** Personal Best ***\n",
      "Epoch 45/2000\n",
      "\t[#    0] train_loss: 3.271372, odo_loss: 2.610203, ine_loss: 0.501943, ref_loss: 0.159227\n",
      "\t[#  180] train_loss: 2.553430, odo_loss: 1.838874, ine_loss: 0.507083, ref_loss: 0.207473\n",
      "\t[#  360] train_loss: 3.498786, odo_loss: 2.712919, ine_loss: 0.563281, ref_loss: 0.222585\n",
      "\t[#  540] train_loss: 3.338639, odo_loss: 2.601155, ine_loss: 0.534272, ref_loss: 0.203212\n",
      "\t[#  720] train_loss: 3.280883, odo_loss: 2.599463, ine_loss: 0.495556, ref_loss: 0.185864\n",
      "\t[#  900] train_loss: 2.735458, odo_loss: 1.923252, ine_loss: 0.589158, ref_loss: 0.223048\n",
      "\ttrain_loss: 3.142783, odo_loss: 2.429183, ine_loss: 0.518031, ref_loss: 0.195568\n",
      "\tval_loss: 3.134135, odo_loss: 2.414998, ine_loss: 0.516649, ref_loss: 0.202488\n",
      "Epoch 46/2000\n",
      "\t[#    0] train_loss: 3.095213, odo_loss: 2.483559, ine_loss: 0.441838, ref_loss: 0.169817\n",
      "\t[#  180] train_loss: 3.281976, odo_loss: 2.625135, ine_loss: 0.478463, ref_loss: 0.178377\n",
      "\t[#  360] train_loss: 3.317296, odo_loss: 2.613473, ine_loss: 0.533122, ref_loss: 0.170700\n",
      "\t[#  540] train_loss: 3.099091, odo_loss: 2.343073, ine_loss: 0.583866, ref_loss: 0.172151\n",
      "\t[#  720] train_loss: 3.345946, odo_loss: 2.504752, ine_loss: 0.631623, ref_loss: 0.209571\n",
      "\t[#  900] train_loss: 3.500109, odo_loss: 2.917255, ine_loss: 0.409792, ref_loss: 0.173062\n",
      "\ttrain_loss: 3.104088, odo_loss: 2.391223, ine_loss: 0.517937, ref_loss: 0.194928\n",
      "\tval_loss: 3.077217, odo_loss: 2.366417, ine_loss: 0.512027, ref_loss: 0.198773\n",
      "Epoch 47/2000\n",
      "\t[#    0] train_loss: 3.552222, odo_loss: 2.710017, ine_loss: 0.644263, ref_loss: 0.197942\n",
      "\t[#  180] train_loss: 2.788010, odo_loss: 2.122214, ine_loss: 0.457422, ref_loss: 0.208373\n",
      "\t[#  360] train_loss: 3.108178, odo_loss: 2.463698, ine_loss: 0.449933, ref_loss: 0.194546\n",
      "\t[#  540] train_loss: 2.966839, odo_loss: 2.182848, ine_loss: 0.596627, ref_loss: 0.187364\n",
      "\t[#  720] train_loss: 3.110080, odo_loss: 2.511449, ine_loss: 0.410269, ref_loss: 0.188361\n",
      "\t[#  900] train_loss: 3.809982, odo_loss: 2.967620, ine_loss: 0.615798, ref_loss: 0.226563\n",
      "\ttrain_loss: 3.591884, odo_loss: 2.877620, ine_loss: 0.517798, ref_loss: 0.196465\n",
      "\tval_loss: 3.771224, odo_loss: 3.055377, ine_loss: 0.513428, ref_loss: 0.202418\n",
      "Epoch 48/2000\n",
      "\t[#    0] train_loss: 2.826985, odo_loss: 2.100076, ine_loss: 0.523520, ref_loss: 0.203389\n",
      "\t[#  180] train_loss: 6.532152, odo_loss: 5.836670, ine_loss: 0.510324, ref_loss: 0.185157\n",
      "\t[#  360] train_loss: 3.007850, odo_loss: 2.130813, ine_loss: 0.625768, ref_loss: 0.251269\n",
      "\t[#  540] train_loss: 2.993109, odo_loss: 2.263715, ine_loss: 0.550172, ref_loss: 0.179222\n",
      "\t[#  720] train_loss: 2.918382, odo_loss: 2.162508, ine_loss: 0.535846, ref_loss: 0.220028\n",
      "\t[#  900] train_loss: 2.976708, odo_loss: 2.271355, ine_loss: 0.465020, ref_loss: 0.240333\n",
      "\ttrain_loss: 3.330359, odo_loss: 2.616801, ine_loss: 0.517673, ref_loss: 0.195886\n",
      "\tval_loss: 3.216996, odo_loss: 2.497401, ine_loss: 0.517481, ref_loss: 0.202114\n",
      "Epoch 49/2000\n",
      "\t[#    0] train_loss: 3.323666, odo_loss: 2.512326, ine_loss: 0.613626, ref_loss: 0.197714\n",
      "\t[#  180] train_loss: 3.018336, odo_loss: 2.260723, ine_loss: 0.539700, ref_loss: 0.217913\n",
      "\t[#  360] train_loss: 2.880645, odo_loss: 2.213904, ine_loss: 0.471384, ref_loss: 0.195357\n",
      "\t[#  540] train_loss: 2.774921, odo_loss: 2.015738, ine_loss: 0.543595, ref_loss: 0.215588\n",
      "\t[#  720] train_loss: 3.659340, odo_loss: 3.045183, ine_loss: 0.442785, ref_loss: 0.171372\n",
      "\t[#  900] train_loss: 3.330294, odo_loss: 2.668930, ine_loss: 0.489563, ref_loss: 0.171801\n",
      "\ttrain_loss: 3.231234, odo_loss: 2.518700, ine_loss: 0.517088, ref_loss: 0.195446\n",
      "\tval_loss: 3.364332, odo_loss: 2.658411, ine_loss: 0.507057, ref_loss: 0.198864\n",
      "Epoch 50/2000\n",
      "\t[#    0] train_loss: 3.187746, odo_loss: 2.575358, ine_loss: 0.448681, ref_loss: 0.163708\n",
      "\t[#  180] train_loss: 2.789886, odo_loss: 2.138052, ine_loss: 0.446427, ref_loss: 0.205408\n",
      "\t[#  360] train_loss: 2.736581, odo_loss: 2.068784, ine_loss: 0.471516, ref_loss: 0.196280\n",
      "\t[#  540] train_loss: 4.090934, odo_loss: 3.221740, ine_loss: 0.627208, ref_loss: 0.241986\n",
      "\t[#  720] train_loss: 2.899342, odo_loss: 2.288491, ine_loss: 0.448250, ref_loss: 0.162601\n",
      "\t[#  900] train_loss: 3.440676, odo_loss: 2.770815, ine_loss: 0.499570, ref_loss: 0.170291\n",
      "\ttrain_loss: 3.143111, odo_loss: 2.434341, ine_loss: 0.515013, ref_loss: 0.193757\n",
      "\tval_loss: 3.122443, odo_loss: 2.407049, ine_loss: 0.514930, ref_loss: 0.200464\n",
      "Epoch 51/2000\n",
      "\t[#    0] train_loss: 2.691352, odo_loss: 2.011205, ine_loss: 0.489002, ref_loss: 0.191145\n",
      "\t[#  180] train_loss: 2.628491, odo_loss: 1.926269, ine_loss: 0.492698, ref_loss: 0.209524\n",
      "\t[#  360] train_loss: 3.056725, odo_loss: 2.467748, ine_loss: 0.436134, ref_loss: 0.152843\n",
      "\t[#  540] train_loss: 2.681245, odo_loss: 1.985076, ine_loss: 0.520153, ref_loss: 0.176015\n",
      "\t[#  720] train_loss: 3.251175, odo_loss: 2.412044, ine_loss: 0.581756, ref_loss: 0.257375\n",
      "\t[#  900] train_loss: 2.798709, odo_loss: 2.194976, ine_loss: 0.411486, ref_loss: 0.192247\n",
      "\ttrain_loss: 3.039167, odo_loss: 2.331912, ine_loss: 0.514945, ref_loss: 0.192310\n",
      "\tval_loss: 3.029271, odo_loss: 2.317631, ine_loss: 0.512137, ref_loss: 0.199503\n",
      "\t*** Personal Best ***\n",
      "Epoch 52/2000\n",
      "\t[#    0] train_loss: 3.690423, odo_loss: 3.060916, ine_loss: 0.439957, ref_loss: 0.189550\n",
      "\t[#  180] train_loss: 3.289983, odo_loss: 2.649491, ine_loss: 0.442942, ref_loss: 0.197550\n",
      "\t[#  360] train_loss: 2.989833, odo_loss: 2.340278, ine_loss: 0.487282, ref_loss: 0.162272\n",
      "\t[#  540] train_loss: 3.104294, odo_loss: 2.431010, ine_loss: 0.494119, ref_loss: 0.179164\n",
      "\t[#  720] train_loss: 2.774707, odo_loss: 2.142820, ine_loss: 0.443434, ref_loss: 0.188453\n",
      "\t[#  900] train_loss: 3.405944, odo_loss: 2.747417, ine_loss: 0.467762, ref_loss: 0.190765\n",
      "\ttrain_loss: 3.025894, odo_loss: 2.320239, ine_loss: 0.514258, ref_loss: 0.191397\n",
      "\tval_loss: 3.132840, odo_loss: 2.424980, ine_loss: 0.510359, ref_loss: 0.197501\n",
      "Epoch 53/2000\n",
      "\t[#    0] train_loss: 2.922943, odo_loss: 2.209346, ine_loss: 0.523353, ref_loss: 0.190245\n",
      "\t[#  180] train_loss: 3.700325, odo_loss: 2.947126, ine_loss: 0.539664, ref_loss: 0.213535\n",
      "\t[#  360] train_loss: 3.702133, odo_loss: 3.029781, ine_loss: 0.509237, ref_loss: 0.163115\n",
      "\t[#  540] train_loss: 3.496531, odo_loss: 2.764861, ine_loss: 0.519083, ref_loss: 0.212587\n",
      "\t[#  720] train_loss: 3.374793, odo_loss: 2.751134, ine_loss: 0.432506, ref_loss: 0.191153\n",
      "\t[#  900] train_loss: 2.982399, odo_loss: 2.384300, ine_loss: 0.409513, ref_loss: 0.188586\n",
      "\ttrain_loss: 3.392974, odo_loss: 2.687272, ine_loss: 0.513234, ref_loss: 0.192468\n",
      "\tval_loss: 3.160102, odo_loss: 2.445251, ine_loss: 0.515458, ref_loss: 0.199392\n",
      "Epoch 54/2000\n",
      "\t[#    0] train_loss: 3.498185, odo_loss: 2.659985, ine_loss: 0.632919, ref_loss: 0.205280\n",
      "\t[#  180] train_loss: 3.303891, odo_loss: 2.664302, ine_loss: 0.469995, ref_loss: 0.169594\n",
      "\t[#  360] train_loss: 3.264088, odo_loss: 2.421829, ine_loss: 0.647695, ref_loss: 0.194563\n",
      "\t[#  540] train_loss: 2.739136, odo_loss: 2.120990, ine_loss: 0.441500, ref_loss: 0.176646\n",
      "\t[#  720] train_loss: 3.241498, odo_loss: 2.466227, ine_loss: 0.590549, ref_loss: 0.184722\n",
      "\t[#  900] train_loss: 3.479718, odo_loss: 2.653375, ine_loss: 0.648789, ref_loss: 0.177554\n",
      "\ttrain_loss: 3.203552, odo_loss: 2.499070, ine_loss: 0.513475, ref_loss: 0.191008\n",
      "\tval_loss: 3.249050, odo_loss: 2.541486, ine_loss: 0.506979, ref_loss: 0.200585\n",
      "Epoch 55/2000\n",
      "\t[#    0] train_loss: 2.498459, odo_loss: 1.911953, ine_loss: 0.418775, ref_loss: 0.167730\n",
      "\t[#  180] train_loss: 3.658708, odo_loss: 2.975487, ine_loss: 0.501486, ref_loss: 0.181736\n",
      "\t[#  360] train_loss: 2.851559, odo_loss: 2.247330, ine_loss: 0.452163, ref_loss: 0.152066\n",
      "\t[#  540] train_loss: 3.593700, odo_loss: 2.809478, ine_loss: 0.566094, ref_loss: 0.218128\n",
      "\t[#  720] train_loss: 3.120394, odo_loss: 2.324212, ine_loss: 0.613800, ref_loss: 0.182382\n",
      "\t[#  900] train_loss: 2.603825, odo_loss: 1.943607, ine_loss: 0.450491, ref_loss: 0.209726\n",
      "\ttrain_loss: 3.241167, odo_loss: 2.536349, ine_loss: 0.513513, ref_loss: 0.191305\n",
      "\tval_loss: 3.131050, odo_loss: 2.427716, ine_loss: 0.506004, ref_loss: 0.197330\n",
      "Epoch 56/2000\n",
      "\t[#    0] train_loss: 3.228483, odo_loss: 2.536221, ine_loss: 0.508765, ref_loss: 0.183498\n",
      "\t[#  180] train_loss: 3.056567, odo_loss: 2.287052, ine_loss: 0.569009, ref_loss: 0.200506\n",
      "\t[#  360] train_loss: 2.758215, odo_loss: 2.147374, ine_loss: 0.433191, ref_loss: 0.177650\n",
      "\t[#  540] train_loss: 3.149214, odo_loss: 2.324667, ine_loss: 0.605508, ref_loss: 0.219039\n",
      "\t[#  720] train_loss: 2.887364, odo_loss: 2.178462, ine_loss: 0.535992, ref_loss: 0.172911\n",
      "\t[#  900] train_loss: 2.759112, odo_loss: 2.092416, ine_loss: 0.453644, ref_loss: 0.213052\n",
      "\ttrain_loss: 3.022913, odo_loss: 2.320345, ine_loss: 0.512291, ref_loss: 0.190277\n",
      "\tval_loss: 3.095014, odo_loss: 2.388233, ine_loss: 0.510235, ref_loss: 0.196547\n",
      "Epoch 57/2000\n",
      "\t[#    0] train_loss: 2.444541, odo_loss: 1.551862, ine_loss: 0.692236, ref_loss: 0.200443\n",
      "\t[#  180] train_loss: 2.954895, odo_loss: 2.291722, ine_loss: 0.493349, ref_loss: 0.169823\n",
      "\t[#  360] train_loss: 2.882149, odo_loss: 2.300819, ine_loss: 0.423310, ref_loss: 0.158020\n",
      "\t[#  540] train_loss: 2.799883, odo_loss: 2.041906, ine_loss: 0.542142, ref_loss: 0.215835\n",
      "\t[#  720] train_loss: 2.862336, odo_loss: 2.097719, ine_loss: 0.588910, ref_loss: 0.175706\n",
      "\t[#  900] train_loss: 2.758804, odo_loss: 2.117524, ine_loss: 0.446831, ref_loss: 0.194449\n",
      "\ttrain_loss: 2.953959, odo_loss: 2.253481, ine_loss: 0.511940, ref_loss: 0.188537\n",
      "\tval_loss: 2.939476, odo_loss: 2.233215, ine_loss: 0.509800, ref_loss: 0.196462\n",
      "\t*** Personal Best ***\n",
      "Epoch 58/2000\n",
      "\t[#    0] train_loss: 2.583130, odo_loss: 1.957569, ine_loss: 0.422031, ref_loss: 0.203531\n",
      "\t[#  180] train_loss: 3.276538, odo_loss: 2.570121, ine_loss: 0.517159, ref_loss: 0.189257\n",
      "\t[#  360] train_loss: 2.716082, odo_loss: 2.013438, ine_loss: 0.512609, ref_loss: 0.190035\n",
      "\t[#  540] train_loss: 2.648369, odo_loss: 2.030504, ine_loss: 0.447354, ref_loss: 0.170511\n",
      "\t[#  720] train_loss: 3.008926, odo_loss: 2.395671, ine_loss: 0.443040, ref_loss: 0.170216\n",
      "\t[#  900] train_loss: 2.827802, odo_loss: 2.100869, ine_loss: 0.540554, ref_loss: 0.186379\n",
      "\ttrain_loss: 2.933387, odo_loss: 2.235131, ine_loss: 0.510796, ref_loss: 0.187460\n",
      "\tval_loss: 2.933074, odo_loss: 2.229123, ine_loss: 0.510453, ref_loss: 0.193498\n",
      "\t*** Personal Best ***\n",
      "Epoch 59/2000\n",
      "\t[#    0] train_loss: 3.051195, odo_loss: 2.311995, ine_loss: 0.543901, ref_loss: 0.195299\n",
      "\t[#  180] train_loss: 2.670305, odo_loss: 2.056694, ine_loss: 0.429019, ref_loss: 0.184592\n",
      "\t[#  360] train_loss: 2.879468, odo_loss: 2.079428, ine_loss: 0.569691, ref_loss: 0.230349\n",
      "\t[#  540] train_loss: 3.622528, odo_loss: 2.882813, ine_loss: 0.558634, ref_loss: 0.181080\n",
      "\t[#  720] train_loss: 3.219956, odo_loss: 2.482021, ine_loss: 0.561829, ref_loss: 0.176106\n",
      "\t[#  900] train_loss: 3.382734, odo_loss: 2.687332, ine_loss: 0.493117, ref_loss: 0.202284\n",
      "\ttrain_loss: 3.131058, odo_loss: 2.430336, ine_loss: 0.512498, ref_loss: 0.188224\n",
      "\tval_loss: 3.061868, odo_loss: 2.357613, ine_loss: 0.507313, ref_loss: 0.196942\n",
      "Epoch 60/2000\n",
      "\t[#    0] train_loss: 2.851957, odo_loss: 2.222332, ine_loss: 0.421846, ref_loss: 0.207779\n",
      "\t[#  180] train_loss: 3.093012, odo_loss: 2.374765, ine_loss: 0.501093, ref_loss: 0.217153\n",
      "\t[#  360] train_loss: 2.826635, odo_loss: 2.208942, ine_loss: 0.430844, ref_loss: 0.186850\n",
      "\t[#  540] train_loss: 3.116046, odo_loss: 2.294312, ine_loss: 0.635007, ref_loss: 0.186726\n",
      "\t[#  720] train_loss: 2.708884, odo_loss: 2.007642, ine_loss: 0.508154, ref_loss: 0.193087\n",
      "\t[#  900] train_loss: 2.764109, odo_loss: 2.154280, ine_loss: 0.413034, ref_loss: 0.196796\n",
      "\ttrain_loss: 3.060963, odo_loss: 2.363126, ine_loss: 0.510710, ref_loss: 0.187128\n",
      "\tval_loss: 2.948446, odo_loss: 2.248339, ine_loss: 0.506075, ref_loss: 0.194032\n",
      "Epoch 61/2000\n",
      "\t[#    0] train_loss: 2.987616, odo_loss: 2.255286, ine_loss: 0.557567, ref_loss: 0.174763\n",
      "\t[#  180] train_loss: 2.261240, odo_loss: 1.627638, ine_loss: 0.463642, ref_loss: 0.169960\n",
      "\t[#  360] train_loss: 2.694697, odo_loss: 2.107303, ine_loss: 0.408967, ref_loss: 0.178427\n",
      "\t[#  540] train_loss: 3.121521, odo_loss: 2.444473, ine_loss: 0.507028, ref_loss: 0.170021\n",
      "\t[#  720] train_loss: 3.398847, odo_loss: 2.809433, ine_loss: 0.403148, ref_loss: 0.186266\n",
      "\t[#  900] train_loss: 9.533702, odo_loss: 8.930719, ine_loss: 0.439277, ref_loss: 0.163705\n",
      "\ttrain_loss: 3.165512, odo_loss: 2.467836, ine_loss: 0.511083, ref_loss: 0.186594\n",
      "\tval_loss: 3.227548, odo_loss: 2.526088, ine_loss: 0.506215, ref_loss: 0.195244\n",
      "Epoch 62/2000\n",
      "\t[#    0] train_loss: 2.630577, odo_loss: 1.944641, ine_loss: 0.513087, ref_loss: 0.172849\n",
      "\t[#  180] train_loss: 2.743517, odo_loss: 2.150126, ine_loss: 0.386975, ref_loss: 0.206417\n",
      "\t[#  360] train_loss: 2.923637, odo_loss: 2.301341, ine_loss: 0.453087, ref_loss: 0.169209\n",
      "\t[#  540] train_loss: 3.005539, odo_loss: 2.292492, ine_loss: 0.543244, ref_loss: 0.169803\n",
      "\t[#  720] train_loss: 2.985284, odo_loss: 2.098012, ine_loss: 0.659834, ref_loss: 0.227439\n",
      "\t[#  900] train_loss: 3.539279, odo_loss: 2.816732, ine_loss: 0.515856, ref_loss: 0.206691\n",
      "\ttrain_loss: 3.103263, odo_loss: 2.405193, ine_loss: 0.511852, ref_loss: 0.186218\n",
      "\tval_loss: 3.004853, odo_loss: 2.306062, ine_loss: 0.505701, ref_loss: 0.193091\n",
      "Epoch 63/2000\n",
      "\t[#    0] train_loss: 2.901198, odo_loss: 2.287329, ine_loss: 0.453892, ref_loss: 0.159978\n",
      "\t[#  180] train_loss: 2.581746, odo_loss: 1.929808, ine_loss: 0.473712, ref_loss: 0.178226\n",
      "\t[#  360] train_loss: 2.768602, odo_loss: 2.147543, ine_loss: 0.445908, ref_loss: 0.175150\n",
      "\t[#  540] train_loss: 2.936857, odo_loss: 2.271357, ine_loss: 0.484528, ref_loss: 0.180972\n",
      "\t[#  720] train_loss: 2.704913, odo_loss: 2.048904, ine_loss: 0.474274, ref_loss: 0.181735\n",
      "\t[#  900] train_loss: 3.247635, odo_loss: 2.447067, ine_loss: 0.581547, ref_loss: 0.219022\n",
      "\ttrain_loss: 2.903171, odo_loss: 2.207390, ine_loss: 0.511521, ref_loss: 0.184259\n",
      "\tval_loss: 2.906326, odo_loss: 2.210011, ine_loss: 0.505757, ref_loss: 0.190558\n",
      "\t*** Personal Best ***\n",
      "Epoch 64/2000\n",
      "\t[#    0] train_loss: 2.953056, odo_loss: 2.312875, ine_loss: 0.473501, ref_loss: 0.166679\n",
      "\t[#  180] train_loss: 2.568679, odo_loss: 1.864216, ine_loss: 0.525567, ref_loss: 0.178895\n",
      "\t[#  360] train_loss: 2.848796, odo_loss: 2.199016, ine_loss: 0.455868, ref_loss: 0.193912\n",
      "\t[#  540] train_loss: 2.732780, odo_loss: 2.073940, ine_loss: 0.483600, ref_loss: 0.175240\n",
      "\t[#  720] train_loss: 3.030090, odo_loss: 2.317068, ine_loss: 0.523376, ref_loss: 0.189646\n",
      "\t[#  900] train_loss: 2.911656, odo_loss: 2.251042, ine_loss: 0.484324, ref_loss: 0.176291\n",
      "\ttrain_loss: 2.888590, odo_loss: 2.194114, ine_loss: 0.510207, ref_loss: 0.184269\n",
      "\tval_loss: 2.909654, odo_loss: 2.213648, ine_loss: 0.504742, ref_loss: 0.191264\n",
      "Epoch 65/2000\n",
      "\t[#    0] train_loss: 2.645086, odo_loss: 1.859270, ine_loss: 0.612255, ref_loss: 0.173561\n",
      "\t[#  180] train_loss: 2.567582, odo_loss: 1.957864, ine_loss: 0.434864, ref_loss: 0.174854\n",
      "\t[#  360] train_loss: 3.106711, odo_loss: 2.369970, ine_loss: 0.551085, ref_loss: 0.185656\n",
      "\t[#  540] train_loss: 2.937246, odo_loss: 2.184781, ine_loss: 0.546641, ref_loss: 0.205824\n",
      "\t[#  720] train_loss: 3.343925, odo_loss: 2.589626, ine_loss: 0.605313, ref_loss: 0.148986\n",
      "\t[#  900] train_loss: 3.267470, odo_loss: 2.422406, ine_loss: 0.665774, ref_loss: 0.179290\n",
      "\ttrain_loss: 2.858571, odo_loss: 2.165062, ine_loss: 0.510304, ref_loss: 0.183205\n",
      "\tval_loss: 2.867042, odo_loss: 2.167627, ine_loss: 0.508441, ref_loss: 0.190974\n",
      "\t*** Personal Best ***\n",
      "Epoch 66/2000\n",
      "\t[#    0] train_loss: 2.977659, odo_loss: 2.241543, ine_loss: 0.576998, ref_loss: 0.159118\n",
      "\t[#  180] train_loss: 2.653677, odo_loss: 2.052603, ine_loss: 0.406603, ref_loss: 0.194471\n",
      "\t[#  360] train_loss: 3.057615, odo_loss: 2.345478, ine_loss: 0.532124, ref_loss: 0.180013\n",
      "\t[#  540] train_loss: 2.514462, odo_loss: 1.880509, ine_loss: 0.451501, ref_loss: 0.182453\n",
      "\t[#  720] train_loss: 3.165618, odo_loss: 2.441861, ine_loss: 0.568159, ref_loss: 0.155597\n",
      "\t[#  900] train_loss: 2.665361, odo_loss: 2.067431, ine_loss: 0.435835, ref_loss: 0.162095\n",
      "\ttrain_loss: 2.850398, odo_loss: 2.158109, ine_loss: 0.510019, ref_loss: 0.182270\n",
      "\tval_loss: 2.831015, odo_loss: 2.135768, ine_loss: 0.506851, ref_loss: 0.188396\n",
      "\t*** Personal Best ***\n",
      "Epoch 67/2000\n",
      "\t[#    0] train_loss: 3.067614, odo_loss: 2.405543, ine_loss: 0.477531, ref_loss: 0.184540\n",
      "\t[#  180] train_loss: 2.971203, odo_loss: 2.345567, ine_loss: 0.486162, ref_loss: 0.139474\n",
      "\t[#  360] train_loss: 3.223887, odo_loss: 2.549315, ine_loss: 0.491399, ref_loss: 0.183173\n",
      "\t[#  540] train_loss: 3.631853, odo_loss: 2.889186, ine_loss: 0.525417, ref_loss: 0.217249\n",
      "\t[#  720] train_loss: 3.106326, odo_loss: 2.435815, ine_loss: 0.498980, ref_loss: 0.171531\n",
      "\t[#  900] train_loss: 3.047366, odo_loss: 2.403789, ine_loss: 0.487123, ref_loss: 0.156454\n",
      "\ttrain_loss: 3.298519, odo_loss: 2.603875, ine_loss: 0.511263, ref_loss: 0.183381\n",
      "\tval_loss: 3.228548, odo_loss: 2.524951, ine_loss: 0.510240, ref_loss: 0.193356\n",
      "Epoch 68/2000\n",
      "\t[#    0] train_loss: 3.041174, odo_loss: 2.398946, ine_loss: 0.469556, ref_loss: 0.172672\n",
      "\t[#  180] train_loss: 3.125524, odo_loss: 2.416295, ine_loss: 0.495902, ref_loss: 0.213327\n",
      "\t[#  360] train_loss: 3.052523, odo_loss: 2.303378, ine_loss: 0.588908, ref_loss: 0.160237\n",
      "\t[#  540] train_loss: 2.717937, odo_loss: 2.061768, ine_loss: 0.477350, ref_loss: 0.178819\n",
      "\t[#  720] train_loss: 2.524168, odo_loss: 1.784039, ine_loss: 0.547272, ref_loss: 0.192858\n",
      "\t[#  900] train_loss: 3.279788, odo_loss: 2.517966, ine_loss: 0.588690, ref_loss: 0.173132\n",
      "\ttrain_loss: 2.924243, odo_loss: 2.229687, ine_loss: 0.511827, ref_loss: 0.182729\n",
      "\tval_loss: 2.871784, odo_loss: 2.167384, ine_loss: 0.511603, ref_loss: 0.192798\n",
      "Epoch 69/2000\n",
      "\t[#    0] train_loss: 2.726946, odo_loss: 2.048666, ine_loss: 0.482492, ref_loss: 0.195788\n",
      "\t[#  180] train_loss: 2.932211, odo_loss: 2.216713, ine_loss: 0.510296, ref_loss: 0.205202\n",
      "\t[#  360] train_loss: 4.520172, odo_loss: 3.893653, ine_loss: 0.447823, ref_loss: 0.178696\n",
      "\t[#  540] train_loss: 3.133306, odo_loss: 2.409157, ine_loss: 0.528352, ref_loss: 0.195797\n",
      "\t[#  720] train_loss: 2.725106, odo_loss: 1.990331, ine_loss: 0.557176, ref_loss: 0.177598\n",
      "\t[#  900] train_loss: 3.043463, odo_loss: 2.308399, ine_loss: 0.532288, ref_loss: 0.202777\n",
      "\ttrain_loss: 2.891143, odo_loss: 2.199006, ine_loss: 0.511520, ref_loss: 0.180616\n",
      "\tval_loss: 2.902974, odo_loss: 2.197790, ine_loss: 0.516119, ref_loss: 0.189064\n",
      "Epoch 70/2000\n",
      "\t[#    0] train_loss: 2.791107, odo_loss: 2.125962, ine_loss: 0.503362, ref_loss: 0.161782\n",
      "\t[#  180] train_loss: 2.545179, odo_loss: 1.905185, ine_loss: 0.477101, ref_loss: 0.162893\n",
      "\t[#  360] train_loss: 2.862080, odo_loss: 2.084064, ine_loss: 0.548693, ref_loss: 0.229323\n",
      "\t[#  540] train_loss: 3.060521, odo_loss: 2.446859, ine_loss: 0.450052, ref_loss: 0.163611\n",
      "\t[#  720] train_loss: 2.866031, odo_loss: 2.104970, ine_loss: 0.598610, ref_loss: 0.162452\n",
      "\t[#  900] train_loss: 2.482469, odo_loss: 1.821251, ine_loss: 0.457068, ref_loss: 0.204150\n",
      "\ttrain_loss: 2.822378, odo_loss: 2.132215, ine_loss: 0.510510, ref_loss: 0.179653\n",
      "\tval_loss: 2.816474, odo_loss: 2.118416, ine_loss: 0.509949, ref_loss: 0.188109\n",
      "\t*** Personal Best ***\n",
      "Epoch 71/2000\n",
      "\t[#    0] train_loss: 2.874087, odo_loss: 2.160405, ine_loss: 0.505243, ref_loss: 0.208438\n",
      "\t[#  180] train_loss: 2.403371, odo_loss: 1.877067, ine_loss: 0.392144, ref_loss: 0.134159\n",
      "\t[#  360] train_loss: 2.729761, odo_loss: 2.154026, ine_loss: 0.411902, ref_loss: 0.163833\n",
      "\t[#  540] train_loss: 2.838948, odo_loss: 2.244554, ine_loss: 0.424251, ref_loss: 0.170144\n",
      "\t[#  720] train_loss: 2.998331, odo_loss: 2.414101, ine_loss: 0.415179, ref_loss: 0.169052\n",
      "\t[#  900] train_loss: 2.859246, odo_loss: 2.112936, ine_loss: 0.547080, ref_loss: 0.199230\n",
      "\ttrain_loss: 2.982749, odo_loss: 2.292330, ine_loss: 0.510760, ref_loss: 0.179658\n",
      "\tval_loss: 3.023695, odo_loss: 2.319058, ine_loss: 0.515336, ref_loss: 0.189300\n",
      "Epoch 72/2000\n",
      "\t[#    0] train_loss: 2.869963, odo_loss: 2.062591, ine_loss: 0.620266, ref_loss: 0.187106\n",
      "\t[#  180] train_loss: 3.444422, odo_loss: 2.636217, ine_loss: 0.623784, ref_loss: 0.184421\n",
      "\t[#  360] train_loss: 3.033473, odo_loss: 2.255397, ine_loss: 0.571124, ref_loss: 0.206953\n",
      "\t[#  540] train_loss: 2.601774, odo_loss: 1.937100, ine_loss: 0.485952, ref_loss: 0.178721\n",
      "\t[#  720] train_loss: 2.696781, odo_loss: 2.058572, ine_loss: 0.438776, ref_loss: 0.199433\n",
      "\t[#  900] train_loss: 3.209373, odo_loss: 2.483495, ine_loss: 0.556969, ref_loss: 0.168910\n",
      "\ttrain_loss: 2.940648, odo_loss: 2.247916, ine_loss: 0.513463, ref_loss: 0.179269\n",
      "\tval_loss: 2.860954, odo_loss: 2.161022, ine_loss: 0.508857, ref_loss: 0.191075\n",
      "Epoch 73/2000\n",
      "\t[#    0] train_loss: 2.915340, odo_loss: 2.190695, ine_loss: 0.540722, ref_loss: 0.183922\n",
      "\t[#  180] train_loss: 3.228472, odo_loss: 2.508893, ine_loss: 0.532895, ref_loss: 0.186683\n",
      "\t[#  360] train_loss: 2.993327, odo_loss: 2.300270, ine_loss: 0.522873, ref_loss: 0.170184\n",
      "\t[#  540] train_loss: 3.009722, odo_loss: 2.227949, ine_loss: 0.587816, ref_loss: 0.193957\n",
      "\t[#  720] train_loss: 3.282411, odo_loss: 2.295157, ine_loss: 0.763922, ref_loss: 0.223332\n",
      "\t[#  900] train_loss: 2.558180, odo_loss: 1.923276, ine_loss: 0.478643, ref_loss: 0.156261\n",
      "\ttrain_loss: 2.859050, odo_loss: 2.169151, ine_loss: 0.511157, ref_loss: 0.178742\n",
      "\tval_loss: 2.894731, odo_loss: 2.196586, ine_loss: 0.509725, ref_loss: 0.188419\n",
      "Epoch 74/2000\n",
      "\t[#    0] train_loss: 3.112511, odo_loss: 2.399702, ine_loss: 0.534206, ref_loss: 0.178604\n",
      "\t[#  180] train_loss: 2.497068, odo_loss: 1.833823, ine_loss: 0.471796, ref_loss: 0.191450\n",
      "\t[#  360] train_loss: 2.638063, odo_loss: 2.117804, ine_loss: 0.361368, ref_loss: 0.158891\n",
      "\t[#  540] train_loss: 2.858132, odo_loss: 2.099989, ine_loss: 0.576759, ref_loss: 0.181384\n",
      "\t[#  720] train_loss: 2.660665, odo_loss: 1.879833, ine_loss: 0.596917, ref_loss: 0.183915\n",
      "\t[#  900] train_loss: 2.766440, odo_loss: 2.097313, ine_loss: 0.503513, ref_loss: 0.165614\n",
      "\ttrain_loss: 2.831481, odo_loss: 2.143063, ine_loss: 0.511147, ref_loss: 0.177272\n",
      "\tval_loss: 2.904716, odo_loss: 2.207857, ine_loss: 0.507710, ref_loss: 0.189149\n",
      "Epoch 75/2000\n",
      "\t[#    0] train_loss: 2.602372, odo_loss: 1.841921, ine_loss: 0.590053, ref_loss: 0.170398\n",
      "\t[#  180] train_loss: 3.148462, odo_loss: 2.349347, ine_loss: 0.585136, ref_loss: 0.213978\n",
      "\t[#  360] train_loss: 3.070459, odo_loss: 2.339248, ine_loss: 0.517845, ref_loss: 0.213365\n",
      "\t[#  540] train_loss: 2.550610, odo_loss: 1.934920, ine_loss: 0.471569, ref_loss: 0.144121\n",
      "\t[#  720] train_loss: 2.548923, odo_loss: 1.869241, ine_loss: 0.513002, ref_loss: 0.166680\n",
      "\t[#  900] train_loss: 2.873789, odo_loss: 2.068833, ine_loss: 0.617515, ref_loss: 0.187441\n",
      "\ttrain_loss: 2.835076, odo_loss: 2.146418, ine_loss: 0.510961, ref_loss: 0.177697\n",
      "\tval_loss: 2.920043, odo_loss: 2.229256, ine_loss: 0.505764, ref_loss: 0.185023\n",
      "Epoch 76/2000\n",
      "\t[#    0] train_loss: 2.337054, odo_loss: 1.760514, ine_loss: 0.383119, ref_loss: 0.193421\n",
      "\t[#  180] train_loss: 2.724104, odo_loss: 1.977019, ine_loss: 0.562748, ref_loss: 0.184337\n",
      "\t[#  360] train_loss: 5.684035, odo_loss: 5.011550, ine_loss: 0.491987, ref_loss: 0.180498\n",
      "\t[#  540] train_loss: 3.140782, odo_loss: 2.402190, ine_loss: 0.576302, ref_loss: 0.162290\n",
      "\t[#  720] train_loss: 2.970848, odo_loss: 2.316773, ine_loss: 0.447263, ref_loss: 0.206813\n",
      "\t[#  900] train_loss: 3.075832, odo_loss: 2.381858, ine_loss: 0.511644, ref_loss: 0.182331\n",
      "\ttrain_loss: 2.982218, odo_loss: 2.293953, ine_loss: 0.510884, ref_loss: 0.177381\n",
      "\tval_loss: 2.814180, odo_loss: 2.122734, ine_loss: 0.503418, ref_loss: 0.188028\n",
      "Epoch 77/2000\n",
      "\t[#    0] train_loss: 2.598706, odo_loss: 1.916057, ine_loss: 0.493055, ref_loss: 0.189595\n",
      "\t[#  180] train_loss: 2.953379, odo_loss: 2.142514, ine_loss: 0.607591, ref_loss: 0.203275\n",
      "\t[#  360] train_loss: 2.792491, odo_loss: 2.150586, ine_loss: 0.487351, ref_loss: 0.154554\n",
      "\t[#  540] train_loss: 2.512677, odo_loss: 1.893004, ine_loss: 0.425473, ref_loss: 0.194200\n",
      "\t[#  720] train_loss: 2.860859, odo_loss: 2.182312, ine_loss: 0.519394, ref_loss: 0.159153\n",
      "\t[#  900] train_loss: 2.911115, odo_loss: 2.208117, ine_loss: 0.515084, ref_loss: 0.187915\n",
      "\ttrain_loss: 2.813704, odo_loss: 2.127760, ine_loss: 0.509972, ref_loss: 0.175972\n",
      "\tval_loss: 2.845981, odo_loss: 2.153557, ine_loss: 0.506698, ref_loss: 0.185726\n",
      "Epoch 78/2000\n",
      "\t[#    0] train_loss: 3.189550, odo_loss: 2.407000, ine_loss: 0.640291, ref_loss: 0.142259\n",
      "\t[#  180] train_loss: 2.456215, odo_loss: 1.720616, ine_loss: 0.563128, ref_loss: 0.172470\n",
      "\t[#  360] train_loss: 3.006804, odo_loss: 2.334897, ine_loss: 0.502882, ref_loss: 0.169025\n",
      "\t[#  540] train_loss: 2.627820, odo_loss: 1.984603, ine_loss: 0.491433, ref_loss: 0.151785\n",
      "\t[#  720] train_loss: 2.182180, odo_loss: 1.679179, ine_loss: 0.342377, ref_loss: 0.160624\n",
      "\t[#  900] train_loss: 2.586134, odo_loss: 1.928660, ine_loss: 0.439049, ref_loss: 0.218424\n",
      "\ttrain_loss: 2.785453, odo_loss: 2.100048, ine_loss: 0.510924, ref_loss: 0.174481\n",
      "\tval_loss: 2.782190, odo_loss: 2.083257, ine_loss: 0.511017, ref_loss: 0.187916\n",
      "\t*** Personal Best ***\n",
      "Epoch 79/2000\n",
      "\t[#    0] train_loss: 2.547927, odo_loss: 1.924629, ine_loss: 0.432770, ref_loss: 0.190528\n",
      "\t[#  180] train_loss: 2.914167, odo_loss: 2.319669, ine_loss: 0.441004, ref_loss: 0.153494\n",
      "\t[#  360] train_loss: 2.953150, odo_loss: 2.342762, ine_loss: 0.448701, ref_loss: 0.161687\n",
      "\t[#  540] train_loss: 2.893925, odo_loss: 2.011039, ine_loss: 0.674725, ref_loss: 0.208161\n",
      "\t[#  720] train_loss: 2.697214, odo_loss: 2.111630, ine_loss: 0.418436, ref_loss: 0.167149\n",
      "\t[#  900] train_loss: 2.849763, odo_loss: 2.188049, ine_loss: 0.485043, ref_loss: 0.176672\n",
      "\ttrain_loss: 2.806788, odo_loss: 2.122779, ine_loss: 0.509768, ref_loss: 0.174241\n",
      "\tval_loss: 3.027608, odo_loss: 2.334846, ine_loss: 0.509316, ref_loss: 0.183447\n",
      "Epoch 80/2000\n",
      "\t[#    0] train_loss: 2.728384, odo_loss: 2.103189, ine_loss: 0.459232, ref_loss: 0.165964\n",
      "\t[#  180] train_loss: 2.648267, odo_loss: 1.947205, ine_loss: 0.523451, ref_loss: 0.177610\n",
      "\t[#  360] train_loss: 2.685503, odo_loss: 2.090073, ine_loss: 0.430438, ref_loss: 0.164992\n",
      "\t[#  540] train_loss: 2.728980, odo_loss: 1.989398, ine_loss: 0.539756, ref_loss: 0.199826\n",
      "\t[#  720] train_loss: 2.880787, odo_loss: 2.098978, ine_loss: 0.600431, ref_loss: 0.181377\n",
      "\t[#  900] train_loss: 2.527492, odo_loss: 1.982559, ine_loss: 0.383980, ref_loss: 0.160953\n",
      "\ttrain_loss: 3.083649, odo_loss: 2.398761, ine_loss: 0.509528, ref_loss: 0.175360\n",
      "\tval_loss: 2.855434, odo_loss: 2.155804, ine_loss: 0.514747, ref_loss: 0.184882\n",
      "Epoch 81/2000\n",
      "\t[#    0] train_loss: 2.654042, odo_loss: 2.057118, ine_loss: 0.452966, ref_loss: 0.143957\n",
      "\t[#  180] train_loss: 2.369714, odo_loss: 1.817889, ine_loss: 0.382908, ref_loss: 0.168917\n",
      "\t[#  360] train_loss: 3.152349, odo_loss: 2.293624, ine_loss: 0.696175, ref_loss: 0.162551\n",
      "\t[#  540] train_loss: 3.007667, odo_loss: 2.200456, ine_loss: 0.602471, ref_loss: 0.204740\n",
      "\t[#  720] train_loss: 3.321603, odo_loss: 2.517875, ine_loss: 0.636316, ref_loss: 0.167412\n",
      "\t[#  900] train_loss: 2.604654, odo_loss: 1.977183, ine_loss: 0.494468, ref_loss: 0.133003\n",
      "\ttrain_loss: 2.912142, odo_loss: 2.227300, ine_loss: 0.510664, ref_loss: 0.174178\n",
      "\tval_loss: 2.929899, odo_loss: 2.235325, ine_loss: 0.509172, ref_loss: 0.185402\n",
      "Epoch 82/2000\n",
      "\t[#    0] train_loss: 3.021263, odo_loss: 2.354750, ine_loss: 0.517637, ref_loss: 0.148876\n",
      "\t[#  180] train_loss: 2.385271, odo_loss: 1.729711, ine_loss: 0.469898, ref_loss: 0.185662\n",
      "\t[#  360] train_loss: 2.735468, odo_loss: 2.078869, ine_loss: 0.505426, ref_loss: 0.151173\n",
      "\t[#  540] train_loss: 2.790926, odo_loss: 2.109949, ine_loss: 0.528695, ref_loss: 0.152283\n",
      "\t[#  720] train_loss: 3.055534, odo_loss: 2.224595, ine_loss: 0.635553, ref_loss: 0.195386\n",
      "\t[#  900] train_loss: 2.676322, odo_loss: 2.070432, ine_loss: 0.437819, ref_loss: 0.168071\n",
      "\ttrain_loss: 2.852438, odo_loss: 2.167970, ine_loss: 0.510950, ref_loss: 0.173519\n",
      "\tval_loss: 2.829533, odo_loss: 2.139427, ine_loss: 0.505056, ref_loss: 0.185050\n",
      "Epoch 83/2000\n",
      "\t[#    0] train_loss: 2.943030, odo_loss: 2.305787, ine_loss: 0.462059, ref_loss: 0.175184\n",
      "\t[#  180] train_loss: 2.627196, odo_loss: 2.034721, ine_loss: 0.443899, ref_loss: 0.148576\n",
      "\t[#  360] train_loss: 2.779544, odo_loss: 2.085875, ine_loss: 0.498235, ref_loss: 0.195434\n",
      "\t[#  540] train_loss: 2.840442, odo_loss: 2.178455, ine_loss: 0.520043, ref_loss: 0.141945\n",
      "\t[#  720] train_loss: 3.794597, odo_loss: 3.074220, ine_loss: 0.510481, ref_loss: 0.209896\n",
      "\t[#  900] train_loss: 3.283491, odo_loss: 2.562696, ine_loss: 0.570034, ref_loss: 0.150761\n",
      "\ttrain_loss: 2.861759, odo_loss: 2.181300, ine_loss: 0.508211, ref_loss: 0.172247\n",
      "\tval_loss: 2.899434, odo_loss: 2.209555, ine_loss: 0.507409, ref_loss: 0.182470\n",
      "Epoch 84/2000\n",
      "\t[#    0] train_loss: 2.795216, odo_loss: 2.161769, ine_loss: 0.485580, ref_loss: 0.147868\n",
      "\t[#  180] train_loss: 2.577605, odo_loss: 1.976753, ine_loss: 0.443205, ref_loss: 0.157647\n",
      "\t[#  360] train_loss: 2.788372, odo_loss: 2.131698, ine_loss: 0.503003, ref_loss: 0.153671\n",
      "\t[#  540] train_loss: 2.548258, odo_loss: 1.962014, ine_loss: 0.409206, ref_loss: 0.177038\n",
      "\t[#  720] train_loss: 2.703616, odo_loss: 2.014866, ine_loss: 0.505571, ref_loss: 0.183180\n",
      "\t[#  900] train_loss: 2.677207, odo_loss: 2.007589, ine_loss: 0.457070, ref_loss: 0.212548\n",
      "\ttrain_loss: 2.810071, odo_loss: 2.128596, ine_loss: 0.509430, ref_loss: 0.172045\n",
      "\tval_loss: 2.794293, odo_loss: 2.105186, ine_loss: 0.505005, ref_loss: 0.184102\n",
      "Epoch 85/2000\n",
      "\t[#    0] train_loss: 2.726298, odo_loss: 2.070031, ine_loss: 0.497152, ref_loss: 0.159115\n",
      "\t[#  180] train_loss: 2.527575, odo_loss: 1.738827, ine_loss: 0.590650, ref_loss: 0.198098\n",
      "\t[#  360] train_loss: 2.544317, odo_loss: 1.895674, ine_loss: 0.462287, ref_loss: 0.186356\n",
      "\t[#  540] train_loss: 3.032961, odo_loss: 2.491963, ine_loss: 0.398382, ref_loss: 0.142616\n",
      "\t[#  720] train_loss: 2.865966, odo_loss: 2.157233, ine_loss: 0.536527, ref_loss: 0.172206\n",
      "\t[#  900] train_loss: 2.893731, odo_loss: 2.293124, ine_loss: 0.439460, ref_loss: 0.161147\n",
      "\ttrain_loss: 3.037463, odo_loss: 2.356095, ine_loss: 0.508430, ref_loss: 0.172938\n",
      "\tval_loss: 3.185001, odo_loss: 2.493465, ine_loss: 0.509249, ref_loss: 0.182287\n",
      "Epoch 86/2000\n",
      "\t[#    0] train_loss: 2.710655, odo_loss: 2.084884, ine_loss: 0.463195, ref_loss: 0.162575\n",
      "\t[#  180] train_loss: 2.790832, odo_loss: 2.171232, ine_loss: 0.460860, ref_loss: 0.158740\n",
      "\t[#  360] train_loss: 2.958086, odo_loss: 2.323701, ine_loss: 0.465727, ref_loss: 0.168658\n",
      "\t[#  540] train_loss: 2.946738, odo_loss: 2.232321, ine_loss: 0.527412, ref_loss: 0.187004\n",
      "\t[#  720] train_loss: 2.634389, odo_loss: 1.978234, ine_loss: 0.499347, ref_loss: 0.156808\n",
      "\t[#  900] train_loss: 2.633126, odo_loss: 2.051963, ine_loss: 0.406785, ref_loss: 0.174379\n",
      "\ttrain_loss: 2.827481, odo_loss: 2.146421, ine_loss: 0.509045, ref_loss: 0.172015\n",
      "\tval_loss: 2.777764, odo_loss: 2.095294, ine_loss: 0.500500, ref_loss: 0.181969\n",
      "Epoch 87/2000\n",
      "\t[#    0] train_loss: 2.537143, odo_loss: 1.874764, ine_loss: 0.506433, ref_loss: 0.155946\n",
      "\t[#  180] train_loss: 2.905403, odo_loss: 2.121276, ine_loss: 0.569256, ref_loss: 0.214870\n",
      "\t[#  360] train_loss: 2.419915, odo_loss: 1.775273, ine_loss: 0.470445, ref_loss: 0.174197\n",
      "\t[#  540] train_loss: 2.691978, odo_loss: 1.892960, ine_loss: 0.576267, ref_loss: 0.222750\n",
      "\t[#  720] train_loss: 2.693858, odo_loss: 2.079595, ine_loss: 0.467561, ref_loss: 0.146702\n",
      "\t[#  900] train_loss: 2.998455, odo_loss: 2.205526, ine_loss: 0.609611, ref_loss: 0.183317\n",
      "\ttrain_loss: 2.752849, odo_loss: 2.073129, ine_loss: 0.509198, ref_loss: 0.170521\n",
      "\tval_loss: 2.784475, odo_loss: 2.098880, ine_loss: 0.504421, ref_loss: 0.181174\n",
      "Epoch 88/2000\n",
      "\t[#    0] train_loss: 2.746602, odo_loss: 2.092800, ine_loss: 0.501017, ref_loss: 0.152785\n",
      "\t[#  180] train_loss: 2.472981, odo_loss: 1.959594, ine_loss: 0.358502, ref_loss: 0.154885\n",
      "\t[#  360] train_loss: 2.672596, odo_loss: 1.946218, ine_loss: 0.544300, ref_loss: 0.182078\n",
      "\t[#  540] train_loss: 2.384363, odo_loss: 1.813277, ine_loss: 0.400464, ref_loss: 0.170622\n",
      "\t[#  720] train_loss: 2.770573, odo_loss: 2.004970, ine_loss: 0.601808, ref_loss: 0.163795\n",
      "\t[#  900] train_loss: 2.656450, odo_loss: 1.929858, ine_loss: 0.544251, ref_loss: 0.182341\n",
      "\ttrain_loss: 2.732169, odo_loss: 2.053411, ine_loss: 0.508865, ref_loss: 0.169893\n",
      "\tval_loss: 2.739963, odo_loss: 2.052261, ine_loss: 0.505486, ref_loss: 0.182216\n",
      "\t*** Personal Best ***\n",
      "Epoch 89/2000\n",
      "\t[#    0] train_loss: 2.620424, odo_loss: 1.911731, ine_loss: 0.543957, ref_loss: 0.164737\n",
      "\t[#  180] train_loss: 2.973841, odo_loss: 2.256754, ine_loss: 0.574561, ref_loss: 0.142525\n",
      "\t[#  360] train_loss: 3.070670, odo_loss: 2.378005, ine_loss: 0.530039, ref_loss: 0.162626\n",
      "\t[#  540] train_loss: 2.406189, odo_loss: 1.749394, ine_loss: 0.461577, ref_loss: 0.195218\n",
      "\t[#  720] train_loss: 2.685228, odo_loss: 2.088522, ine_loss: 0.426771, ref_loss: 0.169935\n",
      "\t[#  900] train_loss: 2.900915, odo_loss: 2.215389, ine_loss: 0.530459, ref_loss: 0.155067\n",
      "\ttrain_loss: 2.782712, odo_loss: 2.103317, ine_loss: 0.509639, ref_loss: 0.169756\n",
      "\tval_loss: 2.855785, odo_loss: 2.177126, ine_loss: 0.499044, ref_loss: 0.179615\n",
      "Epoch 90/2000\n",
      "\t[#    0] train_loss: 2.961302, odo_loss: 2.277728, ine_loss: 0.546125, ref_loss: 0.137449\n",
      "\t[#  180] train_loss: 2.571666, odo_loss: 1.991867, ine_loss: 0.427839, ref_loss: 0.151960\n",
      "\t[#  360] train_loss: 2.789126, odo_loss: 2.151136, ine_loss: 0.463221, ref_loss: 0.174769\n",
      "\t[#  540] train_loss: 2.850676, odo_loss: 2.130048, ine_loss: 0.565784, ref_loss: 0.154844\n",
      "\t[#  720] train_loss: 2.810556, odo_loss: 2.097466, ine_loss: 0.534402, ref_loss: 0.178688\n",
      "\t[#  900] train_loss: 2.362754, odo_loss: 1.800666, ine_loss: 0.420159, ref_loss: 0.141929\n",
      "\ttrain_loss: 2.764912, odo_loss: 2.084883, ine_loss: 0.510698, ref_loss: 0.169332\n",
      "\tval_loss: 2.775778, odo_loss: 2.087976, ine_loss: 0.508048, ref_loss: 0.179754\n",
      "Epoch 91/2000\n",
      "\t[#    0] train_loss: 2.632204, odo_loss: 1.977745, ine_loss: 0.483925, ref_loss: 0.170534\n",
      "\t[#  180] train_loss: 2.983842, odo_loss: 2.344997, ine_loss: 0.470005, ref_loss: 0.168840\n",
      "\t[#  360] train_loss: 2.524922, odo_loss: 1.921011, ine_loss: 0.435071, ref_loss: 0.168840\n",
      "\t[#  540] train_loss: 2.731385, odo_loss: 1.926837, ine_loss: 0.583861, ref_loss: 0.220686\n",
      "\t[#  720] train_loss: 2.904040, odo_loss: 1.984819, ine_loss: 0.747145, ref_loss: 0.172075\n",
      "\t[#  900] train_loss: 2.853917, odo_loss: 2.124065, ine_loss: 0.580830, ref_loss: 0.149022\n",
      "\ttrain_loss: 2.737211, odo_loss: 2.059106, ine_loss: 0.509595, ref_loss: 0.168510\n",
      "\tval_loss: 2.740857, odo_loss: 2.057659, ine_loss: 0.503249, ref_loss: 0.179948\n",
      "Epoch 92/2000\n",
      "\t[#    0] train_loss: 2.769947, odo_loss: 2.130369, ine_loss: 0.485956, ref_loss: 0.153622\n",
      "\t[#  180] train_loss: 2.806317, odo_loss: 2.122784, ine_loss: 0.502460, ref_loss: 0.181072\n",
      "\t[#  360] train_loss: 2.926931, odo_loss: 2.264234, ine_loss: 0.504396, ref_loss: 0.158301\n",
      "\t[#  540] train_loss: 2.350720, odo_loss: 1.777593, ine_loss: 0.428595, ref_loss: 0.144532\n",
      "\t[#  720] train_loss: 5.490548, odo_loss: 4.639345, ine_loss: 0.676737, ref_loss: 0.174465\n",
      "\t[#  900] train_loss: 2.823455, odo_loss: 2.146739, ine_loss: 0.519835, ref_loss: 0.156881\n",
      "\ttrain_loss: 2.941571, odo_loss: 2.261753, ine_loss: 0.510397, ref_loss: 0.169422\n",
      "\tval_loss: 2.987545, odo_loss: 2.293549, ine_loss: 0.512286, ref_loss: 0.181710\n",
      "Epoch 93/2000\n",
      "\t[#    0] train_loss: 2.914870, odo_loss: 2.235767, ine_loss: 0.502786, ref_loss: 0.176317\n",
      "\t[#  180] train_loss: 2.859138, odo_loss: 2.156477, ine_loss: 0.534181, ref_loss: 0.168480\n",
      "\t[#  360] train_loss: 2.669529, odo_loss: 2.116905, ine_loss: 0.389420, ref_loss: 0.163204\n",
      "\t[#  540] train_loss: 2.750957, odo_loss: 2.170095, ine_loss: 0.400651, ref_loss: 0.180211\n",
      "\t[#  720] train_loss: 2.678081, odo_loss: 2.005637, ine_loss: 0.494239, ref_loss: 0.178204\n",
      "\t[#  900] train_loss: 2.628978, odo_loss: 2.061831, ine_loss: 0.420579, ref_loss: 0.146568\n",
      "\ttrain_loss: 2.998958, odo_loss: 2.319594, ine_loss: 0.509086, ref_loss: 0.170278\n",
      "\tval_loss: 2.774747, odo_loss: 2.085789, ine_loss: 0.507617, ref_loss: 0.181341\n",
      "Epoch 94/2000\n",
      "\t[#    0] train_loss: 2.745978, odo_loss: 2.122246, ine_loss: 0.478995, ref_loss: 0.144737\n",
      "\t[#  180] train_loss: 4.071666, odo_loss: 3.324733, ine_loss: 0.577567, ref_loss: 0.169367\n",
      "\t[#  360] train_loss: 2.588131, odo_loss: 1.938843, ine_loss: 0.484546, ref_loss: 0.164742\n",
      "\t[#  540] train_loss: 2.413052, odo_loss: 1.789091, ine_loss: 0.477735, ref_loss: 0.146226\n",
      "\t[#  720] train_loss: 2.401746, odo_loss: 1.847376, ine_loss: 0.379030, ref_loss: 0.175340\n",
      "\t[#  900] train_loss: 2.770037, odo_loss: 1.972421, ine_loss: 0.634120, ref_loss: 0.163495\n",
      "\ttrain_loss: 2.751040, odo_loss: 2.072269, ine_loss: 0.510275, ref_loss: 0.168496\n",
      "\tval_loss: 2.689453, odo_loss: 1.999817, ine_loss: 0.509775, ref_loss: 0.179861\n",
      "\t*** Personal Best ***\n",
      "Epoch 95/2000\n",
      "\t[#    0] train_loss: 2.918778, odo_loss: 2.277256, ine_loss: 0.493926, ref_loss: 0.147597\n",
      "\t[#  180] train_loss: 2.553647, odo_loss: 1.909289, ine_loss: 0.502014, ref_loss: 0.142344\n",
      "\t[#  360] train_loss: 3.152395, odo_loss: 2.379918, ine_loss: 0.588944, ref_loss: 0.183533\n",
      "\t[#  540] train_loss: 3.003451, odo_loss: 2.334714, ine_loss: 0.481554, ref_loss: 0.187183\n",
      "\t[#  720] train_loss: 2.571370, odo_loss: 1.839608, ine_loss: 0.549394, ref_loss: 0.182367\n",
      "\t[#  900] train_loss: 2.865817, odo_loss: 2.217756, ine_loss: 0.443338, ref_loss: 0.204724\n",
      "\ttrain_loss: 2.761660, odo_loss: 2.082811, ine_loss: 0.511306, ref_loss: 0.167543\n",
      "\tval_loss: 2.816207, odo_loss: 2.125887, ine_loss: 0.510100, ref_loss: 0.180219\n",
      "Epoch 96/2000\n",
      "\t[#    0] train_loss: 2.853455, odo_loss: 2.209462, ine_loss: 0.470018, ref_loss: 0.173975\n",
      "\t[#  180] train_loss: 2.481422, odo_loss: 1.864671, ine_loss: 0.454469, ref_loss: 0.162281\n",
      "\t[#  360] train_loss: 2.917406, odo_loss: 2.168801, ine_loss: 0.577711, ref_loss: 0.170894\n",
      "\t[#  540] train_loss: 2.516026, odo_loss: 1.969359, ine_loss: 0.411218, ref_loss: 0.135449\n",
      "\t[#  720] train_loss: 2.707332, odo_loss: 2.147610, ine_loss: 0.405344, ref_loss: 0.154378\n",
      "\t[#  900] train_loss: 2.744611, odo_loss: 1.994116, ine_loss: 0.586394, ref_loss: 0.164101\n",
      "\ttrain_loss: 2.748786, odo_loss: 2.070141, ine_loss: 0.511658, ref_loss: 0.166986\n",
      "\tval_loss: 2.779714, odo_loss: 2.100159, ine_loss: 0.500359, ref_loss: 0.179197\n",
      "Epoch 97/2000\n",
      "\t[#    0] train_loss: 2.569484, odo_loss: 1.880448, ine_loss: 0.514963, ref_loss: 0.174072\n",
      "\t[#  180] train_loss: 2.235280, odo_loss: 1.667097, ine_loss: 0.410804, ref_loss: 0.157379\n",
      "\t[#  360] train_loss: 2.184849, odo_loss: 1.509268, ine_loss: 0.533964, ref_loss: 0.141617\n",
      "\t[#  540] train_loss: 2.311838, odo_loss: 1.684552, ine_loss: 0.470548, ref_loss: 0.156738\n",
      "\t[#  720] train_loss: 2.531826, odo_loss: 1.942339, ine_loss: 0.433374, ref_loss: 0.156113\n",
      "\t[#  900] train_loss: 2.679435, odo_loss: 1.916675, ine_loss: 0.614631, ref_loss: 0.148128\n",
      "\ttrain_loss: 2.735626, odo_loss: 2.058598, ine_loss: 0.510555, ref_loss: 0.166473\n",
      "\tval_loss: 2.675808, odo_loss: 1.990160, ine_loss: 0.507597, ref_loss: 0.178050\n",
      "\t*** Personal Best ***\n",
      "Epoch 98/2000\n",
      "\t[#    0] train_loss: 2.466628, odo_loss: 1.888467, ine_loss: 0.421745, ref_loss: 0.156416\n",
      "\t[#  180] train_loss: 2.723064, odo_loss: 2.121728, ine_loss: 0.469580, ref_loss: 0.131755\n",
      "\t[#  360] train_loss: 2.674608, odo_loss: 2.021707, ine_loss: 0.481096, ref_loss: 0.171806\n",
      "\t[#  540] train_loss: 2.575070, odo_loss: 1.834832, ine_loss: 0.562145, ref_loss: 0.178093\n",
      "\t[#  720] train_loss: 2.530568, odo_loss: 1.916115, ine_loss: 0.471906, ref_loss: 0.142547\n",
      "\t[#  900] train_loss: 2.906170, odo_loss: 2.266746, ine_loss: 0.473893, ref_loss: 0.165531\n",
      "\ttrain_loss: 2.786815, odo_loss: 2.110115, ine_loss: 0.510284, ref_loss: 0.166416\n",
      "\tval_loss: 2.798534, odo_loss: 2.115002, ine_loss: 0.504564, ref_loss: 0.178968\n",
      "Epoch 99/2000\n",
      "\t[#    0] train_loss: 2.645110, odo_loss: 2.100146, ine_loss: 0.369768, ref_loss: 0.175196\n",
      "\t[#  180] train_loss: 3.126339, odo_loss: 2.343459, ine_loss: 0.574721, ref_loss: 0.208160\n",
      "\t[#  360] train_loss: 2.618476, odo_loss: 1.972160, ine_loss: 0.444877, ref_loss: 0.201439\n",
      "\t[#  540] train_loss: 3.045023, odo_loss: 2.405988, ine_loss: 0.494084, ref_loss: 0.144952\n",
      "\t[#  720] train_loss: 2.365946, odo_loss: 1.647053, ine_loss: 0.507156, ref_loss: 0.211736\n",
      "\t[#  900] train_loss: 2.980419, odo_loss: 2.275533, ine_loss: 0.551974, ref_loss: 0.152913\n",
      "\ttrain_loss: 2.788834, odo_loss: 2.111476, ine_loss: 0.511078, ref_loss: 0.166279\n",
      "\tval_loss: 2.767170, odo_loss: 2.080684, ine_loss: 0.509025, ref_loss: 0.177462\n",
      "Epoch 100/2000\n",
      "\t[#    0] train_loss: 2.945884, odo_loss: 2.255803, ine_loss: 0.498316, ref_loss: 0.191765\n",
      "\t[#  180] train_loss: 2.499657, odo_loss: 1.890258, ine_loss: 0.435998, ref_loss: 0.173402\n",
      "\t[#  360] train_loss: 3.018221, odo_loss: 2.341737, ine_loss: 0.507172, ref_loss: 0.169311\n",
      "\t[#  540] train_loss: 2.577596, odo_loss: 1.962769, ine_loss: 0.449006, ref_loss: 0.165822\n",
      "\t[#  720] train_loss: 2.515466, odo_loss: 1.818400, ine_loss: 0.489138, ref_loss: 0.207928\n",
      "\t[#  900] train_loss: 3.000247, odo_loss: 2.213109, ine_loss: 0.604121, ref_loss: 0.183016\n",
      "\ttrain_loss: 2.766305, odo_loss: 2.089114, ine_loss: 0.511424, ref_loss: 0.165767\n",
      "\tval_loss: 2.892950, odo_loss: 2.208507, ine_loss: 0.507228, ref_loss: 0.177214\n",
      "Epoch 101/2000\n",
      "\t[#    0] train_loss: 2.740065, odo_loss: 2.139312, ine_loss: 0.467461, ref_loss: 0.133292\n",
      "\t[#  180] train_loss: 2.937287, odo_loss: 2.335949, ine_loss: 0.463936, ref_loss: 0.137403\n",
      "\t[#  360] train_loss: 4.725421, odo_loss: 4.039093, ine_loss: 0.523695, ref_loss: 0.162634\n",
      "\t[#  540] train_loss: 3.095712, odo_loss: 2.369917, ine_loss: 0.535421, ref_loss: 0.190374\n",
      "\t[#  720] train_loss: 2.975113, odo_loss: 2.302992, ine_loss: 0.511631, ref_loss: 0.160490\n",
      "\t[#  900] train_loss: 2.513310, odo_loss: 1.858853, ine_loss: 0.471974, ref_loss: 0.182482\n",
      "\ttrain_loss: 2.929441, odo_loss: 2.251143, ine_loss: 0.512293, ref_loss: 0.166005\n",
      "\tval_loss: 2.744316, odo_loss: 2.049837, ine_loss: 0.513550, ref_loss: 0.180929\n",
      "Epoch 102/2000\n",
      "\t[#    0] train_loss: 2.854130, odo_loss: 2.244797, ine_loss: 0.471713, ref_loss: 0.137621\n",
      "\t[#  180] train_loss: 2.534166, odo_loss: 1.926593, ine_loss: 0.454740, ref_loss: 0.152834\n",
      "\t[#  360] train_loss: 2.404764, odo_loss: 1.862308, ine_loss: 0.386419, ref_loss: 0.156037\n",
      "\t[#  540] train_loss: 2.606156, odo_loss: 1.927588, ine_loss: 0.504833, ref_loss: 0.173735\n",
      "\t[#  720] train_loss: 2.856031, odo_loss: 2.102215, ine_loss: 0.582481, ref_loss: 0.171334\n",
      "\t[#  900] train_loss: 2.529526, odo_loss: 1.891221, ine_loss: 0.486014, ref_loss: 0.152291\n",
      "\ttrain_loss: 2.696298, odo_loss: 2.019063, ine_loss: 0.512394, ref_loss: 0.164841\n",
      "\tval_loss: 2.686329, odo_loss: 1.998610, ine_loss: 0.510664, ref_loss: 0.177055\n",
      "Epoch 103/2000\n",
      "\t[#    0] train_loss: 2.534990, odo_loss: 1.828247, ine_loss: 0.536075, ref_loss: 0.170667\n",
      "\t[#  180] train_loss: 2.446897, odo_loss: 1.753010, ine_loss: 0.490341, ref_loss: 0.203547\n",
      "\t[#  360] train_loss: 2.770078, odo_loss: 2.059601, ine_loss: 0.545231, ref_loss: 0.165247\n",
      "\t[#  540] train_loss: 2.908127, odo_loss: 2.090735, ine_loss: 0.648506, ref_loss: 0.168886\n",
      "\t[#  720] train_loss: 3.061738, odo_loss: 2.463923, ine_loss: 0.437935, ref_loss: 0.159881\n",
      "\t[#  900] train_loss: 2.770618, odo_loss: 2.120248, ine_loss: 0.490783, ref_loss: 0.159588\n",
      "\ttrain_loss: 2.822222, odo_loss: 2.144928, ine_loss: 0.513015, ref_loss: 0.164280\n",
      "\tval_loss: 2.916132, odo_loss: 2.220626, ine_loss: 0.515092, ref_loss: 0.180414\n",
      "Epoch 104/2000\n",
      "\t[#    0] train_loss: 2.493659, odo_loss: 1.844332, ine_loss: 0.499523, ref_loss: 0.149804\n",
      "\t[#  180] train_loss: 2.671322, odo_loss: 1.963356, ine_loss: 0.534722, ref_loss: 0.173244\n",
      "\t[#  360] train_loss: 2.508584, odo_loss: 1.831316, ine_loss: 0.501481, ref_loss: 0.175788\n",
      "\t[#  540] train_loss: 2.625452, odo_loss: 1.960057, ine_loss: 0.491312, ref_loss: 0.174083\n",
      "\t[#  720] train_loss: 2.382015, odo_loss: 1.724661, ine_loss: 0.509127, ref_loss: 0.148227\n",
      "\t[#  900] train_loss: 3.102235, odo_loss: 2.411224, ine_loss: 0.536588, ref_loss: 0.154424\n",
      "\ttrain_loss: 2.783080, odo_loss: 2.104710, ine_loss: 0.513649, ref_loss: 0.164721\n",
      "\tval_loss: 2.805505, odo_loss: 2.117187, ine_loss: 0.511412, ref_loss: 0.176906\n",
      "Epoch 105/2000\n",
      "\t[#    0] train_loss: 2.592513, odo_loss: 1.793940, ine_loss: 0.631338, ref_loss: 0.167236\n",
      "\t[#  180] train_loss: 2.476162, odo_loss: 1.807234, ine_loss: 0.513035, ref_loss: 0.155893\n",
      "\t[#  360] train_loss: 2.817921, odo_loss: 2.211906, ine_loss: 0.469111, ref_loss: 0.136904\n",
      "\t[#  540] train_loss: 2.887399, odo_loss: 2.089263, ine_loss: 0.629890, ref_loss: 0.168246\n",
      "\t[#  720] train_loss: 2.373726, odo_loss: 1.697902, ine_loss: 0.505076, ref_loss: 0.170748\n",
      "\t[#  900] train_loss: 2.487304, odo_loss: 1.742151, ine_loss: 0.539541, ref_loss: 0.205612\n",
      "\ttrain_loss: 2.724621, odo_loss: 2.047723, ine_loss: 0.512224, ref_loss: 0.164674\n",
      "\tval_loss: 2.716258, odo_loss: 2.029743, ine_loss: 0.509940, ref_loss: 0.176576\n",
      "Epoch 106/2000\n",
      "\t[#    0] train_loss: 2.899890, odo_loss: 2.179245, ine_loss: 0.578970, ref_loss: 0.141675\n",
      "\t[#  180] train_loss: 2.653626, odo_loss: 2.022287, ine_loss: 0.477327, ref_loss: 0.154012\n",
      "\t[#  360] train_loss: 2.734788, odo_loss: 2.049854, ine_loss: 0.508686, ref_loss: 0.176248\n",
      "\t[#  540] train_loss: 2.527900, odo_loss: 1.846655, ine_loss: 0.498242, ref_loss: 0.183003\n",
      "\t[#  720] train_loss: 2.733218, odo_loss: 2.059598, ine_loss: 0.529736, ref_loss: 0.143883\n",
      "\t[#  900] train_loss: 2.885701, odo_loss: 2.022644, ine_loss: 0.725191, ref_loss: 0.137866\n",
      "\ttrain_loss: 2.699056, odo_loss: 2.020577, ine_loss: 0.514459, ref_loss: 0.164020\n",
      "\tval_loss: 2.678148, odo_loss: 1.993709, ine_loss: 0.508908, ref_loss: 0.175530\n",
      "Epoch 107/2000\n",
      "\t[#    0] train_loss: 2.601676, odo_loss: 1.835196, ine_loss: 0.601783, ref_loss: 0.164696\n",
      "\t[#  180] train_loss: 2.481735, odo_loss: 1.854541, ine_loss: 0.486949, ref_loss: 0.140245\n",
      "\t[#  360] train_loss: 2.602713, odo_loss: 1.863021, ine_loss: 0.522441, ref_loss: 0.217251\n",
      "\t[#  540] train_loss: 2.346257, odo_loss: 1.702507, ine_loss: 0.487092, ref_loss: 0.156658\n",
      "\t[#  720] train_loss: 2.454136, odo_loss: 1.821908, ine_loss: 0.486383, ref_loss: 0.145844\n",
      "\t[#  900] train_loss: 2.386836, odo_loss: 1.791275, ine_loss: 0.442441, ref_loss: 0.153120\n",
      "\ttrain_loss: 2.722842, odo_loss: 2.045354, ine_loss: 0.514371, ref_loss: 0.163117\n",
      "\tval_loss: 2.713741, odo_loss: 2.024040, ine_loss: 0.512309, ref_loss: 0.177392\n",
      "Epoch 108/2000\n",
      "\t[#    0] train_loss: 2.656919, odo_loss: 1.881450, ine_loss: 0.605446, ref_loss: 0.170023\n",
      "\t[#  180] train_loss: 2.451406, odo_loss: 1.685973, ine_loss: 0.607689, ref_loss: 0.157743\n",
      "\t[#  360] train_loss: 2.461131, odo_loss: 1.783381, ine_loss: 0.520474, ref_loss: 0.157276\n",
      "\t[#  540] train_loss: 2.917847, odo_loss: 2.237993, ine_loss: 0.479871, ref_loss: 0.199984\n",
      "\t[#  720] train_loss: 2.922006, odo_loss: 2.143846, ine_loss: 0.596424, ref_loss: 0.181736\n",
      "\t[#  900] train_loss: 2.958976, odo_loss: 2.229131, ine_loss: 0.559208, ref_loss: 0.170637\n",
      "\ttrain_loss: 2.679132, odo_loss: 2.001245, ine_loss: 0.514892, ref_loss: 0.162995\n",
      "\tval_loss: 2.663953, odo_loss: 1.976841, ine_loss: 0.508129, ref_loss: 0.178984\n",
      "\t*** Personal Best ***\n",
      "Epoch 109/2000\n",
      "\t[#    0] train_loss: 2.949084, odo_loss: 2.278541, ine_loss: 0.524009, ref_loss: 0.146534\n",
      "\t[#  180] train_loss: 2.593832, odo_loss: 1.917310, ine_loss: 0.513872, ref_loss: 0.162650\n",
      "\t[#  360] train_loss: 2.890652, odo_loss: 2.186612, ine_loss: 0.545634, ref_loss: 0.158407\n",
      "\t[#  540] train_loss: 2.561091, odo_loss: 1.893627, ine_loss: 0.507321, ref_loss: 0.160143\n",
      "\t[#  720] train_loss: 2.383855, odo_loss: 1.620002, ine_loss: 0.571312, ref_loss: 0.192541\n",
      "\t[#  900] train_loss: 2.644092, odo_loss: 2.005522, ine_loss: 0.485297, ref_loss: 0.153274\n",
      "\ttrain_loss: 2.663939, odo_loss: 1.986078, ine_loss: 0.515207, ref_loss: 0.162654\n",
      "\tval_loss: 2.645959, odo_loss: 1.953769, ine_loss: 0.516477, ref_loss: 0.175713\n",
      "\t*** Personal Best ***\n",
      "Epoch 110/2000\n",
      "\t[#    0] train_loss: 2.663197, odo_loss: 2.041022, ine_loss: 0.465835, ref_loss: 0.156340\n",
      "\t[#  180] train_loss: 2.515449, odo_loss: 1.967545, ine_loss: 0.393411, ref_loss: 0.154493\n",
      "\t[#  360] train_loss: 2.711023, odo_loss: 2.140878, ine_loss: 0.414438, ref_loss: 0.155706\n",
      "\t[#  540] train_loss: 2.701006, odo_loss: 1.845854, ine_loss: 0.665496, ref_loss: 0.189655\n",
      "\t[#  720] train_loss: 3.218628, odo_loss: 2.430140, ine_loss: 0.618605, ref_loss: 0.169883\n",
      "\t[#  900] train_loss: 2.833422, odo_loss: 2.141388, ine_loss: 0.564887, ref_loss: 0.127146\n",
      "\ttrain_loss: 2.629555, odo_loss: 1.949794, ine_loss: 0.517508, ref_loss: 0.162253\n",
      "\tval_loss: 2.674482, odo_loss: 1.979916, ine_loss: 0.518865, ref_loss: 0.175701\n",
      "Epoch 111/2000\n",
      "\t[#    0] train_loss: 2.357293, odo_loss: 1.800287, ine_loss: 0.422429, ref_loss: 0.134577\n",
      "\t[#  180] train_loss: 2.858464, odo_loss: 2.098129, ine_loss: 0.566573, ref_loss: 0.193762\n",
      "\t[#  360] train_loss: 2.653786, odo_loss: 2.041195, ine_loss: 0.454879, ref_loss: 0.157712\n",
      "\t[#  540] train_loss: 2.719372, odo_loss: 1.930794, ine_loss: 0.623031, ref_loss: 0.165547\n",
      "\t[#  720] train_loss: 2.225161, odo_loss: 1.627769, ine_loss: 0.448793, ref_loss: 0.148599\n",
      "\t[#  900] train_loss: 2.434670, odo_loss: 1.841924, ine_loss: 0.441752, ref_loss: 0.150994\n",
      "\ttrain_loss: 2.676537, odo_loss: 1.996482, ine_loss: 0.517674, ref_loss: 0.162382\n",
      "\tval_loss: 3.154020, odo_loss: 2.461742, ine_loss: 0.515539, ref_loss: 0.176739\n",
      "Epoch 112/2000\n",
      "\t[#    0] train_loss: 2.716208, odo_loss: 2.097195, ine_loss: 0.457848, ref_loss: 0.161164\n",
      "\t[#  180] train_loss: 2.398217, odo_loss: 1.657749, ine_loss: 0.610041, ref_loss: 0.130428\n",
      "\t[#  360] train_loss: 2.573251, odo_loss: 2.034818, ine_loss: 0.391355, ref_loss: 0.147078\n",
      "\t[#  540] train_loss: 3.175943, odo_loss: 2.448813, ine_loss: 0.544318, ref_loss: 0.182811\n",
      "\t[#  720] train_loss: 2.600683, odo_loss: 1.886312, ine_loss: 0.555684, ref_loss: 0.158687\n",
      "\t[#  900] train_loss: 2.480498, odo_loss: 1.873431, ine_loss: 0.443849, ref_loss: 0.163217\n",
      "\ttrain_loss: 2.874805, odo_loss: 2.193900, ine_loss: 0.518532, ref_loss: 0.162373\n",
      "\tval_loss: 2.729479, odo_loss: 2.036517, ine_loss: 0.516511, ref_loss: 0.176451\n",
      "Epoch 113/2000\n",
      "\t[#    0] train_loss: 2.832718, odo_loss: 2.139321, ine_loss: 0.526850, ref_loss: 0.166546\n",
      "\t[#  180] train_loss: 2.679258, odo_loss: 2.028105, ine_loss: 0.479967, ref_loss: 0.171186\n",
      "\t[#  360] train_loss: 2.494722, odo_loss: 1.882478, ine_loss: 0.476359, ref_loss: 0.135884\n",
      "\t[#  540] train_loss: 2.484351, odo_loss: 1.830873, ine_loss: 0.491205, ref_loss: 0.162273\n",
      "\t[#  720] train_loss: 2.865095, odo_loss: 2.124636, ine_loss: 0.581171, ref_loss: 0.159288\n",
      "\t[#  900] train_loss: 2.335732, odo_loss: 1.738213, ine_loss: 0.427951, ref_loss: 0.169568\n",
      "\ttrain_loss: 2.624362, odo_loss: 1.940494, ine_loss: 0.522196, ref_loss: 0.161672\n",
      "\tval_loss: 2.639992, odo_loss: 1.946401, ine_loss: 0.515908, ref_loss: 0.177684\n",
      "\t*** Personal Best ***\n",
      "Epoch 114/2000\n",
      "\t[#    0] train_loss: 2.387204, odo_loss: 1.785986, ine_loss: 0.420673, ref_loss: 0.180546\n",
      "\t[#  180] train_loss: 3.186804, odo_loss: 2.507581, ine_loss: 0.525991, ref_loss: 0.153232\n",
      "\t[#  360] train_loss: 2.728035, odo_loss: 2.074586, ine_loss: 0.508688, ref_loss: 0.144760\n",
      "\t[#  540] train_loss: 2.522681, odo_loss: 1.837293, ine_loss: 0.525767, ref_loss: 0.159620\n",
      "\t[#  720] train_loss: 2.728582, odo_loss: 1.934023, ine_loss: 0.603562, ref_loss: 0.190997\n",
      "\t[#  900] train_loss: 2.691846, odo_loss: 2.098555, ine_loss: 0.456441, ref_loss: 0.136850\n",
      "\ttrain_loss: 2.684802, odo_loss: 1.999791, ine_loss: 0.523608, ref_loss: 0.161402\n",
      "\tval_loss: 2.816504, odo_loss: 2.124928, ine_loss: 0.514673, ref_loss: 0.176903\n",
      "Epoch 115/2000\n",
      "\t[#    0] train_loss: 2.602706, odo_loss: 1.984537, ine_loss: 0.479625, ref_loss: 0.138544\n",
      "\t[#  180] train_loss: 2.545247, odo_loss: 1.845208, ine_loss: 0.548313, ref_loss: 0.151726\n",
      "\t[#  360] train_loss: 2.714333, odo_loss: 2.087751, ine_loss: 0.451582, ref_loss: 0.175000\n",
      "\t[#  540] train_loss: 2.843048, odo_loss: 2.168350, ine_loss: 0.495635, ref_loss: 0.179064\n",
      "\t[#  720] train_loss: 2.279102, odo_loss: 1.671361, ine_loss: 0.446601, ref_loss: 0.161140\n",
      "\t[#  900] train_loss: 2.683136, odo_loss: 2.029745, ine_loss: 0.512127, ref_loss: 0.141264\n",
      "\ttrain_loss: 2.683971, odo_loss: 1.997917, ine_loss: 0.524786, ref_loss: 0.161267\n",
      "\tval_loss: 2.603193, odo_loss: 1.903863, ine_loss: 0.523093, ref_loss: 0.176237\n",
      "\t*** Personal Best ***\n",
      "Epoch 116/2000\n",
      "\t[#    0] train_loss: 2.461895, odo_loss: 1.847449, ine_loss: 0.451928, ref_loss: 0.162518\n",
      "\t[#  180] train_loss: 2.516837, odo_loss: 1.824036, ine_loss: 0.526988, ref_loss: 0.165813\n",
      "\t[#  360] train_loss: 2.794942, odo_loss: 2.138043, ine_loss: 0.517555, ref_loss: 0.139345\n",
      "\t[#  540] train_loss: 3.314830, odo_loss: 2.494457, ine_loss: 0.645592, ref_loss: 0.174780\n",
      "\t[#  720] train_loss: 2.195582, odo_loss: 1.533661, ine_loss: 0.534638, ref_loss: 0.127282\n",
      "\t[#  900] train_loss: 2.324778, odo_loss: 1.677387, ine_loss: 0.506151, ref_loss: 0.141240\n",
      "\ttrain_loss: 2.627285, odo_loss: 1.939246, ine_loss: 0.526670, ref_loss: 0.161369\n",
      "\tval_loss: 2.605906, odo_loss: 1.905458, ine_loss: 0.523758, ref_loss: 0.176690\n",
      "Epoch 117/2000\n",
      "\t[#    0] train_loss: 2.881432, odo_loss: 2.116970, ine_loss: 0.608761, ref_loss: 0.155701\n",
      "\t[#  180] train_loss: 2.497551, odo_loss: 1.809514, ine_loss: 0.506513, ref_loss: 0.181523\n",
      "\t[#  360] train_loss: 2.092191, odo_loss: 1.429147, ine_loss: 0.509788, ref_loss: 0.153256\n",
      "\t[#  540] train_loss: 2.417262, odo_loss: 1.836511, ine_loss: 0.420403, ref_loss: 0.160349\n",
      "\t[#  720] train_loss: 2.941632, odo_loss: 2.209571, ine_loss: 0.552619, ref_loss: 0.179442\n",
      "\t[#  900] train_loss: 2.731827, odo_loss: 1.975720, ine_loss: 0.613392, ref_loss: 0.142714\n",
      "\ttrain_loss: 2.566250, odo_loss: 1.875296, ine_loss: 0.530241, ref_loss: 0.160713\n",
      "\tval_loss: 2.566154, odo_loss: 1.867072, ine_loss: 0.524859, ref_loss: 0.174224\n",
      "\t*** Personal Best ***\n",
      "Epoch 118/2000\n",
      "\t[#    0] train_loss: 2.623112, odo_loss: 1.906550, ine_loss: 0.551119, ref_loss: 0.165443\n",
      "\t[#  180] train_loss: 2.180042, odo_loss: 1.515359, ine_loss: 0.505374, ref_loss: 0.159309\n",
      "\t[#  360] train_loss: 2.741521, odo_loss: 2.002416, ine_loss: 0.613785, ref_loss: 0.125320\n",
      "\t[#  540] train_loss: 2.736494, odo_loss: 2.015195, ine_loss: 0.576250, ref_loss: 0.145048\n",
      "\t[#  720] train_loss: 2.705327, odo_loss: 1.957697, ine_loss: 0.564142, ref_loss: 0.183488\n",
      "\t[#  900] train_loss: 2.344231, odo_loss: 1.631663, ine_loss: 0.569671, ref_loss: 0.142897\n",
      "\ttrain_loss: 2.547832, odo_loss: 1.856095, ine_loss: 0.531507, ref_loss: 0.160230\n",
      "\tval_loss: 2.502859, odo_loss: 1.797054, ine_loss: 0.532288, ref_loss: 0.173516\n",
      "\t*** Personal Best ***\n",
      "Epoch 119/2000\n",
      "\t[#    0] train_loss: 2.470196, odo_loss: 1.808749, ine_loss: 0.522190, ref_loss: 0.139258\n",
      "\t[#  180] train_loss: 2.457841, odo_loss: 1.725401, ine_loss: 0.559669, ref_loss: 0.172771\n",
      "\t[#  360] train_loss: 2.288990, odo_loss: 1.728449, ine_loss: 0.422703, ref_loss: 0.137838\n",
      "\t[#  540] train_loss: 2.545314, odo_loss: 1.927563, ine_loss: 0.435189, ref_loss: 0.182563\n",
      "\t[#  720] train_loss: 2.517067, odo_loss: 1.773632, ine_loss: 0.557199, ref_loss: 0.186236\n",
      "\t[#  900] train_loss: 2.652191, odo_loss: 1.978329, ine_loss: 0.512659, ref_loss: 0.161203\n",
      "\ttrain_loss: 2.512255, odo_loss: 1.818289, ine_loss: 0.534196, ref_loss: 0.159770\n",
      "\tval_loss: 2.521694, odo_loss: 1.818533, ine_loss: 0.527272, ref_loss: 0.175889\n",
      "Epoch 120/2000\n",
      "\t[#    0] train_loss: 2.255744, odo_loss: 1.630909, ine_loss: 0.482907, ref_loss: 0.141927\n",
      "\t[#  180] train_loss: 2.179540, odo_loss: 1.560835, ine_loss: 0.499726, ref_loss: 0.118979\n",
      "\t[#  360] train_loss: 2.434843, odo_loss: 1.651471, ine_loss: 0.607845, ref_loss: 0.175528\n",
      "\t[#  540] train_loss: 2.929779, odo_loss: 2.310273, ine_loss: 0.463324, ref_loss: 0.156182\n",
      "\t[#  720] train_loss: 2.785962, odo_loss: 2.142078, ine_loss: 0.499857, ref_loss: 0.144027\n",
      "\t[#  900] train_loss: 2.522132, odo_loss: 1.807261, ine_loss: 0.571284, ref_loss: 0.143587\n",
      "\ttrain_loss: 2.514884, odo_loss: 1.821766, ine_loss: 0.533608, ref_loss: 0.159509\n",
      "\tval_loss: 2.512228, odo_loss: 1.805869, ine_loss: 0.530330, ref_loss: 0.176029\n",
      "Epoch 121/2000\n",
      "\t[#    0] train_loss: 2.777043, odo_loss: 2.027315, ine_loss: 0.602852, ref_loss: 0.146875\n",
      "\t[#  180] train_loss: 2.912724, odo_loss: 2.017557, ine_loss: 0.709677, ref_loss: 0.185490\n",
      "\t[#  360] train_loss: 2.365220, odo_loss: 1.683213, ine_loss: 0.531825, ref_loss: 0.150182\n",
      "\t[#  540] train_loss: 2.906324, odo_loss: 2.029115, ine_loss: 0.718726, ref_loss: 0.158484\n",
      "\t[#  720] train_loss: 2.234444, odo_loss: 1.461819, ine_loss: 0.613491, ref_loss: 0.159134\n",
      "\t[#  900] train_loss: 2.373942, odo_loss: 1.794956, ine_loss: 0.453047, ref_loss: 0.125939\n",
      "\ttrain_loss: 2.499692, odo_loss: 1.806709, ine_loss: 0.533637, ref_loss: 0.159347\n",
      "\tval_loss: 2.516305, odo_loss: 1.812492, ine_loss: 0.531693, ref_loss: 0.172120\n",
      "Epoch 122/2000\n",
      "\t[#    0] train_loss: 2.763321, odo_loss: 2.053675, ine_loss: 0.522715, ref_loss: 0.186932\n",
      "\t[#  180] train_loss: 2.414409, odo_loss: 1.814354, ine_loss: 0.444056, ref_loss: 0.155999\n",
      "\t[#  360] train_loss: 2.645689, odo_loss: 1.966852, ine_loss: 0.520470, ref_loss: 0.158367\n",
      "\t[#  540] train_loss: 2.656548, odo_loss: 2.020484, ine_loss: 0.488358, ref_loss: 0.147706\n",
      "\t[#  720] train_loss: 2.056216, odo_loss: 1.475598, ine_loss: 0.440769, ref_loss: 0.139849\n",
      "\t[#  900] train_loss: 2.525033, odo_loss: 1.831420, ine_loss: 0.530021, ref_loss: 0.163592\n",
      "\ttrain_loss: 2.566760, odo_loss: 1.874431, ine_loss: 0.533235, ref_loss: 0.159094\n",
      "\tval_loss: 2.595283, odo_loss: 1.886351, ine_loss: 0.535287, ref_loss: 0.173644\n",
      "Epoch 123/2000\n",
      "\t[#    0] train_loss: 2.416100, odo_loss: 1.781991, ine_loss: 0.466680, ref_loss: 0.167428\n",
      "\t[#  180] train_loss: 2.401704, odo_loss: 1.704641, ine_loss: 0.555763, ref_loss: 0.141299\n",
      "\t[#  360] train_loss: 2.814435, odo_loss: 2.072397, ine_loss: 0.608921, ref_loss: 0.133118\n",
      "\t[#  540] train_loss: 2.348278, odo_loss: 1.623288, ine_loss: 0.564297, ref_loss: 0.160692\n",
      "\t[#  720] train_loss: 3.757054, odo_loss: 3.019718, ine_loss: 0.589394, ref_loss: 0.147942\n",
      "\t[#  900] train_loss: 2.215870, odo_loss: 1.468049, ine_loss: 0.573399, ref_loss: 0.174422\n",
      "\ttrain_loss: 2.570250, odo_loss: 1.878375, ine_loss: 0.532870, ref_loss: 0.159006\n",
      "\tval_loss: 2.600846, odo_loss: 1.897561, ine_loss: 0.527778, ref_loss: 0.175507\n",
      "Epoch 124/2000\n",
      "\t[#    0] train_loss: 2.730943, odo_loss: 1.980514, ine_loss: 0.594743, ref_loss: 0.155686\n",
      "\t[#  180] train_loss: 2.376215, odo_loss: 1.693717, ine_loss: 0.504805, ref_loss: 0.177693\n",
      "\t[#  360] train_loss: 2.645322, odo_loss: 1.910539, ine_loss: 0.558215, ref_loss: 0.176568\n",
      "\t[#  540] train_loss: 2.232643, odo_loss: 1.475942, ine_loss: 0.590149, ref_loss: 0.166552\n",
      "\t[#  720] train_loss: 2.513227, odo_loss: 1.875987, ine_loss: 0.493956, ref_loss: 0.143284\n",
      "\t[#  900] train_loss: 2.479006, odo_loss: 1.797774, ine_loss: 0.518297, ref_loss: 0.162935\n",
      "\ttrain_loss: 2.599737, odo_loss: 1.907671, ine_loss: 0.532747, ref_loss: 0.159319\n",
      "\tval_loss: 2.587284, odo_loss: 1.886707, ine_loss: 0.525220, ref_loss: 0.175356\n",
      "Epoch 125/2000\n",
      "\t[#    0] train_loss: 2.319756, odo_loss: 1.649659, ine_loss: 0.529582, ref_loss: 0.140514\n",
      "\t[#  180] train_loss: 2.705762, odo_loss: 2.074959, ine_loss: 0.439186, ref_loss: 0.191617\n",
      "\t[#  360] train_loss: 2.162957, odo_loss: 1.469835, ine_loss: 0.523055, ref_loss: 0.170067\n",
      "\t[#  540] train_loss: 2.620760, odo_loss: 1.850108, ine_loss: 0.575028, ref_loss: 0.195625\n",
      "\t[#  720] train_loss: 2.416208, odo_loss: 1.816212, ine_loss: 0.434974, ref_loss: 0.165022\n",
      "\t[#  900] train_loss: 2.710459, odo_loss: 1.967533, ine_loss: 0.582915, ref_loss: 0.160011\n",
      "\ttrain_loss: 2.542157, odo_loss: 1.852287, ine_loss: 0.531307, ref_loss: 0.158563\n",
      "\tval_loss: 2.499566, odo_loss: 1.801578, ine_loss: 0.523952, ref_loss: 0.174035\n",
      "Epoch 126/2000\n",
      "\t[#    0] train_loss: 2.456421, odo_loss: 1.718575, ine_loss: 0.618576, ref_loss: 0.119270\n",
      "\t[#  180] train_loss: 2.568654, odo_loss: 1.800781, ine_loss: 0.589452, ref_loss: 0.178421\n",
      "\t[#  360] train_loss: 2.651484, odo_loss: 1.995362, ine_loss: 0.509351, ref_loss: 0.146771\n",
      "\t[#  540] train_loss: 2.307959, odo_loss: 1.635666, ine_loss: 0.515167, ref_loss: 0.157126\n",
      "\t[#  720] train_loss: 2.358081, odo_loss: 1.685877, ine_loss: 0.518266, ref_loss: 0.153938\n",
      "\t[#  900] train_loss: 2.657103, odo_loss: 1.870716, ine_loss: 0.640930, ref_loss: 0.145456\n",
      "\ttrain_loss: 2.508153, odo_loss: 1.817834, ine_loss: 0.531599, ref_loss: 0.158720\n",
      "\tval_loss: 2.520357, odo_loss: 1.816167, ine_loss: 0.528844, ref_loss: 0.175347\n",
      "Epoch 127/2000\n",
      "\t[#    0] train_loss: 2.789864, odo_loss: 1.956823, ine_loss: 0.646269, ref_loss: 0.186772\n",
      "\t[#  180] train_loss: 2.257496, odo_loss: 1.620986, ine_loss: 0.494616, ref_loss: 0.141894\n",
      "\t[#  360] train_loss: 4.626208, odo_loss: 3.849043, ine_loss: 0.615706, ref_loss: 0.161459\n",
      "\t[#  540] train_loss: 2.807190, odo_loss: 2.124163, ine_loss: 0.522971, ref_loss: 0.160055\n",
      "\t[#  720] train_loss: 2.935433, odo_loss: 2.257962, ine_loss: 0.534699, ref_loss: 0.142772\n",
      "\t[#  900] train_loss: 2.712804, odo_loss: 1.941451, ine_loss: 0.596914, ref_loss: 0.174439\n",
      "\ttrain_loss: 2.610075, odo_loss: 1.921871, ine_loss: 0.529761, ref_loss: 0.158443\n",
      "\tval_loss: 2.455348, odo_loss: 1.752760, ine_loss: 0.529175, ref_loss: 0.173413\n",
      "\t*** Personal Best ***\n",
      "Epoch 128/2000\n",
      "\t[#    0] train_loss: 2.312067, odo_loss: 1.645544, ine_loss: 0.499146, ref_loss: 0.167378\n",
      "\t[#  180] train_loss: 2.604481, odo_loss: 1.920077, ine_loss: 0.522827, ref_loss: 0.161577\n",
      "\t[#  360] train_loss: 2.402354, odo_loss: 1.710773, ine_loss: 0.526728, ref_loss: 0.164853\n",
      "\t[#  540] train_loss: 2.169527, odo_loss: 1.571909, ine_loss: 0.440213, ref_loss: 0.157405\n",
      "\t[#  720] train_loss: 2.811696, odo_loss: 2.041985, ine_loss: 0.593483, ref_loss: 0.176228\n",
      "\t[#  900] train_loss: 2.657111, odo_loss: 1.953918, ine_loss: 0.515482, ref_loss: 0.187711\n",
      "\ttrain_loss: 2.426428, odo_loss: 1.737134, ine_loss: 0.531158, ref_loss: 0.158136\n",
      "\tval_loss: 2.364762, odo_loss: 1.664220, ine_loss: 0.524844, ref_loss: 0.175698\n",
      "\t*** Personal Best ***\n",
      "Epoch 129/2000\n",
      "\t[#    0] train_loss: 2.345659, odo_loss: 1.677218, ine_loss: 0.531652, ref_loss: 0.136789\n",
      "\t[#  180] train_loss: 2.293178, odo_loss: 1.652514, ine_loss: 0.492499, ref_loss: 0.148165\n",
      "\t[#  360] train_loss: 2.598005, odo_loss: 1.933288, ine_loss: 0.523654, ref_loss: 0.141063\n",
      "\t[#  540] train_loss: 2.274487, odo_loss: 1.623485, ine_loss: 0.475240, ref_loss: 0.175762\n",
      "\t[#  720] train_loss: 2.039446, odo_loss: 1.356164, ine_loss: 0.517895, ref_loss: 0.165387\n",
      "\t[#  900] train_loss: 2.364188, odo_loss: 1.710557, ine_loss: 0.489753, ref_loss: 0.163879\n",
      "\ttrain_loss: 2.420623, odo_loss: 1.733142, ine_loss: 0.530069, ref_loss: 0.157412\n",
      "\tval_loss: 2.495482, odo_loss: 1.796501, ine_loss: 0.524372, ref_loss: 0.174609\n",
      "Epoch 130/2000\n",
      "\t[#    0] train_loss: 2.967724, odo_loss: 2.339240, ine_loss: 0.473918, ref_loss: 0.154566\n",
      "\t[#  180] train_loss: 2.310346, odo_loss: 1.600159, ine_loss: 0.556109, ref_loss: 0.154079\n",
      "\t[#  360] train_loss: 2.989988, odo_loss: 2.256052, ine_loss: 0.573934, ref_loss: 0.160002\n",
      "\t[#  540] train_loss: 2.575308, odo_loss: 1.802131, ine_loss: 0.596315, ref_loss: 0.176863\n",
      "\t[#  720] train_loss: 2.214703, odo_loss: 1.515019, ine_loss: 0.515249, ref_loss: 0.184436\n",
      "\t[#  900] train_loss: 2.848184, odo_loss: 2.137421, ine_loss: 0.556310, ref_loss: 0.154453\n",
      "\ttrain_loss: 2.417743, odo_loss: 1.730232, ine_loss: 0.529806, ref_loss: 0.157704\n",
      "\tval_loss: 2.439988, odo_loss: 1.744045, ine_loss: 0.523044, ref_loss: 0.172900\n",
      "Epoch 131/2000\n",
      "\t[#    0] train_loss: 2.469852, odo_loss: 1.849840, ine_loss: 0.451655, ref_loss: 0.168357\n",
      "\t[#  180] train_loss: 2.718081, odo_loss: 2.078984, ine_loss: 0.488584, ref_loss: 0.150512\n",
      "\t[#  360] train_loss: 3.426448, odo_loss: 2.583786, ine_loss: 0.691243, ref_loss: 0.151419\n",
      "\t[#  540] train_loss: 2.165912, odo_loss: 1.529357, ine_loss: 0.490691, ref_loss: 0.145865\n",
      "\t[#  720] train_loss: 2.550527, odo_loss: 1.911114, ine_loss: 0.497692, ref_loss: 0.141721\n",
      "\t[#  900] train_loss: 2.462458, odo_loss: 1.777949, ine_loss: 0.492921, ref_loss: 0.191588\n",
      "\ttrain_loss: 2.593043, odo_loss: 1.906786, ine_loss: 0.528524, ref_loss: 0.157733\n",
      "\tval_loss: 2.609684, odo_loss: 1.907372, ine_loss: 0.530463, ref_loss: 0.171849\n",
      "Epoch 132/2000\n",
      "\t[#    0] train_loss: 2.393941, odo_loss: 1.615042, ine_loss: 0.624650, ref_loss: 0.154249\n",
      "\t[#  180] train_loss: 2.468192, odo_loss: 1.704245, ine_loss: 0.621810, ref_loss: 0.142138\n",
      "\t[#  360] train_loss: 2.613686, odo_loss: 1.796143, ine_loss: 0.664643, ref_loss: 0.152900\n",
      "\t[#  540] train_loss: 2.396263, odo_loss: 1.719764, ine_loss: 0.548162, ref_loss: 0.128337\n",
      "\t[#  720] train_loss: 2.522513, odo_loss: 1.880298, ine_loss: 0.470380, ref_loss: 0.171835\n",
      "\t[#  900] train_loss: 2.262671, odo_loss: 1.647673, ine_loss: 0.447831, ref_loss: 0.167167\n",
      "\ttrain_loss: 2.443081, odo_loss: 1.755384, ine_loss: 0.530053, ref_loss: 0.157645\n",
      "\tval_loss: 2.467555, odo_loss: 1.764286, ine_loss: 0.531471, ref_loss: 0.171798\n",
      "Epoch 133/2000\n",
      "\t[#    0] train_loss: 2.457483, odo_loss: 1.777268, ine_loss: 0.517185, ref_loss: 0.163030\n",
      "\t[#  180] train_loss: 2.226633, odo_loss: 1.612412, ine_loss: 0.446666, ref_loss: 0.167555\n",
      "\t[#  360] train_loss: 2.182844, odo_loss: 1.516906, ine_loss: 0.479832, ref_loss: 0.186106\n",
      "\t[#  540] train_loss: 2.199440, odo_loss: 1.616518, ine_loss: 0.440288, ref_loss: 0.142633\n",
      "\t[#  720] train_loss: 2.663410, odo_loss: 1.910129, ine_loss: 0.590454, ref_loss: 0.162827\n",
      "\t[#  900] train_loss: 2.448411, odo_loss: 1.675292, ine_loss: 0.609832, ref_loss: 0.163287\n",
      "\ttrain_loss: 2.389759, odo_loss: 1.703409, ine_loss: 0.529683, ref_loss: 0.156667\n",
      "\tval_loss: 2.353555, odo_loss: 1.657509, ine_loss: 0.524595, ref_loss: 0.171451\n",
      "\t*** Personal Best ***\n",
      "Epoch 134/2000\n",
      "\t[#    0] train_loss: 1.871662, odo_loss: 1.228894, ine_loss: 0.496302, ref_loss: 0.146465\n",
      "\t[#  180] train_loss: 2.322783, odo_loss: 1.687076, ine_loss: 0.474955, ref_loss: 0.160752\n",
      "\t[#  360] train_loss: 2.376417, odo_loss: 1.717428, ine_loss: 0.525451, ref_loss: 0.133538\n",
      "\t[#  540] train_loss: 2.394972, odo_loss: 1.678301, ine_loss: 0.538049, ref_loss: 0.178623\n",
      "\t[#  720] train_loss: 2.430021, odo_loss: 1.791973, ine_loss: 0.486844, ref_loss: 0.151204\n",
      "\t[#  900] train_loss: 2.145813, odo_loss: 1.544339, ine_loss: 0.457820, ref_loss: 0.143653\n",
      "\ttrain_loss: 2.374967, odo_loss: 1.690197, ine_loss: 0.528300, ref_loss: 0.156470\n",
      "\tval_loss: 2.377001, odo_loss: 1.676837, ine_loss: 0.526767, ref_loss: 0.173397\n",
      "Epoch 135/2000\n",
      "\t[#    0] train_loss: 2.480328, odo_loss: 1.812965, ine_loss: 0.516142, ref_loss: 0.151222\n",
      "\t[#  180] train_loss: 2.276597, odo_loss: 1.632458, ine_loss: 0.492485, ref_loss: 0.151654\n",
      "\t[#  360] train_loss: 2.581256, odo_loss: 1.900911, ine_loss: 0.514112, ref_loss: 0.166233\n",
      "\t[#  540] train_loss: 2.674606, odo_loss: 1.969406, ine_loss: 0.562498, ref_loss: 0.142703\n",
      "\t[#  720] train_loss: 2.226454, odo_loss: 1.685052, ine_loss: 0.384284, ref_loss: 0.157118\n",
      "\t[#  900] train_loss: 2.070947, odo_loss: 1.440040, ine_loss: 0.470421, ref_loss: 0.160486\n",
      "\ttrain_loss: 2.680119, odo_loss: 1.995078, ine_loss: 0.527454, ref_loss: 0.157587\n",
      "\tval_loss: 2.696577, odo_loss: 2.000539, ine_loss: 0.519030, ref_loss: 0.177009\n",
      "Epoch 136/2000\n",
      "\t[#    0] train_loss: 2.531068, odo_loss: 1.816839, ine_loss: 0.535674, ref_loss: 0.178555\n",
      "\t[#  180] train_loss: 2.575887, odo_loss: 1.869287, ine_loss: 0.544581, ref_loss: 0.162019\n",
      "\t[#  360] train_loss: 2.538082, odo_loss: 1.904412, ine_loss: 0.499193, ref_loss: 0.134477\n",
      "\t[#  540] train_loss: 2.162538, odo_loss: 1.513838, ine_loss: 0.505429, ref_loss: 0.143271\n",
      "\t[#  720] train_loss: 2.506400, odo_loss: 1.873563, ine_loss: 0.492200, ref_loss: 0.140637\n",
      "\t[#  900] train_loss: 2.216416, odo_loss: 1.614172, ine_loss: 0.492026, ref_loss: 0.110218\n",
      "\ttrain_loss: 2.437389, odo_loss: 1.751260, ine_loss: 0.529466, ref_loss: 0.156663\n",
      "\tval_loss: 2.381500, odo_loss: 1.684983, ine_loss: 0.524044, ref_loss: 0.172473\n",
      "Epoch 137/2000\n",
      "\t[#    0] train_loss: 2.510385, odo_loss: 1.885617, ine_loss: 0.475864, ref_loss: 0.148904\n",
      "\t[#  180] train_loss: 2.573766, odo_loss: 1.910068, ine_loss: 0.517683, ref_loss: 0.146015\n",
      "\t[#  360] train_loss: 2.397317, odo_loss: 1.675271, ine_loss: 0.585728, ref_loss: 0.136318\n",
      "\t[#  540] train_loss: 2.444843, odo_loss: 1.720717, ine_loss: 0.556706, ref_loss: 0.167420\n",
      "\t[#  720] train_loss: 2.270888, odo_loss: 1.666485, ine_loss: 0.441543, ref_loss: 0.162859\n",
      "\t[#  900] train_loss: 2.263099, odo_loss: 1.641576, ine_loss: 0.437351, ref_loss: 0.184172\n",
      "\ttrain_loss: 2.346502, odo_loss: 1.663966, ine_loss: 0.526788, ref_loss: 0.155748\n",
      "\tval_loss: 2.389967, odo_loss: 1.692610, ine_loss: 0.524521, ref_loss: 0.172836\n",
      "Epoch 138/2000\n",
      "\t[#    0] train_loss: 2.453267, odo_loss: 1.679595, ine_loss: 0.595464, ref_loss: 0.178209\n",
      "\t[#  180] train_loss: 2.064432, odo_loss: 1.435625, ine_loss: 0.478906, ref_loss: 0.149901\n",
      "\t[#  360] train_loss: 2.277634, odo_loss: 1.529608, ine_loss: 0.592229, ref_loss: 0.155798\n",
      "\t[#  540] train_loss: 2.209354, odo_loss: 1.550475, ine_loss: 0.506381, ref_loss: 0.152498\n",
      "\t[#  720] train_loss: 2.839123, odo_loss: 2.091922, ine_loss: 0.581346, ref_loss: 0.165855\n",
      "\t[#  900] train_loss: 2.266711, odo_loss: 1.570797, ine_loss: 0.530357, ref_loss: 0.165557\n",
      "\ttrain_loss: 2.456981, odo_loss: 1.773992, ine_loss: 0.527238, ref_loss: 0.155751\n",
      "\tval_loss: 2.435255, odo_loss: 1.737269, ine_loss: 0.523865, ref_loss: 0.174121\n",
      "Epoch 139/2000\n",
      "\t[#    0] train_loss: 2.223597, odo_loss: 1.440481, ine_loss: 0.642850, ref_loss: 0.140265\n",
      "\t[#  180] train_loss: 2.483582, odo_loss: 1.803491, ine_loss: 0.547548, ref_loss: 0.132544\n",
      "\t[#  360] train_loss: 2.187700, odo_loss: 1.556449, ine_loss: 0.488664, ref_loss: 0.142587\n",
      "\t[#  540] train_loss: 2.488585, odo_loss: 1.845298, ine_loss: 0.471017, ref_loss: 0.172270\n",
      "\t[#  720] train_loss: 2.515604, odo_loss: 1.866975, ine_loss: 0.510836, ref_loss: 0.137793\n",
      "\t[#  900] train_loss: 2.575976, odo_loss: 1.878178, ine_loss: 0.540159, ref_loss: 0.157638\n",
      "\ttrain_loss: 2.386973, odo_loss: 1.702458, ine_loss: 0.527762, ref_loss: 0.156752\n",
      "\tval_loss: 2.366735, odo_loss: 1.667160, ine_loss: 0.527401, ref_loss: 0.172174\n",
      "Epoch 140/2000\n",
      "\t[#    0] train_loss: 2.093390, odo_loss: 1.328950, ine_loss: 0.604542, ref_loss: 0.159898\n",
      "\t[#  180] train_loss: 2.331765, odo_loss: 1.576410, ine_loss: 0.582317, ref_loss: 0.173038\n",
      "\t[#  360] train_loss: 2.731412, odo_loss: 2.004053, ine_loss: 0.582210, ref_loss: 0.145149\n",
      "\t[#  540] train_loss: 2.260309, odo_loss: 1.591942, ine_loss: 0.527421, ref_loss: 0.140946\n",
      "\t[#  720] train_loss: 2.344317, odo_loss: 1.710541, ine_loss: 0.451187, ref_loss: 0.182590\n",
      "\t[#  900] train_loss: 2.452903, odo_loss: 1.633287, ine_loss: 0.653491, ref_loss: 0.166124\n",
      "\ttrain_loss: 2.363197, odo_loss: 1.680268, ine_loss: 0.527302, ref_loss: 0.155627\n",
      "\tval_loss: 2.405122, odo_loss: 1.707515, ine_loss: 0.525326, ref_loss: 0.172281\n",
      "Epoch 141/2000\n",
      "\t[#    0] train_loss: 2.161038, odo_loss: 1.405204, ine_loss: 0.595036, ref_loss: 0.160798\n",
      "\t[#  180] train_loss: 2.423458, odo_loss: 1.767725, ine_loss: 0.507445, ref_loss: 0.148288\n",
      "\t[#  360] train_loss: 2.156312, odo_loss: 1.330752, ine_loss: 0.648285, ref_loss: 0.177276\n",
      "\t[#  540] train_loss: 2.379455, odo_loss: 1.658440, ine_loss: 0.538099, ref_loss: 0.182917\n",
      "\t[#  720] train_loss: 6.154733, odo_loss: 5.478466, ine_loss: 0.513855, ref_loss: 0.162412\n",
      "\t[#  900] train_loss: 2.352727, odo_loss: 1.732813, ine_loss: 0.448462, ref_loss: 0.171451\n",
      "\ttrain_loss: 2.377029, odo_loss: 1.695033, ine_loss: 0.526913, ref_loss: 0.155083\n",
      "\tval_loss: 2.542668, odo_loss: 1.847316, ine_loss: 0.522224, ref_loss: 0.173128\n",
      "Epoch 142/2000\n",
      "\t[#    0] train_loss: 2.384464, odo_loss: 1.742052, ine_loss: 0.500120, ref_loss: 0.142291\n",
      "\t[#  180] train_loss: 2.032074, odo_loss: 1.426000, ine_loss: 0.461928, ref_loss: 0.144146\n",
      "\t[#  360] train_loss: 2.401782, odo_loss: 1.703944, ine_loss: 0.488380, ref_loss: 0.209457\n",
      "\t[#  540] train_loss: 2.336231, odo_loss: 1.765277, ine_loss: 0.426373, ref_loss: 0.144580\n",
      "\t[#  720] train_loss: 1.818920, odo_loss: 1.280992, ine_loss: 0.390935, ref_loss: 0.146993\n",
      "\t[#  900] train_loss: 2.680715, odo_loss: 1.891964, ine_loss: 0.640616, ref_loss: 0.148135\n",
      "\ttrain_loss: 2.441879, odo_loss: 1.757943, ine_loss: 0.528339, ref_loss: 0.155596\n",
      "\tval_loss: 2.444472, odo_loss: 1.748306, ine_loss: 0.525541, ref_loss: 0.170625\n",
      "Epoch 143/2000\n",
      "\t[#    0] train_loss: 2.367639, odo_loss: 1.707363, ine_loss: 0.524863, ref_loss: 0.135413\n",
      "\t[#  180] train_loss: 2.437730, odo_loss: 1.765574, ine_loss: 0.508732, ref_loss: 0.163425\n",
      "\t[#  360] train_loss: 2.232321, odo_loss: 1.582462, ine_loss: 0.462845, ref_loss: 0.187013\n",
      "\t[#  540] train_loss: 2.367064, odo_loss: 1.675242, ine_loss: 0.536387, ref_loss: 0.155435\n",
      "\t[#  720] train_loss: 2.129924, odo_loss: 1.481300, ine_loss: 0.503446, ref_loss: 0.145177\n",
      "\t[#  900] train_loss: 8.927900, odo_loss: 8.316002, ine_loss: 0.449693, ref_loss: 0.162205\n",
      "\ttrain_loss: 2.337596, odo_loss: 1.655336, ine_loss: 0.527111, ref_loss: 0.155149\n",
      "\tval_loss: 2.767596, odo_loss: 2.071203, ine_loss: 0.525070, ref_loss: 0.171323\n",
      "Epoch 144/2000\n",
      "\t[#    0] train_loss: 2.214655, odo_loss: 1.461032, ine_loss: 0.618139, ref_loss: 0.135484\n",
      "\t[#  180] train_loss: 2.449019, odo_loss: 1.913738, ine_loss: 0.384514, ref_loss: 0.150767\n",
      "\t[#  360] train_loss: 2.552445, odo_loss: 1.955317, ine_loss: 0.456404, ref_loss: 0.140724\n",
      "\t[#  540] train_loss: 2.583501, odo_loss: 1.861281, ine_loss: 0.539845, ref_loss: 0.182374\n",
      "\t[#  720] train_loss: 2.312693, odo_loss: 1.686088, ine_loss: 0.454408, ref_loss: 0.172196\n",
      "\t[#  900] train_loss: 2.255831, odo_loss: 1.606954, ine_loss: 0.489776, ref_loss: 0.159101\n",
      "\ttrain_loss: 2.421517, odo_loss: 1.740371, ine_loss: 0.525910, ref_loss: 0.155235\n",
      "\tval_loss: 2.329094, odo_loss: 1.634019, ine_loss: 0.522548, ref_loss: 0.172527\n",
      "\t*** Personal Best ***\n",
      "Epoch 145/2000\n",
      "\t[#    0] train_loss: 4.212381, odo_loss: 3.500763, ine_loss: 0.582164, ref_loss: 0.129454\n",
      "\t[#  180] train_loss: 2.320273, odo_loss: 1.609656, ine_loss: 0.551334, ref_loss: 0.159283\n",
      "\t[#  360] train_loss: 2.217244, odo_loss: 1.546138, ine_loss: 0.534198, ref_loss: 0.136908\n",
      "\t[#  540] train_loss: 2.404343, odo_loss: 1.700732, ine_loss: 0.560697, ref_loss: 0.142914\n",
      "\t[#  720] train_loss: 2.293718, odo_loss: 1.638495, ine_loss: 0.502290, ref_loss: 0.152933\n",
      "\t[#  900] train_loss: 2.052813, odo_loss: 1.453589, ine_loss: 0.448095, ref_loss: 0.151128\n",
      "\ttrain_loss: 2.306703, odo_loss: 1.625877, ine_loss: 0.526068, ref_loss: 0.154757\n",
      "\tval_loss: 2.279271, odo_loss: 1.582662, ine_loss: 0.524037, ref_loss: 0.172572\n",
      "\t*** Personal Best ***\n",
      "Epoch 146/2000\n",
      "\t[#    0] train_loss: 2.360293, odo_loss: 1.714587, ine_loss: 0.525710, ref_loss: 0.119996\n",
      "\t[#  180] train_loss: 2.947164, odo_loss: 2.135700, ine_loss: 0.641498, ref_loss: 0.169967\n",
      "\t[#  360] train_loss: 2.473438, odo_loss: 1.666530, ine_loss: 0.660164, ref_loss: 0.146744\n",
      "\t[#  540] train_loss: 2.149248, odo_loss: 1.419408, ine_loss: 0.563225, ref_loss: 0.166614\n",
      "\t[#  720] train_loss: 2.465399, odo_loss: 1.806262, ine_loss: 0.520423, ref_loss: 0.138714\n",
      "\t[#  900] train_loss: 2.696324, odo_loss: 2.011094, ine_loss: 0.534614, ref_loss: 0.150616\n",
      "\ttrain_loss: 2.340043, odo_loss: 1.659034, ine_loss: 0.526380, ref_loss: 0.154630\n",
      "\tval_loss: 2.471286, odo_loss: 1.772117, ine_loss: 0.526209, ref_loss: 0.172960\n",
      "Epoch 147/2000\n",
      "\t[#    0] train_loss: 2.295873, odo_loss: 1.677543, ine_loss: 0.457652, ref_loss: 0.160679\n",
      "\t[#  180] train_loss: 2.435928, odo_loss: 1.747382, ine_loss: 0.533758, ref_loss: 0.154788\n",
      "\t[#  360] train_loss: 2.079503, odo_loss: 1.445636, ine_loss: 0.504694, ref_loss: 0.129174\n",
      "\t[#  540] train_loss: 2.053605, odo_loss: 1.408233, ine_loss: 0.512687, ref_loss: 0.132685\n",
      "\t[#  720] train_loss: 2.420109, odo_loss: 1.580506, ine_loss: 0.649068, ref_loss: 0.190534\n",
      "\t[#  900] train_loss: 2.493285, odo_loss: 1.743509, ine_loss: 0.582890, ref_loss: 0.166886\n",
      "\ttrain_loss: 2.326169, odo_loss: 1.646043, ine_loss: 0.525942, ref_loss: 0.154184\n",
      "\tval_loss: 2.345400, odo_loss: 1.652755, ine_loss: 0.521791, ref_loss: 0.170853\n",
      "Epoch 148/2000\n",
      "\t[#    0] train_loss: 2.267437, odo_loss: 1.397738, ine_loss: 0.682913, ref_loss: 0.186786\n",
      "\t[#  180] train_loss: 2.115192, odo_loss: 1.362442, ine_loss: 0.607181, ref_loss: 0.145569\n",
      "\t[#  360] train_loss: 2.140203, odo_loss: 1.517445, ine_loss: 0.459805, ref_loss: 0.162953\n",
      "\t[#  540] train_loss: 2.163560, odo_loss: 1.467046, ine_loss: 0.529505, ref_loss: 0.167009\n",
      "\t[#  720] train_loss: 2.407763, odo_loss: 1.583447, ine_loss: 0.644604, ref_loss: 0.179712\n",
      "\t[#  900] train_loss: 2.209800, odo_loss: 1.532746, ine_loss: 0.500570, ref_loss: 0.176485\n",
      "\ttrain_loss: 2.294090, odo_loss: 1.615332, ine_loss: 0.524724, ref_loss: 0.154034\n",
      "\tval_loss: 2.366725, odo_loss: 1.676401, ine_loss: 0.521202, ref_loss: 0.169122\n",
      "Epoch 149/2000\n",
      "\t[#    0] train_loss: 2.425827, odo_loss: 1.699619, ine_loss: 0.588697, ref_loss: 0.137510\n",
      "\t[#  180] train_loss: 2.055301, odo_loss: 1.410921, ine_loss: 0.489439, ref_loss: 0.154940\n",
      "\t[#  360] train_loss: 2.651081, odo_loss: 2.020427, ine_loss: 0.482070, ref_loss: 0.148583\n",
      "\t[#  540] train_loss: 2.564617, odo_loss: 1.821007, ine_loss: 0.587660, ref_loss: 0.155949\n",
      "\t[#  720] train_loss: 1.913646, odo_loss: 1.368163, ine_loss: 0.394915, ref_loss: 0.150567\n",
      "\t[#  900] train_loss: 2.476217, odo_loss: 1.689149, ine_loss: 0.598309, ref_loss: 0.188759\n",
      "\ttrain_loss: 2.630370, odo_loss: 1.950704, ine_loss: 0.524303, ref_loss: 0.155363\n",
      "\tval_loss: 2.683647, odo_loss: 1.988697, ine_loss: 0.522198, ref_loss: 0.172752\n",
      "Epoch 150/2000\n",
      "\t[#    0] train_loss: 2.514380, odo_loss: 1.804098, ine_loss: 0.557100, ref_loss: 0.153182\n",
      "\t[#  180] train_loss: 2.585248, odo_loss: 1.806144, ine_loss: 0.637142, ref_loss: 0.141961\n",
      "\t[#  360] train_loss: 2.700351, odo_loss: 1.998097, ine_loss: 0.545026, ref_loss: 0.157228\n",
      "\t[#  540] train_loss: 2.020835, odo_loss: 1.425552, ine_loss: 0.436133, ref_loss: 0.159150\n",
      "\t[#  720] train_loss: 2.265681, odo_loss: 1.511971, ine_loss: 0.598881, ref_loss: 0.154829\n",
      "\t[#  900] train_loss: 2.184161, odo_loss: 1.597738, ine_loss: 0.454191, ref_loss: 0.132232\n",
      "\ttrain_loss: 2.408301, odo_loss: 1.729853, ine_loss: 0.523880, ref_loss: 0.154568\n",
      "\tval_loss: 2.418426, odo_loss: 1.724345, ine_loss: 0.520446, ref_loss: 0.173635\n",
      "Epoch 151/2000\n",
      "\t[#    0] train_loss: 2.414569, odo_loss: 1.620399, ine_loss: 0.631679, ref_loss: 0.162491\n",
      "\t[#  180] train_loss: 2.265169, odo_loss: 1.692011, ine_loss: 0.437542, ref_loss: 0.135617\n",
      "\t[#  360] train_loss: 2.047353, odo_loss: 1.408826, ine_loss: 0.472382, ref_loss: 0.166145\n",
      "\t[#  540] train_loss: 2.493058, odo_loss: 1.749998, ine_loss: 0.555904, ref_loss: 0.187156\n",
      "\t[#  720] train_loss: 1.937928, odo_loss: 1.365542, ine_loss: 0.438934, ref_loss: 0.133453\n",
      "\t[#  900] train_loss: 2.338266, odo_loss: 1.629690, ine_loss: 0.569348, ref_loss: 0.139227\n",
      "\ttrain_loss: 2.347844, odo_loss: 1.669773, ine_loss: 0.523799, ref_loss: 0.154272\n",
      "\tval_loss: 2.447092, odo_loss: 1.750641, ine_loss: 0.524521, ref_loss: 0.171930\n",
      "Epoch 152/2000\n",
      "\t[#    0] train_loss: 2.361466, odo_loss: 1.617242, ine_loss: 0.597620, ref_loss: 0.146603\n",
      "\t[#  180] train_loss: 2.035676, odo_loss: 1.391537, ine_loss: 0.504745, ref_loss: 0.139394\n",
      "\t[#  360] train_loss: 2.052724, odo_loss: 1.424003, ine_loss: 0.465754, ref_loss: 0.162968\n",
      "\t[#  540] train_loss: 2.241442, odo_loss: 1.607739, ine_loss: 0.494924, ref_loss: 0.138779\n",
      "\t[#  720] train_loss: 2.710573, odo_loss: 2.002107, ine_loss: 0.551817, ref_loss: 0.156649\n",
      "\t[#  900] train_loss: 2.109416, odo_loss: 1.481855, ine_loss: 0.444311, ref_loss: 0.183250\n",
      "\ttrain_loss: 2.291755, odo_loss: 1.613852, ine_loss: 0.524139, ref_loss: 0.153765\n",
      "\tval_loss: 2.242440, odo_loss: 1.547262, ine_loss: 0.522926, ref_loss: 0.172251\n",
      "\t*** Personal Best ***\n",
      "Epoch 153/2000\n",
      "\t[#    0] train_loss: 2.097687, odo_loss: 1.419310, ine_loss: 0.541210, ref_loss: 0.137167\n",
      "\t[#  180] train_loss: 2.059354, odo_loss: 1.305283, ine_loss: 0.561216, ref_loss: 0.192855\n",
      "\t[#  360] train_loss: 2.659714, odo_loss: 1.969492, ine_loss: 0.524766, ref_loss: 0.165456\n",
      "\t[#  540] train_loss: 2.442112, odo_loss: 1.676262, ine_loss: 0.608180, ref_loss: 0.157671\n",
      "\t[#  720] train_loss: 2.219795, odo_loss: 1.512083, ine_loss: 0.532498, ref_loss: 0.175214\n",
      "\t[#  900] train_loss: 2.508364, odo_loss: 1.901555, ine_loss: 0.460237, ref_loss: 0.146572\n",
      "\ttrain_loss: 2.360572, odo_loss: 1.683658, ine_loss: 0.523027, ref_loss: 0.153887\n",
      "\tval_loss: 2.586445, odo_loss: 1.894672, ine_loss: 0.519277, ref_loss: 0.172497\n",
      "Epoch 154/2000\n",
      "\t[#    0] train_loss: 2.225405, odo_loss: 1.460860, ine_loss: 0.601772, ref_loss: 0.162772\n",
      "\t[#  180] train_loss: 2.041641, odo_loss: 1.375147, ine_loss: 0.505003, ref_loss: 0.161490\n",
      "\t[#  360] train_loss: 1.801400, odo_loss: 1.229928, ine_loss: 0.421333, ref_loss: 0.150140\n",
      "\t[#  540] train_loss: 2.009810, odo_loss: 1.368787, ine_loss: 0.485831, ref_loss: 0.155192\n",
      "\t[#  720] train_loss: 2.081308, odo_loss: 1.500603, ine_loss: 0.445924, ref_loss: 0.134781\n",
      "\t[#  900] train_loss: 2.069871, odo_loss: 1.439699, ine_loss: 0.504811, ref_loss: 0.125361\n",
      "\ttrain_loss: 2.409949, odo_loss: 1.733710, ine_loss: 0.521880, ref_loss: 0.154359\n",
      "\tval_loss: 2.284218, odo_loss: 1.591557, ine_loss: 0.520081, ref_loss: 0.172580\n",
      "Epoch 155/2000\n",
      "\t[#    0] train_loss: 2.471642, odo_loss: 1.877655, ine_loss: 0.446808, ref_loss: 0.147179\n",
      "\t[#  180] train_loss: 2.320264, odo_loss: 1.586011, ine_loss: 0.586925, ref_loss: 0.147328\n",
      "\t[#  360] train_loss: 2.241468, odo_loss: 1.549381, ine_loss: 0.548764, ref_loss: 0.143323\n",
      "\t[#  540] train_loss: 2.220926, odo_loss: 1.544558, ine_loss: 0.508934, ref_loss: 0.167434\n",
      "\t[#  720] train_loss: 2.413803, odo_loss: 1.702237, ine_loss: 0.586270, ref_loss: 0.125296\n",
      "\t[#  900] train_loss: 2.285164, odo_loss: 1.578948, ine_loss: 0.551435, ref_loss: 0.154781\n",
      "\ttrain_loss: 2.305805, odo_loss: 1.629901, ine_loss: 0.522538, ref_loss: 0.153366\n",
      "\tval_loss: 2.332852, odo_loss: 1.638891, ine_loss: 0.522644, ref_loss: 0.171318\n",
      "Epoch 156/2000\n",
      "\t[#    0] train_loss: 2.247417, odo_loss: 1.570842, ine_loss: 0.515522, ref_loss: 0.161054\n",
      "\t[#  180] train_loss: 1.956585, odo_loss: 1.388894, ine_loss: 0.409470, ref_loss: 0.158221\n",
      "\t[#  360] train_loss: 2.038647, odo_loss: 1.445087, ine_loss: 0.457224, ref_loss: 0.136335\n",
      "\t[#  540] train_loss: 2.017896, odo_loss: 1.378487, ine_loss: 0.476435, ref_loss: 0.162974\n",
      "\t[#  720] train_loss: 2.056110, odo_loss: 1.545817, ine_loss: 0.383154, ref_loss: 0.127139\n",
      "\t[#  900] train_loss: 2.068743, odo_loss: 1.422514, ine_loss: 0.497229, ref_loss: 0.149001\n",
      "\ttrain_loss: 2.257942, odo_loss: 1.581832, ine_loss: 0.523040, ref_loss: 0.153070\n",
      "\tval_loss: 2.278140, odo_loss: 1.587934, ine_loss: 0.518602, ref_loss: 0.171605\n",
      "Epoch 157/2000\n",
      "\t[#    0] train_loss: 2.402443, odo_loss: 1.752432, ine_loss: 0.477291, ref_loss: 0.172720\n",
      "\t[#  180] train_loss: 2.366059, odo_loss: 1.529974, ine_loss: 0.658129, ref_loss: 0.177957\n",
      "\t[#  360] train_loss: 2.173916, odo_loss: 1.520868, ine_loss: 0.501875, ref_loss: 0.151172\n",
      "\t[#  540] train_loss: 2.252174, odo_loss: 1.532892, ine_loss: 0.520598, ref_loss: 0.198684\n",
      "\t[#  720] train_loss: 2.301218, odo_loss: 1.538451, ine_loss: 0.584300, ref_loss: 0.178466\n",
      "\t[#  900] train_loss: 2.258937, odo_loss: 1.644704, ine_loss: 0.489290, ref_loss: 0.124943\n",
      "\ttrain_loss: 2.253560, odo_loss: 1.578742, ine_loss: 0.522043, ref_loss: 0.152775\n",
      "\tval_loss: 2.236460, odo_loss: 1.547163, ine_loss: 0.518990, ref_loss: 0.170307\n",
      "\t*** Personal Best ***\n",
      "Epoch 158/2000\n",
      "\t[#    0] train_loss: 2.365628, odo_loss: 1.762691, ine_loss: 0.473531, ref_loss: 0.129406\n",
      "\t[#  180] train_loss: 2.051238, odo_loss: 1.364549, ine_loss: 0.545997, ref_loss: 0.140692\n",
      "\t[#  360] train_loss: 2.291693, odo_loss: 1.595474, ine_loss: 0.529552, ref_loss: 0.166667\n",
      "\t[#  540] train_loss: 2.925859, odo_loss: 2.195552, ine_loss: 0.549606, ref_loss: 0.180701\n",
      "\t[#  720] train_loss: 2.041916, odo_loss: 1.413497, ine_loss: 0.479502, ref_loss: 0.148917\n",
      "\t[#  900] train_loss: 2.467190, odo_loss: 1.702480, ine_loss: 0.616450, ref_loss: 0.148260\n",
      "\ttrain_loss: 2.248934, odo_loss: 1.574809, ine_loss: 0.521425, ref_loss: 0.152700\n",
      "\tval_loss: 2.303345, odo_loss: 1.613675, ine_loss: 0.517522, ref_loss: 0.172147\n",
      "Epoch 159/2000\n",
      "\t[#    0] train_loss: 2.294818, odo_loss: 1.604513, ine_loss: 0.551004, ref_loss: 0.139301\n",
      "\t[#  180] train_loss: 2.669291, odo_loss: 1.882576, ine_loss: 0.644094, ref_loss: 0.142621\n",
      "\t[#  360] train_loss: 3.238990, odo_loss: 2.561706, ine_loss: 0.552204, ref_loss: 0.125079\n",
      "\t[#  540] train_loss: 2.766617, odo_loss: 1.927818, ine_loss: 0.647528, ref_loss: 0.191270\n",
      "\t[#  720] train_loss: 2.744225, odo_loss: 2.102398, ine_loss: 0.517712, ref_loss: 0.124115\n",
      "\t[#  900] train_loss: 2.962947, odo_loss: 2.287278, ine_loss: 0.507532, ref_loss: 0.168137\n",
      "\ttrain_loss: 2.462288, odo_loss: 1.788032, ine_loss: 0.521313, ref_loss: 0.152943\n",
      "\tval_loss: 2.729053, odo_loss: 2.037724, ine_loss: 0.518644, ref_loss: 0.172684\n",
      "Epoch 160/2000\n",
      "\t[#    0] train_loss: 2.208226, odo_loss: 1.640544, ine_loss: 0.426648, ref_loss: 0.141034\n",
      "\t[#  180] train_loss: 2.000405, odo_loss: 1.419433, ine_loss: 0.430877, ref_loss: 0.150095\n",
      "\t[#  360] train_loss: 2.249780, odo_loss: 1.618146, ine_loss: 0.499372, ref_loss: 0.132262\n",
      "\t[#  540] train_loss: 2.322414, odo_loss: 1.665582, ine_loss: 0.486862, ref_loss: 0.169970\n",
      "\t[#  720] train_loss: 2.324557, odo_loss: 1.686819, ine_loss: 0.494979, ref_loss: 0.142759\n",
      "\t[#  900] train_loss: 2.292491, odo_loss: 1.729748, ine_loss: 0.407143, ref_loss: 0.155601\n",
      "\ttrain_loss: 2.328748, odo_loss: 1.654507, ine_loss: 0.521346, ref_loss: 0.152895\n",
      "\tval_loss: 2.401098, odo_loss: 1.709180, ine_loss: 0.520224, ref_loss: 0.171694\n",
      "Epoch 161/2000\n",
      "\t[#    0] train_loss: 2.845440, odo_loss: 2.041366, ine_loss: 0.654233, ref_loss: 0.149841\n",
      "\t[#  180] train_loss: 2.169161, odo_loss: 1.438745, ine_loss: 0.578888, ref_loss: 0.151528\n",
      "\t[#  360] train_loss: 2.009528, odo_loss: 1.282751, ine_loss: 0.557526, ref_loss: 0.169251\n",
      "\t[#  540] train_loss: 2.242019, odo_loss: 1.624813, ine_loss: 0.465544, ref_loss: 0.151663\n",
      "\t[#  720] train_loss: 2.174013, odo_loss: 1.543449, ine_loss: 0.451419, ref_loss: 0.179144\n",
      "\t[#  900] train_loss: 2.301064, odo_loss: 1.644660, ine_loss: 0.493325, ref_loss: 0.163078\n",
      "\ttrain_loss: 2.276328, odo_loss: 1.603281, ine_loss: 0.520389, ref_loss: 0.152658\n",
      "\tval_loss: 2.397040, odo_loss: 1.713724, ine_loss: 0.512077, ref_loss: 0.171239\n",
      "Epoch 162/2000\n",
      "\t[#    0] train_loss: 2.312366, odo_loss: 1.574461, ine_loss: 0.594917, ref_loss: 0.142988\n",
      "\t[#  180] train_loss: 2.255030, odo_loss: 1.525405, ine_loss: 0.528699, ref_loss: 0.200926\n",
      "\t[#  360] train_loss: 2.607583, odo_loss: 1.900909, ine_loss: 0.553497, ref_loss: 0.153177\n",
      "\t[#  540] train_loss: 2.225003, odo_loss: 1.577401, ine_loss: 0.484297, ref_loss: 0.163305\n",
      "\t[#  720] train_loss: 2.323941, odo_loss: 1.786778, ine_loss: 0.401577, ref_loss: 0.135586\n",
      "\t[#  900] train_loss: 2.316967, odo_loss: 1.692045, ine_loss: 0.482098, ref_loss: 0.142824\n",
      "\ttrain_loss: 2.273581, odo_loss: 1.601630, ine_loss: 0.519801, ref_loss: 0.152150\n",
      "\tval_loss: 2.449790, odo_loss: 1.766431, ine_loss: 0.512352, ref_loss: 0.171006\n",
      "Epoch 163/2000\n",
      "\t[#    0] train_loss: 2.284926, odo_loss: 1.727079, ine_loss: 0.417648, ref_loss: 0.140200\n",
      "\t[#  180] train_loss: 1.980829, odo_loss: 1.334740, ine_loss: 0.496284, ref_loss: 0.149805\n",
      "\t[#  360] train_loss: 2.351758, odo_loss: 1.767425, ine_loss: 0.414774, ref_loss: 0.169560\n",
      "\t[#  540] train_loss: 2.091927, odo_loss: 1.341445, ine_loss: 0.591330, ref_loss: 0.159152\n",
      "\t[#  720] train_loss: 2.317992, odo_loss: 1.609690, ine_loss: 0.537522, ref_loss: 0.170780\n",
      "\t[#  900] train_loss: 2.390065, odo_loss: 1.663343, ine_loss: 0.583356, ref_loss: 0.143366\n",
      "\ttrain_loss: 2.309042, odo_loss: 1.638369, ine_loss: 0.518133, ref_loss: 0.152540\n",
      "\tval_loss: 2.271111, odo_loss: 1.585669, ine_loss: 0.513609, ref_loss: 0.171833\n",
      "Epoch 164/2000\n",
      "\t[#    0] train_loss: 2.037948, odo_loss: 1.430171, ine_loss: 0.479386, ref_loss: 0.128390\n",
      "\t[#  180] train_loss: 2.451795, odo_loss: 1.772657, ine_loss: 0.514258, ref_loss: 0.164879\n",
      "\t[#  360] train_loss: 2.164460, odo_loss: 1.526861, ine_loss: 0.512757, ref_loss: 0.124842\n",
      "\t[#  540] train_loss: 2.038291, odo_loss: 1.484114, ine_loss: 0.393767, ref_loss: 0.160411\n",
      "\t[#  720] train_loss: 2.280828, odo_loss: 1.592276, ine_loss: 0.510614, ref_loss: 0.177938\n",
      "\t[#  900] train_loss: 2.042182, odo_loss: 1.359988, ine_loss: 0.546611, ref_loss: 0.135583\n",
      "\ttrain_loss: 2.344046, odo_loss: 1.674670, ine_loss: 0.516530, ref_loss: 0.152846\n",
      "\tval_loss: 2.399500, odo_loss: 1.710095, ine_loss: 0.517759, ref_loss: 0.171645\n",
      "Epoch 165/2000\n",
      "\t[#    0] train_loss: 2.628117, odo_loss: 1.896832, ine_loss: 0.581857, ref_loss: 0.149428\n",
      "\t[#  180] train_loss: 2.207589, odo_loss: 1.563463, ine_loss: 0.497614, ref_loss: 0.146512\n",
      "\t[#  360] train_loss: 2.153492, odo_loss: 1.487782, ine_loss: 0.525362, ref_loss: 0.140348\n",
      "\t[#  540] train_loss: 2.396209, odo_loss: 1.768180, ine_loss: 0.478743, ref_loss: 0.149286\n",
      "\t[#  720] train_loss: 2.179716, odo_loss: 1.539129, ine_loss: 0.461214, ref_loss: 0.179372\n",
      "\t[#  900] train_loss: 2.640631, odo_loss: 1.918343, ine_loss: 0.573616, ref_loss: 0.148672\n",
      "\ttrain_loss: 2.262343, odo_loss: 1.591543, ine_loss: 0.518174, ref_loss: 0.152627\n",
      "\tval_loss: 2.282095, odo_loss: 1.598171, ine_loss: 0.514824, ref_loss: 0.169100\n",
      "Epoch 166/2000\n",
      "\t[#    0] train_loss: 2.635255, odo_loss: 1.829234, ine_loss: 0.645306, ref_loss: 0.160715\n",
      "\t[#  180] train_loss: 2.221081, odo_loss: 1.592842, ine_loss: 0.486361, ref_loss: 0.141878\n",
      "\t[#  360] train_loss: 2.181295, odo_loss: 1.427572, ine_loss: 0.565354, ref_loss: 0.188369\n",
      "\t[#  540] train_loss: 2.530285, odo_loss: 1.909904, ine_loss: 0.492990, ref_loss: 0.127392\n",
      "\t[#  720] train_loss: 2.523822, odo_loss: 1.830018, ine_loss: 0.529824, ref_loss: 0.163981\n",
      "\t[#  900] train_loss: 2.519525, odo_loss: 1.831501, ine_loss: 0.535232, ref_loss: 0.152792\n",
      "\ttrain_loss: 2.242198, odo_loss: 1.571242, ine_loss: 0.519098, ref_loss: 0.151858\n",
      "\tval_loss: 2.235385, odo_loss: 1.552657, ine_loss: 0.514740, ref_loss: 0.167988\n",
      "Epoch 167/2000\n",
      "\t[#    0] train_loss: 2.421518, odo_loss: 1.828629, ine_loss: 0.475979, ref_loss: 0.116910\n",
      "\t[#  180] train_loss: 2.030860, odo_loss: 1.399978, ine_loss: 0.478517, ref_loss: 0.152365\n",
      "\t[#  360] train_loss: 1.905112, odo_loss: 1.213246, ine_loss: 0.513765, ref_loss: 0.178102\n",
      "\t[#  540] train_loss: 2.271757, odo_loss: 1.488896, ine_loss: 0.612843, ref_loss: 0.170018\n",
      "\t[#  720] train_loss: 1.861778, odo_loss: 1.292114, ine_loss: 0.422632, ref_loss: 0.147032\n",
      "\t[#  900] train_loss: 2.282433, odo_loss: 1.660939, ine_loss: 0.482893, ref_loss: 0.138602\n",
      "\ttrain_loss: 2.270694, odo_loss: 1.601359, ine_loss: 0.516920, ref_loss: 0.152415\n",
      "\tval_loss: 3.796853, odo_loss: 3.115709, ine_loss: 0.510494, ref_loss: 0.170650\n",
      "Epoch 168/2000\n",
      "\t[#    0] train_loss: 2.230661, odo_loss: 1.581787, ine_loss: 0.477443, ref_loss: 0.171431\n",
      "\t[#  180] train_loss: 2.223475, odo_loss: 1.568598, ine_loss: 0.489700, ref_loss: 0.165177\n",
      "\t[#  360] train_loss: 2.433019, odo_loss: 1.709651, ine_loss: 0.539834, ref_loss: 0.183534\n",
      "\t[#  540] train_loss: 2.386369, odo_loss: 1.575966, ine_loss: 0.611536, ref_loss: 0.198868\n",
      "\t[#  720] train_loss: 2.621916, odo_loss: 1.875782, ine_loss: 0.595403, ref_loss: 0.150730\n",
      "\t[#  900] train_loss: 2.504545, odo_loss: 1.849360, ine_loss: 0.514015, ref_loss: 0.141169\n",
      "\ttrain_loss: 2.464459, odo_loss: 1.794878, ine_loss: 0.516257, ref_loss: 0.153324\n",
      "\tval_loss: 2.329033, odo_loss: 1.647405, ine_loss: 0.510591, ref_loss: 0.171037\n",
      "Epoch 169/2000\n",
      "\t[#    0] train_loss: 2.126060, odo_loss: 1.570042, ine_loss: 0.427542, ref_loss: 0.128475\n",
      "\t[#  180] train_loss: 2.452224, odo_loss: 1.811864, ine_loss: 0.504408, ref_loss: 0.135953\n",
      "\t[#  360] train_loss: 1.849006, odo_loss: 1.337790, ine_loss: 0.371999, ref_loss: 0.139217\n",
      "\t[#  540] train_loss: 2.071845, odo_loss: 1.514968, ine_loss: 0.399192, ref_loss: 0.157684\n",
      "\t[#  720] train_loss: 2.526255, odo_loss: 1.916256, ine_loss: 0.473279, ref_loss: 0.136720\n",
      "\t[#  900] train_loss: 2.377265, odo_loss: 1.742508, ine_loss: 0.474238, ref_loss: 0.160519\n",
      "\ttrain_loss: 2.305143, odo_loss: 1.637434, ine_loss: 0.515007, ref_loss: 0.152701\n",
      "\tval_loss: 2.341972, odo_loss: 1.657165, ine_loss: 0.513320, ref_loss: 0.171487\n",
      "Epoch 170/2000\n",
      "\t[#    0] train_loss: 2.216598, odo_loss: 1.596009, ine_loss: 0.466216, ref_loss: 0.154373\n",
      "\t[#  180] train_loss: 1.947225, odo_loss: 1.355593, ine_loss: 0.444556, ref_loss: 0.147077\n",
      "\t[#  360] train_loss: 2.255690, odo_loss: 1.573548, ine_loss: 0.529623, ref_loss: 0.152519\n",
      "\t[#  540] train_loss: 2.430310, odo_loss: 1.794696, ine_loss: 0.490212, ref_loss: 0.145402\n",
      "\t[#  720] train_loss: 2.425705, odo_loss: 1.742997, ine_loss: 0.553840, ref_loss: 0.128867\n",
      "\t[#  900] train_loss: 2.326735, odo_loss: 1.667480, ine_loss: 0.516328, ref_loss: 0.142927\n",
      "\ttrain_loss: 2.308830, odo_loss: 1.639802, ine_loss: 0.515988, ref_loss: 0.153040\n",
      "\tval_loss: 2.381016, odo_loss: 1.696477, ine_loss: 0.514544, ref_loss: 0.169995\n",
      "Epoch 171/2000\n",
      "\t[#    0] train_loss: 2.462456, odo_loss: 1.607936, ine_loss: 0.693077, ref_loss: 0.161443\n",
      "\t[#  180] train_loss: 2.447362, odo_loss: 1.711096, ine_loss: 0.546324, ref_loss: 0.189943\n",
      "\t[#  360] train_loss: 2.035050, odo_loss: 1.436696, ine_loss: 0.439982, ref_loss: 0.158373\n",
      "\t[#  540] train_loss: 2.047223, odo_loss: 1.493622, ine_loss: 0.402080, ref_loss: 0.151521\n",
      "\t[#  720] train_loss: 2.229747, odo_loss: 1.585034, ine_loss: 0.515950, ref_loss: 0.128763\n",
      "\t[#  900] train_loss: 2.799069, odo_loss: 1.998349, ine_loss: 0.637148, ref_loss: 0.163571\n",
      "\ttrain_loss: 2.243211, odo_loss: 1.575643, ine_loss: 0.515166, ref_loss: 0.152402\n",
      "\tval_loss: 2.336001, odo_loss: 1.654442, ine_loss: 0.511880, ref_loss: 0.169678\n",
      "Epoch 172/2000\n",
      "\t[#    0] train_loss: 2.485271, odo_loss: 1.836527, ine_loss: 0.489399, ref_loss: 0.159345\n",
      "\t[#  180] train_loss: 2.065808, odo_loss: 1.414338, ine_loss: 0.505169, ref_loss: 0.146301\n",
      "\t[#  360] train_loss: 2.577984, odo_loss: 1.880338, ine_loss: 0.534422, ref_loss: 0.163224\n",
      "\t[#  540] train_loss: 2.387190, odo_loss: 1.816827, ine_loss: 0.442310, ref_loss: 0.128053\n",
      "\t[#  720] train_loss: 1.662509, odo_loss: 1.103364, ine_loss: 0.417480, ref_loss: 0.141665\n",
      "\t[#  900] train_loss: 2.750866, odo_loss: 2.058712, ine_loss: 0.516886, ref_loss: 0.175267\n",
      "\ttrain_loss: 2.257261, odo_loss: 1.589489, ine_loss: 0.515512, ref_loss: 0.152260\n",
      "\tval_loss: 2.470345, odo_loss: 1.784794, ine_loss: 0.513189, ref_loss: 0.172362\n",
      "Epoch 173/2000\n",
      "\t[#    0] train_loss: 2.105388, odo_loss: 1.544529, ine_loss: 0.427018, ref_loss: 0.133841\n",
      "\t[#  180] train_loss: 2.063159, odo_loss: 1.419081, ine_loss: 0.489615, ref_loss: 0.154462\n",
      "\t[#  360] train_loss: 2.364977, odo_loss: 1.675624, ine_loss: 0.536471, ref_loss: 0.152882\n",
      "\t[#  540] train_loss: 2.141905, odo_loss: 1.524769, ine_loss: 0.474534, ref_loss: 0.142602\n",
      "\t[#  720] train_loss: 2.308856, odo_loss: 1.558891, ine_loss: 0.588905, ref_loss: 0.161060\n",
      "\t[#  900] train_loss: 2.546058, odo_loss: 1.916254, ine_loss: 0.455373, ref_loss: 0.174431\n",
      "\ttrain_loss: 2.272813, odo_loss: 1.604327, ine_loss: 0.515861, ref_loss: 0.152625\n",
      "\tval_loss: 2.224267, odo_loss: 1.541983, ine_loss: 0.509516, ref_loss: 0.172768\n",
      "\t*** Personal Best ***\n",
      "Epoch 174/2000\n",
      "\t[#    0] train_loss: 2.242508, odo_loss: 1.467996, ine_loss: 0.603216, ref_loss: 0.171296\n",
      "\t[#  180] train_loss: 2.164462, odo_loss: 1.609500, ine_loss: 0.406965, ref_loss: 0.147997\n",
      "\t[#  360] train_loss: 1.955020, odo_loss: 1.212872, ine_loss: 0.606970, ref_loss: 0.135178\n",
      "\t[#  540] train_loss: 2.328387, odo_loss: 1.628281, ine_loss: 0.554621, ref_loss: 0.145486\n",
      "\t[#  720] train_loss: 2.373520, odo_loss: 1.684531, ine_loss: 0.541036, ref_loss: 0.147952\n",
      "\t[#  900] train_loss: 2.245779, odo_loss: 1.604180, ine_loss: 0.477109, ref_loss: 0.164490\n",
      "\ttrain_loss: 2.210653, odo_loss: 1.542876, ine_loss: 0.515432, ref_loss: 0.152345\n",
      "\tval_loss: 2.223349, odo_loss: 1.537281, ine_loss: 0.514006, ref_loss: 0.172062\n",
      "\t*** Personal Best ***\n",
      "Epoch 175/2000\n",
      "\t[#    0] train_loss: 2.141470, odo_loss: 1.468165, ine_loss: 0.515365, ref_loss: 0.157941\n",
      "\t[#  180] train_loss: 2.082280, odo_loss: 1.422015, ine_loss: 0.503673, ref_loss: 0.156592\n",
      "\t[#  360] train_loss: 2.202920, odo_loss: 1.543282, ine_loss: 0.522900, ref_loss: 0.136739\n",
      "\t[#  540] train_loss: 1.876580, odo_loss: 1.246105, ine_loss: 0.479244, ref_loss: 0.151231\n",
      "\t[#  720] train_loss: 2.187060, odo_loss: 1.447605, ine_loss: 0.589784, ref_loss: 0.149670\n",
      "\t[#  900] train_loss: 2.246952, odo_loss: 1.686117, ine_loss: 0.432871, ref_loss: 0.127963\n",
      "\ttrain_loss: 2.301095, odo_loss: 1.634883, ine_loss: 0.514312, ref_loss: 0.151900\n",
      "\tval_loss: 2.415928, odo_loss: 1.735094, ine_loss: 0.509517, ref_loss: 0.171316\n",
      "Epoch 176/2000\n",
      "\t[#    0] train_loss: 2.338973, odo_loss: 1.498681, ine_loss: 0.680634, ref_loss: 0.159657\n",
      "\t[#  180] train_loss: 2.862987, odo_loss: 2.227783, ine_loss: 0.468450, ref_loss: 0.166754\n",
      "\t[#  360] train_loss: 2.274507, odo_loss: 1.464115, ine_loss: 0.666946, ref_loss: 0.143445\n",
      "\t[#  540] train_loss: 2.472331, odo_loss: 1.732584, ine_loss: 0.570255, ref_loss: 0.169491\n",
      "\t[#  720] train_loss: 2.595604, odo_loss: 1.856450, ine_loss: 0.597817, ref_loss: 0.141336\n",
      "\t[#  900] train_loss: 2.681567, odo_loss: 1.974463, ine_loss: 0.534916, ref_loss: 0.172188\n",
      "\ttrain_loss: 2.245551, odo_loss: 1.579138, ine_loss: 0.514076, ref_loss: 0.152336\n",
      "\tval_loss: 2.306775, odo_loss: 1.620389, ine_loss: 0.515001, ref_loss: 0.171386\n",
      "Epoch 177/2000\n",
      "\t[#    0] train_loss: 2.289548, odo_loss: 1.562772, ine_loss: 0.574048, ref_loss: 0.152728\n",
      "\t[#  180] train_loss: 2.179782, odo_loss: 1.572578, ine_loss: 0.457259, ref_loss: 0.149945\n",
      "\t[#  360] train_loss: 1.946253, odo_loss: 1.349995, ine_loss: 0.443478, ref_loss: 0.152780\n",
      "\t[#  540] train_loss: 2.462577, odo_loss: 1.793251, ine_loss: 0.529202, ref_loss: 0.140125\n",
      "\t[#  720] train_loss: 2.325583, odo_loss: 1.598602, ine_loss: 0.604826, ref_loss: 0.122155\n",
      "\t[#  900] train_loss: 2.564742, odo_loss: 1.869164, ine_loss: 0.565415, ref_loss: 0.130163\n",
      "\ttrain_loss: 2.293937, odo_loss: 1.627475, ine_loss: 0.514783, ref_loss: 0.151678\n",
      "\tval_loss: 2.404938, odo_loss: 1.721041, ine_loss: 0.511676, ref_loss: 0.172221\n",
      "Epoch 178/2000\n",
      "\t[#    0] train_loss: 4.361572, odo_loss: 3.667782, ine_loss: 0.544825, ref_loss: 0.148966\n",
      "\t[#  180] train_loss: 2.293590, odo_loss: 1.650002, ine_loss: 0.500850, ref_loss: 0.142738\n",
      "\t[#  360] train_loss: 1.817203, odo_loss: 1.094824, ine_loss: 0.576587, ref_loss: 0.145792\n",
      "\t[#  540] train_loss: 2.142740, odo_loss: 1.513956, ine_loss: 0.479927, ref_loss: 0.148857\n",
      "\t[#  720] train_loss: 2.237677, odo_loss: 1.534101, ine_loss: 0.560183, ref_loss: 0.143393\n",
      "\t[#  900] train_loss: 2.077396, odo_loss: 1.472145, ine_loss: 0.452600, ref_loss: 0.152652\n",
      "\ttrain_loss: 2.383007, odo_loss: 1.717592, ine_loss: 0.512852, ref_loss: 0.152564\n",
      "\tval_loss: 2.268147, odo_loss: 1.592488, ine_loss: 0.504633, ref_loss: 0.171026\n",
      "Epoch 179/2000\n",
      "\t[#    0] train_loss: 2.071564, odo_loss: 1.409859, ine_loss: 0.517798, ref_loss: 0.143907\n",
      "\t[#  180] train_loss: 2.003487, odo_loss: 1.348824, ine_loss: 0.500174, ref_loss: 0.154489\n",
      "\t[#  360] train_loss: 2.405919, odo_loss: 1.696228, ine_loss: 0.559710, ref_loss: 0.149982\n",
      "\t[#  540] train_loss: 2.161677, odo_loss: 1.517832, ine_loss: 0.505872, ref_loss: 0.137974\n",
      "\t[#  720] train_loss: 2.373638, odo_loss: 1.703237, ine_loss: 0.518641, ref_loss: 0.151761\n",
      "\t[#  900] train_loss: 2.520981, odo_loss: 1.814255, ine_loss: 0.546317, ref_loss: 0.160409\n",
      "\ttrain_loss: 2.207968, odo_loss: 1.543549, ine_loss: 0.512616, ref_loss: 0.151803\n",
      "\tval_loss: 2.261171, odo_loss: 1.579997, ine_loss: 0.508859, ref_loss: 0.172315\n",
      "Epoch 180/2000\n",
      "\t[#    0] train_loss: 2.273892, odo_loss: 1.536117, ine_loss: 0.575874, ref_loss: 0.161902\n",
      "\t[#  180] train_loss: 2.367232, odo_loss: 1.511796, ine_loss: 0.670199, ref_loss: 0.185237\n",
      "\t[#  360] train_loss: 1.936869, odo_loss: 1.350337, ine_loss: 0.448812, ref_loss: 0.137720\n",
      "\t[#  540] train_loss: 2.354913, odo_loss: 1.729761, ine_loss: 0.480183, ref_loss: 0.144969\n",
      "\t[#  720] train_loss: 1.853423, odo_loss: 1.215046, ine_loss: 0.493963, ref_loss: 0.144415\n",
      "\t[#  900] train_loss: 2.277968, odo_loss: 1.448122, ine_loss: 0.668734, ref_loss: 0.161112\n",
      "\ttrain_loss: 2.182302, odo_loss: 1.516558, ine_loss: 0.513673, ref_loss: 0.152071\n",
      "\tval_loss: 2.217020, odo_loss: 1.537116, ine_loss: 0.508365, ref_loss: 0.171538\n",
      "\t*** Personal Best ***\n",
      "Epoch 181/2000\n",
      "\t[#    0] train_loss: 2.249251, odo_loss: 1.616022, ine_loss: 0.470191, ref_loss: 0.163039\n",
      "\t[#  180] train_loss: 2.108510, odo_loss: 1.430022, ine_loss: 0.540229, ref_loss: 0.138259\n",
      "\t[#  360] train_loss: 2.299214, odo_loss: 1.664114, ine_loss: 0.474534, ref_loss: 0.160566\n",
      "\t[#  540] train_loss: 2.337992, odo_loss: 1.712179, ine_loss: 0.480837, ref_loss: 0.144976\n",
      "\t[#  720] train_loss: 2.412184, odo_loss: 1.736900, ine_loss: 0.529660, ref_loss: 0.145624\n",
      "\t[#  900] train_loss: 2.813136, odo_loss: 2.061718, ine_loss: 0.580063, ref_loss: 0.171354\n",
      "\ttrain_loss: 2.185824, odo_loss: 1.521538, ine_loss: 0.513013, ref_loss: 0.151273\n",
      "\tval_loss: 2.232065, odo_loss: 1.548541, ine_loss: 0.512822, ref_loss: 0.170702\n",
      "Epoch 182/2000\n",
      "\t[#    0] train_loss: 3.464357, odo_loss: 2.755643, ine_loss: 0.548661, ref_loss: 0.160054\n",
      "\t[#  180] train_loss: 2.224917, odo_loss: 1.570179, ine_loss: 0.519365, ref_loss: 0.135373\n",
      "\t[#  360] train_loss: 2.120139, odo_loss: 1.283024, ine_loss: 0.661670, ref_loss: 0.175444\n",
      "\t[#  540] train_loss: 2.482586, odo_loss: 1.739804, ine_loss: 0.571225, ref_loss: 0.171557\n",
      "\t[#  720] train_loss: 2.186474, odo_loss: 1.508697, ine_loss: 0.509085, ref_loss: 0.168691\n",
      "\t[#  900] train_loss: 2.582443, odo_loss: 1.890360, ine_loss: 0.546543, ref_loss: 0.145541\n",
      "\ttrain_loss: 2.193228, odo_loss: 1.529243, ine_loss: 0.513144, ref_loss: 0.150842\n",
      "\tval_loss: 2.245901, odo_loss: 1.558985, ine_loss: 0.514684, ref_loss: 0.172231\n",
      "Epoch 183/2000\n",
      "\t[#    0] train_loss: 2.549387, odo_loss: 1.737310, ine_loss: 0.657600, ref_loss: 0.154477\n",
      "\t[#  180] train_loss: 2.210526, odo_loss: 1.576677, ine_loss: 0.456494, ref_loss: 0.177355\n",
      "\t[#  360] train_loss: 2.213532, odo_loss: 1.505208, ine_loss: 0.540524, ref_loss: 0.167800\n",
      "\t[#  540] train_loss: 2.446090, odo_loss: 1.795007, ine_loss: 0.514907, ref_loss: 0.136176\n",
      "\t[#  720] train_loss: 2.472111, odo_loss: 1.769725, ine_loss: 0.557119, ref_loss: 0.145267\n",
      "\t[#  900] train_loss: 2.463787, odo_loss: 1.772277, ine_loss: 0.514206, ref_loss: 0.177304\n",
      "\ttrain_loss: 2.193941, odo_loss: 1.529618, ine_loss: 0.512755, ref_loss: 0.151568\n",
      "\tval_loss: 2.237896, odo_loss: 1.560764, ine_loss: 0.505869, ref_loss: 0.171264\n",
      "Epoch 184/2000\n",
      "\t[#    0] train_loss: 2.366514, odo_loss: 1.675193, ine_loss: 0.524642, ref_loss: 0.166679\n",
      "\t[#  180] train_loss: 1.969711, odo_loss: 1.408672, ine_loss: 0.424097, ref_loss: 0.136943\n",
      "\t[#  360] train_loss: 2.132308, odo_loss: 1.418704, ine_loss: 0.562267, ref_loss: 0.151338\n",
      "\t[#  540] train_loss: 1.817616, odo_loss: 1.234240, ine_loss: 0.454759, ref_loss: 0.128617\n",
      "\t[#  720] train_loss: 1.670400, odo_loss: 1.067847, ine_loss: 0.449152, ref_loss: 0.153401\n",
      "\t[#  900] train_loss: 1.982042, odo_loss: 1.260469, ine_loss: 0.552971, ref_loss: 0.168602\n",
      "\ttrain_loss: 2.217929, odo_loss: 1.554196, ine_loss: 0.512699, ref_loss: 0.151034\n",
      "\tval_loss: 2.187969, odo_loss: 1.510259, ine_loss: 0.507244, ref_loss: 0.170466\n",
      "\t*** Personal Best ***\n",
      "Epoch 185/2000\n",
      "\t[#    0] train_loss: 2.157901, odo_loss: 1.494365, ine_loss: 0.533776, ref_loss: 0.129759\n",
      "\t[#  180] train_loss: 2.095193, odo_loss: 1.440935, ine_loss: 0.504388, ref_loss: 0.149870\n",
      "\t[#  360] train_loss: 2.165615, odo_loss: 1.512615, ine_loss: 0.518986, ref_loss: 0.134014\n",
      "\t[#  540] train_loss: 2.173961, odo_loss: 1.505708, ine_loss: 0.527950, ref_loss: 0.140303\n",
      "\t[#  720] train_loss: 2.313904, odo_loss: 1.695189, ine_loss: 0.501501, ref_loss: 0.117213\n",
      "\t[#  900] train_loss: 2.529633, odo_loss: 1.835439, ine_loss: 0.550635, ref_loss: 0.143559\n",
      "\ttrain_loss: 2.274077, odo_loss: 1.611484, ine_loss: 0.511878, ref_loss: 0.150715\n",
      "\tval_loss: 2.255603, odo_loss: 1.575919, ine_loss: 0.509292, ref_loss: 0.170392\n",
      "Epoch 186/2000\n",
      "\t[#    0] train_loss: 2.175955, odo_loss: 1.466292, ine_loss: 0.545716, ref_loss: 0.163947\n",
      "\t[#  180] train_loss: 2.240752, odo_loss: 1.617347, ine_loss: 0.469901, ref_loss: 0.153504\n",
      "\t[#  360] train_loss: 1.979564, odo_loss: 1.325418, ine_loss: 0.508883, ref_loss: 0.145263\n",
      "\t[#  540] train_loss: 2.252224, odo_loss: 1.570846, ine_loss: 0.533710, ref_loss: 0.147667\n",
      "\t[#  720] train_loss: 2.142298, odo_loss: 1.345241, ine_loss: 0.653422, ref_loss: 0.143636\n",
      "\t[#  900] train_loss: 2.067575, odo_loss: 1.438516, ine_loss: 0.486310, ref_loss: 0.142749\n",
      "\ttrain_loss: 2.215201, odo_loss: 1.552763, ine_loss: 0.511469, ref_loss: 0.150969\n",
      "\tval_loss: 2.215314, odo_loss: 1.533432, ine_loss: 0.512049, ref_loss: 0.169834\n",
      "Epoch 187/2000\n",
      "\t[#    0] train_loss: 2.175783, odo_loss: 1.321453, ine_loss: 0.693380, ref_loss: 0.160950\n",
      "\t[#  180] train_loss: 2.606776, odo_loss: 1.881541, ine_loss: 0.598481, ref_loss: 0.126754\n",
      "\t[#  360] train_loss: 2.611112, odo_loss: 1.872437, ine_loss: 0.570497, ref_loss: 0.168178\n",
      "\t[#  540] train_loss: 2.005830, odo_loss: 1.323607, ine_loss: 0.521872, ref_loss: 0.160351\n",
      "\t[#  720] train_loss: 2.063579, odo_loss: 1.391800, ine_loss: 0.510925, ref_loss: 0.160853\n",
      "\t[#  900] train_loss: 2.275547, odo_loss: 1.607955, ine_loss: 0.519428, ref_loss: 0.148164\n",
      "\ttrain_loss: 2.192140, odo_loss: 1.529722, ine_loss: 0.511928, ref_loss: 0.150490\n",
      "\tval_loss: 2.195409, odo_loss: 1.515120, ine_loss: 0.511591, ref_loss: 0.168699\n",
      "Epoch 188/2000\n",
      "\t[#    0] train_loss: 1.920335, odo_loss: 1.243752, ine_loss: 0.512509, ref_loss: 0.164074\n",
      "\t[#  180] train_loss: 2.489986, odo_loss: 1.833831, ine_loss: 0.505051, ref_loss: 0.151103\n",
      "\t[#  360] train_loss: 1.947300, odo_loss: 1.230880, ine_loss: 0.565349, ref_loss: 0.151070\n",
      "\t[#  540] train_loss: 2.009516, odo_loss: 1.426069, ine_loss: 0.441045, ref_loss: 0.142402\n",
      "\t[#  720] train_loss: 2.107710, odo_loss: 1.511606, ine_loss: 0.449942, ref_loss: 0.146162\n",
      "\t[#  900] train_loss: 2.058221, odo_loss: 1.470765, ine_loss: 0.462812, ref_loss: 0.124644\n",
      "\ttrain_loss: 2.228758, odo_loss: 1.566554, ine_loss: 0.511413, ref_loss: 0.150790\n",
      "\tval_loss: 2.267915, odo_loss: 1.583379, ine_loss: 0.513934, ref_loss: 0.170601\n",
      "Epoch 189/2000\n",
      "\t[#    0] train_loss: 2.485286, odo_loss: 1.847335, ine_loss: 0.483753, ref_loss: 0.154198\n",
      "\t[#  180] train_loss: 2.222212, odo_loss: 1.542010, ine_loss: 0.545922, ref_loss: 0.134280\n",
      "\t[#  360] train_loss: 2.252619, odo_loss: 1.491795, ine_loss: 0.607597, ref_loss: 0.153226\n",
      "\t[#  540] train_loss: 2.095039, odo_loss: 1.408814, ine_loss: 0.497481, ref_loss: 0.188743\n",
      "\t[#  720] train_loss: 2.348327, odo_loss: 1.731099, ine_loss: 0.426680, ref_loss: 0.190548\n",
      "\t[#  900] train_loss: 1.733296, odo_loss: 1.112749, ine_loss: 0.483526, ref_loss: 0.137020\n",
      "\ttrain_loss: 2.190554, odo_loss: 1.528678, ine_loss: 0.511470, ref_loss: 0.150406\n",
      "\tval_loss: 2.161362, odo_loss: 1.483451, ine_loss: 0.508784, ref_loss: 0.169127\n",
      "\t*** Personal Best ***\n",
      "Epoch 190/2000\n",
      "\t[#    0] train_loss: 1.832594, odo_loss: 1.183855, ine_loss: 0.525445, ref_loss: 0.123294\n",
      "\t[#  180] train_loss: 2.573590, odo_loss: 1.888305, ine_loss: 0.562020, ref_loss: 0.123265\n",
      "\t[#  360] train_loss: 2.339465, odo_loss: 1.645452, ine_loss: 0.548893, ref_loss: 0.145120\n",
      "\t[#  540] train_loss: 2.751325, odo_loss: 2.065642, ine_loss: 0.541678, ref_loss: 0.144006\n",
      "\t[#  720] train_loss: 1.936896, odo_loss: 1.325030, ine_loss: 0.439631, ref_loss: 0.172235\n",
      "\t[#  900] train_loss: 2.217990, odo_loss: 1.401316, ine_loss: 0.676910, ref_loss: 0.139764\n",
      "\ttrain_loss: 2.207010, odo_loss: 1.545840, ine_loss: 0.510821, ref_loss: 0.150349\n",
      "\tval_loss: 2.188232, odo_loss: 1.509579, ine_loss: 0.509417, ref_loss: 0.169235\n",
      "Epoch 191/2000\n",
      "\t[#    0] train_loss: 2.147010, odo_loss: 1.589759, ine_loss: 0.427447, ref_loss: 0.129804\n",
      "\t[#  180] train_loss: 2.090000, odo_loss: 1.486340, ine_loss: 0.474409, ref_loss: 0.129251\n",
      "\t[#  360] train_loss: 2.292457, odo_loss: 1.458677, ine_loss: 0.663327, ref_loss: 0.170453\n",
      "\t[#  540] train_loss: 2.089452, odo_loss: 1.383364, ine_loss: 0.572514, ref_loss: 0.133573\n",
      "\t[#  720] train_loss: 2.411060, odo_loss: 1.774183, ine_loss: 0.490025, ref_loss: 0.146852\n",
      "\t[#  900] train_loss: 2.213153, odo_loss: 1.558797, ine_loss: 0.501100, ref_loss: 0.153256\n",
      "\ttrain_loss: 2.195801, odo_loss: 1.534729, ine_loss: 0.510855, ref_loss: 0.150217\n",
      "\tval_loss: 2.179339, odo_loss: 1.499125, ine_loss: 0.508292, ref_loss: 0.171921\n",
      "Epoch 192/2000\n",
      "\t[#    0] train_loss: 2.429488, odo_loss: 1.585905, ine_loss: 0.633722, ref_loss: 0.209861\n",
      "\t[#  180] train_loss: 2.530426, odo_loss: 1.777573, ine_loss: 0.600805, ref_loss: 0.152048\n",
      "\t[#  360] train_loss: 1.798008, odo_loss: 1.113458, ine_loss: 0.539272, ref_loss: 0.145278\n",
      "\t[#  540] train_loss: 1.858264, odo_loss: 1.290985, ine_loss: 0.421587, ref_loss: 0.145691\n",
      "\t[#  720] train_loss: 2.190282, odo_loss: 1.472431, ine_loss: 0.560345, ref_loss: 0.157506\n",
      "\t[#  900] train_loss: 2.398089, odo_loss: 1.757219, ine_loss: 0.494486, ref_loss: 0.146384\n",
      "\ttrain_loss: 2.167810, odo_loss: 1.507354, ine_loss: 0.510146, ref_loss: 0.150310\n",
      "\tval_loss: 2.237675, odo_loss: 1.563939, ine_loss: 0.503071, ref_loss: 0.170666\n",
      "Epoch 193/2000\n",
      "\t[#    0] train_loss: 1.991580, odo_loss: 1.411472, ine_loss: 0.442079, ref_loss: 0.138029\n",
      "\t[#  180] train_loss: 2.010590, odo_loss: 1.439871, ine_loss: 0.430013, ref_loss: 0.140706\n",
      "\t[#  360] train_loss: 2.092841, odo_loss: 1.369776, ine_loss: 0.551769, ref_loss: 0.171297\n",
      "\t[#  540] train_loss: 2.215020, odo_loss: 1.521719, ine_loss: 0.524029, ref_loss: 0.169271\n",
      "\t[#  720] train_loss: 2.127972, odo_loss: 1.476753, ine_loss: 0.516087, ref_loss: 0.135132\n",
      "\t[#  900] train_loss: 2.071512, odo_loss: 1.495091, ine_loss: 0.444547, ref_loss: 0.131875\n",
      "\ttrain_loss: 2.155525, odo_loss: 1.495363, ine_loss: 0.509974, ref_loss: 0.150188\n",
      "\tval_loss: 2.287668, odo_loss: 1.614624, ine_loss: 0.500622, ref_loss: 0.172422\n",
      "Epoch 194/2000\n",
      "\t[#    0] train_loss: 2.235854, odo_loss: 1.565486, ine_loss: 0.525591, ref_loss: 0.144777\n",
      "\t[#  180] train_loss: 2.068218, odo_loss: 1.420781, ine_loss: 0.489738, ref_loss: 0.157698\n",
      "\t[#  360] train_loss: 2.295827, odo_loss: 1.663384, ine_loss: 0.498147, ref_loss: 0.134296\n",
      "\t[#  540] train_loss: 1.882508, odo_loss: 1.181649, ine_loss: 0.526942, ref_loss: 0.173917\n",
      "\t[#  720] train_loss: 2.220926, odo_loss: 1.668410, ine_loss: 0.386286, ref_loss: 0.166230\n",
      "\t[#  900] train_loss: 1.842247, odo_loss: 1.307998, ine_loss: 0.368021, ref_loss: 0.166228\n",
      "\ttrain_loss: 2.171272, odo_loss: 1.511084, ine_loss: 0.510333, ref_loss: 0.149855\n",
      "\tval_loss: 2.134714, odo_loss: 1.456812, ine_loss: 0.508799, ref_loss: 0.169103\n",
      "\t*** Personal Best ***\n",
      "Epoch 195/2000\n",
      "\t[#    0] train_loss: 2.327490, odo_loss: 1.627725, ine_loss: 0.544928, ref_loss: 0.154837\n",
      "\t[#  180] train_loss: 2.396448, odo_loss: 1.736401, ine_loss: 0.521376, ref_loss: 0.138670\n",
      "\t[#  360] train_loss: 2.470129, odo_loss: 1.749978, ine_loss: 0.549309, ref_loss: 0.170841\n",
      "\t[#  540] train_loss: 2.207812, odo_loss: 1.473481, ine_loss: 0.573938, ref_loss: 0.160393\n",
      "\t[#  720] train_loss: 2.112906, odo_loss: 1.504726, ine_loss: 0.468447, ref_loss: 0.139733\n",
      "\t[#  900] train_loss: 2.052275, odo_loss: 1.575770, ine_loss: 0.336956, ref_loss: 0.139549\n",
      "\ttrain_loss: 2.170912, odo_loss: 1.511346, ine_loss: 0.509546, ref_loss: 0.150020\n",
      "\tval_loss: 2.206660, odo_loss: 1.528223, ine_loss: 0.506292, ref_loss: 0.172145\n",
      "Epoch 196/2000\n",
      "\t[#    0] train_loss: 2.144222, odo_loss: 1.534383, ine_loss: 0.464828, ref_loss: 0.145010\n",
      "\t[#  180] train_loss: 2.091858, odo_loss: 1.437876, ine_loss: 0.498628, ref_loss: 0.155355\n",
      "\t[#  360] train_loss: 2.489426, odo_loss: 1.881272, ine_loss: 0.428291, ref_loss: 0.179862\n",
      "\t[#  540] train_loss: 1.739335, odo_loss: 1.185884, ine_loss: 0.405029, ref_loss: 0.148423\n",
      "\t[#  720] train_loss: 2.146170, odo_loss: 1.376745, ine_loss: 0.641792, ref_loss: 0.127633\n",
      "\t[#  900] train_loss: 2.514456, odo_loss: 1.773259, ine_loss: 0.550463, ref_loss: 0.190733\n",
      "\ttrain_loss: 2.218312, odo_loss: 1.558019, ine_loss: 0.510305, ref_loss: 0.149988\n",
      "\tval_loss: 2.306215, odo_loss: 1.631408, ine_loss: 0.504121, ref_loss: 0.170687\n",
      "Epoch 197/2000\n",
      "\t[#    0] train_loss: 2.238634, odo_loss: 1.512141, ine_loss: 0.583417, ref_loss: 0.143076\n",
      "\t[#  180] train_loss: 2.036674, odo_loss: 1.440674, ine_loss: 0.459316, ref_loss: 0.136685\n",
      "\t[#  360] train_loss: 2.228213, odo_loss: 1.622040, ine_loss: 0.463410, ref_loss: 0.142763\n",
      "\t[#  540] train_loss: 2.425287, odo_loss: 1.757113, ine_loss: 0.516652, ref_loss: 0.151522\n",
      "\t[#  720] train_loss: 2.205352, odo_loss: 1.544291, ine_loss: 0.480647, ref_loss: 0.180414\n",
      "\t[#  900] train_loss: 2.519877, odo_loss: 1.856940, ine_loss: 0.497333, ref_loss: 0.165604\n",
      "\ttrain_loss: 2.186555, odo_loss: 1.526983, ine_loss: 0.509772, ref_loss: 0.149801\n",
      "\tval_loss: 2.290888, odo_loss: 1.608774, ine_loss: 0.513608, ref_loss: 0.168506\n",
      "Epoch 198/2000\n",
      "\t[#    0] train_loss: 1.815947, odo_loss: 1.250716, ine_loss: 0.426621, ref_loss: 0.138610\n",
      "\t[#  180] train_loss: 2.024525, odo_loss: 1.374323, ine_loss: 0.510994, ref_loss: 0.139208\n",
      "\t[#  360] train_loss: 2.217686, odo_loss: 1.590915, ine_loss: 0.492920, ref_loss: 0.133851\n",
      "\t[#  540] train_loss: 2.202039, odo_loss: 1.580240, ine_loss: 0.470641, ref_loss: 0.151158\n",
      "\t[#  720] train_loss: 7.766967, odo_loss: 7.085723, ine_loss: 0.527648, ref_loss: 0.153596\n",
      "\t[#  900] train_loss: 2.528314, odo_loss: 1.770881, ine_loss: 0.595886, ref_loss: 0.161548\n",
      "\ttrain_loss: 2.221792, odo_loss: 1.562660, ine_loss: 0.508960, ref_loss: 0.150172\n",
      "\tval_loss: 2.310233, odo_loss: 1.637551, ine_loss: 0.502991, ref_loss: 0.169690\n",
      "Epoch 199/2000\n",
      "\t[#    0] train_loss: 2.406429, odo_loss: 1.889244, ine_loss: 0.382526, ref_loss: 0.134659\n",
      "\t[#  180] train_loss: 2.384473, odo_loss: 1.863549, ine_loss: 0.401111, ref_loss: 0.119813\n",
      "\t[#  360] train_loss: 2.150504, odo_loss: 1.452146, ine_loss: 0.560755, ref_loss: 0.137602\n",
      "\t[#  540] train_loss: 2.193546, odo_loss: 1.559012, ine_loss: 0.481898, ref_loss: 0.152637\n",
      "\t[#  720] train_loss: 2.110148, odo_loss: 1.459062, ine_loss: 0.536286, ref_loss: 0.114800\n",
      "\t[#  900] train_loss: 2.454078, odo_loss: 1.795505, ine_loss: 0.495784, ref_loss: 0.162789\n",
      "\ttrain_loss: 2.179002, odo_loss: 1.519704, ine_loss: 0.509351, ref_loss: 0.149947\n",
      "\tval_loss: 2.179140, odo_loss: 1.503443, ine_loss: 0.506731, ref_loss: 0.168967\n",
      "Epoch 200/2000\n",
      "\t[#    0] train_loss: 1.997514, odo_loss: 1.433906, ine_loss: 0.428369, ref_loss: 0.135238\n",
      "\t[#  180] train_loss: 2.171431, odo_loss: 1.590623, ine_loss: 0.444613, ref_loss: 0.136196\n",
      "\t[#  360] train_loss: 2.346380, odo_loss: 1.778405, ine_loss: 0.455075, ref_loss: 0.112900\n",
      "\t[#  540] train_loss: 2.022481, odo_loss: 1.390374, ine_loss: 0.477049, ref_loss: 0.155059\n",
      "\t[#  720] train_loss: 2.255188, odo_loss: 1.553371, ine_loss: 0.544399, ref_loss: 0.157417\n",
      "\t[#  900] train_loss: 2.375655, odo_loss: 1.724668, ine_loss: 0.505176, ref_loss: 0.145811\n",
      "\ttrain_loss: 2.234473, odo_loss: 1.576084, ine_loss: 0.508220, ref_loss: 0.150170\n",
      "\tval_loss: 2.320459, odo_loss: 1.644358, ine_loss: 0.507004, ref_loss: 0.169096\n",
      "Epoch 201/2000\n",
      "\t[#    0] train_loss: 2.099849, odo_loss: 1.502439, ine_loss: 0.464978, ref_loss: 0.132432\n",
      "\t[#  180] train_loss: 2.004868, odo_loss: 1.228600, ine_loss: 0.626961, ref_loss: 0.149307\n",
      "\t[#  360] train_loss: 2.481663, odo_loss: 1.873337, ine_loss: 0.434569, ref_loss: 0.173757\n",
      "\t[#  540] train_loss: 2.130585, odo_loss: 1.537021, ine_loss: 0.449562, ref_loss: 0.144002\n",
      "\t[#  720] train_loss: 1.774779, odo_loss: 1.165252, ine_loss: 0.441480, ref_loss: 0.168047\n",
      "\t[#  900] train_loss: 2.044561, odo_loss: 1.381380, ine_loss: 0.525400, ref_loss: 0.137781\n",
      "\ttrain_loss: 2.219861, odo_loss: 1.560383, ine_loss: 0.509054, ref_loss: 0.150424\n",
      "\tval_loss: 2.254977, odo_loss: 1.583121, ine_loss: 0.500770, ref_loss: 0.171086\n",
      "Epoch 202/2000\n",
      "\t[#    0] train_loss: 2.469742, odo_loss: 1.806667, ine_loss: 0.524054, ref_loss: 0.139021\n",
      "\t[#  180] train_loss: 2.338804, odo_loss: 1.670862, ine_loss: 0.470406, ref_loss: 0.197535\n",
      "\t[#  360] train_loss: 2.181269, odo_loss: 1.557329, ine_loss: 0.462660, ref_loss: 0.161280\n",
      "\t[#  540] train_loss: 2.027012, odo_loss: 1.482137, ine_loss: 0.416206, ref_loss: 0.128668\n",
      "\t[#  720] train_loss: 2.683521, odo_loss: 2.017592, ine_loss: 0.518006, ref_loss: 0.147923\n",
      "\t[#  900] train_loss: 1.971299, odo_loss: 1.328340, ine_loss: 0.479556, ref_loss: 0.163402\n",
      "\ttrain_loss: 2.171342, odo_loss: 1.513524, ine_loss: 0.508540, ref_loss: 0.149279\n",
      "\tval_loss: 2.197322, odo_loss: 1.523615, ine_loss: 0.505073, ref_loss: 0.168634\n",
      "Epoch 203/2000\n",
      "\t[#    0] train_loss: 2.344140, odo_loss: 1.542753, ine_loss: 0.651311, ref_loss: 0.150076\n",
      "\t[#  180] train_loss: 2.077123, odo_loss: 1.384351, ine_loss: 0.546876, ref_loss: 0.145896\n",
      "\t[#  360] train_loss: 2.241115, odo_loss: 1.527240, ine_loss: 0.568759, ref_loss: 0.145116\n",
      "\t[#  540] train_loss: 2.053014, odo_loss: 1.334796, ine_loss: 0.531571, ref_loss: 0.186647\n",
      "\t[#  720] train_loss: 1.785897, odo_loss: 1.246174, ine_loss: 0.408333, ref_loss: 0.131390\n",
      "\t[#  900] train_loss: 2.092650, odo_loss: 1.285469, ine_loss: 0.655738, ref_loss: 0.151443\n",
      "\ttrain_loss: 2.145269, odo_loss: 1.486840, ine_loss: 0.509022, ref_loss: 0.149408\n",
      "\tval_loss: 2.273106, odo_loss: 1.598398, ine_loss: 0.506104, ref_loss: 0.168603\n",
      "Epoch 204/2000\n",
      "\t[#    0] train_loss: 2.348877, odo_loss: 1.675267, ine_loss: 0.500084, ref_loss: 0.173526\n",
      "\t[#  180] train_loss: 2.244306, odo_loss: 1.599146, ine_loss: 0.512621, ref_loss: 0.132539\n",
      "\t[#  360] train_loss: 2.763184, odo_loss: 2.142644, ine_loss: 0.466552, ref_loss: 0.153988\n",
      "\t[#  540] train_loss: 2.334051, odo_loss: 1.499771, ine_loss: 0.677315, ref_loss: 0.156964\n",
      "\t[#  720] train_loss: 2.120170, odo_loss: 1.508511, ine_loss: 0.441469, ref_loss: 0.170190\n",
      "\t[#  900] train_loss: 2.231373, odo_loss: 1.594625, ine_loss: 0.493405, ref_loss: 0.143343\n",
      "\ttrain_loss: 2.249906, odo_loss: 1.591287, ine_loss: 0.509005, ref_loss: 0.149614\n",
      "\tval_loss: 2.208514, odo_loss: 1.533048, ine_loss: 0.506260, ref_loss: 0.169206\n",
      "Epoch 205/2000\n",
      "\t[#    0] train_loss: 2.173169, odo_loss: 1.461340, ine_loss: 0.587694, ref_loss: 0.124135\n",
      "\t[#  180] train_loss: 2.070529, odo_loss: 1.361411, ine_loss: 0.576951, ref_loss: 0.132168\n",
      "\t[#  360] train_loss: 2.256680, odo_loss: 1.562733, ine_loss: 0.541546, ref_loss: 0.152400\n",
      "\t[#  540] train_loss: 2.347250, odo_loss: 1.662436, ine_loss: 0.505897, ref_loss: 0.178918\n",
      "\t[#  720] train_loss: 2.479197, odo_loss: 1.764033, ine_loss: 0.560897, ref_loss: 0.154267\n",
      "\t[#  900] train_loss: 2.073857, odo_loss: 1.341991, ine_loss: 0.578378, ref_loss: 0.153489\n",
      "\ttrain_loss: 2.160249, odo_loss: 1.501577, ine_loss: 0.509796, ref_loss: 0.148876\n",
      "\tval_loss: 2.240109, odo_loss: 1.565871, ine_loss: 0.504588, ref_loss: 0.169649\n",
      "Epoch 206/2000\n",
      "\t[#    0] train_loss: 2.066201, odo_loss: 1.444519, ine_loss: 0.481943, ref_loss: 0.139738\n",
      "\t[#  180] train_loss: 1.740317, odo_loss: 1.063087, ine_loss: 0.487959, ref_loss: 0.189270\n",
      "\t[#  360] train_loss: 1.955657, odo_loss: 1.323619, ine_loss: 0.461618, ref_loss: 0.170420\n",
      "\t[#  540] train_loss: 1.924647, odo_loss: 1.268702, ine_loss: 0.489857, ref_loss: 0.166087\n",
      "\t[#  720] train_loss: 2.145885, odo_loss: 1.517183, ine_loss: 0.461233, ref_loss: 0.167468\n",
      "\t[#  900] train_loss: 2.322702, odo_loss: 1.684838, ine_loss: 0.448504, ref_loss: 0.189360\n",
      "\ttrain_loss: 2.190881, odo_loss: 1.531982, ine_loss: 0.509734, ref_loss: 0.149165\n",
      "\tval_loss: 2.185675, odo_loss: 1.515941, ine_loss: 0.501275, ref_loss: 0.168459\n",
      "Epoch 207/2000\n",
      "\t[#    0] train_loss: 2.113069, odo_loss: 1.289545, ine_loss: 0.677970, ref_loss: 0.145554\n",
      "\t[#  180] train_loss: 1.853943, odo_loss: 1.193887, ine_loss: 0.517760, ref_loss: 0.142295\n",
      "\t[#  360] train_loss: 2.033005, odo_loss: 1.297065, ine_loss: 0.562328, ref_loss: 0.173612\n",
      "\t[#  540] train_loss: 2.077950, odo_loss: 1.351702, ine_loss: 0.561692, ref_loss: 0.164556\n",
      "\t[#  720] train_loss: 2.312064, odo_loss: 1.629852, ine_loss: 0.540641, ref_loss: 0.141571\n",
      "\t[#  900] train_loss: 1.909385, odo_loss: 1.316730, ine_loss: 0.474863, ref_loss: 0.117792\n",
      "\ttrain_loss: 2.155819, odo_loss: 1.497931, ine_loss: 0.508652, ref_loss: 0.149236\n",
      "\tval_loss: 2.143358, odo_loss: 1.469432, ine_loss: 0.505259, ref_loss: 0.168667\n",
      "Epoch 208/2000\n",
      "\t[#    0] train_loss: 1.992886, odo_loss: 1.381989, ine_loss: 0.489616, ref_loss: 0.121280\n",
      "\t[#  180] train_loss: 2.036242, odo_loss: 1.449494, ine_loss: 0.455669, ref_loss: 0.131079\n",
      "\t[#  360] train_loss: 2.039037, odo_loss: 1.420575, ine_loss: 0.483974, ref_loss: 0.134488\n",
      "\t[#  540] train_loss: 2.144720, odo_loss: 1.349162, ine_loss: 0.615177, ref_loss: 0.180381\n",
      "\t[#  720] train_loss: 2.105391, odo_loss: 1.457187, ine_loss: 0.474432, ref_loss: 0.173771\n",
      "\t[#  900] train_loss: 2.416437, odo_loss: 1.809322, ine_loss: 0.489280, ref_loss: 0.117835\n",
      "\ttrain_loss: 2.204409, odo_loss: 1.545917, ine_loss: 0.509160, ref_loss: 0.149331\n",
      "\tval_loss: 2.252206, odo_loss: 1.581138, ine_loss: 0.502717, ref_loss: 0.168351\n",
      "Epoch 209/2000\n",
      "\t[#    0] train_loss: 2.084289, odo_loss: 1.379795, ine_loss: 0.585294, ref_loss: 0.119200\n",
      "\t[#  180] train_loss: 2.221158, odo_loss: 1.433550, ine_loss: 0.616921, ref_loss: 0.170686\n",
      "\t[#  360] train_loss: 2.092174, odo_loss: 1.448234, ine_loss: 0.491362, ref_loss: 0.152577\n",
      "\t[#  540] train_loss: 2.180452, odo_loss: 1.383168, ine_loss: 0.622960, ref_loss: 0.174324\n",
      "\t[#  720] train_loss: 2.266746, odo_loss: 1.624635, ine_loss: 0.510593, ref_loss: 0.131518\n",
      "\t[#  900] train_loss: 2.138355, odo_loss: 1.392442, ine_loss: 0.595911, ref_loss: 0.150002\n",
      "\ttrain_loss: 2.156560, odo_loss: 1.498281, ine_loss: 0.509389, ref_loss: 0.148890\n",
      "\tval_loss: 2.277100, odo_loss: 1.599704, ine_loss: 0.507927, ref_loss: 0.169469\n",
      "Epoch 210/2000\n",
      "\t[#    0] train_loss: 2.136822, odo_loss: 1.457025, ine_loss: 0.509607, ref_loss: 0.170190\n",
      "\t[#  180] train_loss: 1.981568, odo_loss: 1.325809, ine_loss: 0.520090, ref_loss: 0.135669\n",
      "\t[#  360] train_loss: 1.961962, odo_loss: 1.405564, ine_loss: 0.433232, ref_loss: 0.123165\n",
      "\t[#  540] train_loss: 1.923651, odo_loss: 1.255175, ine_loss: 0.526475, ref_loss: 0.142001\n",
      "\t[#  720] train_loss: 2.315334, odo_loss: 1.629727, ine_loss: 0.533843, ref_loss: 0.151763\n",
      "\t[#  900] train_loss: 2.604433, odo_loss: 1.823364, ine_loss: 0.600516, ref_loss: 0.180553\n",
      "\ttrain_loss: 2.143411, odo_loss: 1.485220, ine_loss: 0.509097, ref_loss: 0.149093\n",
      "\tval_loss: 2.359002, odo_loss: 1.681346, ine_loss: 0.508569, ref_loss: 0.169087\n",
      "Epoch 211/2000\n",
      "\t[#    0] train_loss: 2.340311, odo_loss: 1.444809, ine_loss: 0.730017, ref_loss: 0.165485\n",
      "\t[#  180] train_loss: 2.134385, odo_loss: 1.524227, ine_loss: 0.443311, ref_loss: 0.166848\n",
      "\t[#  360] train_loss: 2.278695, odo_loss: 1.501764, ine_loss: 0.625868, ref_loss: 0.151062\n",
      "\t[#  540] train_loss: 2.259037, odo_loss: 1.648654, ine_loss: 0.483617, ref_loss: 0.126766\n",
      "\t[#  720] train_loss: 2.266127, odo_loss: 1.628833, ine_loss: 0.489364, ref_loss: 0.147929\n",
      "\t[#  900] train_loss: 4.885027, odo_loss: 4.216177, ine_loss: 0.494516, ref_loss: 0.174335\n",
      "\ttrain_loss: 2.152349, odo_loss: 1.494909, ine_loss: 0.508106, ref_loss: 0.149334\n",
      "\tval_loss: 2.402908, odo_loss: 1.733862, ine_loss: 0.501861, ref_loss: 0.167185\n",
      "Epoch 212/2000\n",
      "\t[#    0] train_loss: 2.360159, odo_loss: 1.640628, ine_loss: 0.579280, ref_loss: 0.140251\n",
      "\t[#  180] train_loss: 2.770244, odo_loss: 2.001629, ine_loss: 0.603194, ref_loss: 0.165422\n",
      "\t[#  360] train_loss: 2.045357, odo_loss: 1.379314, ine_loss: 0.500540, ref_loss: 0.165503\n",
      "\t[#  540] train_loss: 2.090941, odo_loss: 1.440193, ine_loss: 0.477990, ref_loss: 0.172759\n",
      "\t[#  720] train_loss: 2.283399, odo_loss: 1.628822, ine_loss: 0.507579, ref_loss: 0.146998\n",
      "\t[#  900] train_loss: 2.099875, odo_loss: 1.387228, ine_loss: 0.534835, ref_loss: 0.177813\n",
      "\ttrain_loss: 2.168707, odo_loss: 1.512446, ine_loss: 0.507477, ref_loss: 0.148784\n",
      "\tval_loss: 2.194517, odo_loss: 1.519553, ine_loss: 0.502324, ref_loss: 0.172640\n",
      "Epoch 213/2000\n",
      "\t[#    0] train_loss: 1.966565, odo_loss: 1.445770, ine_loss: 0.393330, ref_loss: 0.127464\n",
      "\t[#  180] train_loss: 2.500121, odo_loss: 1.890474, ine_loss: 0.473854, ref_loss: 0.135792\n",
      "\t[#  360] train_loss: 2.059941, odo_loss: 1.469778, ine_loss: 0.430827, ref_loss: 0.159336\n",
      "\t[#  540] train_loss: 1.806753, odo_loss: 1.336874, ine_loss: 0.343130, ref_loss: 0.126749\n",
      "\t[#  720] train_loss: 1.937161, odo_loss: 1.314867, ine_loss: 0.467602, ref_loss: 0.154693\n",
      "\t[#  900] train_loss: 1.810414, odo_loss: 1.203858, ine_loss: 0.462893, ref_loss: 0.143663\n",
      "\ttrain_loss: 2.282075, odo_loss: 1.625428, ine_loss: 0.507568, ref_loss: 0.149079\n",
      "\tval_loss: 2.224279, odo_loss: 1.548646, ine_loss: 0.506749, ref_loss: 0.168885\n",
      "Epoch 214/2000\n",
      "\t[#    0] train_loss: 2.423818, odo_loss: 1.728448, ine_loss: 0.547505, ref_loss: 0.147866\n",
      "\t[#  180] train_loss: 2.287208, odo_loss: 1.579237, ine_loss: 0.585696, ref_loss: 0.122275\n",
      "\t[#  360] train_loss: 2.291833, odo_loss: 1.767350, ine_loss: 0.403963, ref_loss: 0.120521\n",
      "\t[#  540] train_loss: 2.200064, odo_loss: 1.447900, ine_loss: 0.617778, ref_loss: 0.134386\n",
      "\t[#  720] train_loss: 2.519671, odo_loss: 1.734848, ine_loss: 0.632051, ref_loss: 0.152772\n",
      "\t[#  900] train_loss: 2.259798, odo_loss: 1.581816, ine_loss: 0.506651, ref_loss: 0.171331\n",
      "\ttrain_loss: 2.182969, odo_loss: 1.524640, ine_loss: 0.509078, ref_loss: 0.149251\n",
      "\tval_loss: 2.147025, odo_loss: 1.474690, ine_loss: 0.502484, ref_loss: 0.169850\n",
      "Epoch 215/2000\n",
      "\t[#    0] train_loss: 2.380351, odo_loss: 1.783153, ine_loss: 0.430642, ref_loss: 0.166556\n",
      "\t[#  180] train_loss: 2.231545, odo_loss: 1.460320, ine_loss: 0.623166, ref_loss: 0.148059\n",
      "\t[#  360] train_loss: 2.614022, odo_loss: 1.918972, ine_loss: 0.507266, ref_loss: 0.187784\n",
      "\t[#  540] train_loss: 2.576218, odo_loss: 1.949664, ine_loss: 0.456370, ref_loss: 0.170185\n",
      "\t[#  720] train_loss: 2.304729, odo_loss: 1.573236, ine_loss: 0.573097, ref_loss: 0.158396\n",
      "\t[#  900] train_loss: 2.543937, odo_loss: 1.811010, ine_loss: 0.572449, ref_loss: 0.160479\n",
      "\ttrain_loss: 2.247061, odo_loss: 1.590359, ine_loss: 0.507156, ref_loss: 0.149546\n",
      "\tval_loss: 2.212762, odo_loss: 1.538205, ine_loss: 0.503915, ref_loss: 0.170643\n",
      "\n",
      "\tStopped by  early stopping!\n"
     ]
    }
   ],
   "source": [
    "model = InertialNet2().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "h_loss_train = []\n",
    "h_loss_val = []\n",
    "\n",
    "early_stopping = {\"epoch\":0, \"best\":10**3, \"epoch_threshold\":EARLY_STOPPING}\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(f\"Epoch {epoch}/{EPOCHS}\")\n",
    "\n",
    "    _, loss_train, _, _ = train(model, device, train_loader, optimizer, epoch)\n",
    "    _, loss_val, _, _ = validation(model, device, val_loader, epoch)\n",
    "\n",
    "    #populating the history of the loss\n",
    "    h_loss_train.append(loss_train)\n",
    "    h_loss_val.append(loss_val)\n",
    "\n",
    "    # early stopping\n",
    "    if loss_val < early_stopping[\"best\"]:\n",
    "        early_stopping[\"best\"] = loss_val\n",
    "        early_stopping[\"epoch\"] = epoch\n",
    "        print(\"\\t*** Personal Best ***\")\n",
    "\n",
    "    if epoch - early_stopping[\"epoch\"] > early_stopping[\"epoch_threshold\"]:\n",
    "        print(\"\\n\\tStopped by  early stopping!\")\n",
    "        break\n",
    "\n",
    "np.savez(f\"train_loss_{EPOCHS}\", h_loss_train)\n",
    "np.savez(f\"val_loss_{EPOCHS}\", h_loss_val)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(h_loss_train, label=\"train\")\n",
    "plt.plot(h_loss_val, label=\"validation\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zoomed plot (last 30 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(h_loss_train)[-100:], label=\"train\")\n",
    "plt.plot(np.array(h_loss_val)[-100:], label=\"validation\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a60a9521ac24e310983a613c26989eaf1fc2b3e1d7e934fda12fd60cebe70c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
