{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Almost Visual Inertial Odometry"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.models import MobileNetV2, mobilenet_v3_small, MobileNet_V3_Small_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from  matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 20197\n",
    "BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 32\n",
    "GAMMA = 0.1   # torch default\n",
    "LR=0.001 \n",
    "EPOCHS = 2000\n",
    "EARLY_STOPPING = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available cuda: True\n"
     ]
    }
   ],
   "source": [
    "available_cuda = torch.cuda.is_available()\n",
    "print(f\"Available cuda: {available_cuda}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if available_cuda else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvioDataset(torch.utils.data.Dataset):\n",
    "      def __init__(self, frames, inertials, labels, inertials_buffer, choose_split=None, split={'train':0.6, 'val':0.2, 'test':0.2}, shuffle=True):\n",
    "            if shuffle:\n",
    "                  shuffled_index = torch.randperm(frames.shape[0])\n",
    "                  frames = frames[shuffled_index]\n",
    "                  inertials = inertials[shuffled_index]\n",
    "                  labels = labels[shuffled_index]\n",
    "                  inertials_buffer = inertials_buffer[shuffled_index]\n",
    "\n",
    "            if choose_split is None:\n",
    "                  self.frames = frames\n",
    "                  self.inertials = inertials\n",
    "                  self.labels = labels\n",
    "                  self.inertials_buffer = inertials_buffer\n",
    "            else:\n",
    "                  assert split['train'] + split['val'] + split['test'] == 1\n",
    "                  length = frames.shape[0]\n",
    "                  if choose_split == \"train\":\n",
    "                        self.frames = frames[:round(split['train']*length)]\n",
    "                        self.inertials = inertials[:round(split['train']*length)]\n",
    "                        self.labels = labels[:round(split['train']*length)]\n",
    "                        self.inertials_buffer = inertials_buffer[:round(split['train']*length)]\n",
    "                  elif choose_split == \"val\":\n",
    "                        self.frames = frames[round(split['train']*length):-round(split['test']*length)]\n",
    "                        self.inertials = inertials[round(split['train']*length):-round(split['test']*length)]\n",
    "                        self.labels = labels[round(split['train']*length):-round(split['test']*length)]\n",
    "                        self.inertials_buffer = inertials_buffer[round(split['train']*length):-round(split['test']*length)]\n",
    "                  elif choose_split == \"test\":\n",
    "                        self.frames = frames[-round(split['test']*length):]\n",
    "                        self.inertials = inertials[-round(split['test']*length):]\n",
    "                        self.labels = labels[-round(split['test']*length):]\n",
    "                        self.inertials_buffer = inertials_buffer[-round(split['test']*length):]\n",
    "                  else:\n",
    "                        raise Exception(f\"The split name '{choose_split}' doesn't exists\")\n",
    "\n",
    "      def __len__(self):\n",
    "            return len(self.frames) - 1\n",
    "\n",
    "      def __getitem__(self, index):\n",
    "            # load sample of frames\n",
    "            frame_name = self.frames[index]\n",
    "            scene_name, frame_name = frame_name.split(\"_\")\n",
    "            frame_name, file_extension = frame_name.split(\".\")\n",
    "            sample_frame = torch.Tensor(np.load(f\"./data/{scene_name}/iphone/frames/{scene_name}_{frame_name}.npy\", allow_pickle=True))\n",
    "\n",
    "            # build buffer sample of inertials\n",
    "            sample_inertials_buffer = self.inertials_buffer[index]\n",
    "\n",
    "            # load labels\n",
    "            label_odometry = self.labels[index]\n",
    "\n",
    "            # load inertials\n",
    "            label_inertial = self.inertials[index]\n",
    "\n",
    "            return sample_frame, sample_inertials_buffer, label_odometry, label_inertial\n",
    "\n",
    "\n",
    "frames = np.load(\"dataset_frames.npy\", allow_pickle=True)\n",
    "inertials = torch.Tensor(np.load(\"dataset_inertials.npy\", allow_pickle=True))\n",
    "labels = torch.Tensor(np.load(\"dataset_labels.npy\", allow_pickle=True))\n",
    "buffer_inertials = torch.Tensor(np.load(\"dataset_buffer.npy\", allow_pickle=True))\n",
    "\n",
    "train_data = AdvioDataset(frames, inertials, labels, buffer_inertials, \"train\")\n",
    "val_data = AdvioDataset(frames, inertials, labels, buffer_inertials, \"val\")\n",
    "test_data = AdvioDataset(frames, inertials, labels, buffer_inertials, \"test\")\n",
    "\n",
    "del frames\n",
    "del inertials\n",
    "del labels\n",
    "del buffer_inertials\n",
    "\n",
    "params = {'batch_size': BATCH_SIZE,\n",
    "          'num_workers': 6,\n",
    "          'drop_last':True}\n",
    "\n",
    "train_loader = DataLoader(train_data, **params, shuffle=True)\n",
    "val_loader = DataLoader(val_data, **params, shuffle=True)\n",
    "test_loader = DataLoader(test_data, **params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet1D(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(ConvNet1D,self).__init__()\n",
    "    self.conv1 = nn.Conv1d(3,8,3,2)\n",
    "    torch.nn.init.kaiming_uniform_(self.conv1.weight)\n",
    "    \n",
    "    self.conv2 = nn.Conv1d(8,16,3,2)\n",
    "    torch.nn.init.kaiming_uniform_(self.conv2.weight)\n",
    "    \n",
    "    self.conv3 = nn.Conv1d(16,32,3,2)\n",
    "    torch.nn.init.kaiming_uniform_(self.conv3.weight)\n",
    "    \n",
    "    self.conv4 = nn.Conv1d(32,64,3,2)\n",
    "    torch.nn.init.kaiming_uniform_(self.conv4.weight)\n",
    "    \n",
    "    self.conv5 = nn.Conv1d(64,16,3,1)\n",
    "    torch.nn.init.kaiming_uniform_(self.conv5.weight)\n",
    "\n",
    "    self.conv6 = nn.Conv1d(16,3,3,1)\n",
    "    torch.nn.init.kaiming_uniform_(self.conv6.weight)\n",
    "\n",
    "    self.fc1 = nn.Linear(3,3)\n",
    "\n",
    "  def forward(self,x):\n",
    "    # adding uncertanty\n",
    "    # random_weights = torch.randn(x.shape)*2 + 1\n",
    "    # random_weights = random_weights.to(device)\n",
    "    # x = x * random_weights\n",
    "\n",
    "    x = F.silu(self.conv1(x))\n",
    "    x = F.silu(self.conv2(x))\n",
    "    x = F.silu(self.conv3(x))\n",
    "    x = F.silu(self.conv4(x))\n",
    "    x = F.silu(self.conv5(x))\n",
    "    x = F.silu(self.conv6(x))\n",
    "    x = x.reshape(x.shape[0], 3)\n",
    "    x = self.fc1(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InertialNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InertialNet, self).__init__()\n",
    "        \n",
    "        self.conv2d_odometry = MobileNetV2(num_classes=3)\n",
    "        self.conv2d_inertial = MobileNetV2(num_classes=3)\n",
    "        self.conv1d_inertial = ConvNet1D()\n",
    "\n",
    "        self.fc1 = nn.Linear(6,6)\n",
    "        self.fc2 = nn.Linear(6,3)\n",
    "        self.fc3 = nn.Linear(3,3)\n",
    "\n",
    "    def forward(self, x, inertial_buffer):\n",
    "        x_odometry = self.conv2d_odometry(x)\n",
    "        x_inertial = self.conv2d_inertial(x)\n",
    "\n",
    "        x_inertial_unsqueezed = torch.unsqueeze(x_inertial, axis=2)\n",
    "        x_inertial_buffer = torch.concat([inertial_buffer, x_inertial_unsqueezed], axis=2)\n",
    "        x_inertial_refined = self.conv1d_inertial(x_inertial_buffer)\n",
    "\n",
    "        x_odometry = x_odometry.reshape((x.shape[0], -1))\n",
    "        x_inertial_refined = x_inertial_refined.reshape((x.shape[0], -1))\n",
    "        x = torch.concat([x_odometry, x_inertial_refined], axis=1)\n",
    "\n",
    "        x = F.silu(self.fc1(x))\n",
    "        x = F.silu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x, x_inertial, x_inertial_refined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_head(model):\n",
    "    n_inputs = model.classifier[0].in_features\n",
    "    classifier = nn.Linear(n_inputs, 100)\n",
    "    model.classifier[0] = classifier\n",
    "\n",
    "    n_inputs = model.classifier[3].in_features\n",
    "    classifier = nn.Linear(100, 3)\n",
    "    model.classifier[3] = classifier\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InertialNet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InertialNet2, self).__init__()\n",
    "        \n",
    "        self.conv2d_odometry = mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1)\n",
    "        self.conv2d_odometry = replace_head(self.conv2d_odometry)\n",
    "        self.conv2d_inertial = mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1)\n",
    "        self.conv2d_odometry = replace_head(self.conv2d_inertial)\n",
    "        self.conv1d_inertial = ConvNet1D()\n",
    "\n",
    "        self.fc1 = nn.Linear(6,6)\n",
    "        self.fc2 = nn.Linear(6,3)\n",
    "        self.fc3 = nn.Linear(3,3)\n",
    "\n",
    "    def forward(self, x, inertial_buffer):\n",
    "        x_odometry = self.conv2d_odometry(x)\n",
    "        x_inertial = self.conv2d_inertial(x)\n",
    "\n",
    "        x_inertial_unsqueezed = torch.unsqueeze(x_inertial, axis=2)\n",
    "        x_inertial_buffer = torch.concat([inertial_buffer, x_inertial_unsqueezed], axis=2)\n",
    "        x_inertial_refined = self.conv1d_inertial(x_inertial_buffer)\n",
    "\n",
    "        x_odometry = x_odometry.reshape((x.shape[0], -1))\n",
    "        x_inertial_refined = x_inertial_refined.reshape((x.shape[0], -1))\n",
    "        x = torch.concat([x_odometry, x_inertial_refined], axis=1)\n",
    "\n",
    "        x = F.silu(self.fc1(x))\n",
    "        x = F.silu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x, x_inertial, x_inertial_refined"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "  data = data - data.min()\n",
    "  data = data / data.max()\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    history_loss = 0\n",
    "    history_loss=0\n",
    "    history_odometry_loss=0\n",
    "    history_inertial_loss=0\n",
    "    history_inertial_refined_loss=0\n",
    "\n",
    "    for batch_idx, (data, inertials_buffer, labels_odometry, labels_inertial) in enumerate(train_loader):\n",
    "        # data preparation\n",
    "        data = normalize(data)\n",
    "        labels_odometry = labels_odometry.mean(axis=1)\n",
    "        inertials_buffer = inertials_buffer.mean(axis=2)\n",
    "        inertials_buffer = torch.moveaxis(inertials_buffer, 2, 1)\n",
    "        labels_inertial = labels_inertial.mean(axis=1)\n",
    "\n",
    "        data = data.to(device)\n",
    "        inertials_buffer = inertials_buffer.to(device)\n",
    "        labels_odometry = labels_odometry.to(device)\n",
    "        labels_inertial = labels_inertial.to(device)\n",
    "\n",
    "        #forward\n",
    "        optimizer.zero_grad()\n",
    "        out, out_inertial, out_inertial_refined = model(data, inertials_buffer)\n",
    "\n",
    "        # loss\n",
    "        odometry_loss = torch.sqrt(F.mse_loss(out, labels_odometry))\n",
    "        inertial_loss = torch.sqrt(F.mse_loss(out_inertial, labels_inertial))\n",
    "        inertial_refined_loss = torch.sqrt(F.mse_loss(out_inertial_refined, labels_inertial))\n",
    "        loss = odometry_loss + inertial_loss + inertial_refined_loss\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #stats\n",
    "        history_loss += loss.item()\n",
    "        history_odometry_loss += odometry_loss.item()\n",
    "        history_inertial_loss += inertial_loss.item()\n",
    "        history_inertial_refined_loss += inertial_refined_loss.item()\n",
    "\n",
    "        if batch_idx%(len(train_loader)//5)==0:\n",
    "            print(f\"\\t[# {batch_idx: 4}] train_loss: {loss.item():.6f}, odo_loss: {odometry_loss.item():.6f}, ine_loss: {inertial_loss.item():.6f}, ref_loss: {inertial_refined_loss.item():.6f}\")\n",
    "    \n",
    "    history_loss /= len(train_loader) # average epoch loss\n",
    "    history_odometry_loss /= len(train_loader)\n",
    "    history_inertial_loss /= len(train_loader)\n",
    "    history_inertial_refined_loss /= len(train_loader)\n",
    "    print(f\"\\ttrain_loss: {history_loss:.6f}, odo_loss: {history_odometry_loss:.6f}, ine_loss: {history_inertial_loss:.6f}, ref_loss: {history_inertial_refined_loss:.6f}\")\n",
    "    \n",
    "    return history_loss, history_odometry_loss, history_inertial_loss, history_inertial_refined_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, device, val_loader, epoch):\n",
    "    model.train()\n",
    "    history_loss=0\n",
    "    history_odometry_loss=0\n",
    "    history_inertial_loss=0\n",
    "    history_inertial_refined_loss=0\n",
    "\n",
    "    for batch_idx, (data, inertials_buffer, labels_odometry, labels_inertial) in enumerate(val_loader):\n",
    "        # data preparation\n",
    "        data = normalize(data)\n",
    "        labels_odometry = labels_odometry.mean(axis=1)\n",
    "        inertials_buffer = inertials_buffer.mean(axis=2)\n",
    "        inertials_buffer = torch.moveaxis(inertials_buffer, 2, 1)\n",
    "        labels_inertial = labels_inertial.mean(axis=1)\n",
    "\n",
    "        data = data.to(device)\n",
    "        inertials_buffer = inertials_buffer.to(device)\n",
    "        labels_odometry = labels_odometry.to(device)\n",
    "        labels_inertial = labels_inertial.to(device)\n",
    "\n",
    "        # forward\n",
    "        out, out_inertial, out_inertial_refined = model(data, inertials_buffer)\n",
    "\n",
    "        # loss\n",
    "        odometry_loss = torch.sqrt(F.mse_loss(out, labels_odometry))\n",
    "        inertial_loss = torch.sqrt(F.mse_loss(out_inertial, labels_inertial))\n",
    "        inertial_refined_loss = torch.sqrt(F.mse_loss(out_inertial_refined, labels_inertial))\n",
    "        loss = odometry_loss + inertial_loss + inertial_refined_loss\n",
    "        \n",
    "        #stats\n",
    "        history_loss += loss.item()\n",
    "        history_odometry_loss += odometry_loss.item()\n",
    "        history_inertial_loss += inertial_loss.item()\n",
    "        history_inertial_refined_loss += inertial_refined_loss.item()\n",
    "\n",
    "    history_loss /= len(val_loader) # average epoch loss\n",
    "    history_odometry_loss /= len(val_loader)\n",
    "    history_inertial_loss /= len(val_loader)\n",
    "    history_inertial_refined_loss /= len(val_loader)\n",
    "    print(f\"\\tval_loss: {history_loss:.6f}, odo_loss: {history_odometry_loss:.6f}, ine_loss: {history_inertial_loss:.6f}, ref_loss: {history_inertial_refined_loss:.6f}\")\n",
    "\n",
    "    return history_loss, history_odometry_loss, history_inertial_loss, history_inertial_refined_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "\t[#    0] train_loss: 18.536900, odo_loss: 17.134748, ine_loss: 0.676264, ref_loss: 0.725888\n",
      "\t[#  180] train_loss: 22.863979, odo_loss: 22.201708, ine_loss: 0.369722, ref_loss: 0.292549\n",
      "\t[#  360] train_loss: 19.769011, odo_loss: 19.168858, ine_loss: 0.346896, ref_loss: 0.253257\n",
      "\t[#  540] train_loss: 18.706205, odo_loss: 17.558844, ine_loss: 0.912996, ref_loss: 0.234366\n",
      "\t[#  720] train_loss: 18.767729, odo_loss: 17.398020, ine_loss: 1.052042, ref_loss: 0.317667\n",
      "\t[#  900] train_loss: 15.692014, odo_loss: 13.762267, ine_loss: 1.651571, ref_loss: 0.278175\n",
      "\ttrain_loss: 19.050353, odo_loss: 18.034054, ine_loss: 0.725502, ref_loss: 0.290797\n",
      "\tval_loss: 15.358599, odo_loss: 13.592765, ine_loss: 1.504053, ref_loss: 0.261781\n",
      "\t*** Personal Best ***\n",
      "Epoch 2/2000\n",
      "\t[#    0] train_loss: 12.353523, odo_loss: 10.662315, ine_loss: 1.436039, ref_loss: 0.255169\n",
      "\t[#  180] train_loss: 14.736344, odo_loss: 13.179420, ine_loss: 1.286616, ref_loss: 0.270307\n",
      "\t[#  360] train_loss: 13.067213, odo_loss: 11.671004, ine_loss: 1.040468, ref_loss: 0.355741\n",
      "\t[#  540] train_loss: 9.883199, odo_loss: 8.713314, ine_loss: 0.954618, ref_loss: 0.215266\n",
      "\t[#  720] train_loss: 12.032157, odo_loss: 10.671142, ine_loss: 1.124445, ref_loss: 0.236571\n",
      "\t[#  900] train_loss: 10.256164, odo_loss: 8.999200, ine_loss: 0.934250, ref_loss: 0.322714\n",
      "\ttrain_loss: 12.281238, odo_loss: 10.874090, ine_loss: 1.142419, ref_loss: 0.264729\n",
      "\tval_loss: 10.462215, odo_loss: 9.301320, ine_loss: 0.906286, ref_loss: 0.254609\n",
      "\t*** Personal Best ***\n",
      "Epoch 3/2000\n",
      "\t[#    0] train_loss: 9.194778, odo_loss: 7.934384, ine_loss: 0.964498, ref_loss: 0.295897\n",
      "\t[#  180] train_loss: 10.708104, odo_loss: 9.650922, ine_loss: 0.796780, ref_loss: 0.260403\n",
      "\t[#  360] train_loss: 9.756662, odo_loss: 8.723392, ine_loss: 0.779450, ref_loss: 0.253821\n",
      "\t[#  540] train_loss: 8.778183, odo_loss: 7.688451, ine_loss: 0.859384, ref_loss: 0.230347\n",
      "\t[#  720] train_loss: 11.711359, odo_loss: 10.804787, ine_loss: 0.707574, ref_loss: 0.198998\n",
      "\t[#  900] train_loss: 9.740107, odo_loss: 8.818860, ine_loss: 0.689446, ref_loss: 0.231801\n",
      "\ttrain_loss: 10.275757, odo_loss: 9.231774, ine_loss: 0.789851, ref_loss: 0.254132\n",
      "\tval_loss: 10.063586, odo_loss: 9.120634, ine_loss: 0.683120, ref_loss: 0.259832\n",
      "\t*** Personal Best ***\n",
      "Epoch 4/2000\n",
      "\t[#    0] train_loss: 10.957258, odo_loss: 9.953724, ine_loss: 0.722488, ref_loss: 0.281046\n",
      "\t[#  180] train_loss: 9.621970, odo_loss: 8.632568, ine_loss: 0.689836, ref_loss: 0.299565\n",
      "\t[#  360] train_loss: 11.365837, odo_loss: 10.390323, ine_loss: 0.708299, ref_loss: 0.267214\n",
      "\t[#  540] train_loss: 8.987087, odo_loss: 7.976097, ine_loss: 0.770362, ref_loss: 0.240630\n",
      "\t[#  720] train_loss: 13.596936, odo_loss: 12.682624, ine_loss: 0.675582, ref_loss: 0.238731\n",
      "\t[#  900] train_loss: 9.385355, odo_loss: 8.492130, ine_loss: 0.669554, ref_loss: 0.223671\n",
      "\ttrain_loss: 9.569551, odo_loss: 8.639712, ine_loss: 0.680482, ref_loss: 0.249356\n",
      "\tval_loss: 9.359286, odo_loss: 8.462624, ine_loss: 0.652724, ref_loss: 0.243938\n",
      "\t*** Personal Best ***\n",
      "Epoch 5/2000\n",
      "\t[#    0] train_loss: 10.132417, odo_loss: 9.092463, ine_loss: 0.745166, ref_loss: 0.294788\n",
      "\t[#  180] train_loss: 6.082519, odo_loss: 5.288026, ine_loss: 0.554423, ref_loss: 0.240070\n",
      "\t[#  360] train_loss: 8.319532, odo_loss: 7.504124, ine_loss: 0.598742, ref_loss: 0.216667\n",
      "\t[#  540] train_loss: 10.191121, odo_loss: 9.203711, ine_loss: 0.746122, ref_loss: 0.241289\n",
      "\t[#  720] train_loss: 10.808357, odo_loss: 9.787296, ine_loss: 0.754900, ref_loss: 0.266161\n",
      "\t[#  900] train_loss: 5.920269, odo_loss: 5.134354, ine_loss: 0.541560, ref_loss: 0.244355\n",
      "\ttrain_loss: 9.223298, odo_loss: 8.320879, ine_loss: 0.655433, ref_loss: 0.246985\n",
      "\tval_loss: 9.089402, odo_loss: 8.185535, ine_loss: 0.659492, ref_loss: 0.244376\n",
      "\t*** Personal Best ***\n",
      "Epoch 6/2000\n",
      "\t[#    0] train_loss: 8.327546, odo_loss: 7.351549, ine_loss: 0.701188, ref_loss: 0.274810\n",
      "\t[#  180] train_loss: 9.733889, odo_loss: 8.823957, ine_loss: 0.712167, ref_loss: 0.197764\n",
      "\t[#  360] train_loss: 10.158897, odo_loss: 9.213580, ine_loss: 0.675733, ref_loss: 0.269584\n",
      "\t[#  540] train_loss: 8.715450, odo_loss: 7.824648, ine_loss: 0.658059, ref_loss: 0.232742\n",
      "\t[#  720] train_loss: 8.661216, odo_loss: 7.797935, ine_loss: 0.629790, ref_loss: 0.233490\n",
      "\t[#  900] train_loss: 8.700264, odo_loss: 7.739198, ine_loss: 0.697175, ref_loss: 0.263891\n",
      "\ttrain_loss: 8.967630, odo_loss: 8.041927, ine_loss: 0.680174, ref_loss: 0.245529\n",
      "\tval_loss: 9.206838, odo_loss: 8.249257, ine_loss: 0.712862, ref_loss: 0.244718\n",
      "Epoch 7/2000\n",
      "\t[#    0] train_loss: 13.357382, odo_loss: 12.432247, ine_loss: 0.663156, ref_loss: 0.261979\n",
      "\t[#  180] train_loss: 9.445082, odo_loss: 8.577137, ine_loss: 0.632920, ref_loss: 0.235026\n",
      "\t[#  360] train_loss: 9.020117, odo_loss: 8.195705, ine_loss: 0.587510, ref_loss: 0.236901\n",
      "\t[#  540] train_loss: 11.372373, odo_loss: 10.410378, ine_loss: 0.748190, ref_loss: 0.213805\n",
      "\t[#  720] train_loss: 8.105373, odo_loss: 7.250138, ine_loss: 0.606515, ref_loss: 0.248720\n",
      "\t[#  900] train_loss: 8.702615, odo_loss: 7.765017, ine_loss: 0.690839, ref_loss: 0.246759\n",
      "\ttrain_loss: 8.516491, odo_loss: 7.572662, ine_loss: 0.700448, ref_loss: 0.243380\n",
      "\tval_loss: 8.268491, odo_loss: 7.347103, ine_loss: 0.680754, ref_loss: 0.240634\n",
      "\t*** Personal Best ***\n",
      "Epoch 8/2000\n",
      "\t[#    0] train_loss: 8.739070, odo_loss: 7.852505, ine_loss: 0.663303, ref_loss: 0.223262\n",
      "\t[#  180] train_loss: 8.754222, odo_loss: 7.968280, ine_loss: 0.587696, ref_loss: 0.198246\n",
      "\t[#  360] train_loss: 8.153556, odo_loss: 7.343876, ine_loss: 0.616045, ref_loss: 0.193635\n",
      "\t[#  540] train_loss: 9.388226, odo_loss: 8.275331, ine_loss: 0.854816, ref_loss: 0.258079\n",
      "\t[#  720] train_loss: 6.471696, odo_loss: 5.578965, ine_loss: 0.683015, ref_loss: 0.209717\n",
      "\t[#  900] train_loss: 5.380644, odo_loss: 4.413701, ine_loss: 0.709904, ref_loss: 0.257040\n",
      "\ttrain_loss: 7.754729, odo_loss: 6.817992, ine_loss: 0.696547, ref_loss: 0.240190\n",
      "\tval_loss: 7.535313, odo_loss: 6.592647, ine_loss: 0.704307, ref_loss: 0.238359\n",
      "\t*** Personal Best ***\n",
      "Epoch 9/2000\n",
      "\t[#    0] train_loss: 8.352308, odo_loss: 7.481277, ine_loss: 0.693184, ref_loss: 0.177847\n",
      "\t[#  180] train_loss: 7.789990, odo_loss: 6.769415, ine_loss: 0.695525, ref_loss: 0.325050\n",
      "\t[#  360] train_loss: 6.929461, odo_loss: 5.873617, ine_loss: 0.774743, ref_loss: 0.281101\n",
      "\t[#  540] train_loss: 7.757362, odo_loss: 6.687256, ine_loss: 0.812284, ref_loss: 0.257823\n",
      "\t[#  720] train_loss: 10.198589, odo_loss: 9.385235, ine_loss: 0.596501, ref_loss: 0.216853\n",
      "\t[#  900] train_loss: 6.047962, odo_loss: 5.156493, ine_loss: 0.657688, ref_loss: 0.233781\n",
      "\ttrain_loss: 7.433611, odo_loss: 6.508623, ine_loss: 0.686537, ref_loss: 0.238451\n",
      "\tval_loss: 7.520280, odo_loss: 6.591977, ine_loss: 0.691363, ref_loss: 0.236941\n",
      "\t*** Personal Best ***\n",
      "Epoch 10/2000\n",
      "\t[#    0] train_loss: 5.749128, odo_loss: 4.956235, ine_loss: 0.556112, ref_loss: 0.236781\n",
      "\t[#  180] train_loss: 6.766576, odo_loss: 5.861307, ine_loss: 0.678319, ref_loss: 0.226949\n",
      "\t[#  360] train_loss: 7.273996, odo_loss: 6.354034, ine_loss: 0.731523, ref_loss: 0.188440\n",
      "\t[#  540] train_loss: 5.780386, odo_loss: 4.954399, ine_loss: 0.594192, ref_loss: 0.231796\n",
      "\t[#  720] train_loss: 7.193370, odo_loss: 6.274923, ine_loss: 0.714821, ref_loss: 0.203626\n",
      "\t[#  900] train_loss: 6.814597, odo_loss: 6.000398, ine_loss: 0.595867, ref_loss: 0.218331\n",
      "\ttrain_loss: 7.089424, odo_loss: 6.177204, ine_loss: 0.675018, ref_loss: 0.237201\n",
      "\tval_loss: 6.860111, odo_loss: 5.957102, ine_loss: 0.663491, ref_loss: 0.239518\n",
      "\t*** Personal Best ***\n",
      "Epoch 11/2000\n",
      "\t[#    0] train_loss: 6.528986, odo_loss: 5.745432, ine_loss: 0.558249, ref_loss: 0.225304\n",
      "\t[#  180] train_loss: 5.406953, odo_loss: 4.492779, ine_loss: 0.683688, ref_loss: 0.230486\n",
      "\t[#  360] train_loss: 6.198750, odo_loss: 5.290161, ine_loss: 0.633043, ref_loss: 0.275547\n",
      "\t[#  540] train_loss: 7.988686, odo_loss: 7.095327, ine_loss: 0.683892, ref_loss: 0.209466\n",
      "\t[#  720] train_loss: 8.957393, odo_loss: 8.088390, ine_loss: 0.687217, ref_loss: 0.181786\n",
      "\t[#  900] train_loss: 8.917792, odo_loss: 8.045157, ine_loss: 0.655059, ref_loss: 0.217575\n",
      "\ttrain_loss: 6.883053, odo_loss: 5.987701, ine_loss: 0.659868, ref_loss: 0.235484\n",
      "\tval_loss: 6.520933, odo_loss: 5.635100, ine_loss: 0.652141, ref_loss: 0.233691\n",
      "\t*** Personal Best ***\n",
      "Epoch 12/2000\n",
      "\t[#    0] train_loss: 7.768053, odo_loss: 6.738925, ine_loss: 0.779096, ref_loss: 0.250032\n",
      "\t[#  180] train_loss: 8.407838, odo_loss: 7.418554, ine_loss: 0.712912, ref_loss: 0.276372\n",
      "\t[#  360] train_loss: 5.666164, odo_loss: 4.736120, ine_loss: 0.640539, ref_loss: 0.289505\n",
      "\t[#  540] train_loss: 6.365957, odo_loss: 5.398656, ine_loss: 0.698666, ref_loss: 0.268634\n",
      "\t[#  720] train_loss: 6.223690, odo_loss: 5.259046, ine_loss: 0.701846, ref_loss: 0.262798\n",
      "\t[#  900] train_loss: 7.402888, odo_loss: 6.639515, ine_loss: 0.539625, ref_loss: 0.223748\n",
      "\ttrain_loss: 6.345842, odo_loss: 5.461525, ine_loss: 0.651341, ref_loss: 0.232976\n",
      "\tval_loss: 6.321737, odo_loss: 5.448174, ine_loss: 0.641431, ref_loss: 0.232133\n",
      "\t*** Personal Best ***\n",
      "Epoch 13/2000\n",
      "\t[#    0] train_loss: 5.078966, odo_loss: 4.389472, ine_loss: 0.493856, ref_loss: 0.195638\n",
      "\t[#  180] train_loss: 6.001128, odo_loss: 5.288752, ine_loss: 0.522458, ref_loss: 0.189919\n",
      "\t[#  360] train_loss: 7.754154, odo_loss: 6.966618, ine_loss: 0.593774, ref_loss: 0.193761\n",
      "\t[#  540] train_loss: 4.213093, odo_loss: 3.380085, ine_loss: 0.609713, ref_loss: 0.223295\n",
      "\t[#  720] train_loss: 5.624187, odo_loss: 4.816972, ine_loss: 0.599384, ref_loss: 0.207831\n",
      "\t[#  900] train_loss: 5.905665, odo_loss: 4.940082, ine_loss: 0.698424, ref_loss: 0.267160\n",
      "\ttrain_loss: 6.445821, odo_loss: 5.577230, ine_loss: 0.635463, ref_loss: 0.233128\n",
      "\tval_loss: 6.141915, odo_loss: 5.273783, ine_loss: 0.636067, ref_loss: 0.232064\n",
      "\t*** Personal Best ***\n",
      "Epoch 14/2000\n",
      "\t[#    0] train_loss: 7.510538, odo_loss: 6.473656, ine_loss: 0.746706, ref_loss: 0.290176\n",
      "\t[#  180] train_loss: 6.783783, odo_loss: 5.909711, ine_loss: 0.629415, ref_loss: 0.244657\n",
      "\t[#  360] train_loss: 8.212523, odo_loss: 7.443182, ine_loss: 0.562707, ref_loss: 0.206635\n",
      "\t[#  540] train_loss: 5.868741, odo_loss: 5.118063, ine_loss: 0.535448, ref_loss: 0.215230\n",
      "\t[#  720] train_loss: 6.491646, odo_loss: 5.665409, ine_loss: 0.608689, ref_loss: 0.217548\n",
      "\t[#  900] train_loss: 5.454621, odo_loss: 4.578601, ine_loss: 0.620661, ref_loss: 0.255359\n",
      "\ttrain_loss: 6.062572, odo_loss: 5.203012, ine_loss: 0.629214, ref_loss: 0.230345\n",
      "\tval_loss: 5.941136, odo_loss: 5.090067, ine_loss: 0.620808, ref_loss: 0.230261\n",
      "\t*** Personal Best ***\n",
      "Epoch 15/2000\n",
      "\t[#    0] train_loss: 5.202430, odo_loss: 4.458920, ine_loss: 0.552038, ref_loss: 0.191472\n",
      "\t[#  180] train_loss: 4.888828, odo_loss: 3.992490, ine_loss: 0.621975, ref_loss: 0.274363\n",
      "\t[#  360] train_loss: 6.092061, odo_loss: 5.349151, ine_loss: 0.552859, ref_loss: 0.190051\n",
      "\t[#  540] train_loss: 5.264983, odo_loss: 4.299977, ine_loss: 0.708650, ref_loss: 0.256356\n",
      "\t[#  720] train_loss: 6.529244, odo_loss: 5.686923, ine_loss: 0.664059, ref_loss: 0.178262\n",
      "\t[#  900] train_loss: 5.417450, odo_loss: 4.620286, ine_loss: 0.605330, ref_loss: 0.191834\n",
      "\ttrain_loss: 5.862109, odo_loss: 5.012264, ine_loss: 0.620384, ref_loss: 0.229461\n",
      "\tval_loss: 5.599638, odo_loss: 4.758656, ine_loss: 0.613527, ref_loss: 0.227456\n",
      "\t*** Personal Best ***\n",
      "Epoch 16/2000\n",
      "\t[#    0] train_loss: 5.622849, odo_loss: 4.735119, ine_loss: 0.677502, ref_loss: 0.210227\n",
      "\t[#  180] train_loss: 7.624539, odo_loss: 6.682749, ine_loss: 0.662579, ref_loss: 0.279210\n",
      "\t[#  360] train_loss: 7.151979, odo_loss: 6.354376, ine_loss: 0.591423, ref_loss: 0.206181\n",
      "\t[#  540] train_loss: 7.222722, odo_loss: 6.244027, ine_loss: 0.710966, ref_loss: 0.267728\n",
      "\t[#  720] train_loss: 3.927373, odo_loss: 3.116642, ine_loss: 0.588810, ref_loss: 0.221921\n",
      "\t[#  900] train_loss: 6.275033, odo_loss: 5.525008, ine_loss: 0.548091, ref_loss: 0.201934\n",
      "\ttrain_loss: 5.467758, odo_loss: 4.625860, ine_loss: 0.614436, ref_loss: 0.227463\n",
      "\tval_loss: 5.352495, odo_loss: 4.521091, ine_loss: 0.606688, ref_loss: 0.224716\n",
      "\t*** Personal Best ***\n",
      "Epoch 17/2000\n",
      "\t[#    0] train_loss: 4.093949, odo_loss: 3.244732, ine_loss: 0.660409, ref_loss: 0.188808\n",
      "\t[#  180] train_loss: 4.928240, odo_loss: 4.090579, ine_loss: 0.581769, ref_loss: 0.255893\n",
      "\t[#  360] train_loss: 5.748115, odo_loss: 4.833487, ine_loss: 0.639368, ref_loss: 0.275260\n",
      "\t[#  540] train_loss: 3.772478, odo_loss: 2.836352, ine_loss: 0.682035, ref_loss: 0.254091\n",
      "\t[#  720] train_loss: 5.776389, odo_loss: 4.927141, ine_loss: 0.604961, ref_loss: 0.244287\n",
      "\t[#  900] train_loss: 6.328370, odo_loss: 5.551951, ine_loss: 0.579751, ref_loss: 0.196669\n",
      "\ttrain_loss: 5.412135, odo_loss: 4.579851, ine_loss: 0.606078, ref_loss: 0.226206\n",
      "\tval_loss: 5.224358, odo_loss: 4.394805, ine_loss: 0.603509, ref_loss: 0.226044\n",
      "\t*** Personal Best ***\n",
      "Epoch 18/2000\n",
      "\t[#    0] train_loss: 5.328944, odo_loss: 4.352513, ine_loss: 0.657633, ref_loss: 0.318798\n",
      "\t[#  180] train_loss: 5.622846, odo_loss: 4.774190, ine_loss: 0.603201, ref_loss: 0.245455\n",
      "\t[#  360] train_loss: 4.972244, odo_loss: 4.142121, ine_loss: 0.607607, ref_loss: 0.222516\n",
      "\t[#  540] train_loss: 3.773103, odo_loss: 3.024423, ine_loss: 0.542754, ref_loss: 0.205926\n",
      "\t[#  720] train_loss: 3.595502, odo_loss: 2.932326, ine_loss: 0.472382, ref_loss: 0.190794\n",
      "\t[#  900] train_loss: 5.562701, odo_loss: 4.574731, ine_loss: 0.761423, ref_loss: 0.226547\n",
      "\ttrain_loss: 5.397657, odo_loss: 4.575181, ine_loss: 0.596899, ref_loss: 0.225577\n",
      "\tval_loss: 5.186832, odo_loss: 4.376298, ine_loss: 0.585551, ref_loss: 0.224983\n",
      "\t*** Personal Best ***\n",
      "Epoch 19/2000\n",
      "\t[#    0] train_loss: 5.357717, odo_loss: 4.526849, ine_loss: 0.619469, ref_loss: 0.211398\n",
      "\t[#  180] train_loss: 4.099600, odo_loss: 3.240033, ine_loss: 0.608279, ref_loss: 0.251288\n",
      "\t[#  360] train_loss: 5.308990, odo_loss: 4.615396, ine_loss: 0.491984, ref_loss: 0.201609\n",
      "\t[#  540] train_loss: 4.200995, odo_loss: 3.467058, ine_loss: 0.520783, ref_loss: 0.213155\n",
      "\t[#  720] train_loss: 5.485725, odo_loss: 4.690784, ine_loss: 0.587418, ref_loss: 0.207523\n",
      "\t[#  900] train_loss: 6.340807, odo_loss: 5.576050, ine_loss: 0.571220, ref_loss: 0.193538\n",
      "\ttrain_loss: 5.075841, odo_loss: 4.262426, ine_loss: 0.590150, ref_loss: 0.223265\n",
      "\tval_loss: 5.186694, odo_loss: 4.374941, ine_loss: 0.584699, ref_loss: 0.227055\n",
      "\t*** Personal Best ***\n",
      "Epoch 20/2000\n",
      "\t[#    0] train_loss: 5.277606, odo_loss: 4.569060, ine_loss: 0.509550, ref_loss: 0.198996\n",
      "\t[#  180] train_loss: 5.577865, odo_loss: 4.782474, ine_loss: 0.585455, ref_loss: 0.209936\n",
      "\t[#  360] train_loss: 4.744134, odo_loss: 3.884218, ine_loss: 0.613231, ref_loss: 0.246684\n",
      "\t[#  540] train_loss: 3.477873, odo_loss: 2.626263, ine_loss: 0.589347, ref_loss: 0.262263\n",
      "\t[#  720] train_loss: 3.569525, odo_loss: 2.830568, ine_loss: 0.570539, ref_loss: 0.168418\n",
      "\t[#  900] train_loss: 6.882624, odo_loss: 6.008239, ine_loss: 0.672740, ref_loss: 0.201644\n",
      "\ttrain_loss: 5.068145, odo_loss: 4.261808, ine_loss: 0.583438, ref_loss: 0.222899\n",
      "\tval_loss: 4.725792, odo_loss: 3.928842, ine_loss: 0.575862, ref_loss: 0.221087\n",
      "\t*** Personal Best ***\n",
      "Epoch 21/2000\n",
      "\t[#    0] train_loss: 5.681766, odo_loss: 4.895121, ine_loss: 0.582126, ref_loss: 0.204519\n",
      "\t[#  180] train_loss: 5.308265, odo_loss: 4.496950, ine_loss: 0.611297, ref_loss: 0.200018\n",
      "\t[#  360] train_loss: 5.803716, odo_loss: 5.003188, ine_loss: 0.586752, ref_loss: 0.213777\n",
      "\t[#  540] train_loss: 3.487541, odo_loss: 2.742137, ine_loss: 0.523465, ref_loss: 0.221939\n",
      "\t[#  720] train_loss: 5.782475, odo_loss: 4.953067, ine_loss: 0.620946, ref_loss: 0.208462\n",
      "\t[#  900] train_loss: 3.903640, odo_loss: 3.178227, ine_loss: 0.516864, ref_loss: 0.208548\n",
      "\ttrain_loss: 4.644635, odo_loss: 3.845095, ine_loss: 0.579007, ref_loss: 0.220533\n",
      "\tval_loss: 4.641598, odo_loss: 3.854369, ine_loss: 0.567987, ref_loss: 0.219242\n",
      "\t*** Personal Best ***\n",
      "Epoch 22/2000\n",
      "\t[#    0] train_loss: 3.703652, odo_loss: 2.937428, ine_loss: 0.541612, ref_loss: 0.224613\n",
      "\t[#  180] train_loss: 3.301471, odo_loss: 2.524171, ine_loss: 0.541282, ref_loss: 0.236018\n",
      "\t[#  360] train_loss: 5.224002, odo_loss: 4.446075, ine_loss: 0.593088, ref_loss: 0.184839\n",
      "\t[#  540] train_loss: 4.081224, odo_loss: 3.390148, ine_loss: 0.466944, ref_loss: 0.224132\n",
      "\t[#  720] train_loss: 4.429348, odo_loss: 3.642088, ine_loss: 0.552606, ref_loss: 0.234653\n",
      "\t[#  900] train_loss: 3.841785, odo_loss: 3.018236, ine_loss: 0.570125, ref_loss: 0.253424\n",
      "\ttrain_loss: 4.513497, odo_loss: 3.723474, ine_loss: 0.571565, ref_loss: 0.218458\n",
      "\tval_loss: 4.421867, odo_loss: 3.638615, ine_loss: 0.563735, ref_loss: 0.219517\n",
      "\t*** Personal Best ***\n",
      "Epoch 23/2000\n",
      "\t[#    0] train_loss: 4.742625, odo_loss: 3.880583, ine_loss: 0.639386, ref_loss: 0.222657\n",
      "\t[#  180] train_loss: 3.540656, odo_loss: 2.560063, ine_loss: 0.720012, ref_loss: 0.260581\n",
      "\t[#  360] train_loss: 5.697339, odo_loss: 4.981515, ine_loss: 0.533195, ref_loss: 0.182628\n",
      "\t[#  540] train_loss: 5.111115, odo_loss: 4.241602, ine_loss: 0.630147, ref_loss: 0.239366\n",
      "\t[#  720] train_loss: 4.412028, odo_loss: 3.599217, ine_loss: 0.608258, ref_loss: 0.204553\n",
      "\t[#  900] train_loss: 6.303791, odo_loss: 5.506882, ine_loss: 0.563055, ref_loss: 0.233854\n",
      "\ttrain_loss: 4.406800, odo_loss: 3.624594, ine_loss: 0.565452, ref_loss: 0.216754\n",
      "\tval_loss: 5.799534, odo_loss: 5.026097, ine_loss: 0.556536, ref_loss: 0.216900\n",
      "Epoch 24/2000\n",
      "\t[#    0] train_loss: 4.180007, odo_loss: 3.358115, ine_loss: 0.632700, ref_loss: 0.189192\n",
      "\t[#  180] train_loss: 5.136797, odo_loss: 4.303661, ine_loss: 0.597418, ref_loss: 0.235718\n",
      "\t[#  360] train_loss: 4.429636, odo_loss: 3.652343, ine_loss: 0.582012, ref_loss: 0.195281\n",
      "\t[#  540] train_loss: 3.348252, odo_loss: 2.537185, ine_loss: 0.596350, ref_loss: 0.214717\n",
      "\t[#  720] train_loss: 5.597198, odo_loss: 4.824460, ine_loss: 0.551745, ref_loss: 0.220992\n",
      "\t[#  900] train_loss: 3.356062, odo_loss: 2.568257, ine_loss: 0.562900, ref_loss: 0.224905\n",
      "\ttrain_loss: 4.892029, odo_loss: 4.113027, ine_loss: 0.559891, ref_loss: 0.219111\n",
      "\tval_loss: 4.387850, odo_loss: 3.617243, ine_loss: 0.552281, ref_loss: 0.218327\n",
      "\t*** Personal Best ***\n",
      "Epoch 25/2000\n",
      "\t[#    0] train_loss: 3.027941, odo_loss: 2.268952, ine_loss: 0.575808, ref_loss: 0.183181\n",
      "\t[#  180] train_loss: 3.983113, odo_loss: 3.245472, ine_loss: 0.532613, ref_loss: 0.205028\n",
      "\t[#  360] train_loss: 3.296282, odo_loss: 2.503251, ine_loss: 0.547079, ref_loss: 0.245952\n",
      "\t[#  540] train_loss: 3.752720, odo_loss: 2.838863, ine_loss: 0.689375, ref_loss: 0.224481\n",
      "\t[#  720] train_loss: 3.513300, odo_loss: 2.643559, ine_loss: 0.627296, ref_loss: 0.242445\n",
      "\t[#  900] train_loss: 2.683702, odo_loss: 2.004948, ine_loss: 0.466398, ref_loss: 0.212355\n",
      "\ttrain_loss: 4.306966, odo_loss: 3.534421, ine_loss: 0.557299, ref_loss: 0.215246\n",
      "\tval_loss: 4.112750, odo_loss: 3.356659, ine_loss: 0.542355, ref_loss: 0.213737\n",
      "\t*** Personal Best ***\n",
      "Epoch 26/2000\n",
      "\t[#    0] train_loss: 4.001339, odo_loss: 3.327677, ine_loss: 0.486669, ref_loss: 0.186995\n",
      "\t[#  180] train_loss: 4.042152, odo_loss: 3.316518, ine_loss: 0.513745, ref_loss: 0.211889\n",
      "\t[#  360] train_loss: 5.591993, odo_loss: 4.710123, ine_loss: 0.645132, ref_loss: 0.236738\n",
      "\t[#  540] train_loss: 4.291351, odo_loss: 3.574016, ine_loss: 0.549024, ref_loss: 0.168311\n",
      "\t[#  720] train_loss: 4.228462, odo_loss: 3.492874, ine_loss: 0.506970, ref_loss: 0.228617\n",
      "\t[#  900] train_loss: 5.262083, odo_loss: 4.451409, ine_loss: 0.618042, ref_loss: 0.192632\n",
      "\ttrain_loss: 4.089891, odo_loss: 3.327998, ine_loss: 0.548503, ref_loss: 0.213390\n",
      "\tval_loss: 4.093169, odo_loss: 3.337179, ine_loss: 0.543493, ref_loss: 0.212497\n",
      "\t*** Personal Best ***\n",
      "Epoch 27/2000\n",
      "\t[#    0] train_loss: 3.258864, odo_loss: 2.464611, ine_loss: 0.567229, ref_loss: 0.227024\n",
      "\t[#  180] train_loss: 4.248851, odo_loss: 3.535503, ine_loss: 0.500107, ref_loss: 0.213242\n",
      "\t[#  360] train_loss: 3.787509, odo_loss: 3.088624, ine_loss: 0.487410, ref_loss: 0.211475\n",
      "\t[#  540] train_loss: 4.884996, odo_loss: 4.101682, ine_loss: 0.566041, ref_loss: 0.217274\n",
      "\t[#  720] train_loss: 5.168022, odo_loss: 4.427512, ine_loss: 0.511887, ref_loss: 0.228623\n",
      "\t[#  900] train_loss: 5.613484, odo_loss: 4.905513, ine_loss: 0.490734, ref_loss: 0.217237\n",
      "\ttrain_loss: 4.328565, odo_loss: 3.569353, ine_loss: 0.545557, ref_loss: 0.213655\n",
      "\tval_loss: 4.815303, odo_loss: 4.053776, ine_loss: 0.540539, ref_loss: 0.220988\n",
      "Epoch 28/2000\n",
      "\t[#    0] train_loss: 3.560099, odo_loss: 2.686067, ine_loss: 0.629531, ref_loss: 0.244501\n",
      "\t[#  180] train_loss: 5.215311, odo_loss: 4.383394, ine_loss: 0.611790, ref_loss: 0.220127\n",
      "\t[#  360] train_loss: 3.954989, odo_loss: 3.209126, ine_loss: 0.538501, ref_loss: 0.207362\n",
      "\t[#  540] train_loss: 4.328205, odo_loss: 3.672982, ine_loss: 0.484920, ref_loss: 0.170304\n",
      "\t[#  720] train_loss: 3.055015, odo_loss: 2.388099, ine_loss: 0.499684, ref_loss: 0.167232\n",
      "\t[#  900] train_loss: 4.059193, odo_loss: 3.246722, ine_loss: 0.594207, ref_loss: 0.218265\n",
      "\ttrain_loss: 4.191395, odo_loss: 3.436658, ine_loss: 0.541942, ref_loss: 0.212795\n",
      "\tval_loss: 3.988597, odo_loss: 3.238395, ine_loss: 0.535263, ref_loss: 0.214939\n",
      "\t*** Personal Best ***\n",
      "Epoch 29/2000\n",
      "\t[#    0] train_loss: 2.913362, odo_loss: 2.350470, ine_loss: 0.382642, ref_loss: 0.180251\n",
      "\t[#  180] train_loss: 4.360992, odo_loss: 3.628974, ine_loss: 0.505920, ref_loss: 0.226098\n",
      "\t[#  360] train_loss: 5.382057, odo_loss: 4.629361, ine_loss: 0.575069, ref_loss: 0.177626\n",
      "\t[#  540] train_loss: 3.622263, odo_loss: 2.752689, ine_loss: 0.624281, ref_loss: 0.245293\n",
      "\t[#  720] train_loss: 3.990699, odo_loss: 3.314109, ine_loss: 0.497384, ref_loss: 0.179206\n",
      "\t[#  900] train_loss: 4.250663, odo_loss: 3.457667, ine_loss: 0.609177, ref_loss: 0.183819\n",
      "\ttrain_loss: 3.993078, odo_loss: 3.244195, ine_loss: 0.537942, ref_loss: 0.210941\n",
      "\tval_loss: 3.873114, odo_loss: 3.122845, ine_loss: 0.537548, ref_loss: 0.212722\n",
      "\t*** Personal Best ***\n",
      "Epoch 30/2000\n",
      "\t[#    0] train_loss: 3.024762, odo_loss: 2.354479, ine_loss: 0.477784, ref_loss: 0.192499\n",
      "\t[#  180] train_loss: 3.210803, odo_loss: 2.500094, ine_loss: 0.494111, ref_loss: 0.216598\n",
      "\t[#  360] train_loss: 4.072649, odo_loss: 3.359577, ine_loss: 0.511969, ref_loss: 0.201103\n",
      "\t[#  540] train_loss: 3.349848, odo_loss: 2.692641, ine_loss: 0.450979, ref_loss: 0.206228\n",
      "\t[#  720] train_loss: 3.317027, odo_loss: 2.574711, ine_loss: 0.565066, ref_loss: 0.177250\n",
      "\t[#  900] train_loss: 5.169974, odo_loss: 4.444390, ine_loss: 0.528165, ref_loss: 0.197419\n",
      "\ttrain_loss: 3.847023, odo_loss: 3.101693, ine_loss: 0.535892, ref_loss: 0.209438\n",
      "\tval_loss: 3.891664, odo_loss: 3.152635, ine_loss: 0.529449, ref_loss: 0.209580\n",
      "Epoch 31/2000\n",
      "\t[#    0] train_loss: 2.640538, odo_loss: 1.919106, ine_loss: 0.524660, ref_loss: 0.196772\n",
      "\t[#  180] train_loss: 3.220237, odo_loss: 2.541997, ine_loss: 0.445685, ref_loss: 0.232554\n",
      "\t[#  360] train_loss: 4.647674, odo_loss: 3.895762, ine_loss: 0.519686, ref_loss: 0.232226\n",
      "\t[#  540] train_loss: 3.087624, odo_loss: 2.432500, ine_loss: 0.451889, ref_loss: 0.203236\n",
      "\t[#  720] train_loss: 4.102224, odo_loss: 3.393641, ine_loss: 0.507604, ref_loss: 0.200978\n",
      "\t[#  900] train_loss: 4.721567, odo_loss: 4.008969, ine_loss: 0.512665, ref_loss: 0.199933\n",
      "\ttrain_loss: 4.137896, odo_loss: 3.394805, ine_loss: 0.533450, ref_loss: 0.209641\n",
      "\tval_loss: 4.822124, odo_loss: 4.067201, ine_loss: 0.536562, ref_loss: 0.218361\n",
      "Epoch 32/2000\n",
      "\t[#    0] train_loss: 4.497593, odo_loss: 3.667881, ine_loss: 0.557833, ref_loss: 0.271878\n",
      "\t[#  180] train_loss: 3.590136, odo_loss: 2.960095, ine_loss: 0.438293, ref_loss: 0.191747\n",
      "\t[#  360] train_loss: 3.474219, odo_loss: 2.757958, ine_loss: 0.505681, ref_loss: 0.210579\n",
      "\t[#  540] train_loss: 5.017135, odo_loss: 4.275510, ine_loss: 0.526677, ref_loss: 0.214948\n",
      "\t[#  720] train_loss: 4.765074, odo_loss: 3.909810, ine_loss: 0.604757, ref_loss: 0.250508\n",
      "\t[#  900] train_loss: 3.326459, odo_loss: 2.687487, ine_loss: 0.470371, ref_loss: 0.168601\n",
      "\ttrain_loss: 3.868081, odo_loss: 3.126521, ine_loss: 0.531826, ref_loss: 0.209734\n",
      "\tval_loss: 3.714389, odo_loss: 2.970277, ine_loss: 0.532889, ref_loss: 0.211223\n",
      "\t*** Personal Best ***\n",
      "Epoch 33/2000\n",
      "\t[#    0] train_loss: 3.012197, odo_loss: 2.221610, ine_loss: 0.568354, ref_loss: 0.222232\n",
      "\t[#  180] train_loss: 2.811625, odo_loss: 2.115338, ine_loss: 0.484985, ref_loss: 0.211303\n",
      "\t[#  360] train_loss: 4.115958, odo_loss: 3.352566, ine_loss: 0.557527, ref_loss: 0.205865\n",
      "\t[#  540] train_loss: 3.308900, odo_loss: 2.607256, ine_loss: 0.505948, ref_loss: 0.195696\n",
      "\t[#  720] train_loss: 3.547136, odo_loss: 2.805261, ine_loss: 0.535129, ref_loss: 0.206746\n",
      "\t[#  900] train_loss: 3.338128, odo_loss: 2.562791, ine_loss: 0.574612, ref_loss: 0.200725\n",
      "\ttrain_loss: 3.642079, odo_loss: 2.904258, ine_loss: 0.530702, ref_loss: 0.207119\n",
      "\tval_loss: 3.615055, odo_loss: 2.880211, ine_loss: 0.526775, ref_loss: 0.208069\n",
      "\t*** Personal Best ***\n",
      "Epoch 34/2000\n",
      "\t[#    0] train_loss: 3.270043, odo_loss: 2.597911, ine_loss: 0.453494, ref_loss: 0.218638\n",
      "\t[#  180] train_loss: 2.524667, odo_loss: 1.903213, ine_loss: 0.401315, ref_loss: 0.220140\n",
      "\t[#  360] train_loss: 3.134987, odo_loss: 2.443372, ine_loss: 0.480053, ref_loss: 0.211563\n",
      "\t[#  540] train_loss: 4.240605, odo_loss: 3.391156, ine_loss: 0.569058, ref_loss: 0.280390\n",
      "\t[#  720] train_loss: 3.422766, odo_loss: 2.613705, ine_loss: 0.616800, ref_loss: 0.192261\n",
      "\t[#  900] train_loss: 4.971028, odo_loss: 4.231754, ine_loss: 0.546610, ref_loss: 0.192664\n",
      "\ttrain_loss: 3.551781, odo_loss: 2.818757, ine_loss: 0.527614, ref_loss: 0.205410\n",
      "\tval_loss: 3.517460, odo_loss: 2.783950, ine_loss: 0.525303, ref_loss: 0.208208\n",
      "\t*** Personal Best ***\n",
      "Epoch 35/2000\n",
      "\t[#    0] train_loss: 4.303907, odo_loss: 3.553552, ine_loss: 0.567076, ref_loss: 0.183280\n",
      "\t[#  180] train_loss: 3.740439, odo_loss: 2.998831, ine_loss: 0.535258, ref_loss: 0.206351\n",
      "\t[#  360] train_loss: 3.794209, odo_loss: 3.110666, ine_loss: 0.490840, ref_loss: 0.192703\n",
      "\t[#  540] train_loss: 3.057843, odo_loss: 2.243830, ine_loss: 0.598418, ref_loss: 0.215594\n",
      "\t[#  720] train_loss: 2.937911, odo_loss: 2.244131, ine_loss: 0.472668, ref_loss: 0.221111\n",
      "\t[#  900] train_loss: 2.934948, odo_loss: 2.177907, ine_loss: 0.571054, ref_loss: 0.185987\n",
      "\ttrain_loss: 3.475874, odo_loss: 2.744863, ine_loss: 0.526592, ref_loss: 0.204419\n",
      "\tval_loss: 3.650464, odo_loss: 2.928696, ine_loss: 0.515117, ref_loss: 0.206651\n",
      "Epoch 36/2000\n",
      "\t[#    0] train_loss: 4.055325, odo_loss: 3.383395, ine_loss: 0.471989, ref_loss: 0.199940\n",
      "\t[#  180] train_loss: 3.464186, odo_loss: 2.807420, ine_loss: 0.481990, ref_loss: 0.174776\n",
      "\t[#  360] train_loss: 3.642109, odo_loss: 2.941633, ine_loss: 0.479375, ref_loss: 0.221101\n",
      "\t[#  540] train_loss: 3.037920, odo_loss: 2.397579, ine_loss: 0.454261, ref_loss: 0.186080\n",
      "\t[#  720] train_loss: 4.961801, odo_loss: 4.094250, ine_loss: 0.662582, ref_loss: 0.204969\n",
      "\t[#  900] train_loss: 3.570643, odo_loss: 2.645150, ine_loss: 0.701956, ref_loss: 0.223538\n",
      "\ttrain_loss: 3.441822, odo_loss: 2.712881, ine_loss: 0.526180, ref_loss: 0.202761\n",
      "\tval_loss: 3.579357, odo_loss: 2.848241, ine_loss: 0.525709, ref_loss: 0.205407\n",
      "Epoch 37/2000\n",
      "\t[#    0] train_loss: 3.941247, odo_loss: 3.127148, ine_loss: 0.599845, ref_loss: 0.214254\n",
      "\t[#  180] train_loss: 9.132352, odo_loss: 8.411183, ine_loss: 0.526585, ref_loss: 0.194584\n",
      "\t[#  360] train_loss: 3.357962, odo_loss: 2.672321, ine_loss: 0.475009, ref_loss: 0.210631\n",
      "\t[#  540] train_loss: 4.008525, odo_loss: 3.278064, ine_loss: 0.512190, ref_loss: 0.218271\n",
      "\t[#  720] train_loss: 3.529905, odo_loss: 2.627802, ine_loss: 0.654931, ref_loss: 0.247171\n",
      "\t[#  900] train_loss: 3.065924, odo_loss: 2.299148, ine_loss: 0.564023, ref_loss: 0.202753\n",
      "\ttrain_loss: 4.140288, odo_loss: 3.409846, ine_loss: 0.524382, ref_loss: 0.206060\n",
      "\tval_loss: 3.492671, odo_loss: 2.764292, ine_loss: 0.521469, ref_loss: 0.206910\n",
      "\t*** Personal Best ***\n",
      "Epoch 38/2000\n",
      "\t[#    0] train_loss: 3.432434, odo_loss: 2.779099, ine_loss: 0.476783, ref_loss: 0.176553\n",
      "\t[#  180] train_loss: 3.094958, odo_loss: 2.399291, ine_loss: 0.529019, ref_loss: 0.166649\n",
      "\t[#  360] train_loss: 3.012967, odo_loss: 2.331747, ine_loss: 0.478779, ref_loss: 0.202441\n",
      "\t[#  540] train_loss: 3.631032, odo_loss: 2.931113, ine_loss: 0.503162, ref_loss: 0.196757\n",
      "\t[#  720] train_loss: 2.873242, odo_loss: 2.164786, ine_loss: 0.456543, ref_loss: 0.251913\n",
      "\t[#  900] train_loss: 3.852143, odo_loss: 3.026450, ine_loss: 0.599482, ref_loss: 0.226212\n",
      "\ttrain_loss: 3.438205, odo_loss: 2.712817, ine_loss: 0.523100, ref_loss: 0.202289\n",
      "\tval_loss: 3.576426, odo_loss: 2.847199, ine_loss: 0.522561, ref_loss: 0.206666\n",
      "Epoch 39/2000\n",
      "\t[#    0] train_loss: 3.307375, odo_loss: 2.667907, ine_loss: 0.435622, ref_loss: 0.203846\n",
      "\t[#  180] train_loss: 3.743680, odo_loss: 2.998472, ine_loss: 0.525963, ref_loss: 0.219245\n",
      "\t[#  360] train_loss: 3.690005, odo_loss: 3.032649, ine_loss: 0.464977, ref_loss: 0.192379\n",
      "\t[#  540] train_loss: 4.221393, odo_loss: 3.511669, ine_loss: 0.504002, ref_loss: 0.205723\n",
      "\t[#  720] train_loss: 3.668894, odo_loss: 2.971983, ine_loss: 0.502387, ref_loss: 0.194524\n",
      "\t[#  900] train_loss: 2.875364, odo_loss: 2.132603, ine_loss: 0.505132, ref_loss: 0.237629\n",
      "\ttrain_loss: 3.350477, odo_loss: 2.626674, ine_loss: 0.522472, ref_loss: 0.201331\n",
      "\tval_loss: 3.292021, odo_loss: 2.572139, ine_loss: 0.514556, ref_loss: 0.205326\n",
      "\t*** Personal Best ***\n",
      "Epoch 40/2000\n",
      "\t[#    0] train_loss: 2.870949, odo_loss: 2.130578, ine_loss: 0.471590, ref_loss: 0.268781\n",
      "\t[#  180] train_loss: 2.744738, odo_loss: 1.983933, ine_loss: 0.568829, ref_loss: 0.191976\n",
      "\t[#  360] train_loss: 2.963168, odo_loss: 2.304773, ine_loss: 0.492115, ref_loss: 0.166279\n",
      "\t[#  540] train_loss: 2.815033, odo_loss: 2.229791, ine_loss: 0.387177, ref_loss: 0.198066\n",
      "\t[#  720] train_loss: 2.802346, odo_loss: 2.042157, ine_loss: 0.552681, ref_loss: 0.207508\n",
      "\t[#  900] train_loss: 4.028965, odo_loss: 3.243703, ine_loss: 0.538861, ref_loss: 0.246402\n",
      "\ttrain_loss: 3.302464, odo_loss: 2.581607, ine_loss: 0.521069, ref_loss: 0.199789\n",
      "\tval_loss: 3.396366, odo_loss: 2.665662, ine_loss: 0.526101, ref_loss: 0.204603\n",
      "Epoch 41/2000\n",
      "\t[#    0] train_loss: 3.216629, odo_loss: 2.429493, ine_loss: 0.564260, ref_loss: 0.222875\n",
      "\t[#  180] train_loss: 3.508414, odo_loss: 2.939981, ine_loss: 0.388988, ref_loss: 0.179444\n",
      "\t[#  360] train_loss: 2.687557, odo_loss: 1.965123, ine_loss: 0.547851, ref_loss: 0.174584\n",
      "\t[#  540] train_loss: 3.201114, odo_loss: 2.453691, ine_loss: 0.504767, ref_loss: 0.242657\n",
      "\t[#  720] train_loss: 2.370136, odo_loss: 1.702517, ine_loss: 0.505292, ref_loss: 0.162327\n",
      "\t[#  900] train_loss: 13.339328, odo_loss: 12.553165, ine_loss: 0.608164, ref_loss: 0.177999\n",
      "\ttrain_loss: 3.495811, odo_loss: 2.774904, ine_loss: 0.521208, ref_loss: 0.199699\n",
      "\tval_loss: 6.329439, odo_loss: 5.591256, ine_loss: 0.530934, ref_loss: 0.207249\n",
      "Epoch 42/2000\n",
      "\t[#    0] train_loss: 3.378731, odo_loss: 2.782416, ine_loss: 0.452896, ref_loss: 0.143419\n",
      "\t[#  180] train_loss: 3.194306, odo_loss: 2.345282, ine_loss: 0.657380, ref_loss: 0.191644\n",
      "\t[#  360] train_loss: 3.339632, odo_loss: 2.523485, ine_loss: 0.613440, ref_loss: 0.202707\n",
      "\t[#  540] train_loss: 4.135360, odo_loss: 3.523427, ine_loss: 0.426983, ref_loss: 0.184949\n",
      "\t[#  720] train_loss: 3.380871, odo_loss: 2.650665, ine_loss: 0.490024, ref_loss: 0.240181\n",
      "\t[#  900] train_loss: 2.548134, odo_loss: 1.903015, ine_loss: 0.466612, ref_loss: 0.178508\n",
      "\ttrain_loss: 3.650969, odo_loss: 2.928265, ine_loss: 0.521530, ref_loss: 0.201174\n",
      "\tval_loss: 3.328691, odo_loss: 2.610439, ine_loss: 0.513897, ref_loss: 0.204354\n",
      "Epoch 43/2000\n",
      "\t[#    0] train_loss: 3.267796, odo_loss: 2.461334, ine_loss: 0.586788, ref_loss: 0.219674\n",
      "\t[#  180] train_loss: 2.855715, odo_loss: 2.180740, ine_loss: 0.468624, ref_loss: 0.206352\n",
      "\t[#  360] train_loss: 3.787489, odo_loss: 3.033686, ine_loss: 0.556222, ref_loss: 0.197581\n",
      "\t[#  540] train_loss: 3.351810, odo_loss: 2.758842, ine_loss: 0.382483, ref_loss: 0.210485\n",
      "\t[#  720] train_loss: 2.798464, odo_loss: 2.123915, ine_loss: 0.499539, ref_loss: 0.175009\n",
      "\t[#  900] train_loss: 3.162312, odo_loss: 2.458156, ine_loss: 0.485859, ref_loss: 0.218297\n",
      "\ttrain_loss: 3.254294, odo_loss: 2.535709, ine_loss: 0.520592, ref_loss: 0.197992\n",
      "\tval_loss: 3.171528, odo_loss: 2.455341, ine_loss: 0.515881, ref_loss: 0.200305\n",
      "\t*** Personal Best ***\n",
      "Epoch 44/2000\n",
      "\t[#    0] train_loss: 3.351712, odo_loss: 2.654177, ine_loss: 0.524144, ref_loss: 0.173391\n",
      "\t[#  180] train_loss: 2.909688, odo_loss: 2.213971, ine_loss: 0.527646, ref_loss: 0.168072\n",
      "\t[#  360] train_loss: 3.918774, odo_loss: 3.137924, ine_loss: 0.573873, ref_loss: 0.206977\n",
      "\t[#  540] train_loss: 3.145501, odo_loss: 2.382182, ine_loss: 0.518572, ref_loss: 0.244748\n",
      "\t[#  720] train_loss: 3.274326, odo_loss: 2.577854, ine_loss: 0.478336, ref_loss: 0.218136\n",
      "\t[#  900] train_loss: 4.056024, odo_loss: 3.355930, ine_loss: 0.498319, ref_loss: 0.201774\n",
      "\ttrain_loss: 3.155654, odo_loss: 2.439855, ine_loss: 0.518949, ref_loss: 0.196850\n",
      "\tval_loss: 3.078129, odo_loss: 2.363905, ine_loss: 0.513846, ref_loss: 0.200378\n",
      "\t*** Personal Best ***\n",
      "Epoch 45/2000\n",
      "\t[#    0] train_loss: 3.271372, odo_loss: 2.610203, ine_loss: 0.501943, ref_loss: 0.159227\n",
      "\t[#  180] train_loss: 2.553430, odo_loss: 1.838874, ine_loss: 0.507083, ref_loss: 0.207473\n",
      "\t[#  360] train_loss: 3.498786, odo_loss: 2.712919, ine_loss: 0.563281, ref_loss: 0.222585\n",
      "\t[#  540] train_loss: 3.338639, odo_loss: 2.601155, ine_loss: 0.534272, ref_loss: 0.203212\n",
      "\t[#  720] train_loss: 3.280883, odo_loss: 2.599463, ine_loss: 0.495556, ref_loss: 0.185864\n",
      "\t[#  900] train_loss: 2.735458, odo_loss: 1.923252, ine_loss: 0.589158, ref_loss: 0.223048\n",
      "\ttrain_loss: 3.142783, odo_loss: 2.429183, ine_loss: 0.518031, ref_loss: 0.195568\n",
      "\tval_loss: 3.134135, odo_loss: 2.414998, ine_loss: 0.516649, ref_loss: 0.202488\n",
      "Epoch 46/2000\n",
      "\t[#    0] train_loss: 3.095213, odo_loss: 2.483559, ine_loss: 0.441838, ref_loss: 0.169817\n",
      "\t[#  180] train_loss: 3.281976, odo_loss: 2.625135, ine_loss: 0.478463, ref_loss: 0.178377\n",
      "\t[#  360] train_loss: 3.317296, odo_loss: 2.613473, ine_loss: 0.533122, ref_loss: 0.170700\n",
      "\t[#  540] train_loss: 3.099091, odo_loss: 2.343073, ine_loss: 0.583866, ref_loss: 0.172151\n",
      "\t[#  720] train_loss: 3.345946, odo_loss: 2.504752, ine_loss: 0.631623, ref_loss: 0.209571\n",
      "\t[#  900] train_loss: 3.500109, odo_loss: 2.917255, ine_loss: 0.409792, ref_loss: 0.173062\n",
      "\ttrain_loss: 3.104088, odo_loss: 2.391223, ine_loss: 0.517937, ref_loss: 0.194928\n",
      "\tval_loss: 3.077217, odo_loss: 2.366417, ine_loss: 0.512027, ref_loss: 0.198773\n",
      "Epoch 47/2000\n",
      "\t[#    0] train_loss: 3.552222, odo_loss: 2.710017, ine_loss: 0.644263, ref_loss: 0.197942\n",
      "\t[#  180] train_loss: 2.788010, odo_loss: 2.122214, ine_loss: 0.457422, ref_loss: 0.208373\n",
      "\t[#  360] train_loss: 3.108178, odo_loss: 2.463698, ine_loss: 0.449933, ref_loss: 0.194546\n",
      "\t[#  540] train_loss: 2.966839, odo_loss: 2.182848, ine_loss: 0.596627, ref_loss: 0.187364\n",
      "\t[#  720] train_loss: 3.110080, odo_loss: 2.511449, ine_loss: 0.410269, ref_loss: 0.188361\n",
      "\t[#  900] train_loss: 3.809982, odo_loss: 2.967620, ine_loss: 0.615798, ref_loss: 0.226563\n",
      "\ttrain_loss: 3.591884, odo_loss: 2.877620, ine_loss: 0.517798, ref_loss: 0.196465\n",
      "\tval_loss: 3.771224, odo_loss: 3.055377, ine_loss: 0.513428, ref_loss: 0.202418\n",
      "Epoch 48/2000\n",
      "\t[#    0] train_loss: 2.826985, odo_loss: 2.100076, ine_loss: 0.523520, ref_loss: 0.203389\n",
      "\t[#  180] train_loss: 6.532152, odo_loss: 5.836670, ine_loss: 0.510324, ref_loss: 0.185157\n",
      "\t[#  360] train_loss: 3.007850, odo_loss: 2.130813, ine_loss: 0.625768, ref_loss: 0.251269\n",
      "\t[#  540] train_loss: 2.993109, odo_loss: 2.263715, ine_loss: 0.550172, ref_loss: 0.179222\n",
      "\t[#  720] train_loss: 2.918382, odo_loss: 2.162508, ine_loss: 0.535846, ref_loss: 0.220028\n",
      "\t[#  900] train_loss: 2.976708, odo_loss: 2.271355, ine_loss: 0.465020, ref_loss: 0.240333\n",
      "\ttrain_loss: 3.330359, odo_loss: 2.616801, ine_loss: 0.517673, ref_loss: 0.195886\n",
      "\tval_loss: 3.216996, odo_loss: 2.497401, ine_loss: 0.517481, ref_loss: 0.202114\n",
      "Epoch 49/2000\n",
      "\t[#    0] train_loss: 3.323666, odo_loss: 2.512326, ine_loss: 0.613626, ref_loss: 0.197714\n",
      "\t[#  180] train_loss: 3.018336, odo_loss: 2.260723, ine_loss: 0.539700, ref_loss: 0.217913\n",
      "\t[#  360] train_loss: 2.880645, odo_loss: 2.213904, ine_loss: 0.471384, ref_loss: 0.195357\n",
      "\t[#  540] train_loss: 2.774921, odo_loss: 2.015738, ine_loss: 0.543595, ref_loss: 0.215588\n",
      "\t[#  720] train_loss: 3.659340, odo_loss: 3.045183, ine_loss: 0.442785, ref_loss: 0.171372\n",
      "\t[#  900] train_loss: 3.330294, odo_loss: 2.668930, ine_loss: 0.489563, ref_loss: 0.171801\n",
      "\ttrain_loss: 3.231234, odo_loss: 2.518700, ine_loss: 0.517088, ref_loss: 0.195446\n",
      "\tval_loss: 3.364332, odo_loss: 2.658411, ine_loss: 0.507057, ref_loss: 0.198864\n",
      "Epoch 50/2000\n",
      "\t[#    0] train_loss: 3.187746, odo_loss: 2.575358, ine_loss: 0.448681, ref_loss: 0.163708\n",
      "\t[#  180] train_loss: 2.789886, odo_loss: 2.138052, ine_loss: 0.446427, ref_loss: 0.205408\n",
      "\t[#  360] train_loss: 2.736581, odo_loss: 2.068784, ine_loss: 0.471516, ref_loss: 0.196280\n",
      "\t[#  540] train_loss: 4.090934, odo_loss: 3.221740, ine_loss: 0.627208, ref_loss: 0.241986\n",
      "\t[#  720] train_loss: 2.899342, odo_loss: 2.288491, ine_loss: 0.448250, ref_loss: 0.162601\n",
      "\t[#  900] train_loss: 3.440676, odo_loss: 2.770815, ine_loss: 0.499570, ref_loss: 0.170291\n",
      "\ttrain_loss: 3.143111, odo_loss: 2.434341, ine_loss: 0.515013, ref_loss: 0.193757\n",
      "\tval_loss: 3.122443, odo_loss: 2.407049, ine_loss: 0.514930, ref_loss: 0.200464\n",
      "Epoch 51/2000\n",
      "\t[#    0] train_loss: 2.691352, odo_loss: 2.011205, ine_loss: 0.489002, ref_loss: 0.191145\n",
      "\t[#  180] train_loss: 2.628491, odo_loss: 1.926269, ine_loss: 0.492698, ref_loss: 0.209524\n",
      "\t[#  360] train_loss: 3.056725, odo_loss: 2.467748, ine_loss: 0.436134, ref_loss: 0.152843\n",
      "\t[#  540] train_loss: 2.681245, odo_loss: 1.985076, ine_loss: 0.520153, ref_loss: 0.176015\n",
      "\t[#  720] train_loss: 3.251175, odo_loss: 2.412044, ine_loss: 0.581756, ref_loss: 0.257375\n",
      "\t[#  900] train_loss: 2.798709, odo_loss: 2.194976, ine_loss: 0.411486, ref_loss: 0.192247\n",
      "\ttrain_loss: 3.039167, odo_loss: 2.331912, ine_loss: 0.514945, ref_loss: 0.192310\n",
      "\tval_loss: 3.029271, odo_loss: 2.317631, ine_loss: 0.512137, ref_loss: 0.199503\n",
      "\t*** Personal Best ***\n",
      "Epoch 52/2000\n",
      "\t[#    0] train_loss: 3.690423, odo_loss: 3.060916, ine_loss: 0.439957, ref_loss: 0.189550\n",
      "\t[#  180] train_loss: 3.289983, odo_loss: 2.649491, ine_loss: 0.442942, ref_loss: 0.197550\n",
      "\t[#  360] train_loss: 2.989833, odo_loss: 2.340278, ine_loss: 0.487282, ref_loss: 0.162272\n",
      "\t[#  540] train_loss: 3.104294, odo_loss: 2.431010, ine_loss: 0.494119, ref_loss: 0.179164\n",
      "\t[#  720] train_loss: 2.774707, odo_loss: 2.142820, ine_loss: 0.443434, ref_loss: 0.188453\n",
      "\t[#  900] train_loss: 3.405944, odo_loss: 2.747417, ine_loss: 0.467762, ref_loss: 0.190765\n",
      "\ttrain_loss: 3.025894, odo_loss: 2.320239, ine_loss: 0.514258, ref_loss: 0.191397\n",
      "\tval_loss: 3.132840, odo_loss: 2.424980, ine_loss: 0.510359, ref_loss: 0.197501\n",
      "Epoch 53/2000\n",
      "\t[#    0] train_loss: 2.922943, odo_loss: 2.209346, ine_loss: 0.523353, ref_loss: 0.190245\n",
      "\t[#  180] train_loss: 3.700325, odo_loss: 2.947126, ine_loss: 0.539664, ref_loss: 0.213535\n",
      "\t[#  360] train_loss: 3.702133, odo_loss: 3.029781, ine_loss: 0.509237, ref_loss: 0.163115\n",
      "\t[#  540] train_loss: 3.496531, odo_loss: 2.764861, ine_loss: 0.519083, ref_loss: 0.212587\n",
      "\t[#  720] train_loss: 3.374793, odo_loss: 2.751134, ine_loss: 0.432506, ref_loss: 0.191153\n",
      "\t[#  900] train_loss: 2.982399, odo_loss: 2.384300, ine_loss: 0.409513, ref_loss: 0.188586\n",
      "\ttrain_loss: 3.392974, odo_loss: 2.687272, ine_loss: 0.513234, ref_loss: 0.192468\n",
      "\tval_loss: 3.160102, odo_loss: 2.445251, ine_loss: 0.515458, ref_loss: 0.199392\n",
      "Epoch 54/2000\n",
      "\t[#    0] train_loss: 3.498185, odo_loss: 2.659985, ine_loss: 0.632919, ref_loss: 0.205280\n",
      "\t[#  180] train_loss: 3.303891, odo_loss: 2.664302, ine_loss: 0.469995, ref_loss: 0.169594\n",
      "\t[#  360] train_loss: 3.264088, odo_loss: 2.421829, ine_loss: 0.647695, ref_loss: 0.194563\n",
      "\t[#  540] train_loss: 2.739136, odo_loss: 2.120990, ine_loss: 0.441500, ref_loss: 0.176646\n",
      "\t[#  720] train_loss: 3.241498, odo_loss: 2.466227, ine_loss: 0.590549, ref_loss: 0.184722\n",
      "\t[#  900] train_loss: 3.479718, odo_loss: 2.653375, ine_loss: 0.648789, ref_loss: 0.177554\n",
      "\ttrain_loss: 3.203552, odo_loss: 2.499070, ine_loss: 0.513475, ref_loss: 0.191008\n",
      "\tval_loss: 3.249050, odo_loss: 2.541486, ine_loss: 0.506979, ref_loss: 0.200585\n",
      "Epoch 55/2000\n",
      "\t[#    0] train_loss: 2.498459, odo_loss: 1.911953, ine_loss: 0.418775, ref_loss: 0.167730\n",
      "\t[#  180] train_loss: 3.658708, odo_loss: 2.975487, ine_loss: 0.501486, ref_loss: 0.181736\n",
      "\t[#  360] train_loss: 2.851559, odo_loss: 2.247330, ine_loss: 0.452163, ref_loss: 0.152066\n",
      "\t[#  540] train_loss: 3.593700, odo_loss: 2.809478, ine_loss: 0.566094, ref_loss: 0.218128\n",
      "\t[#  720] train_loss: 3.120394, odo_loss: 2.324212, ine_loss: 0.613800, ref_loss: 0.182382\n",
      "\t[#  900] train_loss: 2.603825, odo_loss: 1.943607, ine_loss: 0.450491, ref_loss: 0.209726\n",
      "\ttrain_loss: 3.241167, odo_loss: 2.536349, ine_loss: 0.513513, ref_loss: 0.191305\n",
      "\tval_loss: 3.131050, odo_loss: 2.427716, ine_loss: 0.506004, ref_loss: 0.197330\n",
      "Epoch 56/2000\n",
      "\t[#    0] train_loss: 3.228483, odo_loss: 2.536221, ine_loss: 0.508765, ref_loss: 0.183498\n",
      "\t[#  180] train_loss: 3.056567, odo_loss: 2.287052, ine_loss: 0.569009, ref_loss: 0.200506\n",
      "\t[#  360] train_loss: 2.758215, odo_loss: 2.147374, ine_loss: 0.433191, ref_loss: 0.177650\n",
      "\t[#  540] train_loss: 3.149214, odo_loss: 2.324667, ine_loss: 0.605508, ref_loss: 0.219039\n",
      "\t[#  720] train_loss: 2.887364, odo_loss: 2.178462, ine_loss: 0.535992, ref_loss: 0.172911\n",
      "\t[#  900] train_loss: 2.759112, odo_loss: 2.092416, ine_loss: 0.453644, ref_loss: 0.213052\n",
      "\ttrain_loss: 3.022913, odo_loss: 2.320345, ine_loss: 0.512291, ref_loss: 0.190277\n",
      "\tval_loss: 3.095014, odo_loss: 2.388233, ine_loss: 0.510235, ref_loss: 0.196547\n",
      "Epoch 57/2000\n",
      "\t[#    0] train_loss: 2.444541, odo_loss: 1.551862, ine_loss: 0.692236, ref_loss: 0.200443\n",
      "\t[#  180] train_loss: 2.954895, odo_loss: 2.291722, ine_loss: 0.493349, ref_loss: 0.169823\n",
      "\t[#  360] train_loss: 2.882149, odo_loss: 2.300819, ine_loss: 0.423310, ref_loss: 0.158020\n",
      "\t[#  540] train_loss: 2.799883, odo_loss: 2.041906, ine_loss: 0.542142, ref_loss: 0.215835\n",
      "\t[#  720] train_loss: 2.862336, odo_loss: 2.097719, ine_loss: 0.588910, ref_loss: 0.175706\n",
      "\t[#  900] train_loss: 2.758804, odo_loss: 2.117524, ine_loss: 0.446831, ref_loss: 0.194449\n",
      "\ttrain_loss: 2.953959, odo_loss: 2.253481, ine_loss: 0.511940, ref_loss: 0.188537\n",
      "\tval_loss: 2.939476, odo_loss: 2.233215, ine_loss: 0.509800, ref_loss: 0.196462\n",
      "\t*** Personal Best ***\n",
      "Epoch 58/2000\n",
      "\t[#    0] train_loss: 2.583130, odo_loss: 1.957569, ine_loss: 0.422031, ref_loss: 0.203531\n",
      "\t[#  180] train_loss: 3.276538, odo_loss: 2.570121, ine_loss: 0.517159, ref_loss: 0.189257\n",
      "\t[#  360] train_loss: 2.716082, odo_loss: 2.013438, ine_loss: 0.512609, ref_loss: 0.190035\n",
      "\t[#  540] train_loss: 2.648369, odo_loss: 2.030504, ine_loss: 0.447354, ref_loss: 0.170511\n",
      "\t[#  720] train_loss: 3.008926, odo_loss: 2.395671, ine_loss: 0.443040, ref_loss: 0.170216\n",
      "\t[#  900] train_loss: 2.827802, odo_loss: 2.100869, ine_loss: 0.540554, ref_loss: 0.186379\n",
      "\ttrain_loss: 2.933387, odo_loss: 2.235131, ine_loss: 0.510796, ref_loss: 0.187460\n",
      "\tval_loss: 2.933074, odo_loss: 2.229123, ine_loss: 0.510453, ref_loss: 0.193498\n",
      "\t*** Personal Best ***\n",
      "Epoch 59/2000\n",
      "\t[#    0] train_loss: 3.051195, odo_loss: 2.311995, ine_loss: 0.543901, ref_loss: 0.195299\n",
      "\t[#  180] train_loss: 2.670305, odo_loss: 2.056694, ine_loss: 0.429019, ref_loss: 0.184592\n",
      "\t[#  360] train_loss: 2.879468, odo_loss: 2.079428, ine_loss: 0.569691, ref_loss: 0.230349\n",
      "\t[#  540] train_loss: 3.622528, odo_loss: 2.882813, ine_loss: 0.558634, ref_loss: 0.181080\n",
      "\t[#  720] train_loss: 3.219956, odo_loss: 2.482021, ine_loss: 0.561829, ref_loss: 0.176106\n",
      "\t[#  900] train_loss: 3.382734, odo_loss: 2.687332, ine_loss: 0.493117, ref_loss: 0.202284\n",
      "\ttrain_loss: 3.131058, odo_loss: 2.430336, ine_loss: 0.512498, ref_loss: 0.188224\n",
      "\tval_loss: 3.061868, odo_loss: 2.357613, ine_loss: 0.507313, ref_loss: 0.196942\n",
      "Epoch 60/2000\n",
      "\t[#    0] train_loss: 2.851957, odo_loss: 2.222332, ine_loss: 0.421846, ref_loss: 0.207779\n",
      "\t[#  180] train_loss: 3.093012, odo_loss: 2.374765, ine_loss: 0.501093, ref_loss: 0.217153\n",
      "\t[#  360] train_loss: 2.826635, odo_loss: 2.208942, ine_loss: 0.430844, ref_loss: 0.186850\n",
      "\t[#  540] train_loss: 3.116046, odo_loss: 2.294312, ine_loss: 0.635007, ref_loss: 0.186726\n",
      "\t[#  720] train_loss: 2.708884, odo_loss: 2.007642, ine_loss: 0.508154, ref_loss: 0.193087\n",
      "\t[#  900] train_loss: 2.764109, odo_loss: 2.154280, ine_loss: 0.413034, ref_loss: 0.196796\n",
      "\ttrain_loss: 3.060963, odo_loss: 2.363126, ine_loss: 0.510710, ref_loss: 0.187128\n",
      "\tval_loss: 2.948446, odo_loss: 2.248339, ine_loss: 0.506075, ref_loss: 0.194032\n",
      "Epoch 61/2000\n",
      "\t[#    0] train_loss: 2.987616, odo_loss: 2.255286, ine_loss: 0.557567, ref_loss: 0.174763\n",
      "\t[#  180] train_loss: 2.261240, odo_loss: 1.627638, ine_loss: 0.463642, ref_loss: 0.169960\n",
      "\t[#  360] train_loss: 2.694697, odo_loss: 2.107303, ine_loss: 0.408967, ref_loss: 0.178427\n",
      "\t[#  540] train_loss: 3.121521, odo_loss: 2.444473, ine_loss: 0.507028, ref_loss: 0.170021\n",
      "\t[#  720] train_loss: 3.398847, odo_loss: 2.809433, ine_loss: 0.403148, ref_loss: 0.186266\n",
      "\t[#  900] train_loss: 9.533702, odo_loss: 8.930719, ine_loss: 0.439277, ref_loss: 0.163705\n",
      "\ttrain_loss: 3.165512, odo_loss: 2.467836, ine_loss: 0.511083, ref_loss: 0.186594\n",
      "\tval_loss: 3.227548, odo_loss: 2.526088, ine_loss: 0.506215, ref_loss: 0.195244\n",
      "Epoch 62/2000\n",
      "\t[#    0] train_loss: 2.630577, odo_loss: 1.944641, ine_loss: 0.513087, ref_loss: 0.172849\n",
      "\t[#  180] train_loss: 2.743517, odo_loss: 2.150126, ine_loss: 0.386975, ref_loss: 0.206417\n",
      "\t[#  360] train_loss: 2.923637, odo_loss: 2.301341, ine_loss: 0.453087, ref_loss: 0.169209\n",
      "\t[#  540] train_loss: 3.005539, odo_loss: 2.292492, ine_loss: 0.543244, ref_loss: 0.169803\n",
      "\t[#  720] train_loss: 2.985284, odo_loss: 2.098012, ine_loss: 0.659834, ref_loss: 0.227439\n",
      "\t[#  900] train_loss: 3.539279, odo_loss: 2.816732, ine_loss: 0.515856, ref_loss: 0.206691\n",
      "\ttrain_loss: 3.103263, odo_loss: 2.405193, ine_loss: 0.511852, ref_loss: 0.186218\n",
      "\tval_loss: 3.004853, odo_loss: 2.306062, ine_loss: 0.505701, ref_loss: 0.193091\n",
      "Epoch 63/2000\n",
      "\t[#    0] train_loss: 2.901198, odo_loss: 2.287329, ine_loss: 0.453892, ref_loss: 0.159978\n",
      "\t[#  180] train_loss: 2.581746, odo_loss: 1.929808, ine_loss: 0.473712, ref_loss: 0.178226\n",
      "\t[#  360] train_loss: 2.768602, odo_loss: 2.147543, ine_loss: 0.445908, ref_loss: 0.175150\n",
      "\t[#  540] train_loss: 2.936857, odo_loss: 2.271357, ine_loss: 0.484528, ref_loss: 0.180972\n",
      "\t[#  720] train_loss: 2.704913, odo_loss: 2.048904, ine_loss: 0.474274, ref_loss: 0.181735\n",
      "\t[#  900] train_loss: 3.247635, odo_loss: 2.447067, ine_loss: 0.581547, ref_loss: 0.219022\n",
      "\ttrain_loss: 2.903171, odo_loss: 2.207390, ine_loss: 0.511521, ref_loss: 0.184259\n",
      "\tval_loss: 2.906326, odo_loss: 2.210011, ine_loss: 0.505757, ref_loss: 0.190558\n",
      "\t*** Personal Best ***\n",
      "Epoch 64/2000\n",
      "\t[#    0] train_loss: 2.953056, odo_loss: 2.312875, ine_loss: 0.473501, ref_loss: 0.166679\n",
      "\t[#  180] train_loss: 2.568679, odo_loss: 1.864216, ine_loss: 0.525567, ref_loss: 0.178895\n",
      "\t[#  360] train_loss: 2.848796, odo_loss: 2.199016, ine_loss: 0.455868, ref_loss: 0.193912\n",
      "\t[#  540] train_loss: 2.732780, odo_loss: 2.073940, ine_loss: 0.483600, ref_loss: 0.175240\n",
      "\t[#  720] train_loss: 3.030090, odo_loss: 2.317068, ine_loss: 0.523376, ref_loss: 0.189646\n",
      "\t[#  900] train_loss: 2.911656, odo_loss: 2.251042, ine_loss: 0.484324, ref_loss: 0.176291\n",
      "\ttrain_loss: 2.888590, odo_loss: 2.194114, ine_loss: 0.510207, ref_loss: 0.184269\n",
      "\tval_loss: 2.909654, odo_loss: 2.213648, ine_loss: 0.504742, ref_loss: 0.191264\n",
      "Epoch 65/2000\n",
      "\t[#    0] train_loss: 2.645086, odo_loss: 1.859270, ine_loss: 0.612255, ref_loss: 0.173561\n",
      "\t[#  180] train_loss: 2.567582, odo_loss: 1.957864, ine_loss: 0.434864, ref_loss: 0.174854\n",
      "\t[#  360] train_loss: 3.106711, odo_loss: 2.369970, ine_loss: 0.551085, ref_loss: 0.185656\n",
      "\t[#  540] train_loss: 2.937246, odo_loss: 2.184781, ine_loss: 0.546641, ref_loss: 0.205824\n",
      "\t[#  720] train_loss: 3.343925, odo_loss: 2.589626, ine_loss: 0.605313, ref_loss: 0.148986\n",
      "\t[#  900] train_loss: 3.267470, odo_loss: 2.422406, ine_loss: 0.665774, ref_loss: 0.179290\n",
      "\ttrain_loss: 2.858571, odo_loss: 2.165062, ine_loss: 0.510304, ref_loss: 0.183205\n",
      "\tval_loss: 2.867042, odo_loss: 2.167627, ine_loss: 0.508441, ref_loss: 0.190974\n",
      "\t*** Personal Best ***\n",
      "Epoch 66/2000\n",
      "\t[#    0] train_loss: 2.977659, odo_loss: 2.241543, ine_loss: 0.576998, ref_loss: 0.159118\n",
      "\t[#  180] train_loss: 2.653677, odo_loss: 2.052603, ine_loss: 0.406603, ref_loss: 0.194471\n",
      "\t[#  360] train_loss: 3.057615, odo_loss: 2.345478, ine_loss: 0.532124, ref_loss: 0.180013\n",
      "\t[#  540] train_loss: 2.514462, odo_loss: 1.880509, ine_loss: 0.451501, ref_loss: 0.182453\n",
      "\t[#  720] train_loss: 3.165618, odo_loss: 2.441861, ine_loss: 0.568159, ref_loss: 0.155597\n",
      "\t[#  900] train_loss: 2.665361, odo_loss: 2.067431, ine_loss: 0.435835, ref_loss: 0.162095\n",
      "\ttrain_loss: 2.850398, odo_loss: 2.158109, ine_loss: 0.510019, ref_loss: 0.182270\n",
      "\tval_loss: 2.831015, odo_loss: 2.135768, ine_loss: 0.506851, ref_loss: 0.188396\n",
      "\t*** Personal Best ***\n",
      "Epoch 67/2000\n",
      "\t[#    0] train_loss: 3.067614, odo_loss: 2.405543, ine_loss: 0.477531, ref_loss: 0.184540\n",
      "\t[#  180] train_loss: 2.971203, odo_loss: 2.345567, ine_loss: 0.486162, ref_loss: 0.139474\n",
      "\t[#  360] train_loss: 3.223887, odo_loss: 2.549315, ine_loss: 0.491399, ref_loss: 0.183173\n",
      "\t[#  540] train_loss: 3.631853, odo_loss: 2.889186, ine_loss: 0.525417, ref_loss: 0.217249\n",
      "\t[#  720] train_loss: 3.106326, odo_loss: 2.435815, ine_loss: 0.498980, ref_loss: 0.171531\n",
      "\t[#  900] train_loss: 3.047366, odo_loss: 2.403789, ine_loss: 0.487123, ref_loss: 0.156454\n",
      "\ttrain_loss: 3.298519, odo_loss: 2.603875, ine_loss: 0.511263, ref_loss: 0.183381\n",
      "\tval_loss: 3.228548, odo_loss: 2.524951, ine_loss: 0.510240, ref_loss: 0.193356\n",
      "Epoch 68/2000\n",
      "\t[#    0] train_loss: 3.041174, odo_loss: 2.398946, ine_loss: 0.469556, ref_loss: 0.172672\n",
      "\t[#  180] train_loss: 3.125524, odo_loss: 2.416295, ine_loss: 0.495902, ref_loss: 0.213327\n",
      "\t[#  360] train_loss: 3.052523, odo_loss: 2.303378, ine_loss: 0.588908, ref_loss: 0.160237\n",
      "\t[#  540] train_loss: 2.717937, odo_loss: 2.061768, ine_loss: 0.477350, ref_loss: 0.178819\n",
      "\t[#  720] train_loss: 2.524168, odo_loss: 1.784039, ine_loss: 0.547272, ref_loss: 0.192858\n",
      "\t[#  900] train_loss: 3.279788, odo_loss: 2.517966, ine_loss: 0.588690, ref_loss: 0.173132\n",
      "\ttrain_loss: 2.924243, odo_loss: 2.229687, ine_loss: 0.511827, ref_loss: 0.182729\n",
      "\tval_loss: 2.871784, odo_loss: 2.167384, ine_loss: 0.511603, ref_loss: 0.192798\n",
      "Epoch 69/2000\n",
      "\t[#    0] train_loss: 2.726946, odo_loss: 2.048666, ine_loss: 0.482492, ref_loss: 0.195788\n",
      "\t[#  180] train_loss: 2.932211, odo_loss: 2.216713, ine_loss: 0.510296, ref_loss: 0.205202\n",
      "\t[#  360] train_loss: 4.520172, odo_loss: 3.893653, ine_loss: 0.447823, ref_loss: 0.178696\n",
      "\t[#  540] train_loss: 3.133306, odo_loss: 2.409157, ine_loss: 0.528352, ref_loss: 0.195797\n",
      "\t[#  720] train_loss: 2.725106, odo_loss: 1.990331, ine_loss: 0.557176, ref_loss: 0.177598\n",
      "\t[#  900] train_loss: 3.043463, odo_loss: 2.308399, ine_loss: 0.532288, ref_loss: 0.202777\n",
      "\ttrain_loss: 2.891143, odo_loss: 2.199006, ine_loss: 0.511520, ref_loss: 0.180616\n",
      "\tval_loss: 2.902974, odo_loss: 2.197790, ine_loss: 0.516119, ref_loss: 0.189064\n",
      "Epoch 70/2000\n",
      "\t[#    0] train_loss: 2.791107, odo_loss: 2.125962, ine_loss: 0.503362, ref_loss: 0.161782\n",
      "\t[#  180] train_loss: 2.545179, odo_loss: 1.905185, ine_loss: 0.477101, ref_loss: 0.162893\n",
      "\t[#  360] train_loss: 2.862080, odo_loss: 2.084064, ine_loss: 0.548693, ref_loss: 0.229323\n",
      "\t[#  540] train_loss: 3.060521, odo_loss: 2.446859, ine_loss: 0.450052, ref_loss: 0.163611\n",
      "\t[#  720] train_loss: 2.866031, odo_loss: 2.104970, ine_loss: 0.598610, ref_loss: 0.162452\n",
      "\t[#  900] train_loss: 2.482469, odo_loss: 1.821251, ine_loss: 0.457068, ref_loss: 0.204150\n",
      "\ttrain_loss: 2.822378, odo_loss: 2.132215, ine_loss: 0.510510, ref_loss: 0.179653\n",
      "\tval_loss: 2.816474, odo_loss: 2.118416, ine_loss: 0.509949, ref_loss: 0.188109\n",
      "\t*** Personal Best ***\n",
      "Epoch 71/2000\n",
      "\t[#    0] train_loss: 2.874087, odo_loss: 2.160405, ine_loss: 0.505243, ref_loss: 0.208438\n",
      "\t[#  180] train_loss: 2.403371, odo_loss: 1.877067, ine_loss: 0.392144, ref_loss: 0.134159\n",
      "\t[#  360] train_loss: 2.729761, odo_loss: 2.154026, ine_loss: 0.411902, ref_loss: 0.163833\n",
      "\t[#  540] train_loss: 2.838948, odo_loss: 2.244554, ine_loss: 0.424251, ref_loss: 0.170144\n",
      "\t[#  720] train_loss: 2.998331, odo_loss: 2.414101, ine_loss: 0.415179, ref_loss: 0.169052\n",
      "\t[#  900] train_loss: 2.859246, odo_loss: 2.112936, ine_loss: 0.547080, ref_loss: 0.199230\n",
      "\ttrain_loss: 2.982749, odo_loss: 2.292330, ine_loss: 0.510760, ref_loss: 0.179658\n",
      "\tval_loss: 3.023695, odo_loss: 2.319058, ine_loss: 0.515336, ref_loss: 0.189300\n",
      "Epoch 72/2000\n",
      "\t[#    0] train_loss: 2.869963, odo_loss: 2.062591, ine_loss: 0.620266, ref_loss: 0.187106\n",
      "\t[#  180] train_loss: 3.444422, odo_loss: 2.636217, ine_loss: 0.623784, ref_loss: 0.184421\n",
      "\t[#  360] train_loss: 3.033473, odo_loss: 2.255397, ine_loss: 0.571124, ref_loss: 0.206953\n",
      "\t[#  540] train_loss: 2.601774, odo_loss: 1.937100, ine_loss: 0.485952, ref_loss: 0.178721\n",
      "\t[#  720] train_loss: 2.696781, odo_loss: 2.058572, ine_loss: 0.438776, ref_loss: 0.199433\n",
      "\t[#  900] train_loss: 3.209373, odo_loss: 2.483495, ine_loss: 0.556969, ref_loss: 0.168910\n",
      "\ttrain_loss: 2.940648, odo_loss: 2.247916, ine_loss: 0.513463, ref_loss: 0.179269\n",
      "\tval_loss: 2.860954, odo_loss: 2.161022, ine_loss: 0.508857, ref_loss: 0.191075\n",
      "Epoch 73/2000\n",
      "\t[#    0] train_loss: 2.915340, odo_loss: 2.190695, ine_loss: 0.540722, ref_loss: 0.183922\n",
      "\t[#  180] train_loss: 3.228472, odo_loss: 2.508893, ine_loss: 0.532895, ref_loss: 0.186683\n",
      "\t[#  360] train_loss: 2.993327, odo_loss: 2.300270, ine_loss: 0.522873, ref_loss: 0.170184\n",
      "\t[#  540] train_loss: 3.009722, odo_loss: 2.227949, ine_loss: 0.587816, ref_loss: 0.193957\n",
      "\t[#  720] train_loss: 3.282411, odo_loss: 2.295157, ine_loss: 0.763922, ref_loss: 0.223332\n",
      "\t[#  900] train_loss: 2.558180, odo_loss: 1.923276, ine_loss: 0.478643, ref_loss: 0.156261\n",
      "\ttrain_loss: 2.859050, odo_loss: 2.169151, ine_loss: 0.511157, ref_loss: 0.178742\n",
      "\tval_loss: 2.894731, odo_loss: 2.196586, ine_loss: 0.509725, ref_loss: 0.188419\n",
      "Epoch 74/2000\n",
      "\t[#    0] train_loss: 3.112511, odo_loss: 2.399702, ine_loss: 0.534206, ref_loss: 0.178604\n",
      "\t[#  180] train_loss: 2.497068, odo_loss: 1.833823, ine_loss: 0.471796, ref_loss: 0.191450\n",
      "\t[#  360] train_loss: 2.638063, odo_loss: 2.117804, ine_loss: 0.361368, ref_loss: 0.158891\n",
      "\t[#  540] train_loss: 2.858132, odo_loss: 2.099989, ine_loss: 0.576759, ref_loss: 0.181384\n",
      "\t[#  720] train_loss: 2.660665, odo_loss: 1.879833, ine_loss: 0.596917, ref_loss: 0.183915\n",
      "\t[#  900] train_loss: 2.766440, odo_loss: 2.097313, ine_loss: 0.503513, ref_loss: 0.165614\n",
      "\ttrain_loss: 2.831481, odo_loss: 2.143063, ine_loss: 0.511147, ref_loss: 0.177272\n",
      "\tval_loss: 2.904716, odo_loss: 2.207857, ine_loss: 0.507710, ref_loss: 0.189149\n",
      "Epoch 75/2000\n",
      "\t[#    0] train_loss: 2.602372, odo_loss: 1.841921, ine_loss: 0.590053, ref_loss: 0.170398\n",
      "\t[#  180] train_loss: 3.148462, odo_loss: 2.349347, ine_loss: 0.585136, ref_loss: 0.213978\n",
      "\t[#  360] train_loss: 3.070459, odo_loss: 2.339248, ine_loss: 0.517845, ref_loss: 0.213365\n",
      "\t[#  540] train_loss: 2.550610, odo_loss: 1.934920, ine_loss: 0.471569, ref_loss: 0.144121\n",
      "\t[#  720] train_loss: 2.548923, odo_loss: 1.869241, ine_loss: 0.513002, ref_loss: 0.166680\n",
      "\t[#  900] train_loss: 2.873789, odo_loss: 2.068833, ine_loss: 0.617515, ref_loss: 0.187441\n",
      "\ttrain_loss: 2.835076, odo_loss: 2.146418, ine_loss: 0.510961, ref_loss: 0.177697\n",
      "\tval_loss: 2.920043, odo_loss: 2.229256, ine_loss: 0.505764, ref_loss: 0.185023\n",
      "Epoch 76/2000\n",
      "\t[#    0] train_loss: 2.337054, odo_loss: 1.760514, ine_loss: 0.383119, ref_loss: 0.193421\n",
      "\t[#  180] train_loss: 2.724104, odo_loss: 1.977019, ine_loss: 0.562748, ref_loss: 0.184337\n",
      "\t[#  360] train_loss: 5.684035, odo_loss: 5.011550, ine_loss: 0.491987, ref_loss: 0.180498\n",
      "\t[#  540] train_loss: 3.140782, odo_loss: 2.402190, ine_loss: 0.576302, ref_loss: 0.162290\n",
      "\t[#  720] train_loss: 2.970848, odo_loss: 2.316773, ine_loss: 0.447263, ref_loss: 0.206813\n",
      "\t[#  900] train_loss: 3.075832, odo_loss: 2.381858, ine_loss: 0.511644, ref_loss: 0.182331\n",
      "\ttrain_loss: 2.982218, odo_loss: 2.293953, ine_loss: 0.510884, ref_loss: 0.177381\n",
      "\tval_loss: 2.814180, odo_loss: 2.122734, ine_loss: 0.503418, ref_loss: 0.188028\n",
      "Epoch 77/2000\n",
      "\t[#    0] train_loss: 2.598706, odo_loss: 1.916057, ine_loss: 0.493055, ref_loss: 0.189595\n",
      "\t[#  180] train_loss: 2.953379, odo_loss: 2.142514, ine_loss: 0.607591, ref_loss: 0.203275\n",
      "\t[#  360] train_loss: 2.792491, odo_loss: 2.150586, ine_loss: 0.487351, ref_loss: 0.154554\n",
      "\t[#  540] train_loss: 2.512677, odo_loss: 1.893004, ine_loss: 0.425473, ref_loss: 0.194200\n",
      "\t[#  720] train_loss: 2.860859, odo_loss: 2.182312, ine_loss: 0.519394, ref_loss: 0.159153\n",
      "\t[#  900] train_loss: 2.911115, odo_loss: 2.208117, ine_loss: 0.515084, ref_loss: 0.187915\n",
      "\ttrain_loss: 2.813704, odo_loss: 2.127760, ine_loss: 0.509972, ref_loss: 0.175972\n",
      "\tval_loss: 2.845981, odo_loss: 2.153557, ine_loss: 0.506698, ref_loss: 0.185726\n",
      "Epoch 78/2000\n",
      "\t[#    0] train_loss: 3.189550, odo_loss: 2.407000, ine_loss: 0.640291, ref_loss: 0.142259\n",
      "\t[#  180] train_loss: 2.456215, odo_loss: 1.720616, ine_loss: 0.563128, ref_loss: 0.172470\n",
      "\t[#  360] train_loss: 3.006804, odo_loss: 2.334897, ine_loss: 0.502882, ref_loss: 0.169025\n",
      "\t[#  540] train_loss: 2.627820, odo_loss: 1.984603, ine_loss: 0.491433, ref_loss: 0.151785\n",
      "\t[#  720] train_loss: 2.182180, odo_loss: 1.679179, ine_loss: 0.342377, ref_loss: 0.160624\n",
      "\t[#  900] train_loss: 2.586134, odo_loss: 1.928660, ine_loss: 0.439049, ref_loss: 0.218424\n",
      "\ttrain_loss: 2.785453, odo_loss: 2.100048, ine_loss: 0.510924, ref_loss: 0.174481\n",
      "\tval_loss: 2.782190, odo_loss: 2.083257, ine_loss: 0.511017, ref_loss: 0.187916\n",
      "\t*** Personal Best ***\n",
      "Epoch 79/2000\n",
      "\t[#    0] train_loss: 2.547927, odo_loss: 1.924629, ine_loss: 0.432770, ref_loss: 0.190528\n",
      "\t[#  180] train_loss: 2.914167, odo_loss: 2.319669, ine_loss: 0.441004, ref_loss: 0.153494\n",
      "\t[#  360] train_loss: 2.953150, odo_loss: 2.342762, ine_loss: 0.448701, ref_loss: 0.161687\n",
      "\t[#  540] train_loss: 2.893925, odo_loss: 2.011039, ine_loss: 0.674725, ref_loss: 0.208161\n",
      "\t[#  720] train_loss: 2.697214, odo_loss: 2.111630, ine_loss: 0.418436, ref_loss: 0.167149\n",
      "\t[#  900] train_loss: 2.849763, odo_loss: 2.188049, ine_loss: 0.485043, ref_loss: 0.176672\n",
      "\ttrain_loss: 2.806788, odo_loss: 2.122779, ine_loss: 0.509768, ref_loss: 0.174241\n",
      "\tval_loss: 3.027608, odo_loss: 2.334846, ine_loss: 0.509316, ref_loss: 0.183447\n",
      "Epoch 80/2000\n",
      "\t[#    0] train_loss: 2.728384, odo_loss: 2.103189, ine_loss: 0.459232, ref_loss: 0.165964\n",
      "\t[#  180] train_loss: 2.648267, odo_loss: 1.947205, ine_loss: 0.523451, ref_loss: 0.177610\n",
      "\t[#  360] train_loss: 2.685503, odo_loss: 2.090073, ine_loss: 0.430438, ref_loss: 0.164992\n",
      "\t[#  540] train_loss: 2.728980, odo_loss: 1.989398, ine_loss: 0.539756, ref_loss: 0.199826\n",
      "\t[#  720] train_loss: 2.880787, odo_loss: 2.098978, ine_loss: 0.600431, ref_loss: 0.181377\n",
      "\t[#  900] train_loss: 2.527492, odo_loss: 1.982559, ine_loss: 0.383980, ref_loss: 0.160953\n",
      "\ttrain_loss: 3.083649, odo_loss: 2.398761, ine_loss: 0.509528, ref_loss: 0.175360\n",
      "\tval_loss: 2.855434, odo_loss: 2.155804, ine_loss: 0.514747, ref_loss: 0.184882\n",
      "Epoch 81/2000\n",
      "\t[#    0] train_loss: 2.654042, odo_loss: 2.057118, ine_loss: 0.452966, ref_loss: 0.143957\n",
      "\t[#  180] train_loss: 2.369714, odo_loss: 1.817889, ine_loss: 0.382908, ref_loss: 0.168917\n",
      "\t[#  360] train_loss: 3.152349, odo_loss: 2.293624, ine_loss: 0.696175, ref_loss: 0.162551\n",
      "\t[#  540] train_loss: 3.007667, odo_loss: 2.200456, ine_loss: 0.602471, ref_loss: 0.204740\n",
      "\t[#  720] train_loss: 3.321603, odo_loss: 2.517875, ine_loss: 0.636316, ref_loss: 0.167412\n",
      "\t[#  900] train_loss: 2.604654, odo_loss: 1.977183, ine_loss: 0.494468, ref_loss: 0.133003\n",
      "\ttrain_loss: 2.912142, odo_loss: 2.227300, ine_loss: 0.510664, ref_loss: 0.174178\n",
      "\tval_loss: 2.929899, odo_loss: 2.235325, ine_loss: 0.509172, ref_loss: 0.185402\n",
      "Epoch 82/2000\n",
      "\t[#    0] train_loss: 3.021263, odo_loss: 2.354750, ine_loss: 0.517637, ref_loss: 0.148876\n",
      "\t[#  180] train_loss: 2.385271, odo_loss: 1.729711, ine_loss: 0.469898, ref_loss: 0.185662\n",
      "\t[#  360] train_loss: 2.735468, odo_loss: 2.078869, ine_loss: 0.505426, ref_loss: 0.151173\n",
      "\t[#  540] train_loss: 2.790926, odo_loss: 2.109949, ine_loss: 0.528695, ref_loss: 0.152283\n",
      "\t[#  720] train_loss: 3.055534, odo_loss: 2.224595, ine_loss: 0.635553, ref_loss: 0.195386\n",
      "\t[#  900] train_loss: 2.676322, odo_loss: 2.070432, ine_loss: 0.437819, ref_loss: 0.168071\n",
      "\ttrain_loss: 2.852438, odo_loss: 2.167970, ine_loss: 0.510950, ref_loss: 0.173519\n",
      "\tval_loss: 2.829533, odo_loss: 2.139427, ine_loss: 0.505056, ref_loss: 0.185050\n",
      "Epoch 83/2000\n",
      "\t[#    0] train_loss: 2.943030, odo_loss: 2.305787, ine_loss: 0.462059, ref_loss: 0.175184\n",
      "\t[#  180] train_loss: 2.627196, odo_loss: 2.034721, ine_loss: 0.443899, ref_loss: 0.148576\n",
      "\t[#  360] train_loss: 2.779544, odo_loss: 2.085875, ine_loss: 0.498235, ref_loss: 0.195434\n",
      "\t[#  540] train_loss: 2.840442, odo_loss: 2.178455, ine_loss: 0.520043, ref_loss: 0.141945\n",
      "\t[#  720] train_loss: 3.794597, odo_loss: 3.074220, ine_loss: 0.510481, ref_loss: 0.209896\n",
      "\t[#  900] train_loss: 3.283491, odo_loss: 2.562696, ine_loss: 0.570034, ref_loss: 0.150761\n",
      "\ttrain_loss: 2.861759, odo_loss: 2.181300, ine_loss: 0.508211, ref_loss: 0.172247\n",
      "\tval_loss: 2.899434, odo_loss: 2.209555, ine_loss: 0.507409, ref_loss: 0.182470\n",
      "Epoch 84/2000\n",
      "\t[#    0] train_loss: 2.795216, odo_loss: 2.161769, ine_loss: 0.485580, ref_loss: 0.147868\n",
      "\t[#  180] train_loss: 2.577605, odo_loss: 1.976753, ine_loss: 0.443205, ref_loss: 0.157647\n",
      "\t[#  360] train_loss: 2.788372, odo_loss: 2.131698, ine_loss: 0.503003, ref_loss: 0.153671\n",
      "\t[#  540] train_loss: 2.548258, odo_loss: 1.962014, ine_loss: 0.409206, ref_loss: 0.177038\n",
      "\t[#  720] train_loss: 2.703616, odo_loss: 2.014866, ine_loss: 0.505571, ref_loss: 0.183180\n",
      "\t[#  900] train_loss: 2.677207, odo_loss: 2.007589, ine_loss: 0.457070, ref_loss: 0.212548\n",
      "\ttrain_loss: 2.810071, odo_loss: 2.128596, ine_loss: 0.509430, ref_loss: 0.172045\n",
      "\tval_loss: 2.794293, odo_loss: 2.105186, ine_loss: 0.505005, ref_loss: 0.184102\n",
      "Epoch 85/2000\n",
      "\t[#    0] train_loss: 2.726298, odo_loss: 2.070031, ine_loss: 0.497152, ref_loss: 0.159115\n",
      "\t[#  180] train_loss: 2.527575, odo_loss: 1.738827, ine_loss: 0.590650, ref_loss: 0.198098\n",
      "\t[#  360] train_loss: 2.544317, odo_loss: 1.895674, ine_loss: 0.462287, ref_loss: 0.186356\n",
      "\t[#  540] train_loss: 3.032961, odo_loss: 2.491963, ine_loss: 0.398382, ref_loss: 0.142616\n",
      "\t[#  720] train_loss: 2.865966, odo_loss: 2.157233, ine_loss: 0.536527, ref_loss: 0.172206\n",
      "\t[#  900] train_loss: 2.893731, odo_loss: 2.293124, ine_loss: 0.439460, ref_loss: 0.161147\n",
      "\ttrain_loss: 3.037463, odo_loss: 2.356095, ine_loss: 0.508430, ref_loss: 0.172938\n",
      "\tval_loss: 3.185001, odo_loss: 2.493465, ine_loss: 0.509249, ref_loss: 0.182287\n",
      "Epoch 86/2000\n",
      "\t[#    0] train_loss: 2.710655, odo_loss: 2.084884, ine_loss: 0.463195, ref_loss: 0.162575\n",
      "\t[#  180] train_loss: 2.790832, odo_loss: 2.171232, ine_loss: 0.460860, ref_loss: 0.158740\n",
      "\t[#  360] train_loss: 2.958086, odo_loss: 2.323701, ine_loss: 0.465727, ref_loss: 0.168658\n",
      "\t[#  540] train_loss: 2.946738, odo_loss: 2.232321, ine_loss: 0.527412, ref_loss: 0.187004\n",
      "\t[#  720] train_loss: 2.634389, odo_loss: 1.978234, ine_loss: 0.499347, ref_loss: 0.156808\n",
      "\t[#  900] train_loss: 2.633126, odo_loss: 2.051963, ine_loss: 0.406785, ref_loss: 0.174379\n",
      "\ttrain_loss: 2.827481, odo_loss: 2.146421, ine_loss: 0.509045, ref_loss: 0.172015\n",
      "\tval_loss: 2.777764, odo_loss: 2.095294, ine_loss: 0.500500, ref_loss: 0.181969\n",
      "Epoch 87/2000\n",
      "\t[#    0] train_loss: 2.537143, odo_loss: 1.874764, ine_loss: 0.506433, ref_loss: 0.155946\n",
      "\t[#  180] train_loss: 2.905403, odo_loss: 2.121276, ine_loss: 0.569256, ref_loss: 0.214870\n",
      "\t[#  360] train_loss: 2.419915, odo_loss: 1.775273, ine_loss: 0.470445, ref_loss: 0.174197\n",
      "\t[#  540] train_loss: 2.691978, odo_loss: 1.892960, ine_loss: 0.576267, ref_loss: 0.222750\n",
      "\t[#  720] train_loss: 2.693858, odo_loss: 2.079595, ine_loss: 0.467561, ref_loss: 0.146702\n",
      "\t[#  900] train_loss: 2.998455, odo_loss: 2.205526, ine_loss: 0.609611, ref_loss: 0.183317\n",
      "\ttrain_loss: 2.752849, odo_loss: 2.073129, ine_loss: 0.509198, ref_loss: 0.170521\n",
      "\tval_loss: 2.784475, odo_loss: 2.098880, ine_loss: 0.504421, ref_loss: 0.181174\n",
      "Epoch 88/2000\n",
      "\t[#    0] train_loss: 2.746602, odo_loss: 2.092800, ine_loss: 0.501017, ref_loss: 0.152785\n",
      "\t[#  180] train_loss: 2.472981, odo_loss: 1.959594, ine_loss: 0.358502, ref_loss: 0.154885\n",
      "\t[#  360] train_loss: 2.672596, odo_loss: 1.946218, ine_loss: 0.544300, ref_loss: 0.182078\n",
      "\t[#  540] train_loss: 2.384363, odo_loss: 1.813277, ine_loss: 0.400464, ref_loss: 0.170622\n",
      "\t[#  720] train_loss: 2.770573, odo_loss: 2.004970, ine_loss: 0.601808, ref_loss: 0.163795\n",
      "\t[#  900] train_loss: 2.656450, odo_loss: 1.929858, ine_loss: 0.544251, ref_loss: 0.182341\n",
      "\ttrain_loss: 2.732169, odo_loss: 2.053411, ine_loss: 0.508865, ref_loss: 0.169893\n",
      "\tval_loss: 2.739963, odo_loss: 2.052261, ine_loss: 0.505486, ref_loss: 0.182216\n",
      "\t*** Personal Best ***\n",
      "Epoch 89/2000\n",
      "\t[#    0] train_loss: 2.620424, odo_loss: 1.911731, ine_loss: 0.543957, ref_loss: 0.164737\n",
      "\t[#  180] train_loss: 2.973841, odo_loss: 2.256754, ine_loss: 0.574561, ref_loss: 0.142525\n",
      "\t[#  360] train_loss: 3.070670, odo_loss: 2.378005, ine_loss: 0.530039, ref_loss: 0.162626\n",
      "\t[#  540] train_loss: 2.406189, odo_loss: 1.749394, ine_loss: 0.461577, ref_loss: 0.195218\n",
      "\t[#  720] train_loss: 2.685228, odo_loss: 2.088522, ine_loss: 0.426771, ref_loss: 0.169935\n",
      "\t[#  900] train_loss: 2.900915, odo_loss: 2.215389, ine_loss: 0.530459, ref_loss: 0.155067\n",
      "\ttrain_loss: 2.782712, odo_loss: 2.103317, ine_loss: 0.509639, ref_loss: 0.169756\n",
      "\tval_loss: 2.855785, odo_loss: 2.177126, ine_loss: 0.499044, ref_loss: 0.179615\n",
      "Epoch 90/2000\n",
      "\t[#    0] train_loss: 2.961302, odo_loss: 2.277728, ine_loss: 0.546125, ref_loss: 0.137449\n",
      "\t[#  180] train_loss: 2.571666, odo_loss: 1.991867, ine_loss: 0.427839, ref_loss: 0.151960\n",
      "\t[#  360] train_loss: 2.789126, odo_loss: 2.151136, ine_loss: 0.463221, ref_loss: 0.174769\n",
      "\t[#  540] train_loss: 2.850676, odo_loss: 2.130048, ine_loss: 0.565784, ref_loss: 0.154844\n",
      "\t[#  720] train_loss: 2.810556, odo_loss: 2.097466, ine_loss: 0.534402, ref_loss: 0.178688\n",
      "\t[#  900] train_loss: 2.362754, odo_loss: 1.800666, ine_loss: 0.420159, ref_loss: 0.141929\n",
      "\ttrain_loss: 2.764912, odo_loss: 2.084883, ine_loss: 0.510698, ref_loss: 0.169332\n",
      "\tval_loss: 2.775778, odo_loss: 2.087976, ine_loss: 0.508048, ref_loss: 0.179754\n",
      "Epoch 91/2000\n",
      "\t[#    0] train_loss: 2.632204, odo_loss: 1.977745, ine_loss: 0.483925, ref_loss: 0.170534\n",
      "\t[#  180] train_loss: 2.983842, odo_loss: 2.344997, ine_loss: 0.470005, ref_loss: 0.168840\n",
      "\t[#  360] train_loss: 2.524922, odo_loss: 1.921011, ine_loss: 0.435071, ref_loss: 0.168840\n",
      "\t[#  540] train_loss: 2.731385, odo_loss: 1.926837, ine_loss: 0.583861, ref_loss: 0.220686\n",
      "\t[#  720] train_loss: 2.904040, odo_loss: 1.984819, ine_loss: 0.747145, ref_loss: 0.172075\n",
      "\t[#  900] train_loss: 2.853917, odo_loss: 2.124065, ine_loss: 0.580830, ref_loss: 0.149022\n",
      "\ttrain_loss: 2.737211, odo_loss: 2.059106, ine_loss: 0.509595, ref_loss: 0.168510\n",
      "\tval_loss: 2.740857, odo_loss: 2.057659, ine_loss: 0.503249, ref_loss: 0.179948\n",
      "Epoch 92/2000\n",
      "\t[#    0] train_loss: 2.769947, odo_loss: 2.130369, ine_loss: 0.485956, ref_loss: 0.153622\n",
      "\t[#  180] train_loss: 2.806317, odo_loss: 2.122784, ine_loss: 0.502460, ref_loss: 0.181072\n",
      "\t[#  360] train_loss: 2.926931, odo_loss: 2.264234, ine_loss: 0.504396, ref_loss: 0.158301\n",
      "\t[#  540] train_loss: 2.350720, odo_loss: 1.777593, ine_loss: 0.428595, ref_loss: 0.144532\n",
      "\t[#  720] train_loss: 5.490548, odo_loss: 4.639345, ine_loss: 0.676737, ref_loss: 0.174465\n",
      "\t[#  900] train_loss: 2.823455, odo_loss: 2.146739, ine_loss: 0.519835, ref_loss: 0.156881\n",
      "\ttrain_loss: 2.941571, odo_loss: 2.261753, ine_loss: 0.510397, ref_loss: 0.169422\n",
      "\tval_loss: 2.987545, odo_loss: 2.293549, ine_loss: 0.512286, ref_loss: 0.181710\n",
      "Epoch 93/2000\n",
      "\t[#    0] train_loss: 2.914870, odo_loss: 2.235767, ine_loss: 0.502786, ref_loss: 0.176317\n",
      "\t[#  180] train_loss: 2.859138, odo_loss: 2.156477, ine_loss: 0.534181, ref_loss: 0.168480\n",
      "\t[#  360] train_loss: 2.669529, odo_loss: 2.116905, ine_loss: 0.389420, ref_loss: 0.163204\n",
      "\t[#  540] train_loss: 2.750957, odo_loss: 2.170095, ine_loss: 0.400651, ref_loss: 0.180211\n",
      "\t[#  720] train_loss: 2.678081, odo_loss: 2.005637, ine_loss: 0.494239, ref_loss: 0.178204\n",
      "\t[#  900] train_loss: 2.628978, odo_loss: 2.061831, ine_loss: 0.420579, ref_loss: 0.146568\n",
      "\ttrain_loss: 2.998958, odo_loss: 2.319594, ine_loss: 0.509086, ref_loss: 0.170278\n",
      "\tval_loss: 2.774747, odo_loss: 2.085789, ine_loss: 0.507617, ref_loss: 0.181341\n",
      "Epoch 94/2000\n",
      "\t[#    0] train_loss: 2.745978, odo_loss: 2.122246, ine_loss: 0.478995, ref_loss: 0.144737\n",
      "\t[#  180] train_loss: 4.071666, odo_loss: 3.324733, ine_loss: 0.577567, ref_loss: 0.169367\n",
      "\t[#  360] train_loss: 2.588131, odo_loss: 1.938843, ine_loss: 0.484546, ref_loss: 0.164742\n",
      "\t[#  540] train_loss: 2.413052, odo_loss: 1.789091, ine_loss: 0.477735, ref_loss: 0.146226\n",
      "\t[#  720] train_loss: 2.401746, odo_loss: 1.847376, ine_loss: 0.379030, ref_loss: 0.175340\n",
      "\t[#  900] train_loss: 2.770037, odo_loss: 1.972421, ine_loss: 0.634120, ref_loss: 0.163495\n",
      "\ttrain_loss: 2.751040, odo_loss: 2.072269, ine_loss: 0.510275, ref_loss: 0.168496\n",
      "\tval_loss: 2.689453, odo_loss: 1.999817, ine_loss: 0.509775, ref_loss: 0.179861\n",
      "\t*** Personal Best ***\n",
      "Epoch 95/2000\n",
      "\t[#    0] train_loss: 2.918778, odo_loss: 2.277256, ine_loss: 0.493926, ref_loss: 0.147597\n",
      "\t[#  180] train_loss: 2.553647, odo_loss: 1.909289, ine_loss: 0.502014, ref_loss: 0.142344\n",
      "\t[#  360] train_loss: 3.152395, odo_loss: 2.379918, ine_loss: 0.588944, ref_loss: 0.183533\n",
      "\t[#  540] train_loss: 3.003451, odo_loss: 2.334714, ine_loss: 0.481554, ref_loss: 0.187183\n",
      "\t[#  720] train_loss: 2.571370, odo_loss: 1.839608, ine_loss: 0.549394, ref_loss: 0.182367\n",
      "\t[#  900] train_loss: 2.865817, odo_loss: 2.217756, ine_loss: 0.443338, ref_loss: 0.204724\n",
      "\ttrain_loss: 2.761660, odo_loss: 2.082811, ine_loss: 0.511306, ref_loss: 0.167543\n",
      "\tval_loss: 2.816207, odo_loss: 2.125887, ine_loss: 0.510100, ref_loss: 0.180219\n",
      "Epoch 96/2000\n",
      "\t[#    0] train_loss: 2.853455, odo_loss: 2.209462, ine_loss: 0.470018, ref_loss: 0.173975\n",
      "\t[#  180] train_loss: 2.481422, odo_loss: 1.864671, ine_loss: 0.454469, ref_loss: 0.162281\n",
      "\t[#  360] train_loss: 2.917406, odo_loss: 2.168801, ine_loss: 0.577711, ref_loss: 0.170894\n",
      "\t[#  540] train_loss: 2.516026, odo_loss: 1.969359, ine_loss: 0.411218, ref_loss: 0.135449\n",
      "\t[#  720] train_loss: 2.707332, odo_loss: 2.147610, ine_loss: 0.405344, ref_loss: 0.154378\n",
      "\t[#  900] train_loss: 2.744611, odo_loss: 1.994116, ine_loss: 0.586394, ref_loss: 0.164101\n",
      "\ttrain_loss: 2.748786, odo_loss: 2.070141, ine_loss: 0.511658, ref_loss: 0.166986\n",
      "\tval_loss: 2.779714, odo_loss: 2.100159, ine_loss: 0.500359, ref_loss: 0.179197\n",
      "Epoch 97/2000\n",
      "\t[#    0] train_loss: 2.569484, odo_loss: 1.880448, ine_loss: 0.514963, ref_loss: 0.174072\n",
      "\t[#  180] train_loss: 2.235280, odo_loss: 1.667097, ine_loss: 0.410804, ref_loss: 0.157379\n",
      "\t[#  360] train_loss: 2.184849, odo_loss: 1.509268, ine_loss: 0.533964, ref_loss: 0.141617\n",
      "\t[#  540] train_loss: 2.311838, odo_loss: 1.684552, ine_loss: 0.470548, ref_loss: 0.156738\n",
      "\t[#  720] train_loss: 2.531826, odo_loss: 1.942339, ine_loss: 0.433374, ref_loss: 0.156113\n",
      "\t[#  900] train_loss: 2.679435, odo_loss: 1.916675, ine_loss: 0.614631, ref_loss: 0.148128\n",
      "\ttrain_loss: 2.735626, odo_loss: 2.058598, ine_loss: 0.510555, ref_loss: 0.166473\n",
      "\tval_loss: 2.675808, odo_loss: 1.990160, ine_loss: 0.507597, ref_loss: 0.178050\n",
      "\t*** Personal Best ***\n",
      "Epoch 98/2000\n",
      "\t[#    0] train_loss: 2.466628, odo_loss: 1.888467, ine_loss: 0.421745, ref_loss: 0.156416\n",
      "\t[#  180] train_loss: 2.723064, odo_loss: 2.121728, ine_loss: 0.469580, ref_loss: 0.131755\n",
      "\t[#  360] train_loss: 2.674608, odo_loss: 2.021707, ine_loss: 0.481096, ref_loss: 0.171806\n",
      "\t[#  540] train_loss: 2.575070, odo_loss: 1.834832, ine_loss: 0.562145, ref_loss: 0.178093\n",
      "\t[#  720] train_loss: 2.530568, odo_loss: 1.916115, ine_loss: 0.471906, ref_loss: 0.142547\n",
      "\t[#  900] train_loss: 2.906170, odo_loss: 2.266746, ine_loss: 0.473893, ref_loss: 0.165531\n",
      "\ttrain_loss: 2.786815, odo_loss: 2.110115, ine_loss: 0.510284, ref_loss: 0.166416\n",
      "\tval_loss: 2.798534, odo_loss: 2.115002, ine_loss: 0.504564, ref_loss: 0.178968\n",
      "Epoch 99/2000\n",
      "\t[#    0] train_loss: 2.645110, odo_loss: 2.100146, ine_loss: 0.369768, ref_loss: 0.175196\n",
      "\t[#  180] train_loss: 3.126339, odo_loss: 2.343459, ine_loss: 0.574721, ref_loss: 0.208160\n",
      "\t[#  360] train_loss: 2.618476, odo_loss: 1.972160, ine_loss: 0.444877, ref_loss: 0.201439\n",
      "\t[#  540] train_loss: 3.045023, odo_loss: 2.405988, ine_loss: 0.494084, ref_loss: 0.144952\n",
      "\t[#  720] train_loss: 2.365946, odo_loss: 1.647053, ine_loss: 0.507156, ref_loss: 0.211736\n",
      "\t[#  900] train_loss: 2.980419, odo_loss: 2.275533, ine_loss: 0.551974, ref_loss: 0.152913\n",
      "\ttrain_loss: 2.788834, odo_loss: 2.111476, ine_loss: 0.511078, ref_loss: 0.166279\n",
      "\tval_loss: 2.767170, odo_loss: 2.080684, ine_loss: 0.509025, ref_loss: 0.177462\n",
      "Epoch 100/2000\n",
      "\t[#    0] train_loss: 2.945884, odo_loss: 2.255803, ine_loss: 0.498316, ref_loss: 0.191765\n",
      "\t[#  180] train_loss: 2.499657, odo_loss: 1.890258, ine_loss: 0.435998, ref_loss: 0.173402\n",
      "\t[#  360] train_loss: 3.018221, odo_loss: 2.341737, ine_loss: 0.507172, ref_loss: 0.169311\n",
      "\t[#  540] train_loss: 2.577596, odo_loss: 1.962769, ine_loss: 0.449006, ref_loss: 0.165822\n",
      "\t[#  720] train_loss: 2.515466, odo_loss: 1.818400, ine_loss: 0.489138, ref_loss: 0.207928\n",
      "\t[#  900] train_loss: 3.000247, odo_loss: 2.213109, ine_loss: 0.604121, ref_loss: 0.183016\n",
      "\ttrain_loss: 2.766305, odo_loss: 2.089114, ine_loss: 0.511424, ref_loss: 0.165767\n",
      "\tval_loss: 2.892950, odo_loss: 2.208507, ine_loss: 0.507228, ref_loss: 0.177214\n",
      "Epoch 101/2000\n",
      "\t[#    0] train_loss: 2.740065, odo_loss: 2.139312, ine_loss: 0.467461, ref_loss: 0.133292\n",
      "\t[#  180] train_loss: 2.937287, odo_loss: 2.335949, ine_loss: 0.463936, ref_loss: 0.137403\n",
      "\t[#  360] train_loss: 4.725421, odo_loss: 4.039093, ine_loss: 0.523695, ref_loss: 0.162634\n",
      "\t[#  540] train_loss: 3.095712, odo_loss: 2.369917, ine_loss: 0.535421, ref_loss: 0.190374\n",
      "\t[#  720] train_loss: 2.975113, odo_loss: 2.302992, ine_loss: 0.511631, ref_loss: 0.160490\n",
      "\t[#  900] train_loss: 2.513310, odo_loss: 1.858853, ine_loss: 0.471974, ref_loss: 0.182482\n",
      "\ttrain_loss: 2.929441, odo_loss: 2.251143, ine_loss: 0.512293, ref_loss: 0.166005\n",
      "\tval_loss: 2.744316, odo_loss: 2.049837, ine_loss: 0.513550, ref_loss: 0.180929\n",
      "Epoch 102/2000\n",
      "\t[#    0] train_loss: 2.854130, odo_loss: 2.244797, ine_loss: 0.471713, ref_loss: 0.137621\n",
      "\t[#  180] train_loss: 2.534166, odo_loss: 1.926593, ine_loss: 0.454740, ref_loss: 0.152834\n",
      "\t[#  360] train_loss: 2.404764, odo_loss: 1.862308, ine_loss: 0.386419, ref_loss: 0.156037\n",
      "\t[#  540] train_loss: 2.606156, odo_loss: 1.927588, ine_loss: 0.504833, ref_loss: 0.173735\n",
      "\t[#  720] train_loss: 2.856031, odo_loss: 2.102215, ine_loss: 0.582481, ref_loss: 0.171334\n",
      "\t[#  900] train_loss: 2.529526, odo_loss: 1.891221, ine_loss: 0.486014, ref_loss: 0.152291\n",
      "\ttrain_loss: 2.696298, odo_loss: 2.019063, ine_loss: 0.512394, ref_loss: 0.164841\n",
      "\tval_loss: 2.686329, odo_loss: 1.998610, ine_loss: 0.510664, ref_loss: 0.177055\n",
      "Epoch 103/2000\n",
      "\t[#    0] train_loss: 2.534990, odo_loss: 1.828247, ine_loss: 0.536075, ref_loss: 0.170667\n",
      "\t[#  180] train_loss: 2.446897, odo_loss: 1.753010, ine_loss: 0.490341, ref_loss: 0.203547\n",
      "\t[#  360] train_loss: 2.770078, odo_loss: 2.059601, ine_loss: 0.545231, ref_loss: 0.165247\n",
      "\t[#  540] train_loss: 2.908127, odo_loss: 2.090735, ine_loss: 0.648506, ref_loss: 0.168886\n",
      "\t[#  720] train_loss: 3.061738, odo_loss: 2.463923, ine_loss: 0.437935, ref_loss: 0.159881\n",
      "\t[#  900] train_loss: 2.770618, odo_loss: 2.120248, ine_loss: 0.490783, ref_loss: 0.159588\n",
      "\ttrain_loss: 2.822222, odo_loss: 2.144928, ine_loss: 0.513015, ref_loss: 0.164280\n",
      "\tval_loss: 2.916132, odo_loss: 2.220626, ine_loss: 0.515092, ref_loss: 0.180414\n",
      "Epoch 104/2000\n",
      "\t[#    0] train_loss: 2.493659, odo_loss: 1.844332, ine_loss: 0.499523, ref_loss: 0.149804\n",
      "\t[#  180] train_loss: 2.671322, odo_loss: 1.963356, ine_loss: 0.534722, ref_loss: 0.173244\n",
      "\t[#  360] train_loss: 2.508584, odo_loss: 1.831316, ine_loss: 0.501481, ref_loss: 0.175788\n",
      "\t[#  540] train_loss: 2.625452, odo_loss: 1.960057, ine_loss: 0.491312, ref_loss: 0.174083\n",
      "\t[#  720] train_loss: 2.382015, odo_loss: 1.724661, ine_loss: 0.509127, ref_loss: 0.148227\n",
      "\t[#  900] train_loss: 3.102235, odo_loss: 2.411224, ine_loss: 0.536588, ref_loss: 0.154424\n",
      "\ttrain_loss: 2.783080, odo_loss: 2.104710, ine_loss: 0.513649, ref_loss: 0.164721\n",
      "\tval_loss: 2.805505, odo_loss: 2.117187, ine_loss: 0.511412, ref_loss: 0.176906\n",
      "Epoch 105/2000\n",
      "\t[#    0] train_loss: 2.592513, odo_loss: 1.793940, ine_loss: 0.631338, ref_loss: 0.167236\n",
      "\t[#  180] train_loss: 2.476162, odo_loss: 1.807234, ine_loss: 0.513035, ref_loss: 0.155893\n",
      "\t[#  360] train_loss: 2.817921, odo_loss: 2.211906, ine_loss: 0.469111, ref_loss: 0.136904\n",
      "\t[#  540] train_loss: 2.887399, odo_loss: 2.089263, ine_loss: 0.629890, ref_loss: 0.168246\n",
      "\t[#  720] train_loss: 2.373726, odo_loss: 1.697902, ine_loss: 0.505076, ref_loss: 0.170748\n",
      "\t[#  900] train_loss: 2.487304, odo_loss: 1.742151, ine_loss: 0.539541, ref_loss: 0.205612\n",
      "\ttrain_loss: 2.724621, odo_loss: 2.047723, ine_loss: 0.512224, ref_loss: 0.164674\n",
      "\tval_loss: 2.716258, odo_loss: 2.029743, ine_loss: 0.509940, ref_loss: 0.176576\n",
      "Epoch 106/2000\n",
      "\t[#    0] train_loss: 2.899890, odo_loss: 2.179245, ine_loss: 0.578970, ref_loss: 0.141675\n",
      "\t[#  180] train_loss: 2.653626, odo_loss: 2.022287, ine_loss: 0.477327, ref_loss: 0.154012\n",
      "\t[#  360] train_loss: 2.734788, odo_loss: 2.049854, ine_loss: 0.508686, ref_loss: 0.176248\n",
      "\t[#  540] train_loss: 2.527900, odo_loss: 1.846655, ine_loss: 0.498242, ref_loss: 0.183003\n",
      "\t[#  720] train_loss: 2.733218, odo_loss: 2.059598, ine_loss: 0.529736, ref_loss: 0.143883\n",
      "\t[#  900] train_loss: 2.885701, odo_loss: 2.022644, ine_loss: 0.725191, ref_loss: 0.137866\n",
      "\ttrain_loss: 2.699056, odo_loss: 2.020577, ine_loss: 0.514459, ref_loss: 0.164020\n",
      "\tval_loss: 2.678148, odo_loss: 1.993709, ine_loss: 0.508908, ref_loss: 0.175530\n",
      "Epoch 107/2000\n",
      "\t[#    0] train_loss: 2.601676, odo_loss: 1.835196, ine_loss: 0.601783, ref_loss: 0.164696\n",
      "\t[#  180] train_loss: 2.481735, odo_loss: 1.854541, ine_loss: 0.486949, ref_loss: 0.140245\n",
      "\t[#  360] train_loss: 2.602713, odo_loss: 1.863021, ine_loss: 0.522441, ref_loss: 0.217251\n",
      "\t[#  540] train_loss: 2.346257, odo_loss: 1.702507, ine_loss: 0.487092, ref_loss: 0.156658\n",
      "\t[#  720] train_loss: 2.454136, odo_loss: 1.821908, ine_loss: 0.486383, ref_loss: 0.145844\n",
      "\t[#  900] train_loss: 2.386836, odo_loss: 1.791275, ine_loss: 0.442441, ref_loss: 0.153120\n",
      "\ttrain_loss: 2.722842, odo_loss: 2.045354, ine_loss: 0.514371, ref_loss: 0.163117\n",
      "\tval_loss: 2.713741, odo_loss: 2.024040, ine_loss: 0.512309, ref_loss: 0.177392\n",
      "Epoch 108/2000\n",
      "\t[#    0] train_loss: 2.656919, odo_loss: 1.881450, ine_loss: 0.605446, ref_loss: 0.170023\n",
      "\t[#  180] train_loss: 2.451406, odo_loss: 1.685973, ine_loss: 0.607689, ref_loss: 0.157743\n",
      "\t[#  360] train_loss: 2.461131, odo_loss: 1.783381, ine_loss: 0.520474, ref_loss: 0.157276\n",
      "\t[#  540] train_loss: 2.917847, odo_loss: 2.237993, ine_loss: 0.479871, ref_loss: 0.199984\n",
      "\t[#  720] train_loss: 2.922006, odo_loss: 2.143846, ine_loss: 0.596424, ref_loss: 0.181736\n",
      "\t[#  900] train_loss: 2.958976, odo_loss: 2.229131, ine_loss: 0.559208, ref_loss: 0.170637\n",
      "\ttrain_loss: 2.679132, odo_loss: 2.001245, ine_loss: 0.514892, ref_loss: 0.162995\n",
      "\tval_loss: 2.663953, odo_loss: 1.976841, ine_loss: 0.508129, ref_loss: 0.178984\n",
      "\t*** Personal Best ***\n",
      "Epoch 109/2000\n",
      "\t[#    0] train_loss: 2.949084, odo_loss: 2.278541, ine_loss: 0.524009, ref_loss: 0.146534\n",
      "\t[#  180] train_loss: 2.593832, odo_loss: 1.917310, ine_loss: 0.513872, ref_loss: 0.162650\n",
      "\t[#  360] train_loss: 2.890652, odo_loss: 2.186612, ine_loss: 0.545634, ref_loss: 0.158407\n",
      "\t[#  540] train_loss: 2.561091, odo_loss: 1.893627, ine_loss: 0.507321, ref_loss: 0.160143\n",
      "\t[#  720] train_loss: 2.383855, odo_loss: 1.620002, ine_loss: 0.571312, ref_loss: 0.192541\n",
      "\t[#  900] train_loss: 2.644092, odo_loss: 2.005522, ine_loss: 0.485297, ref_loss: 0.153274\n",
      "\ttrain_loss: 2.663939, odo_loss: 1.986078, ine_loss: 0.515207, ref_loss: 0.162654\n",
      "\tval_loss: 2.645959, odo_loss: 1.953769, ine_loss: 0.516477, ref_loss: 0.175713\n",
      "\t*** Personal Best ***\n",
      "Epoch 110/2000\n",
      "\t[#    0] train_loss: 2.663197, odo_loss: 2.041022, ine_loss: 0.465835, ref_loss: 0.156340\n",
      "\t[#  180] train_loss: 2.515449, odo_loss: 1.967545, ine_loss: 0.393411, ref_loss: 0.154493\n",
      "\t[#  360] train_loss: 2.711023, odo_loss: 2.140878, ine_loss: 0.414438, ref_loss: 0.155706\n",
      "\t[#  540] train_loss: 2.701006, odo_loss: 1.845854, ine_loss: 0.665496, ref_loss: 0.189655\n",
      "\t[#  720] train_loss: 3.218628, odo_loss: 2.430140, ine_loss: 0.618605, ref_loss: 0.169883\n",
      "\t[#  900] train_loss: 2.833422, odo_loss: 2.141388, ine_loss: 0.564887, ref_loss: 0.127146\n",
      "\ttrain_loss: 2.629555, odo_loss: 1.949794, ine_loss: 0.517508, ref_loss: 0.162253\n",
      "\tval_loss: 2.674482, odo_loss: 1.979916, ine_loss: 0.518865, ref_loss: 0.175701\n",
      "Epoch 111/2000\n",
      "\t[#    0] train_loss: 2.357293, odo_loss: 1.800287, ine_loss: 0.422429, ref_loss: 0.134577\n",
      "\t[#  180] train_loss: 2.858464, odo_loss: 2.098129, ine_loss: 0.566573, ref_loss: 0.193762\n",
      "\t[#  360] train_loss: 2.653786, odo_loss: 2.041195, ine_loss: 0.454879, ref_loss: 0.157712\n",
      "\t[#  540] train_loss: 2.719372, odo_loss: 1.930794, ine_loss: 0.623031, ref_loss: 0.165547\n",
      "\t[#  720] train_loss: 2.225161, odo_loss: 1.627769, ine_loss: 0.448793, ref_loss: 0.148599\n",
      "\t[#  900] train_loss: 2.434670, odo_loss: 1.841924, ine_loss: 0.441752, ref_loss: 0.150994\n",
      "\ttrain_loss: 2.676537, odo_loss: 1.996482, ine_loss: 0.517674, ref_loss: 0.162382\n",
      "\tval_loss: 3.154020, odo_loss: 2.461742, ine_loss: 0.515539, ref_loss: 0.176739\n",
      "Epoch 112/2000\n",
      "\t[#    0] train_loss: 2.716208, odo_loss: 2.097195, ine_loss: 0.457848, ref_loss: 0.161164\n",
      "\t[#  180] train_loss: 2.398217, odo_loss: 1.657749, ine_loss: 0.610041, ref_loss: 0.130428\n",
      "\t[#  360] train_loss: 2.573251, odo_loss: 2.034818, ine_loss: 0.391355, ref_loss: 0.147078\n",
      "\t[#  540] train_loss: 3.175943, odo_loss: 2.448813, ine_loss: 0.544318, ref_loss: 0.182811\n",
      "\t[#  720] train_loss: 2.600683, odo_loss: 1.886312, ine_loss: 0.555684, ref_loss: 0.158687\n",
      "\t[#  900] train_loss: 2.480498, odo_loss: 1.873431, ine_loss: 0.443849, ref_loss: 0.163217\n",
      "\ttrain_loss: 2.874805, odo_loss: 2.193900, ine_loss: 0.518532, ref_loss: 0.162373\n",
      "\tval_loss: 2.729479, odo_loss: 2.036517, ine_loss: 0.516511, ref_loss: 0.176451\n",
      "Epoch 113/2000\n",
      "\t[#    0] train_loss: 2.832718, odo_loss: 2.139321, ine_loss: 0.526850, ref_loss: 0.166546\n",
      "\t[#  180] train_loss: 2.679258, odo_loss: 2.028105, ine_loss: 0.479967, ref_loss: 0.171186\n",
      "\t[#  360] train_loss: 2.494722, odo_loss: 1.882478, ine_loss: 0.476359, ref_loss: 0.135884\n",
      "\t[#  540] train_loss: 2.484351, odo_loss: 1.830873, ine_loss: 0.491205, ref_loss: 0.162273\n",
      "\t[#  720] train_loss: 2.865095, odo_loss: 2.124636, ine_loss: 0.581171, ref_loss: 0.159288\n",
      "\t[#  900] train_loss: 2.335732, odo_loss: 1.738213, ine_loss: 0.427951, ref_loss: 0.169568\n",
      "\ttrain_loss: 2.624362, odo_loss: 1.940494, ine_loss: 0.522196, ref_loss: 0.161672\n",
      "\tval_loss: 2.639992, odo_loss: 1.946401, ine_loss: 0.515908, ref_loss: 0.177684\n",
      "\t*** Personal Best ***\n",
      "Epoch 114/2000\n",
      "\t[#    0] train_loss: 2.387204, odo_loss: 1.785986, ine_loss: 0.420673, ref_loss: 0.180546\n",
      "\t[#  180] train_loss: 3.186804, odo_loss: 2.507581, ine_loss: 0.525991, ref_loss: 0.153232\n",
      "\t[#  360] train_loss: 2.728035, odo_loss: 2.074586, ine_loss: 0.508688, ref_loss: 0.144760\n",
      "\t[#  540] train_loss: 2.522681, odo_loss: 1.837293, ine_loss: 0.525767, ref_loss: 0.159620\n",
      "\t[#  720] train_loss: 2.728582, odo_loss: 1.934023, ine_loss: 0.603562, ref_loss: 0.190997\n",
      "\t[#  900] train_loss: 2.691846, odo_loss: 2.098555, ine_loss: 0.456441, ref_loss: 0.136850\n",
      "\ttrain_loss: 2.684802, odo_loss: 1.999791, ine_loss: 0.523608, ref_loss: 0.161402\n",
      "\tval_loss: 2.816504, odo_loss: 2.124928, ine_loss: 0.514673, ref_loss: 0.176903\n",
      "Epoch 115/2000\n",
      "\t[#    0] train_loss: 2.602706, odo_loss: 1.984537, ine_loss: 0.479625, ref_loss: 0.138544\n",
      "\t[#  180] train_loss: 2.545247, odo_loss: 1.845208, ine_loss: 0.548313, ref_loss: 0.151726\n",
      "\t[#  360] train_loss: 2.714333, odo_loss: 2.087751, ine_loss: 0.451582, ref_loss: 0.175000\n",
      "\t[#  540] train_loss: 2.843048, odo_loss: 2.168350, ine_loss: 0.495635, ref_loss: 0.179064\n",
      "\t[#  720] train_loss: 2.279102, odo_loss: 1.671361, ine_loss: 0.446601, ref_loss: 0.161140\n",
      "\t[#  900] train_loss: 2.683136, odo_loss: 2.029745, ine_loss: 0.512127, ref_loss: 0.141264\n",
      "\ttrain_loss: 2.683971, odo_loss: 1.997917, ine_loss: 0.524786, ref_loss: 0.161267\n",
      "\tval_loss: 2.603193, odo_loss: 1.903863, ine_loss: 0.523093, ref_loss: 0.176237\n",
      "\t*** Personal Best ***\n",
      "Epoch 116/2000\n",
      "\t[#    0] train_loss: 2.461895, odo_loss: 1.847449, ine_loss: 0.451928, ref_loss: 0.162518\n",
      "\t[#  180] train_loss: 2.516837, odo_loss: 1.824036, ine_loss: 0.526988, ref_loss: 0.165813\n",
      "\t[#  360] train_loss: 2.794942, odo_loss: 2.138043, ine_loss: 0.517555, ref_loss: 0.139345\n",
      "\t[#  540] train_loss: 3.314830, odo_loss: 2.494457, ine_loss: 0.645592, ref_loss: 0.174780\n",
      "\t[#  720] train_loss: 2.195582, odo_loss: 1.533661, ine_loss: 0.534638, ref_loss: 0.127282\n",
      "\t[#  900] train_loss: 2.324778, odo_loss: 1.677387, ine_loss: 0.506151, ref_loss: 0.141240\n",
      "\ttrain_loss: 2.627285, odo_loss: 1.939246, ine_loss: 0.526670, ref_loss: 0.161369\n",
      "\tval_loss: 2.605906, odo_loss: 1.905458, ine_loss: 0.523758, ref_loss: 0.176690\n",
      "Epoch 117/2000\n",
      "\t[#    0] train_loss: 2.881432, odo_loss: 2.116970, ine_loss: 0.608761, ref_loss: 0.155701\n",
      "\t[#  180] train_loss: 2.497551, odo_loss: 1.809514, ine_loss: 0.506513, ref_loss: 0.181523\n",
      "\t[#  360] train_loss: 2.092191, odo_loss: 1.429147, ine_loss: 0.509788, ref_loss: 0.153256\n",
      "\t[#  540] train_loss: 2.417262, odo_loss: 1.836511, ine_loss: 0.420403, ref_loss: 0.160349\n",
      "\t[#  720] train_loss: 2.941632, odo_loss: 2.209571, ine_loss: 0.552619, ref_loss: 0.179442\n",
      "\t[#  900] train_loss: 2.731827, odo_loss: 1.975720, ine_loss: 0.613392, ref_loss: 0.142714\n",
      "\ttrain_loss: 2.566250, odo_loss: 1.875296, ine_loss: 0.530241, ref_loss: 0.160713\n",
      "\tval_loss: 2.566154, odo_loss: 1.867072, ine_loss: 0.524859, ref_loss: 0.174224\n",
      "\t*** Personal Best ***\n",
      "Epoch 118/2000\n",
      "\t[#    0] train_loss: 2.623112, odo_loss: 1.906550, ine_loss: 0.551119, ref_loss: 0.165443\n",
      "\t[#  180] train_loss: 2.180042, odo_loss: 1.515359, ine_loss: 0.505374, ref_loss: 0.159309\n",
      "\t[#  360] train_loss: 2.741521, odo_loss: 2.002416, ine_loss: 0.613785, ref_loss: 0.125320\n",
      "\t[#  540] train_loss: 2.736494, odo_loss: 2.015195, ine_loss: 0.576250, ref_loss: 0.145048\n",
      "\t[#  720] train_loss: 2.705327, odo_loss: 1.957697, ine_loss: 0.564142, ref_loss: 0.183488\n",
      "\t[#  900] train_loss: 2.344231, odo_loss: 1.631663, ine_loss: 0.569671, ref_loss: 0.142897\n",
      "\ttrain_loss: 2.547832, odo_loss: 1.856095, ine_loss: 0.531507, ref_loss: 0.160230\n",
      "\tval_loss: 2.502859, odo_loss: 1.797054, ine_loss: 0.532288, ref_loss: 0.173516\n",
      "\t*** Personal Best ***\n",
      "Epoch 119/2000\n",
      "\t[#    0] train_loss: 2.470196, odo_loss: 1.808749, ine_loss: 0.522190, ref_loss: 0.139258\n",
      "\t[#  180] train_loss: 2.457841, odo_loss: 1.725401, ine_loss: 0.559669, ref_loss: 0.172771\n",
      "\t[#  360] train_loss: 2.288990, odo_loss: 1.728449, ine_loss: 0.422703, ref_loss: 0.137838\n",
      "\t[#  540] train_loss: 2.545314, odo_loss: 1.927563, ine_loss: 0.435189, ref_loss: 0.182563\n",
      "\t[#  720] train_loss: 2.517067, odo_loss: 1.773632, ine_loss: 0.557199, ref_loss: 0.186236\n",
      "\t[#  900] train_loss: 2.652191, odo_loss: 1.978329, ine_loss: 0.512659, ref_loss: 0.161203\n",
      "\ttrain_loss: 2.512255, odo_loss: 1.818289, ine_loss: 0.534196, ref_loss: 0.159770\n",
      "\tval_loss: 2.521694, odo_loss: 1.818533, ine_loss: 0.527272, ref_loss: 0.175889\n",
      "Epoch 120/2000\n",
      "\t[#    0] train_loss: 2.255744, odo_loss: 1.630909, ine_loss: 0.482907, ref_loss: 0.141927\n",
      "\t[#  180] train_loss: 2.179540, odo_loss: 1.560835, ine_loss: 0.499726, ref_loss: 0.118979\n",
      "\t[#  360] train_loss: 2.434843, odo_loss: 1.651471, ine_loss: 0.607845, ref_loss: 0.175528\n",
      "\t[#  540] train_loss: 2.929779, odo_loss: 2.310273, ine_loss: 0.463324, ref_loss: 0.156182\n",
      "\t[#  720] train_loss: 2.785962, odo_loss: 2.142078, ine_loss: 0.499857, ref_loss: 0.144027\n",
      "\t[#  900] train_loss: 2.522132, odo_loss: 1.807261, ine_loss: 0.571284, ref_loss: 0.143587\n",
      "\ttrain_loss: 2.514884, odo_loss: 1.821766, ine_loss: 0.533608, ref_loss: 0.159509\n",
      "\tval_loss: 2.512228, odo_loss: 1.805869, ine_loss: 0.530330, ref_loss: 0.176029\n",
      "Epoch 121/2000\n",
      "\t[#    0] train_loss: 2.777043, odo_loss: 2.027315, ine_loss: 0.602852, ref_loss: 0.146875\n",
      "\t[#  180] train_loss: 2.912724, odo_loss: 2.017557, ine_loss: 0.709677, ref_loss: 0.185490\n",
      "\t[#  360] train_loss: 2.365220, odo_loss: 1.683213, ine_loss: 0.531825, ref_loss: 0.150182\n",
      "\t[#  540] train_loss: 2.906324, odo_loss: 2.029115, ine_loss: 0.718726, ref_loss: 0.158484\n",
      "\t[#  720] train_loss: 2.234444, odo_loss: 1.461819, ine_loss: 0.613491, ref_loss: 0.159134\n",
      "\t[#  900] train_loss: 2.373942, odo_loss: 1.794956, ine_loss: 0.453047, ref_loss: 0.125939\n",
      "\ttrain_loss: 2.499692, odo_loss: 1.806709, ine_loss: 0.533637, ref_loss: 0.159347\n",
      "\tval_loss: 2.516305, odo_loss: 1.812492, ine_loss: 0.531693, ref_loss: 0.172120\n",
      "Epoch 122/2000\n",
      "\t[#    0] train_loss: 2.763321, odo_loss: 2.053675, ine_loss: 0.522715, ref_loss: 0.186932\n",
      "\t[#  180] train_loss: 2.414409, odo_loss: 1.814354, ine_loss: 0.444056, ref_loss: 0.155999\n",
      "\t[#  360] train_loss: 2.645689, odo_loss: 1.966852, ine_loss: 0.520470, ref_loss: 0.158367\n",
      "\t[#  540] train_loss: 2.656548, odo_loss: 2.020484, ine_loss: 0.488358, ref_loss: 0.147706\n",
      "\t[#  720] train_loss: 2.056216, odo_loss: 1.475598, ine_loss: 0.440769, ref_loss: 0.139849\n",
      "\t[#  900] train_loss: 2.525033, odo_loss: 1.831420, ine_loss: 0.530021, ref_loss: 0.163592\n",
      "\ttrain_loss: 2.566760, odo_loss: 1.874431, ine_loss: 0.533235, ref_loss: 0.159094\n",
      "\tval_loss: 2.595283, odo_loss: 1.886351, ine_loss: 0.535287, ref_loss: 0.173644\n",
      "Epoch 123/2000\n",
      "\t[#    0] train_loss: 2.416100, odo_loss: 1.781991, ine_loss: 0.466680, ref_loss: 0.167428\n",
      "\t[#  180] train_loss: 2.401704, odo_loss: 1.704641, ine_loss: 0.555763, ref_loss: 0.141299\n",
      "\t[#  360] train_loss: 2.814435, odo_loss: 2.072397, ine_loss: 0.608921, ref_loss: 0.133118\n",
      "\t[#  540] train_loss: 2.348278, odo_loss: 1.623288, ine_loss: 0.564297, ref_loss: 0.160692\n",
      "\t[#  720] train_loss: 3.757054, odo_loss: 3.019718, ine_loss: 0.589394, ref_loss: 0.147942\n",
      "\t[#  900] train_loss: 2.215870, odo_loss: 1.468049, ine_loss: 0.573399, ref_loss: 0.174422\n",
      "\ttrain_loss: 2.570250, odo_loss: 1.878375, ine_loss: 0.532870, ref_loss: 0.159006\n",
      "\tval_loss: 2.600846, odo_loss: 1.897561, ine_loss: 0.527778, ref_loss: 0.175507\n",
      "Epoch 124/2000\n",
      "\t[#    0] train_loss: 2.730943, odo_loss: 1.980514, ine_loss: 0.594743, ref_loss: 0.155686\n",
      "\t[#  180] train_loss: 2.376215, odo_loss: 1.693717, ine_loss: 0.504805, ref_loss: 0.177693\n",
      "\t[#  360] train_loss: 2.645322, odo_loss: 1.910539, ine_loss: 0.558215, ref_loss: 0.176568\n",
      "\t[#  540] train_loss: 2.232643, odo_loss: 1.475942, ine_loss: 0.590149, ref_loss: 0.166552\n",
      "\t[#  720] train_loss: 2.513227, odo_loss: 1.875987, ine_loss: 0.493956, ref_loss: 0.143284\n",
      "\t[#  900] train_loss: 2.479006, odo_loss: 1.797774, ine_loss: 0.518297, ref_loss: 0.162935\n",
      "\ttrain_loss: 2.599737, odo_loss: 1.907671, ine_loss: 0.532747, ref_loss: 0.159319\n",
      "\tval_loss: 2.587284, odo_loss: 1.886707, ine_loss: 0.525220, ref_loss: 0.175356\n",
      "Epoch 125/2000\n",
      "\t[#    0] train_loss: 2.319756, odo_loss: 1.649659, ine_loss: 0.529582, ref_loss: 0.140514\n",
      "\t[#  180] train_loss: 2.705762, odo_loss: 2.074959, ine_loss: 0.439186, ref_loss: 0.191617\n",
      "\t[#  360] train_loss: 2.162957, odo_loss: 1.469835, ine_loss: 0.523055, ref_loss: 0.170067\n",
      "\t[#  540] train_loss: 2.620760, odo_loss: 1.850108, ine_loss: 0.575028, ref_loss: 0.195625\n",
      "\t[#  720] train_loss: 2.416208, odo_loss: 1.816212, ine_loss: 0.434974, ref_loss: 0.165022\n",
      "\t[#  900] train_loss: 2.710459, odo_loss: 1.967533, ine_loss: 0.582915, ref_loss: 0.160011\n",
      "\ttrain_loss: 2.542157, odo_loss: 1.852287, ine_loss: 0.531307, ref_loss: 0.158563\n",
      "\tval_loss: 2.499566, odo_loss: 1.801578, ine_loss: 0.523952, ref_loss: 0.174035\n",
      "Epoch 126/2000\n",
      "\t[#    0] train_loss: 2.456421, odo_loss: 1.718575, ine_loss: 0.618576, ref_loss: 0.119270\n",
      "\t[#  180] train_loss: 2.568654, odo_loss: 1.800781, ine_loss: 0.589452, ref_loss: 0.178421\n",
      "\t[#  360] train_loss: 2.651484, odo_loss: 1.995362, ine_loss: 0.509351, ref_loss: 0.146771\n",
      "\t[#  540] train_loss: 2.307959, odo_loss: 1.635666, ine_loss: 0.515167, ref_loss: 0.157126\n",
      "\t[#  720] train_loss: 2.358081, odo_loss: 1.685877, ine_loss: 0.518266, ref_loss: 0.153938\n",
      "\t[#  900] train_loss: 2.657103, odo_loss: 1.870716, ine_loss: 0.640930, ref_loss: 0.145456\n",
      "\ttrain_loss: 2.508153, odo_loss: 1.817834, ine_loss: 0.531599, ref_loss: 0.158720\n",
      "\tval_loss: 2.520357, odo_loss: 1.816167, ine_loss: 0.528844, ref_loss: 0.175347\n",
      "Epoch 127/2000\n",
      "\t[#    0] train_loss: 2.789864, odo_loss: 1.956823, ine_loss: 0.646269, ref_loss: 0.186772\n",
      "\t[#  180] train_loss: 2.257496, odo_loss: 1.620986, ine_loss: 0.494616, ref_loss: 0.141894\n",
      "\t[#  360] train_loss: 4.626208, odo_loss: 3.849043, ine_loss: 0.615706, ref_loss: 0.161459\n",
      "\t[#  540] train_loss: 2.807190, odo_loss: 2.124163, ine_loss: 0.522971, ref_loss: 0.160055\n",
      "\t[#  720] train_loss: 2.935433, odo_loss: 2.257962, ine_loss: 0.534699, ref_loss: 0.142772\n",
      "\t[#  900] train_loss: 2.712804, odo_loss: 1.941451, ine_loss: 0.596914, ref_loss: 0.174439\n",
      "\ttrain_loss: 2.610075, odo_loss: 1.921871, ine_loss: 0.529761, ref_loss: 0.158443\n",
      "\tval_loss: 2.455348, odo_loss: 1.752760, ine_loss: 0.529175, ref_loss: 0.173413\n",
      "\t*** Personal Best ***\n",
      "Epoch 128/2000\n",
      "\t[#    0] train_loss: 2.312067, odo_loss: 1.645544, ine_loss: 0.499146, ref_loss: 0.167378\n",
      "\t[#  180] train_loss: 2.604481, odo_loss: 1.920077, ine_loss: 0.522827, ref_loss: 0.161577\n",
      "\t[#  360] train_loss: 2.402354, odo_loss: 1.710773, ine_loss: 0.526728, ref_loss: 0.164853\n",
      "\t[#  540] train_loss: 2.169527, odo_loss: 1.571909, ine_loss: 0.440213, ref_loss: 0.157405\n",
      "\t[#  720] train_loss: 2.811696, odo_loss: 2.041985, ine_loss: 0.593483, ref_loss: 0.176228\n",
      "\t[#  900] train_loss: 2.657111, odo_loss: 1.953918, ine_loss: 0.515482, ref_loss: 0.187711\n",
      "\ttrain_loss: 2.426428, odo_loss: 1.737134, ine_loss: 0.531158, ref_loss: 0.158136\n",
      "\tval_loss: 2.364762, odo_loss: 1.664220, ine_loss: 0.524844, ref_loss: 0.175698\n",
      "\t*** Personal Best ***\n",
      "Epoch 129/2000\n",
      "\t[#    0] train_loss: 2.345659, odo_loss: 1.677218, ine_loss: 0.531652, ref_loss: 0.136789\n",
      "\t[#  180] train_loss: 2.293178, odo_loss: 1.652514, ine_loss: 0.492499, ref_loss: 0.148165\n",
      "\t[#  360] train_loss: 2.598005, odo_loss: 1.933288, ine_loss: 0.523654, ref_loss: 0.141063\n",
      "\t[#  540] train_loss: 2.274487, odo_loss: 1.623485, ine_loss: 0.475240, ref_loss: 0.175762\n",
      "\t[#  720] train_loss: 2.039446, odo_loss: 1.356164, ine_loss: 0.517895, ref_loss: 0.165387\n",
      "\t[#  900] train_loss: 2.364188, odo_loss: 1.710557, ine_loss: 0.489753, ref_loss: 0.163879\n",
      "\ttrain_loss: 2.420623, odo_loss: 1.733142, ine_loss: 0.530069, ref_loss: 0.157412\n",
      "\tval_loss: 2.495482, odo_loss: 1.796501, ine_loss: 0.524372, ref_loss: 0.174609\n",
      "Epoch 130/2000\n",
      "\t[#    0] train_loss: 2.967724, odo_loss: 2.339240, ine_loss: 0.473918, ref_loss: 0.154566\n",
      "\t[#  180] train_loss: 2.310346, odo_loss: 1.600159, ine_loss: 0.556109, ref_loss: 0.154079\n",
      "\t[#  360] train_loss: 2.989988, odo_loss: 2.256052, ine_loss: 0.573934, ref_loss: 0.160002\n",
      "\t[#  540] train_loss: 2.575308, odo_loss: 1.802131, ine_loss: 0.596315, ref_loss: 0.176863\n",
      "\t[#  720] train_loss: 2.214703, odo_loss: 1.515019, ine_loss: 0.515249, ref_loss: 0.184436\n",
      "\t[#  900] train_loss: 2.848184, odo_loss: 2.137421, ine_loss: 0.556310, ref_loss: 0.154453\n",
      "\ttrain_loss: 2.417743, odo_loss: 1.730232, ine_loss: 0.529806, ref_loss: 0.157704\n",
      "\tval_loss: 2.439988, odo_loss: 1.744045, ine_loss: 0.523044, ref_loss: 0.172900\n",
      "Epoch 131/2000\n",
      "\t[#    0] train_loss: 2.469852, odo_loss: 1.849840, ine_loss: 0.451655, ref_loss: 0.168357\n",
      "\t[#  180] train_loss: 2.718081, odo_loss: 2.078984, ine_loss: 0.488584, ref_loss: 0.150512\n",
      "\t[#  360] train_loss: 3.426448, odo_loss: 2.583786, ine_loss: 0.691243, ref_loss: 0.151419\n",
      "\t[#  540] train_loss: 2.165912, odo_loss: 1.529357, ine_loss: 0.490691, ref_loss: 0.145865\n",
      "\t[#  720] train_loss: 2.550527, odo_loss: 1.911114, ine_loss: 0.497692, ref_loss: 0.141721\n",
      "\t[#  900] train_loss: 2.462458, odo_loss: 1.777949, ine_loss: 0.492921, ref_loss: 0.191588\n",
      "\ttrain_loss: 2.593043, odo_loss: 1.906786, ine_loss: 0.528524, ref_loss: 0.157733\n",
      "\tval_loss: 2.609684, odo_loss: 1.907372, ine_loss: 0.530463, ref_loss: 0.171849\n",
      "Epoch 132/2000\n",
      "\t[#    0] train_loss: 2.393941, odo_loss: 1.615042, ine_loss: 0.624650, ref_loss: 0.154249\n",
      "\t[#  180] train_loss: 2.468192, odo_loss: 1.704245, ine_loss: 0.621810, ref_loss: 0.142138\n",
      "\t[#  360] train_loss: 2.613686, odo_loss: 1.796143, ine_loss: 0.664643, ref_loss: 0.152900\n",
      "\t[#  540] train_loss: 2.396263, odo_loss: 1.719764, ine_loss: 0.548162, ref_loss: 0.128337\n",
      "\t[#  720] train_loss: 2.522513, odo_loss: 1.880298, ine_loss: 0.470380, ref_loss: 0.171835\n",
      "\t[#  900] train_loss: 2.262671, odo_loss: 1.647673, ine_loss: 0.447831, ref_loss: 0.167167\n",
      "\ttrain_loss: 2.443081, odo_loss: 1.755384, ine_loss: 0.530053, ref_loss: 0.157645\n",
      "\tval_loss: 2.467555, odo_loss: 1.764286, ine_loss: 0.531471, ref_loss: 0.171798\n",
      "Epoch 133/2000\n",
      "\t[#    0] train_loss: 2.457483, odo_loss: 1.777268, ine_loss: 0.517185, ref_loss: 0.163030\n",
      "\t[#  180] train_loss: 2.226633, odo_loss: 1.612412, ine_loss: 0.446666, ref_loss: 0.167555\n",
      "\t[#  360] train_loss: 2.182844, odo_loss: 1.516906, ine_loss: 0.479832, ref_loss: 0.186106\n",
      "\t[#  540] train_loss: 2.199440, odo_loss: 1.616518, ine_loss: 0.440288, ref_loss: 0.142633\n",
      "\t[#  720] train_loss: 2.663410, odo_loss: 1.910129, ine_loss: 0.590454, ref_loss: 0.162827\n",
      "\t[#  900] train_loss: 2.448411, odo_loss: 1.675292, ine_loss: 0.609832, ref_loss: 0.163287\n",
      "\ttrain_loss: 2.389759, odo_loss: 1.703409, ine_loss: 0.529683, ref_loss: 0.156667\n",
      "\tval_loss: 2.353555, odo_loss: 1.657509, ine_loss: 0.524595, ref_loss: 0.171451\n",
      "\t*** Personal Best ***\n",
      "Epoch 134/2000\n",
      "\t[#    0] train_loss: 1.871662, odo_loss: 1.228894, ine_loss: 0.496302, ref_loss: 0.146465\n",
      "\t[#  180] train_loss: 2.322783, odo_loss: 1.687076, ine_loss: 0.474955, ref_loss: 0.160752\n",
      "\t[#  360] train_loss: 2.376417, odo_loss: 1.717428, ine_loss: 0.525451, ref_loss: 0.133538\n",
      "\t[#  540] train_loss: 2.394972, odo_loss: 1.678301, ine_loss: 0.538049, ref_loss: 0.178623\n",
      "\t[#  720] train_loss: 2.430021, odo_loss: 1.791973, ine_loss: 0.486844, ref_loss: 0.151204\n",
      "\t[#  900] train_loss: 2.145813, odo_loss: 1.544339, ine_loss: 0.457820, ref_loss: 0.143653\n",
      "\ttrain_loss: 2.374967, odo_loss: 1.690197, ine_loss: 0.528300, ref_loss: 0.156470\n",
      "\tval_loss: 2.377001, odo_loss: 1.676837, ine_loss: 0.526767, ref_loss: 0.173397\n",
      "Epoch 135/2000\n",
      "\t[#    0] train_loss: 2.480328, odo_loss: 1.812965, ine_loss: 0.516142, ref_loss: 0.151222\n",
      "\t[#  180] train_loss: 2.276597, odo_loss: 1.632458, ine_loss: 0.492485, ref_loss: 0.151654\n",
      "\t[#  360] train_loss: 2.581256, odo_loss: 1.900911, ine_loss: 0.514112, ref_loss: 0.166233\n",
      "\t[#  540] train_loss: 2.674606, odo_loss: 1.969406, ine_loss: 0.562498, ref_loss: 0.142703\n",
      "\t[#  720] train_loss: 2.226454, odo_loss: 1.685052, ine_loss: 0.384284, ref_loss: 0.157118\n",
      "\t[#  900] train_loss: 2.070947, odo_loss: 1.440040, ine_loss: 0.470421, ref_loss: 0.160486\n",
      "\ttrain_loss: 2.680119, odo_loss: 1.995078, ine_loss: 0.527454, ref_loss: 0.157587\n",
      "\tval_loss: 2.696577, odo_loss: 2.000539, ine_loss: 0.519030, ref_loss: 0.177009\n",
      "Epoch 136/2000\n",
      "\t[#    0] train_loss: 2.531068, odo_loss: 1.816839, ine_loss: 0.535674, ref_loss: 0.178555\n",
      "\t[#  180] train_loss: 2.575887, odo_loss: 1.869287, ine_loss: 0.544581, ref_loss: 0.162019\n",
      "\t[#  360] train_loss: 2.538082, odo_loss: 1.904412, ine_loss: 0.499193, ref_loss: 0.134477\n",
      "\t[#  540] train_loss: 2.162538, odo_loss: 1.513838, ine_loss: 0.505429, ref_loss: 0.143271\n",
      "\t[#  720] train_loss: 2.506400, odo_loss: 1.873563, ine_loss: 0.492200, ref_loss: 0.140637\n",
      "\t[#  900] train_loss: 2.216416, odo_loss: 1.614172, ine_loss: 0.492026, ref_loss: 0.110218\n",
      "\ttrain_loss: 2.437389, odo_loss: 1.751260, ine_loss: 0.529466, ref_loss: 0.156663\n",
      "\tval_loss: 2.381500, odo_loss: 1.684983, ine_loss: 0.524044, ref_loss: 0.172473\n",
      "Epoch 137/2000\n",
      "\t[#    0] train_loss: 2.510385, odo_loss: 1.885617, ine_loss: 0.475864, ref_loss: 0.148904\n",
      "\t[#  180] train_loss: 2.573766, odo_loss: 1.910068, ine_loss: 0.517683, ref_loss: 0.146015\n",
      "\t[#  360] train_loss: 2.397317, odo_loss: 1.675271, ine_loss: 0.585728, ref_loss: 0.136318\n",
      "\t[#  540] train_loss: 2.444843, odo_loss: 1.720717, ine_loss: 0.556706, ref_loss: 0.167420\n",
      "\t[#  720] train_loss: 2.270888, odo_loss: 1.666485, ine_loss: 0.441543, ref_loss: 0.162859\n",
      "\t[#  900] train_loss: 2.263099, odo_loss: 1.641576, ine_loss: 0.437351, ref_loss: 0.184172\n",
      "\ttrain_loss: 2.346502, odo_loss: 1.663966, ine_loss: 0.526788, ref_loss: 0.155748\n",
      "\tval_loss: 2.389967, odo_loss: 1.692610, ine_loss: 0.524521, ref_loss: 0.172836\n",
      "Epoch 138/2000\n",
      "\t[#    0] train_loss: 2.453267, odo_loss: 1.679595, ine_loss: 0.595464, ref_loss: 0.178209\n",
      "\t[#  180] train_loss: 2.064432, odo_loss: 1.435625, ine_loss: 0.478906, ref_loss: 0.149901\n",
      "\t[#  360] train_loss: 2.277634, odo_loss: 1.529608, ine_loss: 0.592229, ref_loss: 0.155798\n",
      "\t[#  540] train_loss: 2.209354, odo_loss: 1.550475, ine_loss: 0.506381, ref_loss: 0.152498\n",
      "\t[#  720] train_loss: 2.839123, odo_loss: 2.091922, ine_loss: 0.581346, ref_loss: 0.165855\n",
      "\t[#  900] train_loss: 2.266711, odo_loss: 1.570797, ine_loss: 0.530357, ref_loss: 0.165557\n",
      "\ttrain_loss: 2.456981, odo_loss: 1.773992, ine_loss: 0.527238, ref_loss: 0.155751\n",
      "\tval_loss: 2.435255, odo_loss: 1.737269, ine_loss: 0.523865, ref_loss: 0.174121\n",
      "Epoch 139/2000\n",
      "\t[#    0] train_loss: 2.223597, odo_loss: 1.440481, ine_loss: 0.642850, ref_loss: 0.140265\n",
      "\t[#  180] train_loss: 2.483582, odo_loss: 1.803491, ine_loss: 0.547548, ref_loss: 0.132544\n",
      "\t[#  360] train_loss: 2.187700, odo_loss: 1.556449, ine_loss: 0.488664, ref_loss: 0.142587\n",
      "\t[#  540] train_loss: 2.488585, odo_loss: 1.845298, ine_loss: 0.471017, ref_loss: 0.172270\n",
      "\t[#  720] train_loss: 2.515604, odo_loss: 1.866975, ine_loss: 0.510836, ref_loss: 0.137793\n",
      "\t[#  900] train_loss: 2.575976, odo_loss: 1.878178, ine_loss: 0.540159, ref_loss: 0.157638\n",
      "\ttrain_loss: 2.386973, odo_loss: 1.702458, ine_loss: 0.527762, ref_loss: 0.156752\n",
      "\tval_loss: 2.366735, odo_loss: 1.667160, ine_loss: 0.527401, ref_loss: 0.172174\n",
      "Epoch 140/2000\n",
      "\t[#    0] train_loss: 2.093390, odo_loss: 1.328950, ine_loss: 0.604542, ref_loss: 0.159898\n",
      "\t[#  180] train_loss: 2.331765, odo_loss: 1.576410, ine_loss: 0.582317, ref_loss: 0.173038\n",
      "\t[#  360] train_loss: 2.731412, odo_loss: 2.004053, ine_loss: 0.582210, ref_loss: 0.145149\n",
      "\t[#  540] train_loss: 2.260309, odo_loss: 1.591942, ine_loss: 0.527421, ref_loss: 0.140946\n",
      "\t[#  720] train_loss: 2.344317, odo_loss: 1.710541, ine_loss: 0.451187, ref_loss: 0.182590\n",
      "\t[#  900] train_loss: 2.452903, odo_loss: 1.633287, ine_loss: 0.653491, ref_loss: 0.166124\n",
      "\ttrain_loss: 2.363197, odo_loss: 1.680268, ine_loss: 0.527302, ref_loss: 0.155627\n",
      "\tval_loss: 2.405122, odo_loss: 1.707515, ine_loss: 0.525326, ref_loss: 0.172281\n",
      "Epoch 141/2000\n",
      "\t[#    0] train_loss: 2.161038, odo_loss: 1.405204, ine_loss: 0.595036, ref_loss: 0.160798\n",
      "\t[#  180] train_loss: 2.423458, odo_loss: 1.767725, ine_loss: 0.507445, ref_loss: 0.148288\n",
      "\t[#  360] train_loss: 2.156312, odo_loss: 1.330752, ine_loss: 0.648285, ref_loss: 0.177276\n",
      "\t[#  540] train_loss: 2.379455, odo_loss: 1.658440, ine_loss: 0.538099, ref_loss: 0.182917\n",
      "\t[#  720] train_loss: 6.154733, odo_loss: 5.478466, ine_loss: 0.513855, ref_loss: 0.162412\n",
      "\t[#  900] train_loss: 2.352727, odo_loss: 1.732813, ine_loss: 0.448462, ref_loss: 0.171451\n",
      "\ttrain_loss: 2.377029, odo_loss: 1.695033, ine_loss: 0.526913, ref_loss: 0.155083\n",
      "\tval_loss: 2.542668, odo_loss: 1.847316, ine_loss: 0.522224, ref_loss: 0.173128\n",
      "Epoch 142/2000\n",
      "\t[#    0] train_loss: 2.384464, odo_loss: 1.742052, ine_loss: 0.500120, ref_loss: 0.142291\n",
      "\t[#  180] train_loss: 2.032074, odo_loss: 1.426000, ine_loss: 0.461928, ref_loss: 0.144146\n",
      "\t[#  360] train_loss: 2.401782, odo_loss: 1.703944, ine_loss: 0.488380, ref_loss: 0.209457\n",
      "\t[#  540] train_loss: 2.336231, odo_loss: 1.765277, ine_loss: 0.426373, ref_loss: 0.144580\n",
      "\t[#  720] train_loss: 1.818920, odo_loss: 1.280992, ine_loss: 0.390935, ref_loss: 0.146993\n",
      "\t[#  900] train_loss: 2.680715, odo_loss: 1.891964, ine_loss: 0.640616, ref_loss: 0.148135\n",
      "\ttrain_loss: 2.441879, odo_loss: 1.757943, ine_loss: 0.528339, ref_loss: 0.155596\n",
      "\tval_loss: 2.444472, odo_loss: 1.748306, ine_loss: 0.525541, ref_loss: 0.170625\n",
      "Epoch 143/2000\n",
      "\t[#    0] train_loss: 2.367639, odo_loss: 1.707363, ine_loss: 0.524863, ref_loss: 0.135413\n",
      "\t[#  180] train_loss: 2.437730, odo_loss: 1.765574, ine_loss: 0.508732, ref_loss: 0.163425\n",
      "\t[#  360] train_loss: 2.232321, odo_loss: 1.582462, ine_loss: 0.462845, ref_loss: 0.187013\n",
      "\t[#  540] train_loss: 2.367064, odo_loss: 1.675242, ine_loss: 0.536387, ref_loss: 0.155435\n",
      "\t[#  720] train_loss: 2.129924, odo_loss: 1.481300, ine_loss: 0.503446, ref_loss: 0.145177\n",
      "\t[#  900] train_loss: 8.927900, odo_loss: 8.316002, ine_loss: 0.449693, ref_loss: 0.162205\n",
      "\ttrain_loss: 2.337596, odo_loss: 1.655336, ine_loss: 0.527111, ref_loss: 0.155149\n",
      "\tval_loss: 2.767596, odo_loss: 2.071203, ine_loss: 0.525070, ref_loss: 0.171323\n",
      "Epoch 144/2000\n",
      "\t[#    0] train_loss: 2.214655, odo_loss: 1.461032, ine_loss: 0.618139, ref_loss: 0.135484\n",
      "\t[#  180] train_loss: 2.449019, odo_loss: 1.913738, ine_loss: 0.384514, ref_loss: 0.150767\n",
      "\t[#  360] train_loss: 2.552445, odo_loss: 1.955317, ine_loss: 0.456404, ref_loss: 0.140724\n",
      "\t[#  540] train_loss: 2.583501, odo_loss: 1.861281, ine_loss: 0.539845, ref_loss: 0.182374\n",
      "\t[#  720] train_loss: 2.312693, odo_loss: 1.686088, ine_loss: 0.454408, ref_loss: 0.172196\n",
      "\t[#  900] train_loss: 2.255831, odo_loss: 1.606954, ine_loss: 0.489776, ref_loss: 0.159101\n",
      "\ttrain_loss: 2.421517, odo_loss: 1.740371, ine_loss: 0.525910, ref_loss: 0.155235\n",
      "\tval_loss: 2.329094, odo_loss: 1.634019, ine_loss: 0.522548, ref_loss: 0.172527\n",
      "\t*** Personal Best ***\n",
      "Epoch 145/2000\n",
      "\t[#    0] train_loss: 4.212381, odo_loss: 3.500763, ine_loss: 0.582164, ref_loss: 0.129454\n",
      "\t[#  180] train_loss: 2.320273, odo_loss: 1.609656, ine_loss: 0.551334, ref_loss: 0.159283\n",
      "\t[#  360] train_loss: 2.217244, odo_loss: 1.546138, ine_loss: 0.534198, ref_loss: 0.136908\n",
      "\t[#  540] train_loss: 2.404343, odo_loss: 1.700732, ine_loss: 0.560697, ref_loss: 0.142914\n",
      "\t[#  720] train_loss: 2.293718, odo_loss: 1.638495, ine_loss: 0.502290, ref_loss: 0.152933\n",
      "\t[#  900] train_loss: 2.052813, odo_loss: 1.453589, ine_loss: 0.448095, ref_loss: 0.151128\n",
      "\ttrain_loss: 2.306703, odo_loss: 1.625877, ine_loss: 0.526068, ref_loss: 0.154757\n",
      "\tval_loss: 2.279271, odo_loss: 1.582662, ine_loss: 0.524037, ref_loss: 0.172572\n",
      "\t*** Personal Best ***\n",
      "Epoch 146/2000\n",
      "\t[#    0] train_loss: 2.360293, odo_loss: 1.714587, ine_loss: 0.525710, ref_loss: 0.119996\n",
      "\t[#  180] train_loss: 2.947164, odo_loss: 2.135700, ine_loss: 0.641498, ref_loss: 0.169967\n",
      "\t[#  360] train_loss: 2.473438, odo_loss: 1.666530, ine_loss: 0.660164, ref_loss: 0.146744\n",
      "\t[#  540] train_loss: 2.149248, odo_loss: 1.419408, ine_loss: 0.563225, ref_loss: 0.166614\n",
      "\t[#  720] train_loss: 2.465399, odo_loss: 1.806262, ine_loss: 0.520423, ref_loss: 0.138714\n",
      "\t[#  900] train_loss: 2.696324, odo_loss: 2.011094, ine_loss: 0.534614, ref_loss: 0.150616\n",
      "\ttrain_loss: 2.340043, odo_loss: 1.659034, ine_loss: 0.526380, ref_loss: 0.154630\n",
      "\tval_loss: 2.471286, odo_loss: 1.772117, ine_loss: 0.526209, ref_loss: 0.172960\n",
      "Epoch 147/2000\n",
      "\t[#    0] train_loss: 2.295873, odo_loss: 1.677543, ine_loss: 0.457652, ref_loss: 0.160679\n",
      "\t[#  180] train_loss: 2.435928, odo_loss: 1.747382, ine_loss: 0.533758, ref_loss: 0.154788\n",
      "\t[#  360] train_loss: 2.079503, odo_loss: 1.445636, ine_loss: 0.504694, ref_loss: 0.129174\n",
      "\t[#  540] train_loss: 2.053605, odo_loss: 1.408233, ine_loss: 0.512687, ref_loss: 0.132685\n",
      "\t[#  720] train_loss: 2.420109, odo_loss: 1.580506, ine_loss: 0.649068, ref_loss: 0.190534\n",
      "\t[#  900] train_loss: 2.493285, odo_loss: 1.743509, ine_loss: 0.582890, ref_loss: 0.166886\n",
      "\ttrain_loss: 2.326169, odo_loss: 1.646043, ine_loss: 0.525942, ref_loss: 0.154184\n",
      "\tval_loss: 2.345400, odo_loss: 1.652755, ine_loss: 0.521791, ref_loss: 0.170853\n",
      "Epoch 148/2000\n",
      "\t[#    0] train_loss: 2.267437, odo_loss: 1.397738, ine_loss: 0.682913, ref_loss: 0.186786\n",
      "\t[#  180] train_loss: 2.115192, odo_loss: 1.362442, ine_loss: 0.607181, ref_loss: 0.145569\n",
      "\t[#  360] train_loss: 2.140203, odo_loss: 1.517445, ine_loss: 0.459805, ref_loss: 0.162953\n",
      "\t[#  540] train_loss: 2.163560, odo_loss: 1.467046, ine_loss: 0.529505, ref_loss: 0.167009\n",
      "\t[#  720] train_loss: 2.407763, odo_loss: 1.583447, ine_loss: 0.644604, ref_loss: 0.179712\n",
      "\t[#  900] train_loss: 2.209800, odo_loss: 1.532746, ine_loss: 0.500570, ref_loss: 0.176485\n",
      "\ttrain_loss: 2.294090, odo_loss: 1.615332, ine_loss: 0.524724, ref_loss: 0.154034\n",
      "\tval_loss: 2.366725, odo_loss: 1.676401, ine_loss: 0.521202, ref_loss: 0.169122\n",
      "Epoch 149/2000\n",
      "\t[#    0] train_loss: 2.425827, odo_loss: 1.699619, ine_loss: 0.588697, ref_loss: 0.137510\n",
      "\t[#  180] train_loss: 2.055301, odo_loss: 1.410921, ine_loss: 0.489439, ref_loss: 0.154940\n",
      "\t[#  360] train_loss: 2.651081, odo_loss: 2.020427, ine_loss: 0.482070, ref_loss: 0.148583\n",
      "\t[#  540] train_loss: 2.564617, odo_loss: 1.821007, ine_loss: 0.587660, ref_loss: 0.155949\n",
      "\t[#  720] train_loss: 1.913646, odo_loss: 1.368163, ine_loss: 0.394915, ref_loss: 0.150567\n",
      "\t[#  900] train_loss: 2.476217, odo_loss: 1.689149, ine_loss: 0.598309, ref_loss: 0.188759\n",
      "\ttrain_loss: 2.630370, odo_loss: 1.950704, ine_loss: 0.524303, ref_loss: 0.155363\n",
      "\tval_loss: 2.683647, odo_loss: 1.988697, ine_loss: 0.522198, ref_loss: 0.172752\n",
      "Epoch 150/2000\n",
      "\t[#    0] train_loss: 2.514380, odo_loss: 1.804098, ine_loss: 0.557100, ref_loss: 0.153182\n",
      "\t[#  180] train_loss: 2.585248, odo_loss: 1.806144, ine_loss: 0.637142, ref_loss: 0.141961\n",
      "\t[#  360] train_loss: 2.700351, odo_loss: 1.998097, ine_loss: 0.545026, ref_loss: 0.157228\n",
      "\t[#  540] train_loss: 2.020835, odo_loss: 1.425552, ine_loss: 0.436133, ref_loss: 0.159150\n",
      "\t[#  720] train_loss: 2.265681, odo_loss: 1.511971, ine_loss: 0.598881, ref_loss: 0.154829\n",
      "\t[#  900] train_loss: 2.184161, odo_loss: 1.597738, ine_loss: 0.454191, ref_loss: 0.132232\n",
      "\ttrain_loss: 2.408301, odo_loss: 1.729853, ine_loss: 0.523880, ref_loss: 0.154568\n",
      "\tval_loss: 2.418426, odo_loss: 1.724345, ine_loss: 0.520446, ref_loss: 0.173635\n",
      "Epoch 151/2000\n",
      "\t[#    0] train_loss: 2.414569, odo_loss: 1.620399, ine_loss: 0.631679, ref_loss: 0.162491\n",
      "\t[#  180] train_loss: 2.265169, odo_loss: 1.692011, ine_loss: 0.437542, ref_loss: 0.135617\n",
      "\t[#  360] train_loss: 2.047353, odo_loss: 1.408826, ine_loss: 0.472382, ref_loss: 0.166145\n",
      "\t[#  540] train_loss: 2.493058, odo_loss: 1.749998, ine_loss: 0.555904, ref_loss: 0.187156\n",
      "\t[#  720] train_loss: 1.937928, odo_loss: 1.365542, ine_loss: 0.438934, ref_loss: 0.133453\n",
      "\t[#  900] train_loss: 2.338266, odo_loss: 1.629690, ine_loss: 0.569348, ref_loss: 0.139227\n",
      "\ttrain_loss: 2.347844, odo_loss: 1.669773, ine_loss: 0.523799, ref_loss: 0.154272\n",
      "\tval_loss: 2.447092, odo_loss: 1.750641, ine_loss: 0.524521, ref_loss: 0.171930\n",
      "Epoch 152/2000\n",
      "\t[#    0] train_loss: 2.361466, odo_loss: 1.617242, ine_loss: 0.597620, ref_loss: 0.146603\n",
      "\t[#  180] train_loss: 2.035676, odo_loss: 1.391537, ine_loss: 0.504745, ref_loss: 0.139394\n",
      "\t[#  360] train_loss: 2.052724, odo_loss: 1.424003, ine_loss: 0.465754, ref_loss: 0.162968\n",
      "\t[#  540] train_loss: 2.241442, odo_loss: 1.607739, ine_loss: 0.494924, ref_loss: 0.138779\n",
      "\t[#  720] train_loss: 2.710573, odo_loss: 2.002107, ine_loss: 0.551817, ref_loss: 0.156649\n",
      "\t[#  900] train_loss: 2.109416, odo_loss: 1.481855, ine_loss: 0.444311, ref_loss: 0.183250\n",
      "\ttrain_loss: 2.291755, odo_loss: 1.613852, ine_loss: 0.524139, ref_loss: 0.153765\n",
      "\tval_loss: 2.242440, odo_loss: 1.547262, ine_loss: 0.522926, ref_loss: 0.172251\n",
      "\t*** Personal Best ***\n",
      "Epoch 153/2000\n",
      "\t[#    0] train_loss: 2.097687, odo_loss: 1.419310, ine_loss: 0.541210, ref_loss: 0.137167\n",
      "\t[#  180] train_loss: 2.059354, odo_loss: 1.305283, ine_loss: 0.561216, ref_loss: 0.192855\n",
      "\t[#  360] train_loss: 2.659714, odo_loss: 1.969492, ine_loss: 0.524766, ref_loss: 0.165456\n",
      "\t[#  540] train_loss: 2.442112, odo_loss: 1.676262, ine_loss: 0.608180, ref_loss: 0.157671\n",
      "\t[#  720] train_loss: 2.219795, odo_loss: 1.512083, ine_loss: 0.532498, ref_loss: 0.175214\n",
      "\t[#  900] train_loss: 2.508364, odo_loss: 1.901555, ine_loss: 0.460237, ref_loss: 0.146572\n",
      "\ttrain_loss: 2.360572, odo_loss: 1.683658, ine_loss: 0.523027, ref_loss: 0.153887\n",
      "\tval_loss: 2.586445, odo_loss: 1.894672, ine_loss: 0.519277, ref_loss: 0.172497\n",
      "Epoch 154/2000\n",
      "\t[#    0] train_loss: 2.225405, odo_loss: 1.460860, ine_loss: 0.601772, ref_loss: 0.162772\n",
      "\t[#  180] train_loss: 2.041641, odo_loss: 1.375147, ine_loss: 0.505003, ref_loss: 0.161490\n",
      "\t[#  360] train_loss: 1.801400, odo_loss: 1.229928, ine_loss: 0.421333, ref_loss: 0.150140\n",
      "\t[#  540] train_loss: 2.009810, odo_loss: 1.368787, ine_loss: 0.485831, ref_loss: 0.155192\n",
      "\t[#  720] train_loss: 2.081308, odo_loss: 1.500603, ine_loss: 0.445924, ref_loss: 0.134781\n",
      "\t[#  900] train_loss: 2.069871, odo_loss: 1.439699, ine_loss: 0.504811, ref_loss: 0.125361\n",
      "\ttrain_loss: 2.409949, odo_loss: 1.733710, ine_loss: 0.521880, ref_loss: 0.154359\n",
      "\tval_loss: 2.284218, odo_loss: 1.591557, ine_loss: 0.520081, ref_loss: 0.172580\n",
      "Epoch 155/2000\n",
      "\t[#    0] train_loss: 2.471642, odo_loss: 1.877655, ine_loss: 0.446808, ref_loss: 0.147179\n",
      "\t[#  180] train_loss: 2.320264, odo_loss: 1.586011, ine_loss: 0.586925, ref_loss: 0.147328\n",
      "\t[#  360] train_loss: 2.241468, odo_loss: 1.549381, ine_loss: 0.548764, ref_loss: 0.143323\n",
      "\t[#  540] train_loss: 2.220926, odo_loss: 1.544558, ine_loss: 0.508934, ref_loss: 0.167434\n",
      "\t[#  720] train_loss: 2.413803, odo_loss: 1.702237, ine_loss: 0.586270, ref_loss: 0.125296\n",
      "\t[#  900] train_loss: 2.285164, odo_loss: 1.578948, ine_loss: 0.551435, ref_loss: 0.154781\n",
      "\ttrain_loss: 2.305805, odo_loss: 1.629901, ine_loss: 0.522538, ref_loss: 0.153366\n",
      "\tval_loss: 2.332852, odo_loss: 1.638891, ine_loss: 0.522644, ref_loss: 0.171318\n",
      "Epoch 156/2000\n",
      "\t[#    0] train_loss: 2.247417, odo_loss: 1.570842, ine_loss: 0.515522, ref_loss: 0.161054\n",
      "\t[#  180] train_loss: 1.956585, odo_loss: 1.388894, ine_loss: 0.409470, ref_loss: 0.158221\n",
      "\t[#  360] train_loss: 2.038647, odo_loss: 1.445087, ine_loss: 0.457224, ref_loss: 0.136335\n",
      "\t[#  540] train_loss: 2.017896, odo_loss: 1.378487, ine_loss: 0.476435, ref_loss: 0.162974\n",
      "\t[#  720] train_loss: 2.056110, odo_loss: 1.545817, ine_loss: 0.383154, ref_loss: 0.127139\n",
      "\t[#  900] train_loss: 2.068743, odo_loss: 1.422514, ine_loss: 0.497229, ref_loss: 0.149001\n",
      "\ttrain_loss: 2.257942, odo_loss: 1.581832, ine_loss: 0.523040, ref_loss: 0.153070\n",
      "\tval_loss: 2.278140, odo_loss: 1.587934, ine_loss: 0.518602, ref_loss: 0.171605\n",
      "Epoch 157/2000\n",
      "\t[#    0] train_loss: 2.402443, odo_loss: 1.752432, ine_loss: 0.477291, ref_loss: 0.172720\n",
      "\t[#  180] train_loss: 2.366059, odo_loss: 1.529974, ine_loss: 0.658129, ref_loss: 0.177957\n",
      "\t[#  360] train_loss: 2.173916, odo_loss: 1.520868, ine_loss: 0.501875, ref_loss: 0.151172\n",
      "\t[#  540] train_loss: 2.252174, odo_loss: 1.532892, ine_loss: 0.520598, ref_loss: 0.198684\n",
      "\t[#  720] train_loss: 2.301218, odo_loss: 1.538451, ine_loss: 0.584300, ref_loss: 0.178466\n",
      "\t[#  900] train_loss: 2.258937, odo_loss: 1.644704, ine_loss: 0.489290, ref_loss: 0.124943\n",
      "\ttrain_loss: 2.253560, odo_loss: 1.578742, ine_loss: 0.522043, ref_loss: 0.152775\n",
      "\tval_loss: 2.236460, odo_loss: 1.547163, ine_loss: 0.518990, ref_loss: 0.170307\n",
      "\t*** Personal Best ***\n",
      "Epoch 158/2000\n",
      "\t[#    0] train_loss: 2.365628, odo_loss: 1.762691, ine_loss: 0.473531, ref_loss: 0.129406\n",
      "\t[#  180] train_loss: 2.051238, odo_loss: 1.364549, ine_loss: 0.545997, ref_loss: 0.140692\n",
      "\t[#  360] train_loss: 2.291693, odo_loss: 1.595474, ine_loss: 0.529552, ref_loss: 0.166667\n",
      "\t[#  540] train_loss: 2.925859, odo_loss: 2.195552, ine_loss: 0.549606, ref_loss: 0.180701\n",
      "\t[#  720] train_loss: 2.041916, odo_loss: 1.413497, ine_loss: 0.479502, ref_loss: 0.148917\n",
      "\t[#  900] train_loss: 2.467190, odo_loss: 1.702480, ine_loss: 0.616450, ref_loss: 0.148260\n",
      "\ttrain_loss: 2.248934, odo_loss: 1.574809, ine_loss: 0.521425, ref_loss: 0.152700\n",
      "\tval_loss: 2.303345, odo_loss: 1.613675, ine_loss: 0.517522, ref_loss: 0.172147\n",
      "Epoch 159/2000\n",
      "\t[#    0] train_loss: 2.294818, odo_loss: 1.604513, ine_loss: 0.551004, ref_loss: 0.139301\n",
      "\t[#  180] train_loss: 2.669291, odo_loss: 1.882576, ine_loss: 0.644094, ref_loss: 0.142621\n",
      "\t[#  360] train_loss: 3.238990, odo_loss: 2.561706, ine_loss: 0.552204, ref_loss: 0.125079\n",
      "\t[#  540] train_loss: 2.766617, odo_loss: 1.927818, ine_loss: 0.647528, ref_loss: 0.191270\n",
      "\t[#  720] train_loss: 2.744225, odo_loss: 2.102398, ine_loss: 0.517712, ref_loss: 0.124115\n",
      "\t[#  900] train_loss: 2.962947, odo_loss: 2.287278, ine_loss: 0.507532, ref_loss: 0.168137\n",
      "\ttrain_loss: 2.462288, odo_loss: 1.788032, ine_loss: 0.521313, ref_loss: 0.152943\n",
      "\tval_loss: 2.729053, odo_loss: 2.037724, ine_loss: 0.518644, ref_loss: 0.172684\n",
      "Epoch 160/2000\n",
      "\t[#    0] train_loss: 2.208226, odo_loss: 1.640544, ine_loss: 0.426648, ref_loss: 0.141034\n",
      "\t[#  180] train_loss: 2.000405, odo_loss: 1.419433, ine_loss: 0.430877, ref_loss: 0.150095\n",
      "\t[#  360] train_loss: 2.249780, odo_loss: 1.618146, ine_loss: 0.499372, ref_loss: 0.132262\n",
      "\t[#  540] train_loss: 2.322414, odo_loss: 1.665582, ine_loss: 0.486862, ref_loss: 0.169970\n",
      "\t[#  720] train_loss: 2.324557, odo_loss: 1.686819, ine_loss: 0.494979, ref_loss: 0.142759\n",
      "\t[#  900] train_loss: 2.292491, odo_loss: 1.729748, ine_loss: 0.407143, ref_loss: 0.155601\n",
      "\ttrain_loss: 2.328748, odo_loss: 1.654507, ine_loss: 0.521346, ref_loss: 0.152895\n",
      "\tval_loss: 2.401098, odo_loss: 1.709180, ine_loss: 0.520224, ref_loss: 0.171694\n",
      "Epoch 161/2000\n",
      "\t[#    0] train_loss: 2.845440, odo_loss: 2.041366, ine_loss: 0.654233, ref_loss: 0.149841\n",
      "\t[#  180] train_loss: 2.169161, odo_loss: 1.438745, ine_loss: 0.578888, ref_loss: 0.151528\n",
      "\t[#  360] train_loss: 2.009528, odo_loss: 1.282751, ine_loss: 0.557526, ref_loss: 0.169251\n",
      "\t[#  540] train_loss: 2.242019, odo_loss: 1.624813, ine_loss: 0.465544, ref_loss: 0.151663\n",
      "\t[#  720] train_loss: 2.174013, odo_loss: 1.543449, ine_loss: 0.451419, ref_loss: 0.179144\n",
      "\t[#  900] train_loss: 2.301064, odo_loss: 1.644660, ine_loss: 0.493325, ref_loss: 0.163078\n",
      "\ttrain_loss: 2.276328, odo_loss: 1.603281, ine_loss: 0.520389, ref_loss: 0.152658\n",
      "\tval_loss: 2.397040, odo_loss: 1.713724, ine_loss: 0.512077, ref_loss: 0.171239\n",
      "Epoch 162/2000\n",
      "\t[#    0] train_loss: 2.312366, odo_loss: 1.574461, ine_loss: 0.594917, ref_loss: 0.142988\n",
      "\t[#  180] train_loss: 2.255030, odo_loss: 1.525405, ine_loss: 0.528699, ref_loss: 0.200926\n",
      "\t[#  360] train_loss: 2.607583, odo_loss: 1.900909, ine_loss: 0.553497, ref_loss: 0.153177\n",
      "\t[#  540] train_loss: 2.225003, odo_loss: 1.577401, ine_loss: 0.484297, ref_loss: 0.163305\n",
      "\t[#  720] train_loss: 2.323941, odo_loss: 1.786778, ine_loss: 0.401577, ref_loss: 0.135586\n",
      "\t[#  900] train_loss: 2.316967, odo_loss: 1.692045, ine_loss: 0.482098, ref_loss: 0.142824\n",
      "\ttrain_loss: 2.273581, odo_loss: 1.601630, ine_loss: 0.519801, ref_loss: 0.152150\n",
      "\tval_loss: 2.449790, odo_loss: 1.766431, ine_loss: 0.512352, ref_loss: 0.171006\n",
      "Epoch 163/2000\n",
      "\t[#    0] train_loss: 2.284926, odo_loss: 1.727079, ine_loss: 0.417648, ref_loss: 0.140200\n",
      "\t[#  180] train_loss: 1.980829, odo_loss: 1.334740, ine_loss: 0.496284, ref_loss: 0.149805\n",
      "\t[#  360] train_loss: 2.351758, odo_loss: 1.767425, ine_loss: 0.414774, ref_loss: 0.169560\n",
      "\t[#  540] train_loss: 2.091927, odo_loss: 1.341445, ine_loss: 0.591330, ref_loss: 0.159152\n",
      "\t[#  720] train_loss: 2.317992, odo_loss: 1.609690, ine_loss: 0.537522, ref_loss: 0.170780\n",
      "\t[#  900] train_loss: 2.390065, odo_loss: 1.663343, ine_loss: 0.583356, ref_loss: 0.143366\n",
      "\ttrain_loss: 2.309042, odo_loss: 1.638369, ine_loss: 0.518133, ref_loss: 0.152540\n",
      "\tval_loss: 2.271111, odo_loss: 1.585669, ine_loss: 0.513609, ref_loss: 0.171833\n",
      "Epoch 164/2000\n",
      "\t[#    0] train_loss: 2.037948, odo_loss: 1.430171, ine_loss: 0.479386, ref_loss: 0.128390\n",
      "\t[#  180] train_loss: 2.451795, odo_loss: 1.772657, ine_loss: 0.514258, ref_loss: 0.164879\n",
      "\t[#  360] train_loss: 2.164460, odo_loss: 1.526861, ine_loss: 0.512757, ref_loss: 0.124842\n",
      "\t[#  540] train_loss: 2.038291, odo_loss: 1.484114, ine_loss: 0.393767, ref_loss: 0.160411\n",
      "\t[#  720] train_loss: 2.280828, odo_loss: 1.592276, ine_loss: 0.510614, ref_loss: 0.177938\n",
      "\t[#  900] train_loss: 2.042182, odo_loss: 1.359988, ine_loss: 0.546611, ref_loss: 0.135583\n",
      "\ttrain_loss: 2.344046, odo_loss: 1.674670, ine_loss: 0.516530, ref_loss: 0.152846\n",
      "\tval_loss: 2.399500, odo_loss: 1.710095, ine_loss: 0.517759, ref_loss: 0.171645\n",
      "Epoch 165/2000\n",
      "\t[#    0] train_loss: 2.628117, odo_loss: 1.896832, ine_loss: 0.581857, ref_loss: 0.149428\n",
      "\t[#  180] train_loss: 2.207589, odo_loss: 1.563463, ine_loss: 0.497614, ref_loss: 0.146512\n",
      "\t[#  360] train_loss: 2.153492, odo_loss: 1.487782, ine_loss: 0.525362, ref_loss: 0.140348\n",
      "\t[#  540] train_loss: 2.396209, odo_loss: 1.768180, ine_loss: 0.478743, ref_loss: 0.149286\n",
      "\t[#  720] train_loss: 2.179716, odo_loss: 1.539129, ine_loss: 0.461214, ref_loss: 0.179372\n",
      "\t[#  900] train_loss: 2.640631, odo_loss: 1.918343, ine_loss: 0.573616, ref_loss: 0.148672\n",
      "\ttrain_loss: 2.262343, odo_loss: 1.591543, ine_loss: 0.518174, ref_loss: 0.152627\n",
      "\tval_loss: 2.282095, odo_loss: 1.598171, ine_loss: 0.514824, ref_loss: 0.169100\n",
      "Epoch 166/2000\n",
      "\t[#    0] train_loss: 2.635255, odo_loss: 1.829234, ine_loss: 0.645306, ref_loss: 0.160715\n",
      "\t[#  180] train_loss: 2.221081, odo_loss: 1.592842, ine_loss: 0.486361, ref_loss: 0.141878\n",
      "\t[#  360] train_loss: 2.181295, odo_loss: 1.427572, ine_loss: 0.565354, ref_loss: 0.188369\n",
      "\t[#  540] train_loss: 2.530285, odo_loss: 1.909904, ine_loss: 0.492990, ref_loss: 0.127392\n",
      "\t[#  720] train_loss: 2.523822, odo_loss: 1.830018, ine_loss: 0.529824, ref_loss: 0.163981\n",
      "\t[#  900] train_loss: 2.519525, odo_loss: 1.831501, ine_loss: 0.535232, ref_loss: 0.152792\n",
      "\ttrain_loss: 2.242198, odo_loss: 1.571242, ine_loss: 0.519098, ref_loss: 0.151858\n",
      "\tval_loss: 2.235385, odo_loss: 1.552657, ine_loss: 0.514740, ref_loss: 0.167988\n",
      "Epoch 167/2000\n",
      "\t[#    0] train_loss: 2.421518, odo_loss: 1.828629, ine_loss: 0.475979, ref_loss: 0.116910\n",
      "\t[#  180] train_loss: 2.030860, odo_loss: 1.399978, ine_loss: 0.478517, ref_loss: 0.152365\n",
      "\t[#  360] train_loss: 1.905112, odo_loss: 1.213246, ine_loss: 0.513765, ref_loss: 0.178102\n",
      "\t[#  540] train_loss: 2.271757, odo_loss: 1.488896, ine_loss: 0.612843, ref_loss: 0.170018\n",
      "\t[#  720] train_loss: 1.861778, odo_loss: 1.292114, ine_loss: 0.422632, ref_loss: 0.147032\n",
      "\t[#  900] train_loss: 2.282433, odo_loss: 1.660939, ine_loss: 0.482893, ref_loss: 0.138602\n",
      "\ttrain_loss: 2.270694, odo_loss: 1.601359, ine_loss: 0.516920, ref_loss: 0.152415\n",
      "\tval_loss: 3.796853, odo_loss: 3.115709, ine_loss: 0.510494, ref_loss: 0.170650\n",
      "Epoch 168/2000\n",
      "\t[#    0] train_loss: 2.230661, odo_loss: 1.581787, ine_loss: 0.477443, ref_loss: 0.171431\n",
      "\t[#  180] train_loss: 2.223475, odo_loss: 1.568598, ine_loss: 0.489700, ref_loss: 0.165177\n",
      "\t[#  360] train_loss: 2.433019, odo_loss: 1.709651, ine_loss: 0.539834, ref_loss: 0.183534\n",
      "\t[#  540] train_loss: 2.386369, odo_loss: 1.575966, ine_loss: 0.611536, ref_loss: 0.198868\n",
      "\t[#  720] train_loss: 2.621916, odo_loss: 1.875782, ine_loss: 0.595403, ref_loss: 0.150730\n",
      "\t[#  900] train_loss: 2.504545, odo_loss: 1.849360, ine_loss: 0.514015, ref_loss: 0.141169\n",
      "\ttrain_loss: 2.464459, odo_loss: 1.794878, ine_loss: 0.516257, ref_loss: 0.153324\n",
      "\tval_loss: 2.329033, odo_loss: 1.647405, ine_loss: 0.510591, ref_loss: 0.171037\n",
      "Epoch 169/2000\n",
      "\t[#    0] train_loss: 2.126060, odo_loss: 1.570042, ine_loss: 0.427542, ref_loss: 0.128475\n",
      "\t[#  180] train_loss: 2.452224, odo_loss: 1.811864, ine_loss: 0.504408, ref_loss: 0.135953\n",
      "\t[#  360] train_loss: 1.849006, odo_loss: 1.337790, ine_loss: 0.371999, ref_loss: 0.139217\n",
      "\t[#  540] train_loss: 2.071845, odo_loss: 1.514968, ine_loss: 0.399192, ref_loss: 0.157684\n",
      "\t[#  720] train_loss: 2.526255, odo_loss: 1.916256, ine_loss: 0.473279, ref_loss: 0.136720\n",
      "\t[#  900] train_loss: 2.377265, odo_loss: 1.742508, ine_loss: 0.474238, ref_loss: 0.160519\n",
      "\ttrain_loss: 2.305143, odo_loss: 1.637434, ine_loss: 0.515007, ref_loss: 0.152701\n",
      "\tval_loss: 2.341972, odo_loss: 1.657165, ine_loss: 0.513320, ref_loss: 0.171487\n",
      "Epoch 170/2000\n",
      "\t[#    0] train_loss: 2.216598, odo_loss: 1.596009, ine_loss: 0.466216, ref_loss: 0.154373\n",
      "\t[#  180] train_loss: 1.947225, odo_loss: 1.355593, ine_loss: 0.444556, ref_loss: 0.147077\n",
      "\t[#  360] train_loss: 2.255690, odo_loss: 1.573548, ine_loss: 0.529623, ref_loss: 0.152519\n",
      "\t[#  540] train_loss: 2.430310, odo_loss: 1.794696, ine_loss: 0.490212, ref_loss: 0.145402\n",
      "\t[#  720] train_loss: 2.425705, odo_loss: 1.742997, ine_loss: 0.553840, ref_loss: 0.128867\n",
      "\t[#  900] train_loss: 2.326735, odo_loss: 1.667480, ine_loss: 0.516328, ref_loss: 0.142927\n",
      "\ttrain_loss: 2.308830, odo_loss: 1.639802, ine_loss: 0.515988, ref_loss: 0.153040\n",
      "\tval_loss: 2.381016, odo_loss: 1.696477, ine_loss: 0.514544, ref_loss: 0.169995\n",
      "Epoch 171/2000\n",
      "\t[#    0] train_loss: 2.462456, odo_loss: 1.607936, ine_loss: 0.693077, ref_loss: 0.161443\n",
      "\t[#  180] train_loss: 2.447362, odo_loss: 1.711096, ine_loss: 0.546324, ref_loss: 0.189943\n",
      "\t[#  360] train_loss: 2.035050, odo_loss: 1.436696, ine_loss: 0.439982, ref_loss: 0.158373\n",
      "\t[#  540] train_loss: 2.047223, odo_loss: 1.493622, ine_loss: 0.402080, ref_loss: 0.151521\n",
      "\t[#  720] train_loss: 2.229747, odo_loss: 1.585034, ine_loss: 0.515950, ref_loss: 0.128763\n",
      "\t[#  900] train_loss: 2.799069, odo_loss: 1.998349, ine_loss: 0.637148, ref_loss: 0.163571\n",
      "\ttrain_loss: 2.243211, odo_loss: 1.575643, ine_loss: 0.515166, ref_loss: 0.152402\n",
      "\tval_loss: 2.336001, odo_loss: 1.654442, ine_loss: 0.511880, ref_loss: 0.169678\n",
      "Epoch 172/2000\n",
      "\t[#    0] train_loss: 2.485271, odo_loss: 1.836527, ine_loss: 0.489399, ref_loss: 0.159345\n",
      "\t[#  180] train_loss: 2.065808, odo_loss: 1.414338, ine_loss: 0.505169, ref_loss: 0.146301\n",
      "\t[#  360] train_loss: 2.577984, odo_loss: 1.880338, ine_loss: 0.534422, ref_loss: 0.163224\n",
      "\t[#  540] train_loss: 2.387190, odo_loss: 1.816827, ine_loss: 0.442310, ref_loss: 0.128053\n",
      "\t[#  720] train_loss: 1.662509, odo_loss: 1.103364, ine_loss: 0.417480, ref_loss: 0.141665\n",
      "\t[#  900] train_loss: 2.750866, odo_loss: 2.058712, ine_loss: 0.516886, ref_loss: 0.175267\n",
      "\ttrain_loss: 2.257261, odo_loss: 1.589489, ine_loss: 0.515512, ref_loss: 0.152260\n",
      "\tval_loss: 2.470345, odo_loss: 1.784794, ine_loss: 0.513189, ref_loss: 0.172362\n",
      "Epoch 173/2000\n",
      "\t[#    0] train_loss: 2.105388, odo_loss: 1.544529, ine_loss: 0.427018, ref_loss: 0.133841\n",
      "\t[#  180] train_loss: 2.063159, odo_loss: 1.419081, ine_loss: 0.489615, ref_loss: 0.154462\n",
      "\t[#  360] train_loss: 2.364977, odo_loss: 1.675624, ine_loss: 0.536471, ref_loss: 0.152882\n",
      "\t[#  540] train_loss: 2.141905, odo_loss: 1.524769, ine_loss: 0.474534, ref_loss: 0.142602\n",
      "\t[#  720] train_loss: 2.308856, odo_loss: 1.558891, ine_loss: 0.588905, ref_loss: 0.161060\n",
      "\t[#  900] train_loss: 2.546058, odo_loss: 1.916254, ine_loss: 0.455373, ref_loss: 0.174431\n",
      "\ttrain_loss: 2.272813, odo_loss: 1.604327, ine_loss: 0.515861, ref_loss: 0.152625\n",
      "\tval_loss: 2.224267, odo_loss: 1.541983, ine_loss: 0.509516, ref_loss: 0.172768\n",
      "\t*** Personal Best ***\n",
      "Epoch 174/2000\n",
      "\t[#    0] train_loss: 2.242508, odo_loss: 1.467996, ine_loss: 0.603216, ref_loss: 0.171296\n",
      "\t[#  180] train_loss: 2.164462, odo_loss: 1.609500, ine_loss: 0.406965, ref_loss: 0.147997\n",
      "\t[#  360] train_loss: 1.955020, odo_loss: 1.212872, ine_loss: 0.606970, ref_loss: 0.135178\n",
      "\t[#  540] train_loss: 2.328387, odo_loss: 1.628281, ine_loss: 0.554621, ref_loss: 0.145486\n",
      "\t[#  720] train_loss: 2.373520, odo_loss: 1.684531, ine_loss: 0.541036, ref_loss: 0.147952\n",
      "\t[#  900] train_loss: 2.245779, odo_loss: 1.604180, ine_loss: 0.477109, ref_loss: 0.164490\n",
      "\ttrain_loss: 2.210653, odo_loss: 1.542876, ine_loss: 0.515432, ref_loss: 0.152345\n",
      "\tval_loss: 2.223349, odo_loss: 1.537281, ine_loss: 0.514006, ref_loss: 0.172062\n",
      "\t*** Personal Best ***\n",
      "Epoch 175/2000\n",
      "\t[#    0] train_loss: 2.141470, odo_loss: 1.468165, ine_loss: 0.515365, ref_loss: 0.157941\n",
      "\t[#  180] train_loss: 2.082280, odo_loss: 1.422015, ine_loss: 0.503673, ref_loss: 0.156592\n",
      "\t[#  360] train_loss: 2.202920, odo_loss: 1.543282, ine_loss: 0.522900, ref_loss: 0.136739\n",
      "\t[#  540] train_loss: 1.876580, odo_loss: 1.246105, ine_loss: 0.479244, ref_loss: 0.151231\n",
      "\t[#  720] train_loss: 2.187060, odo_loss: 1.447605, ine_loss: 0.589784, ref_loss: 0.149670\n",
      "\t[#  900] train_loss: 2.246952, odo_loss: 1.686117, ine_loss: 0.432871, ref_loss: 0.127963\n",
      "\ttrain_loss: 2.301095, odo_loss: 1.634883, ine_loss: 0.514312, ref_loss: 0.151900\n",
      "\tval_loss: 2.415928, odo_loss: 1.735094, ine_loss: 0.509517, ref_loss: 0.171316\n",
      "Epoch 176/2000\n",
      "\t[#    0] train_loss: 2.338973, odo_loss: 1.498681, ine_loss: 0.680634, ref_loss: 0.159657\n",
      "\t[#  180] train_loss: 2.862987, odo_loss: 2.227783, ine_loss: 0.468450, ref_loss: 0.166754\n",
      "\t[#  360] train_loss: 2.274507, odo_loss: 1.464115, ine_loss: 0.666946, ref_loss: 0.143445\n",
      "\t[#  540] train_loss: 2.472331, odo_loss: 1.732584, ine_loss: 0.570255, ref_loss: 0.169491\n",
      "\t[#  720] train_loss: 2.595604, odo_loss: 1.856450, ine_loss: 0.597817, ref_loss: 0.141336\n",
      "\t[#  900] train_loss: 2.681567, odo_loss: 1.974463, ine_loss: 0.534916, ref_loss: 0.172188\n",
      "\ttrain_loss: 2.245551, odo_loss: 1.579138, ine_loss: 0.514076, ref_loss: 0.152336\n",
      "\tval_loss: 2.306775, odo_loss: 1.620389, ine_loss: 0.515001, ref_loss: 0.171386\n",
      "Epoch 177/2000\n",
      "\t[#    0] train_loss: 2.289548, odo_loss: 1.562772, ine_loss: 0.574048, ref_loss: 0.152728\n",
      "\t[#  180] train_loss: 2.179782, odo_loss: 1.572578, ine_loss: 0.457259, ref_loss: 0.149945\n",
      "\t[#  360] train_loss: 1.946253, odo_loss: 1.349995, ine_loss: 0.443478, ref_loss: 0.152780\n",
      "\t[#  540] train_loss: 2.462577, odo_loss: 1.793251, ine_loss: 0.529202, ref_loss: 0.140125\n",
      "\t[#  720] train_loss: 2.325583, odo_loss: 1.598602, ine_loss: 0.604826, ref_loss: 0.122155\n",
      "\t[#  900] train_loss: 2.564742, odo_loss: 1.869164, ine_loss: 0.565415, ref_loss: 0.130163\n",
      "\ttrain_loss: 2.293937, odo_loss: 1.627475, ine_loss: 0.514783, ref_loss: 0.151678\n",
      "\tval_loss: 2.404938, odo_loss: 1.721041, ine_loss: 0.511676, ref_loss: 0.172221\n",
      "Epoch 178/2000\n",
      "\t[#    0] train_loss: 4.361572, odo_loss: 3.667782, ine_loss: 0.544825, ref_loss: 0.148966\n",
      "\t[#  180] train_loss: 2.293590, odo_loss: 1.650002, ine_loss: 0.500850, ref_loss: 0.142738\n",
      "\t[#  360] train_loss: 1.817203, odo_loss: 1.094824, ine_loss: 0.576587, ref_loss: 0.145792\n",
      "\t[#  540] train_loss: 2.142740, odo_loss: 1.513956, ine_loss: 0.479927, ref_loss: 0.148857\n",
      "\t[#  720] train_loss: 2.237677, odo_loss: 1.534101, ine_loss: 0.560183, ref_loss: 0.143393\n",
      "\t[#  900] train_loss: 2.077396, odo_loss: 1.472145, ine_loss: 0.452600, ref_loss: 0.152652\n",
      "\ttrain_loss: 2.383007, odo_loss: 1.717592, ine_loss: 0.512852, ref_loss: 0.152564\n",
      "\tval_loss: 2.268147, odo_loss: 1.592488, ine_loss: 0.504633, ref_loss: 0.171026\n",
      "Epoch 179/2000\n",
      "\t[#    0] train_loss: 2.071564, odo_loss: 1.409859, ine_loss: 0.517798, ref_loss: 0.143907\n",
      "\t[#  180] train_loss: 2.003487, odo_loss: 1.348824, ine_loss: 0.500174, ref_loss: 0.154489\n",
      "\t[#  360] train_loss: 2.405919, odo_loss: 1.696228, ine_loss: 0.559710, ref_loss: 0.149982\n",
      "\t[#  540] train_loss: 2.161677, odo_loss: 1.517832, ine_loss: 0.505872, ref_loss: 0.137974\n",
      "\t[#  720] train_loss: 2.373638, odo_loss: 1.703237, ine_loss: 0.518641, ref_loss: 0.151761\n",
      "\t[#  900] train_loss: 2.520981, odo_loss: 1.814255, ine_loss: 0.546317, ref_loss: 0.160409\n",
      "\ttrain_loss: 2.207968, odo_loss: 1.543549, ine_loss: 0.512616, ref_loss: 0.151803\n",
      "\tval_loss: 2.261171, odo_loss: 1.579997, ine_loss: 0.508859, ref_loss: 0.172315\n",
      "Epoch 180/2000\n",
      "\t[#    0] train_loss: 2.273892, odo_loss: 1.536117, ine_loss: 0.575874, ref_loss: 0.161902\n",
      "\t[#  180] train_loss: 2.367232, odo_loss: 1.511796, ine_loss: 0.670199, ref_loss: 0.185237\n",
      "\t[#  360] train_loss: 1.936869, odo_loss: 1.350337, ine_loss: 0.448812, ref_loss: 0.137720\n",
      "\t[#  540] train_loss: 2.354913, odo_loss: 1.729761, ine_loss: 0.480183, ref_loss: 0.144969\n",
      "\t[#  720] train_loss: 1.853423, odo_loss: 1.215046, ine_loss: 0.493963, ref_loss: 0.144415\n",
      "\t[#  900] train_loss: 2.277968, odo_loss: 1.448122, ine_loss: 0.668734, ref_loss: 0.161112\n",
      "\ttrain_loss: 2.182302, odo_loss: 1.516558, ine_loss: 0.513673, ref_loss: 0.152071\n",
      "\tval_loss: 2.217020, odo_loss: 1.537116, ine_loss: 0.508365, ref_loss: 0.171538\n",
      "\t*** Personal Best ***\n",
      "Epoch 181/2000\n",
      "\t[#    0] train_loss: 2.249251, odo_loss: 1.616022, ine_loss: 0.470191, ref_loss: 0.163039\n",
      "\t[#  180] train_loss: 2.108510, odo_loss: 1.430022, ine_loss: 0.540229, ref_loss: 0.138259\n",
      "\t[#  360] train_loss: 2.299214, odo_loss: 1.664114, ine_loss: 0.474534, ref_loss: 0.160566\n",
      "\t[#  540] train_loss: 2.337992, odo_loss: 1.712179, ine_loss: 0.480837, ref_loss: 0.144976\n",
      "\t[#  720] train_loss: 2.412184, odo_loss: 1.736900, ine_loss: 0.529660, ref_loss: 0.145624\n",
      "\t[#  900] train_loss: 2.813136, odo_loss: 2.061718, ine_loss: 0.580063, ref_loss: 0.171354\n",
      "\ttrain_loss: 2.185824, odo_loss: 1.521538, ine_loss: 0.513013, ref_loss: 0.151273\n",
      "\tval_loss: 2.232065, odo_loss: 1.548541, ine_loss: 0.512822, ref_loss: 0.170702\n",
      "Epoch 182/2000\n",
      "\t[#    0] train_loss: 3.464357, odo_loss: 2.755643, ine_loss: 0.548661, ref_loss: 0.160054\n",
      "\t[#  180] train_loss: 2.224917, odo_loss: 1.570179, ine_loss: 0.519365, ref_loss: 0.135373\n",
      "\t[#  360] train_loss: 2.120139, odo_loss: 1.283024, ine_loss: 0.661670, ref_loss: 0.175444\n",
      "\t[#  540] train_loss: 2.482586, odo_loss: 1.739804, ine_loss: 0.571225, ref_loss: 0.171557\n",
      "\t[#  720] train_loss: 2.186474, odo_loss: 1.508697, ine_loss: 0.509085, ref_loss: 0.168691\n",
      "\t[#  900] train_loss: 2.582443, odo_loss: 1.890360, ine_loss: 0.546543, ref_loss: 0.145541\n",
      "\ttrain_loss: 2.193228, odo_loss: 1.529243, ine_loss: 0.513144, ref_loss: 0.150842\n",
      "\tval_loss: 2.245901, odo_loss: 1.558985, ine_loss: 0.514684, ref_loss: 0.172231\n",
      "Epoch 183/2000\n",
      "\t[#    0] train_loss: 2.549387, odo_loss: 1.737310, ine_loss: 0.657600, ref_loss: 0.154477\n",
      "\t[#  180] train_loss: 2.210526, odo_loss: 1.576677, ine_loss: 0.456494, ref_loss: 0.177355\n",
      "\t[#  360] train_loss: 2.213532, odo_loss: 1.505208, ine_loss: 0.540524, ref_loss: 0.167800\n",
      "\t[#  540] train_loss: 2.446090, odo_loss: 1.795007, ine_loss: 0.514907, ref_loss: 0.136176\n",
      "\t[#  720] train_loss: 2.472111, odo_loss: 1.769725, ine_loss: 0.557119, ref_loss: 0.145267\n",
      "\t[#  900] train_loss: 2.463787, odo_loss: 1.772277, ine_loss: 0.514206, ref_loss: 0.177304\n",
      "\ttrain_loss: 2.193941, odo_loss: 1.529618, ine_loss: 0.512755, ref_loss: 0.151568\n",
      "\tval_loss: 2.237896, odo_loss: 1.560764, ine_loss: 0.505869, ref_loss: 0.171264\n",
      "Epoch 184/2000\n",
      "\t[#    0] train_loss: 2.366514, odo_loss: 1.675193, ine_loss: 0.524642, ref_loss: 0.166679\n",
      "\t[#  180] train_loss: 1.969711, odo_loss: 1.408672, ine_loss: 0.424097, ref_loss: 0.136943\n",
      "\t[#  360] train_loss: 2.132308, odo_loss: 1.418704, ine_loss: 0.562267, ref_loss: 0.151338\n",
      "\t[#  540] train_loss: 1.817616, odo_loss: 1.234240, ine_loss: 0.454759, ref_loss: 0.128617\n",
      "\t[#  720] train_loss: 1.670400, odo_loss: 1.067847, ine_loss: 0.449152, ref_loss: 0.153401\n",
      "\t[#  900] train_loss: 1.982042, odo_loss: 1.260469, ine_loss: 0.552971, ref_loss: 0.168602\n",
      "\ttrain_loss: 2.217929, odo_loss: 1.554196, ine_loss: 0.512699, ref_loss: 0.151034\n",
      "\tval_loss: 2.187969, odo_loss: 1.510259, ine_loss: 0.507244, ref_loss: 0.170466\n",
      "\t*** Personal Best ***\n",
      "Epoch 185/2000\n",
      "\t[#    0] train_loss: 2.157901, odo_loss: 1.494365, ine_loss: 0.533776, ref_loss: 0.129759\n",
      "\t[#  180] train_loss: 2.095193, odo_loss: 1.440935, ine_loss: 0.504388, ref_loss: 0.149870\n",
      "\t[#  360] train_loss: 2.165615, odo_loss: 1.512615, ine_loss: 0.518986, ref_loss: 0.134014\n",
      "\t[#  540] train_loss: 2.173961, odo_loss: 1.505708, ine_loss: 0.527950, ref_loss: 0.140303\n",
      "\t[#  720] train_loss: 2.313904, odo_loss: 1.695189, ine_loss: 0.501501, ref_loss: 0.117213\n",
      "\t[#  900] train_loss: 2.529633, odo_loss: 1.835439, ine_loss: 0.550635, ref_loss: 0.143559\n",
      "\ttrain_loss: 2.274077, odo_loss: 1.611484, ine_loss: 0.511878, ref_loss: 0.150715\n",
      "\tval_loss: 2.255603, odo_loss: 1.575919, ine_loss: 0.509292, ref_loss: 0.170392\n",
      "Epoch 186/2000\n",
      "\t[#    0] train_loss: 2.175955, odo_loss: 1.466292, ine_loss: 0.545716, ref_loss: 0.163947\n",
      "\t[#  180] train_loss: 2.240752, odo_loss: 1.617347, ine_loss: 0.469901, ref_loss: 0.153504\n",
      "\t[#  360] train_loss: 1.979564, odo_loss: 1.325418, ine_loss: 0.508883, ref_loss: 0.145263\n",
      "\t[#  540] train_loss: 2.252224, odo_loss: 1.570846, ine_loss: 0.533710, ref_loss: 0.147667\n",
      "\t[#  720] train_loss: 2.142298, odo_loss: 1.345241, ine_loss: 0.653422, ref_loss: 0.143636\n",
      "\t[#  900] train_loss: 2.067575, odo_loss: 1.438516, ine_loss: 0.486310, ref_loss: 0.142749\n",
      "\ttrain_loss: 2.215201, odo_loss: 1.552763, ine_loss: 0.511469, ref_loss: 0.150969\n",
      "\tval_loss: 2.215314, odo_loss: 1.533432, ine_loss: 0.512049, ref_loss: 0.169834\n",
      "Epoch 187/2000\n",
      "\t[#    0] train_loss: 2.175783, odo_loss: 1.321453, ine_loss: 0.693380, ref_loss: 0.160950\n",
      "\t[#  180] train_loss: 2.606776, odo_loss: 1.881541, ine_loss: 0.598481, ref_loss: 0.126754\n",
      "\t[#  360] train_loss: 2.611112, odo_loss: 1.872437, ine_loss: 0.570497, ref_loss: 0.168178\n",
      "\t[#  540] train_loss: 2.005830, odo_loss: 1.323607, ine_loss: 0.521872, ref_loss: 0.160351\n",
      "\t[#  720] train_loss: 2.063579, odo_loss: 1.391800, ine_loss: 0.510925, ref_loss: 0.160853\n",
      "\t[#  900] train_loss: 2.275547, odo_loss: 1.607955, ine_loss: 0.519428, ref_loss: 0.148164\n",
      "\ttrain_loss: 2.192140, odo_loss: 1.529722, ine_loss: 0.511928, ref_loss: 0.150490\n",
      "\tval_loss: 2.195409, odo_loss: 1.515120, ine_loss: 0.511591, ref_loss: 0.168699\n",
      "Epoch 188/2000\n",
      "\t[#    0] train_loss: 1.920335, odo_loss: 1.243752, ine_loss: 0.512509, ref_loss: 0.164074\n",
      "\t[#  180] train_loss: 2.489986, odo_loss: 1.833831, ine_loss: 0.505051, ref_loss: 0.151103\n",
      "\t[#  360] train_loss: 1.947300, odo_loss: 1.230880, ine_loss: 0.565349, ref_loss: 0.151070\n",
      "\t[#  540] train_loss: 2.009516, odo_loss: 1.426069, ine_loss: 0.441045, ref_loss: 0.142402\n",
      "\t[#  720] train_loss: 2.107710, odo_loss: 1.511606, ine_loss: 0.449942, ref_loss: 0.146162\n",
      "\t[#  900] train_loss: 2.058221, odo_loss: 1.470765, ine_loss: 0.462812, ref_loss: 0.124644\n",
      "\ttrain_loss: 2.228758, odo_loss: 1.566554, ine_loss: 0.511413, ref_loss: 0.150790\n",
      "\tval_loss: 2.267915, odo_loss: 1.583379, ine_loss: 0.513934, ref_loss: 0.170601\n",
      "Epoch 189/2000\n",
      "\t[#    0] train_loss: 2.485286, odo_loss: 1.847335, ine_loss: 0.483753, ref_loss: 0.154198\n",
      "\t[#  180] train_loss: 2.222212, odo_loss: 1.542010, ine_loss: 0.545922, ref_loss: 0.134280\n",
      "\t[#  360] train_loss: 2.252619, odo_loss: 1.491795, ine_loss: 0.607597, ref_loss: 0.153226\n",
      "\t[#  540] train_loss: 2.095039, odo_loss: 1.408814, ine_loss: 0.497481, ref_loss: 0.188743\n",
      "\t[#  720] train_loss: 2.348327, odo_loss: 1.731099, ine_loss: 0.426680, ref_loss: 0.190548\n",
      "\t[#  900] train_loss: 1.733296, odo_loss: 1.112749, ine_loss: 0.483526, ref_loss: 0.137020\n",
      "\ttrain_loss: 2.190554, odo_loss: 1.528678, ine_loss: 0.511470, ref_loss: 0.150406\n",
      "\tval_loss: 2.161362, odo_loss: 1.483451, ine_loss: 0.508784, ref_loss: 0.169127\n",
      "\t*** Personal Best ***\n",
      "Epoch 190/2000\n",
      "\t[#    0] train_loss: 1.832594, odo_loss: 1.183855, ine_loss: 0.525445, ref_loss: 0.123294\n",
      "\t[#  180] train_loss: 2.573590, odo_loss: 1.888305, ine_loss: 0.562020, ref_loss: 0.123265\n",
      "\t[#  360] train_loss: 2.339465, odo_loss: 1.645452, ine_loss: 0.548893, ref_loss: 0.145120\n",
      "\t[#  540] train_loss: 2.751325, odo_loss: 2.065642, ine_loss: 0.541678, ref_loss: 0.144006\n",
      "\t[#  720] train_loss: 1.936896, odo_loss: 1.325030, ine_loss: 0.439631, ref_loss: 0.172235\n",
      "\t[#  900] train_loss: 2.217990, odo_loss: 1.401316, ine_loss: 0.676910, ref_loss: 0.139764\n",
      "\ttrain_loss: 2.207010, odo_loss: 1.545840, ine_loss: 0.510821, ref_loss: 0.150349\n",
      "\tval_loss: 2.188232, odo_loss: 1.509579, ine_loss: 0.509417, ref_loss: 0.169235\n",
      "Epoch 191/2000\n",
      "\t[#    0] train_loss: 2.147010, odo_loss: 1.589759, ine_loss: 0.427447, ref_loss: 0.129804\n",
      "\t[#  180] train_loss: 2.090000, odo_loss: 1.486340, ine_loss: 0.474409, ref_loss: 0.129251\n",
      "\t[#  360] train_loss: 2.292457, odo_loss: 1.458677, ine_loss: 0.663327, ref_loss: 0.170453\n",
      "\t[#  540] train_loss: 2.089452, odo_loss: 1.383364, ine_loss: 0.572514, ref_loss: 0.133573\n",
      "\t[#  720] train_loss: 2.411060, odo_loss: 1.774183, ine_loss: 0.490025, ref_loss: 0.146852\n",
      "\t[#  900] train_loss: 2.213153, odo_loss: 1.558797, ine_loss: 0.501100, ref_loss: 0.153256\n",
      "\ttrain_loss: 2.195801, odo_loss: 1.534729, ine_loss: 0.510855, ref_loss: 0.150217\n",
      "\tval_loss: 2.179339, odo_loss: 1.499125, ine_loss: 0.508292, ref_loss: 0.171921\n",
      "Epoch 192/2000\n",
      "\t[#    0] train_loss: 2.429488, odo_loss: 1.585905, ine_loss: 0.633722, ref_loss: 0.209861\n",
      "\t[#  180] train_loss: 2.530426, odo_loss: 1.777573, ine_loss: 0.600805, ref_loss: 0.152048\n",
      "\t[#  360] train_loss: 1.798008, odo_loss: 1.113458, ine_loss: 0.539272, ref_loss: 0.145278\n",
      "\t[#  540] train_loss: 1.858264, odo_loss: 1.290985, ine_loss: 0.421587, ref_loss: 0.145691\n",
      "\t[#  720] train_loss: 2.190282, odo_loss: 1.472431, ine_loss: 0.560345, ref_loss: 0.157506\n",
      "\t[#  900] train_loss: 2.398089, odo_loss: 1.757219, ine_loss: 0.494486, ref_loss: 0.146384\n",
      "\ttrain_loss: 2.167810, odo_loss: 1.507354, ine_loss: 0.510146, ref_loss: 0.150310\n",
      "\tval_loss: 2.237675, odo_loss: 1.563939, ine_loss: 0.503071, ref_loss: 0.170666\n",
      "Epoch 193/2000\n",
      "\t[#    0] train_loss: 1.991580, odo_loss: 1.411472, ine_loss: 0.442079, ref_loss: 0.138029\n",
      "\t[#  180] train_loss: 2.010590, odo_loss: 1.439871, ine_loss: 0.430013, ref_loss: 0.140706\n",
      "\t[#  360] train_loss: 2.092841, odo_loss: 1.369776, ine_loss: 0.551769, ref_loss: 0.171297\n",
      "\t[#  540] train_loss: 2.215020, odo_loss: 1.521719, ine_loss: 0.524029, ref_loss: 0.169271\n",
      "\t[#  720] train_loss: 2.127972, odo_loss: 1.476753, ine_loss: 0.516087, ref_loss: 0.135132\n",
      "\t[#  900] train_loss: 2.071512, odo_loss: 1.495091, ine_loss: 0.444547, ref_loss: 0.131875\n",
      "\ttrain_loss: 2.155525, odo_loss: 1.495363, ine_loss: 0.509974, ref_loss: 0.150188\n",
      "\tval_loss: 2.287668, odo_loss: 1.614624, ine_loss: 0.500622, ref_loss: 0.172422\n",
      "Epoch 194/2000\n",
      "\t[#    0] train_loss: 2.235854, odo_loss: 1.565486, ine_loss: 0.525591, ref_loss: 0.144777\n",
      "\t[#  180] train_loss: 2.068218, odo_loss: 1.420781, ine_loss: 0.489738, ref_loss: 0.157698\n",
      "\t[#  360] train_loss: 2.295827, odo_loss: 1.663384, ine_loss: 0.498147, ref_loss: 0.134296\n",
      "\t[#  540] train_loss: 1.882508, odo_loss: 1.181649, ine_loss: 0.526942, ref_loss: 0.173917\n",
      "\t[#  720] train_loss: 2.220926, odo_loss: 1.668410, ine_loss: 0.386286, ref_loss: 0.166230\n",
      "\t[#  900] train_loss: 1.842247, odo_loss: 1.307998, ine_loss: 0.368021, ref_loss: 0.166228\n",
      "\ttrain_loss: 2.171272, odo_loss: 1.511084, ine_loss: 0.510333, ref_loss: 0.149855\n",
      "\tval_loss: 2.134714, odo_loss: 1.456812, ine_loss: 0.508799, ref_loss: 0.169103\n",
      "\t*** Personal Best ***\n",
      "Epoch 195/2000\n",
      "\t[#    0] train_loss: 2.327490, odo_loss: 1.627725, ine_loss: 0.544928, ref_loss: 0.154837\n",
      "\t[#  180] train_loss: 2.396448, odo_loss: 1.736401, ine_loss: 0.521376, ref_loss: 0.138670\n",
      "\t[#  360] train_loss: 2.470129, odo_loss: 1.749978, ine_loss: 0.549309, ref_loss: 0.170841\n",
      "\t[#  540] train_loss: 2.207812, odo_loss: 1.473481, ine_loss: 0.573938, ref_loss: 0.160393\n",
      "\t[#  720] train_loss: 2.112906, odo_loss: 1.504726, ine_loss: 0.468447, ref_loss: 0.139733\n",
      "\t[#  900] train_loss: 2.052275, odo_loss: 1.575770, ine_loss: 0.336956, ref_loss: 0.139549\n",
      "\ttrain_loss: 2.170912, odo_loss: 1.511346, ine_loss: 0.509546, ref_loss: 0.150020\n",
      "\tval_loss: 2.206660, odo_loss: 1.528223, ine_loss: 0.506292, ref_loss: 0.172145\n",
      "Epoch 196/2000\n",
      "\t[#    0] train_loss: 2.144222, odo_loss: 1.534383, ine_loss: 0.464828, ref_loss: 0.145010\n",
      "\t[#  180] train_loss: 2.091858, odo_loss: 1.437876, ine_loss: 0.498628, ref_loss: 0.155355\n",
      "\t[#  360] train_loss: 2.489426, odo_loss: 1.881272, ine_loss: 0.428291, ref_loss: 0.179862\n",
      "\t[#  540] train_loss: 1.739335, odo_loss: 1.185884, ine_loss: 0.405029, ref_loss: 0.148423\n",
      "\t[#  720] train_loss: 2.146170, odo_loss: 1.376745, ine_loss: 0.641792, ref_loss: 0.127633\n",
      "\t[#  900] train_loss: 2.514456, odo_loss: 1.773259, ine_loss: 0.550463, ref_loss: 0.190733\n",
      "\ttrain_loss: 2.218312, odo_loss: 1.558019, ine_loss: 0.510305, ref_loss: 0.149988\n",
      "\tval_loss: 2.306215, odo_loss: 1.631408, ine_loss: 0.504121, ref_loss: 0.170687\n",
      "Epoch 197/2000\n",
      "\t[#    0] train_loss: 2.238634, odo_loss: 1.512141, ine_loss: 0.583417, ref_loss: 0.143076\n",
      "\t[#  180] train_loss: 2.036674, odo_loss: 1.440674, ine_loss: 0.459316, ref_loss: 0.136685\n",
      "\t[#  360] train_loss: 2.228213, odo_loss: 1.622040, ine_loss: 0.463410, ref_loss: 0.142763\n",
      "\t[#  540] train_loss: 2.425287, odo_loss: 1.757113, ine_loss: 0.516652, ref_loss: 0.151522\n",
      "\t[#  720] train_loss: 2.205352, odo_loss: 1.544291, ine_loss: 0.480647, ref_loss: 0.180414\n",
      "\t[#  900] train_loss: 2.519877, odo_loss: 1.856940, ine_loss: 0.497333, ref_loss: 0.165604\n",
      "\ttrain_loss: 2.186555, odo_loss: 1.526983, ine_loss: 0.509772, ref_loss: 0.149801\n",
      "\tval_loss: 2.290888, odo_loss: 1.608774, ine_loss: 0.513608, ref_loss: 0.168506\n",
      "Epoch 198/2000\n",
      "\t[#    0] train_loss: 1.815947, odo_loss: 1.250716, ine_loss: 0.426621, ref_loss: 0.138610\n",
      "\t[#  180] train_loss: 2.024525, odo_loss: 1.374323, ine_loss: 0.510994, ref_loss: 0.139208\n",
      "\t[#  360] train_loss: 2.217686, odo_loss: 1.590915, ine_loss: 0.492920, ref_loss: 0.133851\n",
      "\t[#  540] train_loss: 2.202039, odo_loss: 1.580240, ine_loss: 0.470641, ref_loss: 0.151158\n",
      "\t[#  720] train_loss: 7.766967, odo_loss: 7.085723, ine_loss: 0.527648, ref_loss: 0.153596\n",
      "\t[#  900] train_loss: 2.528314, odo_loss: 1.770881, ine_loss: 0.595886, ref_loss: 0.161548\n",
      "\ttrain_loss: 2.221792, odo_loss: 1.562660, ine_loss: 0.508960, ref_loss: 0.150172\n",
      "\tval_loss: 2.310233, odo_loss: 1.637551, ine_loss: 0.502991, ref_loss: 0.169690\n",
      "Epoch 199/2000\n",
      "\t[#    0] train_loss: 2.406429, odo_loss: 1.889244, ine_loss: 0.382526, ref_loss: 0.134659\n",
      "\t[#  180] train_loss: 2.384473, odo_loss: 1.863549, ine_loss: 0.401111, ref_loss: 0.119813\n",
      "\t[#  360] train_loss: 2.150504, odo_loss: 1.452146, ine_loss: 0.560755, ref_loss: 0.137602\n",
      "\t[#  540] train_loss: 2.193546, odo_loss: 1.559012, ine_loss: 0.481898, ref_loss: 0.152637\n",
      "\t[#  720] train_loss: 2.110148, odo_loss: 1.459062, ine_loss: 0.536286, ref_loss: 0.114800\n",
      "\t[#  900] train_loss: 2.454078, odo_loss: 1.795505, ine_loss: 0.495784, ref_loss: 0.162789\n",
      "\ttrain_loss: 2.179002, odo_loss: 1.519704, ine_loss: 0.509351, ref_loss: 0.149947\n",
      "\tval_loss: 2.179140, odo_loss: 1.503443, ine_loss: 0.506731, ref_loss: 0.168967\n",
      "Epoch 200/2000\n",
      "\t[#    0] train_loss: 1.997514, odo_loss: 1.433906, ine_loss: 0.428369, ref_loss: 0.135238\n",
      "\t[#  180] train_loss: 2.171431, odo_loss: 1.590623, ine_loss: 0.444613, ref_loss: 0.136196\n",
      "\t[#  360] train_loss: 2.346380, odo_loss: 1.778405, ine_loss: 0.455075, ref_loss: 0.112900\n",
      "\t[#  540] train_loss: 2.022481, odo_loss: 1.390374, ine_loss: 0.477049, ref_loss: 0.155059\n",
      "\t[#  720] train_loss: 2.255188, odo_loss: 1.553371, ine_loss: 0.544399, ref_loss: 0.157417\n",
      "\t[#  900] train_loss: 2.375655, odo_loss: 1.724668, ine_loss: 0.505176, ref_loss: 0.145811\n",
      "\ttrain_loss: 2.234473, odo_loss: 1.576084, ine_loss: 0.508220, ref_loss: 0.150170\n",
      "\tval_loss: 2.320459, odo_loss: 1.644358, ine_loss: 0.507004, ref_loss: 0.169096\n",
      "Epoch 201/2000\n",
      "\t[#    0] train_loss: 2.099849, odo_loss: 1.502439, ine_loss: 0.464978, ref_loss: 0.132432\n",
      "\t[#  180] train_loss: 2.004868, odo_loss: 1.228600, ine_loss: 0.626961, ref_loss: 0.149307\n",
      "\t[#  360] train_loss: 2.481663, odo_loss: 1.873337, ine_loss: 0.434569, ref_loss: 0.173757\n",
      "\t[#  540] train_loss: 2.130585, odo_loss: 1.537021, ine_loss: 0.449562, ref_loss: 0.144002\n",
      "\t[#  720] train_loss: 1.774779, odo_loss: 1.165252, ine_loss: 0.441480, ref_loss: 0.168047\n",
      "\t[#  900] train_loss: 2.044561, odo_loss: 1.381380, ine_loss: 0.525400, ref_loss: 0.137781\n",
      "\ttrain_loss: 2.219861, odo_loss: 1.560383, ine_loss: 0.509054, ref_loss: 0.150424\n",
      "\tval_loss: 2.254977, odo_loss: 1.583121, ine_loss: 0.500770, ref_loss: 0.171086\n",
      "Epoch 202/2000\n",
      "\t[#    0] train_loss: 2.469742, odo_loss: 1.806667, ine_loss: 0.524054, ref_loss: 0.139021\n",
      "\t[#  180] train_loss: 2.338804, odo_loss: 1.670862, ine_loss: 0.470406, ref_loss: 0.197535\n",
      "\t[#  360] train_loss: 2.181269, odo_loss: 1.557329, ine_loss: 0.462660, ref_loss: 0.161280\n",
      "\t[#  540] train_loss: 2.027012, odo_loss: 1.482137, ine_loss: 0.416206, ref_loss: 0.128668\n",
      "\t[#  720] train_loss: 2.683521, odo_loss: 2.017592, ine_loss: 0.518006, ref_loss: 0.147923\n",
      "\t[#  900] train_loss: 1.971299, odo_loss: 1.328340, ine_loss: 0.479556, ref_loss: 0.163402\n",
      "\ttrain_loss: 2.171342, odo_loss: 1.513524, ine_loss: 0.508540, ref_loss: 0.149279\n",
      "\tval_loss: 2.197322, odo_loss: 1.523615, ine_loss: 0.505073, ref_loss: 0.168634\n",
      "Epoch 203/2000\n",
      "\t[#    0] train_loss: 2.344140, odo_loss: 1.542753, ine_loss: 0.651311, ref_loss: 0.150076\n",
      "\t[#  180] train_loss: 2.077123, odo_loss: 1.384351, ine_loss: 0.546876, ref_loss: 0.145896\n",
      "\t[#  360] train_loss: 2.241115, odo_loss: 1.527240, ine_loss: 0.568759, ref_loss: 0.145116\n",
      "\t[#  540] train_loss: 2.053014, odo_loss: 1.334796, ine_loss: 0.531571, ref_loss: 0.186647\n",
      "\t[#  720] train_loss: 1.785897, odo_loss: 1.246174, ine_loss: 0.408333, ref_loss: 0.131390\n",
      "\t[#  900] train_loss: 2.092650, odo_loss: 1.285469, ine_loss: 0.655738, ref_loss: 0.151443\n",
      "\ttrain_loss: 2.145269, odo_loss: 1.486840, ine_loss: 0.509022, ref_loss: 0.149408\n",
      "\tval_loss: 2.273106, odo_loss: 1.598398, ine_loss: 0.506104, ref_loss: 0.168603\n",
      "Epoch 204/2000\n",
      "\t[#    0] train_loss: 2.348877, odo_loss: 1.675267, ine_loss: 0.500084, ref_loss: 0.173526\n",
      "\t[#  180] train_loss: 2.244306, odo_loss: 1.599146, ine_loss: 0.512621, ref_loss: 0.132539\n",
      "\t[#  360] train_loss: 2.763184, odo_loss: 2.142644, ine_loss: 0.466552, ref_loss: 0.153988\n",
      "\t[#  540] train_loss: 2.334051, odo_loss: 1.499771, ine_loss: 0.677315, ref_loss: 0.156964\n",
      "\t[#  720] train_loss: 2.120170, odo_loss: 1.508511, ine_loss: 0.441469, ref_loss: 0.170190\n",
      "\t[#  900] train_loss: 2.231373, odo_loss: 1.594625, ine_loss: 0.493405, ref_loss: 0.143343\n",
      "\ttrain_loss: 2.249906, odo_loss: 1.591287, ine_loss: 0.509005, ref_loss: 0.149614\n",
      "\tval_loss: 2.208514, odo_loss: 1.533048, ine_loss: 0.506260, ref_loss: 0.169206\n",
      "Epoch 205/2000\n",
      "\t[#    0] train_loss: 2.173169, odo_loss: 1.461340, ine_loss: 0.587694, ref_loss: 0.124135\n",
      "\t[#  180] train_loss: 2.070529, odo_loss: 1.361411, ine_loss: 0.576951, ref_loss: 0.132168\n",
      "\t[#  360] train_loss: 2.256680, odo_loss: 1.562733, ine_loss: 0.541546, ref_loss: 0.152400\n",
      "\t[#  540] train_loss: 2.347250, odo_loss: 1.662436, ine_loss: 0.505897, ref_loss: 0.178918\n",
      "\t[#  720] train_loss: 2.479197, odo_loss: 1.764033, ine_loss: 0.560897, ref_loss: 0.154267\n",
      "\t[#  900] train_loss: 2.073857, odo_loss: 1.341991, ine_loss: 0.578378, ref_loss: 0.153489\n",
      "\ttrain_loss: 2.160249, odo_loss: 1.501577, ine_loss: 0.509796, ref_loss: 0.148876\n",
      "\tval_loss: 2.240109, odo_loss: 1.565871, ine_loss: 0.504588, ref_loss: 0.169649\n",
      "Epoch 206/2000\n",
      "\t[#    0] train_loss: 2.066201, odo_loss: 1.444519, ine_loss: 0.481943, ref_loss: 0.139738\n",
      "\t[#  180] train_loss: 1.740317, odo_loss: 1.063087, ine_loss: 0.487959, ref_loss: 0.189270\n",
      "\t[#  360] train_loss: 1.955657, odo_loss: 1.323619, ine_loss: 0.461618, ref_loss: 0.170420\n",
      "\t[#  540] train_loss: 1.924647, odo_loss: 1.268702, ine_loss: 0.489857, ref_loss: 0.166087\n",
      "\t[#  720] train_loss: 2.145885, odo_loss: 1.517183, ine_loss: 0.461233, ref_loss: 0.167468\n",
      "\t[#  900] train_loss: 2.322702, odo_loss: 1.684838, ine_loss: 0.448504, ref_loss: 0.189360\n",
      "\ttrain_loss: 2.190881, odo_loss: 1.531982, ine_loss: 0.509734, ref_loss: 0.149165\n",
      "\tval_loss: 2.185675, odo_loss: 1.515941, ine_loss: 0.501275, ref_loss: 0.168459\n",
      "Epoch 207/2000\n",
      "\t[#    0] train_loss: 2.113069, odo_loss: 1.289545, ine_loss: 0.677970, ref_loss: 0.145554\n",
      "\t[#  180] train_loss: 1.853943, odo_loss: 1.193887, ine_loss: 0.517760, ref_loss: 0.142295\n",
      "\t[#  360] train_loss: 2.033005, odo_loss: 1.297065, ine_loss: 0.562328, ref_loss: 0.173612\n",
      "\t[#  540] train_loss: 2.077950, odo_loss: 1.351702, ine_loss: 0.561692, ref_loss: 0.164556\n",
      "\t[#  720] train_loss: 2.312064, odo_loss: 1.629852, ine_loss: 0.540641, ref_loss: 0.141571\n",
      "\t[#  900] train_loss: 1.909385, odo_loss: 1.316730, ine_loss: 0.474863, ref_loss: 0.117792\n",
      "\ttrain_loss: 2.155819, odo_loss: 1.497931, ine_loss: 0.508652, ref_loss: 0.149236\n",
      "\tval_loss: 2.143358, odo_loss: 1.469432, ine_loss: 0.505259, ref_loss: 0.168667\n",
      "Epoch 208/2000\n",
      "\t[#    0] train_loss: 1.992886, odo_loss: 1.381989, ine_loss: 0.489616, ref_loss: 0.121280\n",
      "\t[#  180] train_loss: 2.036242, odo_loss: 1.449494, ine_loss: 0.455669, ref_loss: 0.131079\n",
      "\t[#  360] train_loss: 2.039037, odo_loss: 1.420575, ine_loss: 0.483974, ref_loss: 0.134488\n",
      "\t[#  540] train_loss: 2.144720, odo_loss: 1.349162, ine_loss: 0.615177, ref_loss: 0.180381\n",
      "\t[#  720] train_loss: 2.105391, odo_loss: 1.457187, ine_loss: 0.474432, ref_loss: 0.173771\n",
      "\t[#  900] train_loss: 2.416437, odo_loss: 1.809322, ine_loss: 0.489280, ref_loss: 0.117835\n",
      "\ttrain_loss: 2.204409, odo_loss: 1.545917, ine_loss: 0.509160, ref_loss: 0.149331\n",
      "\tval_loss: 2.252206, odo_loss: 1.581138, ine_loss: 0.502717, ref_loss: 0.168351\n",
      "Epoch 209/2000\n",
      "\t[#    0] train_loss: 2.084289, odo_loss: 1.379795, ine_loss: 0.585294, ref_loss: 0.119200\n",
      "\t[#  180] train_loss: 2.221158, odo_loss: 1.433550, ine_loss: 0.616921, ref_loss: 0.170686\n",
      "\t[#  360] train_loss: 2.092174, odo_loss: 1.448234, ine_loss: 0.491362, ref_loss: 0.152577\n",
      "\t[#  540] train_loss: 2.180452, odo_loss: 1.383168, ine_loss: 0.622960, ref_loss: 0.174324\n",
      "\t[#  720] train_loss: 2.266746, odo_loss: 1.624635, ine_loss: 0.510593, ref_loss: 0.131518\n",
      "\t[#  900] train_loss: 2.138355, odo_loss: 1.392442, ine_loss: 0.595911, ref_loss: 0.150002\n",
      "\ttrain_loss: 2.156560, odo_loss: 1.498281, ine_loss: 0.509389, ref_loss: 0.148890\n",
      "\tval_loss: 2.277100, odo_loss: 1.599704, ine_loss: 0.507927, ref_loss: 0.169469\n",
      "Epoch 210/2000\n",
      "\t[#    0] train_loss: 2.136822, odo_loss: 1.457025, ine_loss: 0.509607, ref_loss: 0.170190\n",
      "\t[#  180] train_loss: 1.981568, odo_loss: 1.325809, ine_loss: 0.520090, ref_loss: 0.135669\n",
      "\t[#  360] train_loss: 1.961962, odo_loss: 1.405564, ine_loss: 0.433232, ref_loss: 0.123165\n",
      "\t[#  540] train_loss: 1.923651, odo_loss: 1.255175, ine_loss: 0.526475, ref_loss: 0.142001\n",
      "\t[#  720] train_loss: 2.315334, odo_loss: 1.629727, ine_loss: 0.533843, ref_loss: 0.151763\n",
      "\t[#  900] train_loss: 2.604433, odo_loss: 1.823364, ine_loss: 0.600516, ref_loss: 0.180553\n",
      "\ttrain_loss: 2.143411, odo_loss: 1.485220, ine_loss: 0.509097, ref_loss: 0.149093\n",
      "\tval_loss: 2.359002, odo_loss: 1.681346, ine_loss: 0.508569, ref_loss: 0.169087\n",
      "Epoch 211/2000\n",
      "\t[#    0] train_loss: 2.340311, odo_loss: 1.444809, ine_loss: 0.730017, ref_loss: 0.165485\n",
      "\t[#  180] train_loss: 2.134385, odo_loss: 1.524227, ine_loss: 0.443311, ref_loss: 0.166848\n",
      "\t[#  360] train_loss: 2.278695, odo_loss: 1.501764, ine_loss: 0.625868, ref_loss: 0.151062\n",
      "\t[#  540] train_loss: 2.259037, odo_loss: 1.648654, ine_loss: 0.483617, ref_loss: 0.126766\n",
      "\t[#  720] train_loss: 2.266127, odo_loss: 1.628833, ine_loss: 0.489364, ref_loss: 0.147929\n",
      "\t[#  900] train_loss: 4.885027, odo_loss: 4.216177, ine_loss: 0.494516, ref_loss: 0.174335\n",
      "\ttrain_loss: 2.152349, odo_loss: 1.494909, ine_loss: 0.508106, ref_loss: 0.149334\n",
      "\tval_loss: 2.402908, odo_loss: 1.733862, ine_loss: 0.501861, ref_loss: 0.167185\n",
      "Epoch 212/2000\n",
      "\t[#    0] train_loss: 2.360159, odo_loss: 1.640628, ine_loss: 0.579280, ref_loss: 0.140251\n",
      "\t[#  180] train_loss: 2.770244, odo_loss: 2.001629, ine_loss: 0.603194, ref_loss: 0.165422\n",
      "\t[#  360] train_loss: 2.045357, odo_loss: 1.379314, ine_loss: 0.500540, ref_loss: 0.165503\n",
      "\t[#  540] train_loss: 2.090941, odo_loss: 1.440193, ine_loss: 0.477990, ref_loss: 0.172759\n",
      "\t[#  720] train_loss: 2.283399, odo_loss: 1.628822, ine_loss: 0.507579, ref_loss: 0.146998\n",
      "\t[#  900] train_loss: 2.099875, odo_loss: 1.387228, ine_loss: 0.534835, ref_loss: 0.177813\n",
      "\ttrain_loss: 2.168707, odo_loss: 1.512446, ine_loss: 0.507477, ref_loss: 0.148784\n",
      "\tval_loss: 2.194517, odo_loss: 1.519553, ine_loss: 0.502324, ref_loss: 0.172640\n",
      "Epoch 213/2000\n",
      "\t[#    0] train_loss: 1.966565, odo_loss: 1.445770, ine_loss: 0.393330, ref_loss: 0.127464\n",
      "\t[#  180] train_loss: 2.500121, odo_loss: 1.890474, ine_loss: 0.473854, ref_loss: 0.135792\n",
      "\t[#  360] train_loss: 2.059941, odo_loss: 1.469778, ine_loss: 0.430827, ref_loss: 0.159336\n",
      "\t[#  540] train_loss: 1.806753, odo_loss: 1.336874, ine_loss: 0.343130, ref_loss: 0.126749\n",
      "\t[#  720] train_loss: 1.937161, odo_loss: 1.314867, ine_loss: 0.467602, ref_loss: 0.154693\n",
      "\t[#  900] train_loss: 1.810414, odo_loss: 1.203858, ine_loss: 0.462893, ref_loss: 0.143663\n",
      "\ttrain_loss: 2.282075, odo_loss: 1.625428, ine_loss: 0.507568, ref_loss: 0.149079\n",
      "\tval_loss: 2.224279, odo_loss: 1.548646, ine_loss: 0.506749, ref_loss: 0.168885\n",
      "Epoch 214/2000\n",
      "\t[#    0] train_loss: 2.423818, odo_loss: 1.728448, ine_loss: 0.547505, ref_loss: 0.147866\n",
      "\t[#  180] train_loss: 2.287208, odo_loss: 1.579237, ine_loss: 0.585696, ref_loss: 0.122275\n",
      "\t[#  360] train_loss: 2.291833, odo_loss: 1.767350, ine_loss: 0.403963, ref_loss: 0.120521\n",
      "\t[#  540] train_loss: 2.200064, odo_loss: 1.447900, ine_loss: 0.617778, ref_loss: 0.134386\n",
      "\t[#  720] train_loss: 2.519671, odo_loss: 1.734848, ine_loss: 0.632051, ref_loss: 0.152772\n",
      "\t[#  900] train_loss: 2.259798, odo_loss: 1.581816, ine_loss: 0.506651, ref_loss: 0.171331\n",
      "\ttrain_loss: 2.182969, odo_loss: 1.524640, ine_loss: 0.509078, ref_loss: 0.149251\n",
      "\tval_loss: 2.147025, odo_loss: 1.474690, ine_loss: 0.502484, ref_loss: 0.169850\n",
      "Epoch 215/2000\n",
      "\t[#    0] train_loss: 2.380351, odo_loss: 1.783153, ine_loss: 0.430642, ref_loss: 0.166556\n",
      "\t[#  180] train_loss: 2.231545, odo_loss: 1.460320, ine_loss: 0.623166, ref_loss: 0.148059\n",
      "\t[#  360] train_loss: 2.614022, odo_loss: 1.918972, ine_loss: 0.507266, ref_loss: 0.187784\n",
      "\t[#  540] train_loss: 2.576218, odo_loss: 1.949664, ine_loss: 0.456370, ref_loss: 0.170185\n",
      "\t[#  720] train_loss: 2.304729, odo_loss: 1.573236, ine_loss: 0.573097, ref_loss: 0.158396\n",
      "\t[#  900] train_loss: 2.543937, odo_loss: 1.811010, ine_loss: 0.572449, ref_loss: 0.160479\n",
      "\ttrain_loss: 2.247061, odo_loss: 1.590359, ine_loss: 0.507156, ref_loss: 0.149546\n",
      "\tval_loss: 2.212762, odo_loss: 1.538205, ine_loss: 0.503915, ref_loss: 0.170643\n",
      "\n",
      "\tStopped by  early stopping!\n"
     ]
    }
   ],
   "source": [
    "model = InertialNet2().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "h_loss_train = []\n",
    "h_loss_val = []\n",
    "\n",
    "early_stopping = {\"epoch\":0, \"best\":10**3, \"epoch_threshold\":EARLY_STOPPING}\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(f\"Epoch {epoch}/{EPOCHS}\")\n",
    "\n",
    "    _, loss_train, _, _ = train(model, device, train_loader, optimizer, epoch)\n",
    "    _, loss_val, _, _ = validation(model, device, val_loader, epoch)\n",
    "\n",
    "    #populating the history of the loss\n",
    "    h_loss_train.append(loss_train)\n",
    "    h_loss_val.append(loss_val)\n",
    "\n",
    "    # early stopping\n",
    "    if loss_val < early_stopping[\"best\"]:\n",
    "        early_stopping[\"best\"] = loss_val\n",
    "        early_stopping[\"epoch\"] = epoch\n",
    "        print(\"\\t*** Personal Best ***\")\n",
    "\n",
    "    if epoch - early_stopping[\"epoch\"] > early_stopping[\"epoch_threshold\"]:\n",
    "        print(\"\\n\\tStopped by  early stopping!\")\n",
    "        break\n",
    "\n",
    "np.savez(f\"train_loss_{EPOCHS}\", h_loss_train)\n",
    "np.savez(f\"val_loss_{EPOCHS}\", h_loss_val)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(h_loss_train, label=\"train\")\n",
    "plt.plot(h_loss_val, label=\"validation\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zoomed plot (last 30 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(h_loss_train)[-50:], label=\"train\")\n",
    "plt.plot(np.array(h_loss_val)[-50:], label=\"validation\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a60a9521ac24e310983a613c26989eaf1fc2b3e1d7e934fda12fd60cebe70c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
