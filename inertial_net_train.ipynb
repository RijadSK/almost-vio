{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Almost Visual Inertial Odometry"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.models import MobileNetV2, mobilenet_v3_small, MobileNet_V3_Small_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from  matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 20197\n",
    "BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 32\n",
    "GAMMA = 0.1   # torch default\n",
    "LR=0.001 \n",
    "EPOCHS = 2000\n",
    "EARLY_STOPPING = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available cuda: True\n"
     ]
    }
   ],
   "source": [
    "available_cuda = torch.cuda.is_available()\n",
    "print(f\"Available cuda: {available_cuda}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if available_cuda else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvioDataset(torch.utils.data.Dataset):\n",
    "      def __init__(self, frames, inertials, labels, inertials_buffer, choose_split=None, split={'train':0.6, 'val':0.2, 'test':0.2}, shuffle=True):\n",
    "            if shuffle:\n",
    "                  shuffled_index = torch.randperm(frames.shape[0])\n",
    "                  frames = frames[shuffled_index]\n",
    "                  inertials = inertials[shuffled_index]\n",
    "                  labels = labels[shuffled_index]\n",
    "                  inertials_buffer = inertials_buffer[shuffled_index]\n",
    "\n",
    "            if choose_split is None:\n",
    "                  self.frames = frames\n",
    "                  self.inertials = inertials\n",
    "                  self.labels = labels\n",
    "                  self.inertials_buffer = inertials_buffer\n",
    "            else:\n",
    "                  assert split['train'] + split['val'] + split['test'] == 1\n",
    "                  length = frames.shape[0]\n",
    "                  if choose_split == \"train\":\n",
    "                        self.frames = frames[:round(split['train']*length)]\n",
    "                        self.inertials = inertials[:round(split['train']*length)]\n",
    "                        self.labels = labels[:round(split['train']*length)]\n",
    "                        self.inertials_buffer = inertials_buffer[:round(split['train']*length)]\n",
    "                  elif choose_split == \"val\":\n",
    "                        self.frames = frames[round(split['train']*length):-round(split['test']*length)]\n",
    "                        self.inertials = inertials[round(split['train']*length):-round(split['test']*length)]\n",
    "                        self.labels = labels[round(split['train']*length):-round(split['test']*length)]\n",
    "                        self.inertials_buffer = inertials_buffer[round(split['train']*length):-round(split['test']*length)]\n",
    "                  elif choose_split == \"test\":\n",
    "                        self.frames = frames[-round(split['test']*length):]\n",
    "                        self.inertials = inertials[-round(split['test']*length):]\n",
    "                        self.labels = labels[-round(split['test']*length):]\n",
    "                        self.inertials_buffer = inertials_buffer[-round(split['test']*length):]\n",
    "                  else:\n",
    "                        raise Exception(f\"The split name '{choose_split}' doesn't exists\")\n",
    "\n",
    "      def __len__(self):\n",
    "            return len(self.frames) - 1\n",
    "\n",
    "      def __getitem__(self, index):\n",
    "            # load sample of frames\n",
    "            frame_name = self.frames[index]\n",
    "            scene_name, frame_name = frame_name.split(\"_\")\n",
    "            frame_name, file_extension = frame_name.split(\".\")\n",
    "            sample_frame = torch.Tensor(np.load(f\"./data/{scene_name}/iphone/frames/{scene_name}_{frame_name}.npy\", allow_pickle=True))\n",
    "\n",
    "            # build buffer sample of inertials\n",
    "            sample_inertials_buffer = self.inertials_buffer[index]\n",
    "\n",
    "            # load labels\n",
    "            label_odometry = self.labels[index]\n",
    "\n",
    "            # load inertials\n",
    "            label_inertial = self.inertials[index]\n",
    "\n",
    "            return sample_frame, sample_inertials_buffer, label_odometry, label_inertial\n",
    "\n",
    "\n",
    "frames = np.load(\"dataset_frames.npy\", allow_pickle=True)\n",
    "inertials = torch.Tensor(np.load(\"dataset_inertials.npy\", allow_pickle=True))\n",
    "labels = torch.Tensor(np.load(\"dataset_labels.npy\", allow_pickle=True))\n",
    "buffer_inertials = torch.Tensor(np.load(\"dataset_buffer.npy\", allow_pickle=True))\n",
    "\n",
    "train_data = AdvioDataset(frames, inertials, labels, buffer_inertials, \"train\")\n",
    "val_data = AdvioDataset(frames, inertials, labels, buffer_inertials, \"val\")\n",
    "test_data = AdvioDataset(frames, inertials, labels, buffer_inertials, \"test\")\n",
    "\n",
    "del frames\n",
    "del inertials\n",
    "del labels\n",
    "del buffer_inertials\n",
    "\n",
    "params = {'batch_size': BATCH_SIZE,\n",
    "          'num_workers': 6,\n",
    "          'drop_last':True}\n",
    "\n",
    "train_loader = DataLoader(train_data, **params, shuffle=True)\n",
    "val_loader = DataLoader(val_data, **params, shuffle=True)\n",
    "test_loader = DataLoader(test_data, **params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet1D(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(ConvNet1D,self).__init__()\n",
    "    self.conv1 = nn.Conv1d(3,8,3,2)\n",
    "    torch.nn.init.kaiming_uniform_(self.conv1.weight)\n",
    "    \n",
    "    self.conv2 = nn.Conv1d(8,16,3,2)\n",
    "    torch.nn.init.kaiming_uniform_(self.conv2.weight)\n",
    "    \n",
    "    self.conv3 = nn.Conv1d(16,32,3,2)\n",
    "    torch.nn.init.kaiming_uniform_(self.conv3.weight)\n",
    "    \n",
    "    self.conv4 = nn.Conv1d(32,64,3,2)\n",
    "    torch.nn.init.kaiming_uniform_(self.conv4.weight)\n",
    "    \n",
    "    self.conv5 = nn.Conv1d(64,16,3,1)\n",
    "    torch.nn.init.kaiming_uniform_(self.conv5.weight)\n",
    "\n",
    "    self.conv6 = nn.Conv1d(16,3,3,1)\n",
    "    torch.nn.init.kaiming_uniform_(self.conv6.weight)\n",
    "\n",
    "    self.fc1 = nn.Linear(3,3)\n",
    "\n",
    "  def forward(self,x):\n",
    "    # adding uncertanty\n",
    "    # random_weights = torch.randn(x.shape)*2 + 1\n",
    "    # random_weights = random_weights.to(device)\n",
    "    # x = x * random_weights\n",
    "\n",
    "    x = F.silu(self.conv1(x))\n",
    "    x = F.silu(self.conv2(x))\n",
    "    x = F.silu(self.conv3(x))\n",
    "    x = F.silu(self.conv4(x))\n",
    "    x = F.silu(self.conv5(x))\n",
    "    x = F.silu(self.conv6(x))\n",
    "    x = x.reshape(x.shape[0], 3)\n",
    "    x = self.fc1(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InertialNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InertialNet, self).__init__()\n",
    "        \n",
    "        self.conv2d_odometry = MobileNetV2(num_classes=3)\n",
    "        self.conv2d_inertial = MobileNetV2(num_classes=3)\n",
    "        self.conv1d_inertial = ConvNet1D()\n",
    "\n",
    "        self.fc1 = nn.Linear(6,6)\n",
    "        self.fc2 = nn.Linear(6,3)\n",
    "        self.fc3 = nn.Linear(3,3)\n",
    "\n",
    "    def forward(self, x, inertial_buffer):\n",
    "        x_odometry = self.conv2d_odometry(x)\n",
    "        x_inertial = self.conv2d_inertial(x)\n",
    "\n",
    "        x_inertial_unsqueezed = torch.unsqueeze(x_inertial, axis=2)\n",
    "        x_inertial_buffer = torch.concat([inertial_buffer, x_inertial_unsqueezed], axis=2)\n",
    "        x_inertial_refined = self.conv1d_inertial(x_inertial_buffer)\n",
    "\n",
    "        x_odometry = x_odometry.reshape((x.shape[0], -1))\n",
    "        x_inertial_refined = x_inertial_refined.reshape((x.shape[0], -1))\n",
    "        x = torch.concat([x_odometry, x_inertial_refined], axis=1)\n",
    "\n",
    "        x = F.silu(self.fc1(x))\n",
    "        x = F.silu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x, x_inertial, x_inertial_refined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_head(model):\n",
    "    n_inputs = model.classifier[0].in_features\n",
    "    classifier = nn.Linear(n_inputs, 100)\n",
    "    model.classifier[0] = classifier\n",
    "\n",
    "    n_inputs = model.classifier[3].in_features\n",
    "    classifier = nn.Linear(100, 3)\n",
    "    model.classifier[3] = classifier\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InertialNet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InertialNet2, self).__init__()\n",
    "        \n",
    "        self.conv2d_odometry = mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1)\n",
    "        self.conv2d_odometry = replace_head(self.conv2d_odometry)\n",
    "        self.conv2d_inertial = mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1)\n",
    "        self.conv2d_odometry = replace_head(self.conv2d_inertial)\n",
    "        self.conv1d_inertial = ConvNet1D()\n",
    "\n",
    "        self.fc1 = nn.Linear(6,6)\n",
    "        self.fc2 = nn.Linear(6,3)\n",
    "        self.fc3 = nn.Linear(3,3)\n",
    "\n",
    "    def forward(self, x, inertial_buffer):\n",
    "        x_odometry = self.conv2d_odometry(x)\n",
    "        x_inertial = self.conv2d_inertial(x)\n",
    "\n",
    "        x_inertial_unsqueezed = torch.unsqueeze(x_inertial, axis=2)\n",
    "        x_inertial_buffer = torch.concat([inertial_buffer, x_inertial_unsqueezed], axis=2)\n",
    "        x_inertial_refined = self.conv1d_inertial(x_inertial_buffer)\n",
    "\n",
    "        x_odometry = x_odometry.reshape((x.shape[0], -1))\n",
    "        x_inertial_refined = x_inertial_refined.reshape((x.shape[0], -1))\n",
    "        x = torch.concat([x_odometry, x_inertial_refined], axis=1)\n",
    "\n",
    "        x = F.silu(self.fc1(x))\n",
    "        x = F.silu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x, x_inertial, x_inertial_refined"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "  data = data - data.min()\n",
    "  data = data / data.max()\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    history_loss = 0\n",
    "    history_loss=0\n",
    "    history_odometry_loss=0\n",
    "    history_inertial_loss=0\n",
    "    history_inertial_refined_loss=0\n",
    "\n",
    "    for batch_idx, (data, inertials_buffer, labels_odometry, labels_inertial) in enumerate(train_loader):\n",
    "        # data preparation\n",
    "        data = normalize(data)\n",
    "        labels_odometry = labels_odometry.mean(axis=1)\n",
    "        inertials_buffer = inertials_buffer.mean(axis=2)\n",
    "        inertials_buffer = torch.moveaxis(inertials_buffer, 2, 1)\n",
    "        labels_inertial = labels_inertial.mean(axis=1)\n",
    "\n",
    "        data = data.to(device)\n",
    "        inertials_buffer = inertials_buffer.to(device)\n",
    "        labels_odometry = labels_odometry.to(device)\n",
    "        labels_inertial = labels_inertial.to(device)\n",
    "\n",
    "        #forward\n",
    "        optimizer.zero_grad()\n",
    "        out, out_inertial, out_inertial_refined = model(data, inertials_buffer)\n",
    "\n",
    "        # loss\n",
    "        odometry_loss = torch.sqrt(F.mse_loss(out, labels_odometry))\n",
    "        inertial_loss = torch.sqrt(F.mse_loss(out_inertial, labels_inertial))\n",
    "        inertial_refined_loss = torch.sqrt(F.mse_loss(out_inertial_refined, labels_inertial))\n",
    "        loss = odometry_loss + inertial_loss + inertial_refined_loss\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #stats\n",
    "        history_loss += loss.item()\n",
    "        history_odometry_loss += odometry_loss.item()\n",
    "        history_inertial_loss += inertial_loss.item()\n",
    "        history_inertial_refined_loss += inertial_refined_loss.item()\n",
    "\n",
    "        if batch_idx%(len(train_loader)//5)==0:\n",
    "            print(f\"\\t[# {batch_idx: 4}] train_loss: {loss.item():.6f}, odo_loss: {odometry_loss.item():.6f}, ine_loss: {inertial_loss.item():.6f}, ref_loss: {inertial_refined_loss.item():.6f}\")\n",
    "    \n",
    "    history_loss /= len(train_loader) # average epoch loss\n",
    "    history_odometry_loss /= len(train_loader)\n",
    "    history_inertial_loss /= len(train_loader)\n",
    "    history_inertial_refined_loss /= len(train_loader)\n",
    "    print(f\"\\ttrain_loss: {history_loss:.6f}, odo_loss: {history_odometry_loss:.6f}, ine_loss: {history_inertial_loss:.6f}, ref_loss: {history_inertial_refined_loss:.6f}\")\n",
    "    \n",
    "    return history_loss, history_odometry_loss, history_inertial_loss, history_inertial_refined_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, device, val_loader, epoch):\n",
    "    model.train()\n",
    "    history_loss=0\n",
    "    history_odometry_loss=0\n",
    "    history_inertial_loss=0\n",
    "    history_inertial_refined_loss=0\n",
    "\n",
    "    for batch_idx, (data, inertials_buffer, labels_odometry, labels_inertial) in enumerate(val_loader):\n",
    "        # data preparation\n",
    "        data = normalize(data)\n",
    "        labels_odometry = labels_odometry.mean(axis=1)\n",
    "        inertials_buffer = inertials_buffer.mean(axis=2)\n",
    "        inertials_buffer = torch.moveaxis(inertials_buffer, 2, 1)\n",
    "        labels_inertial = labels_inertial.mean(axis=1)\n",
    "\n",
    "        data = data.to(device)\n",
    "        inertials_buffer = inertials_buffer.to(device)\n",
    "        labels_odometry = labels_odometry.to(device)\n",
    "        labels_inertial = labels_inertial.to(device)\n",
    "\n",
    "        # forward\n",
    "        out, out_inertial, out_inertial_refined = model(data, inertials_buffer)\n",
    "\n",
    "        # loss\n",
    "        odometry_loss = torch.sqrt(F.mse_loss(out, labels_odometry))\n",
    "        inertial_loss = torch.sqrt(F.mse_loss(out_inertial, labels_inertial))\n",
    "        inertial_refined_loss = torch.sqrt(F.mse_loss(out_inertial_refined, labels_inertial))\n",
    "        loss = odometry_loss + inertial_loss + inertial_refined_loss\n",
    "        \n",
    "        #stats\n",
    "        history_loss += loss.item()\n",
    "        history_odometry_loss += odometry_loss.item()\n",
    "        history_inertial_loss += inertial_loss.item()\n",
    "        history_inertial_refined_loss += inertial_refined_loss.item()\n",
    "\n",
    "    history_loss /= len(val_loader) # average epoch loss\n",
    "    history_odometry_loss /= len(val_loader)\n",
    "    history_inertial_loss /= len(val_loader)\n",
    "    history_inertial_refined_loss /= len(val_loader)\n",
    "    print(f\"\\tval_loss: {history_loss:.6f}, odo_loss: {history_odometry_loss:.6f}, ine_loss: {history_inertial_loss:.6f}, ref_loss: {history_inertial_refined_loss:.6f}\")\n",
    "\n",
    "    return history_loss, history_odometry_loss, history_inertial_loss, history_inertial_refined_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "\t[#    0] train_loss: 18.536900, odo_loss: 17.134748, ine_loss: 0.676264, ref_loss: 0.725888\n",
      "\t[#  180] train_loss: 22.863979, odo_loss: 22.201708, ine_loss: 0.369722, ref_loss: 0.292549\n",
      "\t[#  360] train_loss: 19.769011, odo_loss: 19.168858, ine_loss: 0.346896, ref_loss: 0.253257\n",
      "\t[#  540] train_loss: 18.706205, odo_loss: 17.558844, ine_loss: 0.912996, ref_loss: 0.234366\n",
      "\t[#  720] train_loss: 18.767729, odo_loss: 17.398020, ine_loss: 1.052042, ref_loss: 0.317667\n",
      "\t[#  900] train_loss: 15.692014, odo_loss: 13.762267, ine_loss: 1.651571, ref_loss: 0.278175\n",
      "\ttrain_loss: 19.050353, odo_loss: 18.034054, ine_loss: 0.725502, ref_loss: 0.290797\n",
      "\tval_loss: 15.358599, odo_loss: 13.592765, ine_loss: 1.504053, ref_loss: 0.261781\n",
      "\t*** Personal Best ***\n",
      "Epoch 2/2000\n",
      "\t[#    0] train_loss: 12.353523, odo_loss: 10.662315, ine_loss: 1.436039, ref_loss: 0.255169\n",
      "\t[#  180] train_loss: 14.736344, odo_loss: 13.179420, ine_loss: 1.286616, ref_loss: 0.270307\n",
      "\t[#  360] train_loss: 13.067213, odo_loss: 11.671004, ine_loss: 1.040468, ref_loss: 0.355741\n",
      "\t[#  540] train_loss: 9.883199, odo_loss: 8.713314, ine_loss: 0.954618, ref_loss: 0.215266\n",
      "\t[#  720] train_loss: 12.032157, odo_loss: 10.671142, ine_loss: 1.124445, ref_loss: 0.236571\n",
      "\t[#  900] train_loss: 10.256164, odo_loss: 8.999200, ine_loss: 0.934250, ref_loss: 0.322714\n",
      "\ttrain_loss: 12.281238, odo_loss: 10.874090, ine_loss: 1.142419, ref_loss: 0.264729\n",
      "\tval_loss: 10.462215, odo_loss: 9.301320, ine_loss: 0.906286, ref_loss: 0.254609\n",
      "\t*** Personal Best ***\n",
      "Epoch 3/2000\n",
      "\t[#    0] train_loss: 9.194778, odo_loss: 7.934384, ine_loss: 0.964498, ref_loss: 0.295897\n",
      "\t[#  180] train_loss: 10.708104, odo_loss: 9.650922, ine_loss: 0.796780, ref_loss: 0.260403\n",
      "\t[#  360] train_loss: 9.756662, odo_loss: 8.723392, ine_loss: 0.779450, ref_loss: 0.253821\n",
      "\t[#  540] train_loss: 8.778183, odo_loss: 7.688451, ine_loss: 0.859384, ref_loss: 0.230347\n",
      "\t[#  720] train_loss: 11.711359, odo_loss: 10.804787, ine_loss: 0.707574, ref_loss: 0.198998\n",
      "\t[#  900] train_loss: 9.740107, odo_loss: 8.818860, ine_loss: 0.689446, ref_loss: 0.231801\n",
      "\ttrain_loss: 10.275757, odo_loss: 9.231774, ine_loss: 0.789851, ref_loss: 0.254132\n",
      "\tval_loss: 10.063586, odo_loss: 9.120634, ine_loss: 0.683120, ref_loss: 0.259832\n",
      "\t*** Personal Best ***\n",
      "Epoch 4/2000\n",
      "\t[#    0] train_loss: 10.957258, odo_loss: 9.953724, ine_loss: 0.722488, ref_loss: 0.281046\n",
      "\t[#  180] train_loss: 9.621970, odo_loss: 8.632568, ine_loss: 0.689836, ref_loss: 0.299565\n",
      "\t[#  360] train_loss: 11.365837, odo_loss: 10.390323, ine_loss: 0.708299, ref_loss: 0.267214\n",
      "\t[#  540] train_loss: 8.987087, odo_loss: 7.976097, ine_loss: 0.770362, ref_loss: 0.240630\n",
      "\t[#  720] train_loss: 13.596936, odo_loss: 12.682624, ine_loss: 0.675582, ref_loss: 0.238731\n",
      "\t[#  900] train_loss: 9.385355, odo_loss: 8.492130, ine_loss: 0.669554, ref_loss: 0.223671\n",
      "\ttrain_loss: 9.569551, odo_loss: 8.639712, ine_loss: 0.680482, ref_loss: 0.249356\n",
      "\tval_loss: 9.359286, odo_loss: 8.462624, ine_loss: 0.652724, ref_loss: 0.243938\n",
      "\t*** Personal Best ***\n",
      "Epoch 5/2000\n",
      "\t[#    0] train_loss: 10.132417, odo_loss: 9.092463, ine_loss: 0.745166, ref_loss: 0.294788\n",
      "\t[#  180] train_loss: 6.082519, odo_loss: 5.288026, ine_loss: 0.554423, ref_loss: 0.240070\n",
      "\t[#  360] train_loss: 8.319532, odo_loss: 7.504124, ine_loss: 0.598742, ref_loss: 0.216667\n",
      "\t[#  540] train_loss: 10.191121, odo_loss: 9.203711, ine_loss: 0.746122, ref_loss: 0.241289\n",
      "\t[#  720] train_loss: 10.808357, odo_loss: 9.787296, ine_loss: 0.754900, ref_loss: 0.266161\n",
      "\t[#  900] train_loss: 5.920269, odo_loss: 5.134354, ine_loss: 0.541560, ref_loss: 0.244355\n",
      "\ttrain_loss: 9.223298, odo_loss: 8.320879, ine_loss: 0.655433, ref_loss: 0.246985\n",
      "\tval_loss: 9.089402, odo_loss: 8.185535, ine_loss: 0.659492, ref_loss: 0.244376\n",
      "\t*** Personal Best ***\n",
      "Epoch 6/2000\n",
      "\t[#    0] train_loss: 8.327546, odo_loss: 7.351549, ine_loss: 0.701188, ref_loss: 0.274810\n",
      "\t[#  180] train_loss: 9.733889, odo_loss: 8.823957, ine_loss: 0.712167, ref_loss: 0.197764\n",
      "\t[#  360] train_loss: 10.158897, odo_loss: 9.213580, ine_loss: 0.675733, ref_loss: 0.269584\n",
      "\t[#  540] train_loss: 8.715450, odo_loss: 7.824648, ine_loss: 0.658059, ref_loss: 0.232742\n",
      "\t[#  720] train_loss: 8.661216, odo_loss: 7.797935, ine_loss: 0.629790, ref_loss: 0.233490\n",
      "\t[#  900] train_loss: 8.700264, odo_loss: 7.739198, ine_loss: 0.697175, ref_loss: 0.263891\n",
      "\ttrain_loss: 8.967630, odo_loss: 8.041927, ine_loss: 0.680174, ref_loss: 0.245529\n",
      "\tval_loss: 9.206838, odo_loss: 8.249257, ine_loss: 0.712862, ref_loss: 0.244718\n",
      "Epoch 7/2000\n",
      "\t[#    0] train_loss: 13.357382, odo_loss: 12.432247, ine_loss: 0.663156, ref_loss: 0.261979\n",
      "\t[#  180] train_loss: 9.445082, odo_loss: 8.577137, ine_loss: 0.632920, ref_loss: 0.235026\n",
      "\t[#  360] train_loss: 9.020117, odo_loss: 8.195705, ine_loss: 0.587510, ref_loss: 0.236901\n",
      "\t[#  540] train_loss: 11.372373, odo_loss: 10.410378, ine_loss: 0.748190, ref_loss: 0.213805\n",
      "\t[#  720] train_loss: 8.105373, odo_loss: 7.250138, ine_loss: 0.606515, ref_loss: 0.248720\n",
      "\t[#  900] train_loss: 8.702615, odo_loss: 7.765017, ine_loss: 0.690839, ref_loss: 0.246759\n",
      "\ttrain_loss: 8.516491, odo_loss: 7.572662, ine_loss: 0.700448, ref_loss: 0.243380\n",
      "\tval_loss: 8.268491, odo_loss: 7.347103, ine_loss: 0.680754, ref_loss: 0.240634\n",
      "\t*** Personal Best ***\n",
      "Epoch 8/2000\n",
      "\t[#    0] train_loss: 8.739070, odo_loss: 7.852505, ine_loss: 0.663303, ref_loss: 0.223262\n",
      "\t[#  180] train_loss: 8.754222, odo_loss: 7.968280, ine_loss: 0.587696, ref_loss: 0.198246\n",
      "\t[#  360] train_loss: 8.153556, odo_loss: 7.343876, ine_loss: 0.616045, ref_loss: 0.193635\n",
      "\t[#  540] train_loss: 9.388226, odo_loss: 8.275331, ine_loss: 0.854816, ref_loss: 0.258079\n",
      "\t[#  720] train_loss: 6.471696, odo_loss: 5.578965, ine_loss: 0.683015, ref_loss: 0.209717\n",
      "\t[#  900] train_loss: 5.380644, odo_loss: 4.413701, ine_loss: 0.709904, ref_loss: 0.257040\n",
      "\ttrain_loss: 7.754729, odo_loss: 6.817992, ine_loss: 0.696547, ref_loss: 0.240190\n",
      "\tval_loss: 7.535313, odo_loss: 6.592647, ine_loss: 0.704307, ref_loss: 0.238359\n",
      "\t*** Personal Best ***\n",
      "Epoch 9/2000\n",
      "\t[#    0] train_loss: 8.352308, odo_loss: 7.481277, ine_loss: 0.693184, ref_loss: 0.177847\n",
      "\t[#  180] train_loss: 7.789990, odo_loss: 6.769415, ine_loss: 0.695525, ref_loss: 0.325050\n",
      "\t[#  360] train_loss: 6.929461, odo_loss: 5.873617, ine_loss: 0.774743, ref_loss: 0.281101\n",
      "\t[#  540] train_loss: 7.757362, odo_loss: 6.687256, ine_loss: 0.812284, ref_loss: 0.257823\n",
      "\t[#  720] train_loss: 10.198589, odo_loss: 9.385235, ine_loss: 0.596501, ref_loss: 0.216853\n",
      "\t[#  900] train_loss: 6.047962, odo_loss: 5.156493, ine_loss: 0.657688, ref_loss: 0.233781\n",
      "\ttrain_loss: 7.433611, odo_loss: 6.508623, ine_loss: 0.686537, ref_loss: 0.238451\n",
      "\tval_loss: 7.520280, odo_loss: 6.591977, ine_loss: 0.691363, ref_loss: 0.236941\n",
      "\t*** Personal Best ***\n",
      "Epoch 10/2000\n",
      "\t[#    0] train_loss: 5.749128, odo_loss: 4.956235, ine_loss: 0.556112, ref_loss: 0.236781\n",
      "\t[#  180] train_loss: 6.766576, odo_loss: 5.861307, ine_loss: 0.678319, ref_loss: 0.226949\n",
      "\t[#  360] train_loss: 7.273996, odo_loss: 6.354034, ine_loss: 0.731523, ref_loss: 0.188440\n",
      "\t[#  540] train_loss: 5.780386, odo_loss: 4.954399, ine_loss: 0.594192, ref_loss: 0.231796\n",
      "\t[#  720] train_loss: 7.193370, odo_loss: 6.274923, ine_loss: 0.714821, ref_loss: 0.203626\n",
      "\t[#  900] train_loss: 6.814597, odo_loss: 6.000398, ine_loss: 0.595867, ref_loss: 0.218331\n",
      "\ttrain_loss: 7.089424, odo_loss: 6.177204, ine_loss: 0.675018, ref_loss: 0.237201\n",
      "\tval_loss: 6.860111, odo_loss: 5.957102, ine_loss: 0.663491, ref_loss: 0.239518\n",
      "\t*** Personal Best ***\n",
      "Epoch 11/2000\n",
      "\t[#    0] train_loss: 6.528986, odo_loss: 5.745432, ine_loss: 0.558249, ref_loss: 0.225304\n",
      "\t[#  180] train_loss: 5.406953, odo_loss: 4.492779, ine_loss: 0.683688, ref_loss: 0.230486\n",
      "\t[#  360] train_loss: 6.198750, odo_loss: 5.290161, ine_loss: 0.633043, ref_loss: 0.275547\n",
      "\t[#  540] train_loss: 7.988686, odo_loss: 7.095327, ine_loss: 0.683892, ref_loss: 0.209466\n",
      "\t[#  720] train_loss: 8.957393, odo_loss: 8.088390, ine_loss: 0.687217, ref_loss: 0.181786\n",
      "\t[#  900] train_loss: 8.917792, odo_loss: 8.045157, ine_loss: 0.655059, ref_loss: 0.217575\n",
      "\ttrain_loss: 6.883053, odo_loss: 5.987701, ine_loss: 0.659868, ref_loss: 0.235484\n",
      "\tval_loss: 6.520933, odo_loss: 5.635100, ine_loss: 0.652141, ref_loss: 0.233691\n",
      "\t*** Personal Best ***\n",
      "Epoch 12/2000\n",
      "\t[#    0] train_loss: 7.768053, odo_loss: 6.738925, ine_loss: 0.779096, ref_loss: 0.250032\n",
      "\t[#  180] train_loss: 8.407838, odo_loss: 7.418554, ine_loss: 0.712912, ref_loss: 0.276372\n",
      "\t[#  360] train_loss: 5.666164, odo_loss: 4.736120, ine_loss: 0.640539, ref_loss: 0.289505\n",
      "\t[#  540] train_loss: 6.365957, odo_loss: 5.398656, ine_loss: 0.698666, ref_loss: 0.268634\n",
      "\t[#  720] train_loss: 6.223690, odo_loss: 5.259046, ine_loss: 0.701846, ref_loss: 0.262798\n",
      "\t[#  900] train_loss: 7.402888, odo_loss: 6.639515, ine_loss: 0.539625, ref_loss: 0.223748\n",
      "\ttrain_loss: 6.345842, odo_loss: 5.461525, ine_loss: 0.651341, ref_loss: 0.232976\n",
      "\tval_loss: 6.321737, odo_loss: 5.448174, ine_loss: 0.641431, ref_loss: 0.232133\n",
      "\t*** Personal Best ***\n",
      "Epoch 13/2000\n",
      "\t[#    0] train_loss: 5.078966, odo_loss: 4.389472, ine_loss: 0.493856, ref_loss: 0.195638\n",
      "\t[#  180] train_loss: 6.001128, odo_loss: 5.288752, ine_loss: 0.522458, ref_loss: 0.189919\n",
      "\t[#  360] train_loss: 7.754154, odo_loss: 6.966618, ine_loss: 0.593774, ref_loss: 0.193761\n",
      "\t[#  540] train_loss: 4.213093, odo_loss: 3.380085, ine_loss: 0.609713, ref_loss: 0.223295\n",
      "\t[#  720] train_loss: 5.624187, odo_loss: 4.816972, ine_loss: 0.599384, ref_loss: 0.207831\n",
      "\t[#  900] train_loss: 5.905665, odo_loss: 4.940082, ine_loss: 0.698424, ref_loss: 0.267160\n",
      "\ttrain_loss: 6.445821, odo_loss: 5.577230, ine_loss: 0.635463, ref_loss: 0.233128\n",
      "\tval_loss: 6.141915, odo_loss: 5.273783, ine_loss: 0.636067, ref_loss: 0.232064\n",
      "\t*** Personal Best ***\n",
      "Epoch 14/2000\n",
      "\t[#    0] train_loss: 7.510538, odo_loss: 6.473656, ine_loss: 0.746706, ref_loss: 0.290176\n",
      "\t[#  180] train_loss: 6.783783, odo_loss: 5.909711, ine_loss: 0.629415, ref_loss: 0.244657\n",
      "\t[#  360] train_loss: 8.212523, odo_loss: 7.443182, ine_loss: 0.562707, ref_loss: 0.206635\n",
      "\t[#  540] train_loss: 5.868741, odo_loss: 5.118063, ine_loss: 0.535448, ref_loss: 0.215230\n",
      "\t[#  720] train_loss: 6.491646, odo_loss: 5.665409, ine_loss: 0.608689, ref_loss: 0.217548\n",
      "\t[#  900] train_loss: 5.454621, odo_loss: 4.578601, ine_loss: 0.620661, ref_loss: 0.255359\n",
      "\ttrain_loss: 6.062572, odo_loss: 5.203012, ine_loss: 0.629214, ref_loss: 0.230345\n",
      "\tval_loss: 5.941136, odo_loss: 5.090067, ine_loss: 0.620808, ref_loss: 0.230261\n",
      "\t*** Personal Best ***\n",
      "Epoch 15/2000\n",
      "\t[#    0] train_loss: 5.202430, odo_loss: 4.458920, ine_loss: 0.552038, ref_loss: 0.191472\n",
      "\t[#  180] train_loss: 4.888828, odo_loss: 3.992490, ine_loss: 0.621975, ref_loss: 0.274363\n",
      "\t[#  360] train_loss: 6.092061, odo_loss: 5.349151, ine_loss: 0.552859, ref_loss: 0.190051\n",
      "\t[#  540] train_loss: 5.264983, odo_loss: 4.299977, ine_loss: 0.708650, ref_loss: 0.256356\n",
      "\t[#  720] train_loss: 6.529244, odo_loss: 5.686923, ine_loss: 0.664059, ref_loss: 0.178262\n",
      "\t[#  900] train_loss: 5.417450, odo_loss: 4.620286, ine_loss: 0.605330, ref_loss: 0.191834\n",
      "\ttrain_loss: 5.862109, odo_loss: 5.012264, ine_loss: 0.620384, ref_loss: 0.229461\n",
      "\tval_loss: 5.599638, odo_loss: 4.758656, ine_loss: 0.613527, ref_loss: 0.227456\n",
      "\t*** Personal Best ***\n",
      "Epoch 16/2000\n",
      "\t[#    0] train_loss: 5.622849, odo_loss: 4.735119, ine_loss: 0.677502, ref_loss: 0.210227\n",
      "\t[#  180] train_loss: 7.624539, odo_loss: 6.682749, ine_loss: 0.662579, ref_loss: 0.279210\n",
      "\t[#  360] train_loss: 7.151979, odo_loss: 6.354376, ine_loss: 0.591423, ref_loss: 0.206181\n",
      "\t[#  540] train_loss: 7.222722, odo_loss: 6.244027, ine_loss: 0.710966, ref_loss: 0.267728\n",
      "\t[#  720] train_loss: 3.927373, odo_loss: 3.116642, ine_loss: 0.588810, ref_loss: 0.221921\n",
      "\t[#  900] train_loss: 6.275033, odo_loss: 5.525008, ine_loss: 0.548091, ref_loss: 0.201934\n",
      "\ttrain_loss: 5.467758, odo_loss: 4.625860, ine_loss: 0.614436, ref_loss: 0.227463\n",
      "\tval_loss: 5.352495, odo_loss: 4.521091, ine_loss: 0.606688, ref_loss: 0.224716\n",
      "\t*** Personal Best ***\n",
      "Epoch 17/2000\n",
      "\t[#    0] train_loss: 4.093949, odo_loss: 3.244732, ine_loss: 0.660409, ref_loss: 0.188808\n",
      "\t[#  180] train_loss: 4.928240, odo_loss: 4.090579, ine_loss: 0.581769, ref_loss: 0.255893\n",
      "\t[#  360] train_loss: 5.748115, odo_loss: 4.833487, ine_loss: 0.639368, ref_loss: 0.275260\n",
      "\t[#  540] train_loss: 3.772478, odo_loss: 2.836352, ine_loss: 0.682035, ref_loss: 0.254091\n",
      "\t[#  720] train_loss: 5.776389, odo_loss: 4.927141, ine_loss: 0.604961, ref_loss: 0.244287\n",
      "\t[#  900] train_loss: 6.328370, odo_loss: 5.551951, ine_loss: 0.579751, ref_loss: 0.196669\n",
      "\ttrain_loss: 5.412135, odo_loss: 4.579851, ine_loss: 0.606078, ref_loss: 0.226206\n",
      "\tval_loss: 5.224358, odo_loss: 4.394805, ine_loss: 0.603509, ref_loss: 0.226044\n",
      "\t*** Personal Best ***\n",
      "Epoch 18/2000\n",
      "\t[#    0] train_loss: 5.328944, odo_loss: 4.352513, ine_loss: 0.657633, ref_loss: 0.318798\n",
      "\t[#  180] train_loss: 5.622846, odo_loss: 4.774190, ine_loss: 0.603201, ref_loss: 0.245455\n",
      "\t[#  360] train_loss: 4.972244, odo_loss: 4.142121, ine_loss: 0.607607, ref_loss: 0.222516\n",
      "\t[#  540] train_loss: 3.773103, odo_loss: 3.024423, ine_loss: 0.542754, ref_loss: 0.205926\n",
      "\t[#  720] train_loss: 3.595502, odo_loss: 2.932326, ine_loss: 0.472382, ref_loss: 0.190794\n",
      "\t[#  900] train_loss: 5.562701, odo_loss: 4.574731, ine_loss: 0.761423, ref_loss: 0.226547\n",
      "\ttrain_loss: 5.397657, odo_loss: 4.575181, ine_loss: 0.596899, ref_loss: 0.225577\n",
      "\tval_loss: 5.186832, odo_loss: 4.376298, ine_loss: 0.585551, ref_loss: 0.224983\n",
      "\t*** Personal Best ***\n",
      "Epoch 19/2000\n",
      "\t[#    0] train_loss: 5.357717, odo_loss: 4.526849, ine_loss: 0.619469, ref_loss: 0.211398\n",
      "\t[#  180] train_loss: 4.099600, odo_loss: 3.240033, ine_loss: 0.608279, ref_loss: 0.251288\n",
      "\t[#  360] train_loss: 5.308990, odo_loss: 4.615396, ine_loss: 0.491984, ref_loss: 0.201609\n",
      "\t[#  540] train_loss: 4.200995, odo_loss: 3.467058, ine_loss: 0.520783, ref_loss: 0.213155\n",
      "\t[#  720] train_loss: 5.485725, odo_loss: 4.690784, ine_loss: 0.587418, ref_loss: 0.207523\n",
      "\t[#  900] train_loss: 6.340807, odo_loss: 5.576050, ine_loss: 0.571220, ref_loss: 0.193538\n",
      "\ttrain_loss: 5.075841, odo_loss: 4.262426, ine_loss: 0.590150, ref_loss: 0.223265\n",
      "\tval_loss: 5.186694, odo_loss: 4.374941, ine_loss: 0.584699, ref_loss: 0.227055\n",
      "\t*** Personal Best ***\n",
      "Epoch 20/2000\n",
      "\t[#    0] train_loss: 5.277606, odo_loss: 4.569060, ine_loss: 0.509550, ref_loss: 0.198996\n",
      "\t[#  180] train_loss: 5.577865, odo_loss: 4.782474, ine_loss: 0.585455, ref_loss: 0.209936\n",
      "\t[#  360] train_loss: 4.744134, odo_loss: 3.884218, ine_loss: 0.613231, ref_loss: 0.246684\n",
      "\t[#  540] train_loss: 3.477873, odo_loss: 2.626263, ine_loss: 0.589347, ref_loss: 0.262263\n",
      "\t[#  720] train_loss: 3.569525, odo_loss: 2.830568, ine_loss: 0.570539, ref_loss: 0.168418\n",
      "\t[#  900] train_loss: 6.882624, odo_loss: 6.008239, ine_loss: 0.672740, ref_loss: 0.201644\n",
      "\ttrain_loss: 5.068145, odo_loss: 4.261808, ine_loss: 0.583438, ref_loss: 0.222899\n",
      "\tval_loss: 4.725792, odo_loss: 3.928842, ine_loss: 0.575862, ref_loss: 0.221087\n",
      "\t*** Personal Best ***\n",
      "Epoch 21/2000\n",
      "\t[#    0] train_loss: 5.681766, odo_loss: 4.895121, ine_loss: 0.582126, ref_loss: 0.204519\n",
      "\t[#  180] train_loss: 5.308265, odo_loss: 4.496950, ine_loss: 0.611297, ref_loss: 0.200018\n",
      "\t[#  360] train_loss: 5.803716, odo_loss: 5.003188, ine_loss: 0.586752, ref_loss: 0.213777\n",
      "\t[#  540] train_loss: 3.487541, odo_loss: 2.742137, ine_loss: 0.523465, ref_loss: 0.221939\n",
      "\t[#  720] train_loss: 5.782475, odo_loss: 4.953067, ine_loss: 0.620946, ref_loss: 0.208462\n",
      "\t[#  900] train_loss: 3.903640, odo_loss: 3.178227, ine_loss: 0.516864, ref_loss: 0.208548\n",
      "\ttrain_loss: 4.644635, odo_loss: 3.845095, ine_loss: 0.579007, ref_loss: 0.220533\n",
      "\tval_loss: 4.641598, odo_loss: 3.854369, ine_loss: 0.567987, ref_loss: 0.219242\n",
      "\t*** Personal Best ***\n",
      "Epoch 22/2000\n",
      "\t[#    0] train_loss: 3.703652, odo_loss: 2.937428, ine_loss: 0.541612, ref_loss: 0.224613\n",
      "\t[#  180] train_loss: 3.301471, odo_loss: 2.524171, ine_loss: 0.541282, ref_loss: 0.236018\n",
      "\t[#  360] train_loss: 5.224002, odo_loss: 4.446075, ine_loss: 0.593088, ref_loss: 0.184839\n",
      "\t[#  540] train_loss: 4.081224, odo_loss: 3.390148, ine_loss: 0.466944, ref_loss: 0.224132\n",
      "\t[#  720] train_loss: 4.429348, odo_loss: 3.642088, ine_loss: 0.552606, ref_loss: 0.234653\n",
      "\t[#  900] train_loss: 3.841785, odo_loss: 3.018236, ine_loss: 0.570125, ref_loss: 0.253424\n",
      "\ttrain_loss: 4.513497, odo_loss: 3.723474, ine_loss: 0.571565, ref_loss: 0.218458\n",
      "\tval_loss: 4.421867, odo_loss: 3.638615, ine_loss: 0.563735, ref_loss: 0.219517\n",
      "\t*** Personal Best ***\n",
      "Epoch 23/2000\n",
      "\t[#    0] train_loss: 4.742625, odo_loss: 3.880583, ine_loss: 0.639386, ref_loss: 0.222657\n",
      "\t[#  180] train_loss: 3.540656, odo_loss: 2.560063, ine_loss: 0.720012, ref_loss: 0.260581\n",
      "\t[#  360] train_loss: 5.697339, odo_loss: 4.981515, ine_loss: 0.533195, ref_loss: 0.182628\n",
      "\t[#  540] train_loss: 5.111115, odo_loss: 4.241602, ine_loss: 0.630147, ref_loss: 0.239366\n",
      "\t[#  720] train_loss: 4.412028, odo_loss: 3.599217, ine_loss: 0.608258, ref_loss: 0.204553\n",
      "\t[#  900] train_loss: 6.303791, odo_loss: 5.506882, ine_loss: 0.563055, ref_loss: 0.233854\n",
      "\ttrain_loss: 4.406800, odo_loss: 3.624594, ine_loss: 0.565452, ref_loss: 0.216754\n",
      "\tval_loss: 5.799534, odo_loss: 5.026097, ine_loss: 0.556536, ref_loss: 0.216900\n",
      "Epoch 24/2000\n",
      "\t[#    0] train_loss: 4.180007, odo_loss: 3.358115, ine_loss: 0.632700, ref_loss: 0.189192\n",
      "\t[#  180] train_loss: 5.136797, odo_loss: 4.303661, ine_loss: 0.597418, ref_loss: 0.235718\n",
      "\t[#  360] train_loss: 4.429636, odo_loss: 3.652343, ine_loss: 0.582012, ref_loss: 0.195281\n",
      "\t[#  540] train_loss: 3.348252, odo_loss: 2.537185, ine_loss: 0.596350, ref_loss: 0.214717\n",
      "\t[#  720] train_loss: 5.597198, odo_loss: 4.824460, ine_loss: 0.551745, ref_loss: 0.220992\n",
      "\t[#  900] train_loss: 3.356062, odo_loss: 2.568257, ine_loss: 0.562900, ref_loss: 0.224905\n",
      "\ttrain_loss: 4.892029, odo_loss: 4.113027, ine_loss: 0.559891, ref_loss: 0.219111\n",
      "\tval_loss: 4.387850, odo_loss: 3.617243, ine_loss: 0.552281, ref_loss: 0.218327\n",
      "\t*** Personal Best ***\n",
      "Epoch 25/2000\n",
      "\t[#    0] train_loss: 3.027941, odo_loss: 2.268952, ine_loss: 0.575808, ref_loss: 0.183181\n",
      "\t[#  180] train_loss: 3.983113, odo_loss: 3.245472, ine_loss: 0.532613, ref_loss: 0.205028\n",
      "\t[#  360] train_loss: 3.296282, odo_loss: 2.503251, ine_loss: 0.547079, ref_loss: 0.245952\n",
      "\t[#  540] train_loss: 3.752720, odo_loss: 2.838863, ine_loss: 0.689375, ref_loss: 0.224481\n",
      "\t[#  720] train_loss: 3.513300, odo_loss: 2.643559, ine_loss: 0.627296, ref_loss: 0.242445\n",
      "\t[#  900] train_loss: 2.683702, odo_loss: 2.004948, ine_loss: 0.466398, ref_loss: 0.212355\n",
      "\ttrain_loss: 4.306966, odo_loss: 3.534421, ine_loss: 0.557299, ref_loss: 0.215246\n",
      "\tval_loss: 4.112750, odo_loss: 3.356659, ine_loss: 0.542355, ref_loss: 0.213737\n",
      "\t*** Personal Best ***\n",
      "Epoch 26/2000\n",
      "\t[#    0] train_loss: 4.001339, odo_loss: 3.327677, ine_loss: 0.486669, ref_loss: 0.186995\n",
      "\t[#  180] train_loss: 4.042152, odo_loss: 3.316518, ine_loss: 0.513745, ref_loss: 0.211889\n",
      "\t[#  360] train_loss: 5.591993, odo_loss: 4.710123, ine_loss: 0.645132, ref_loss: 0.236738\n",
      "\t[#  540] train_loss: 4.291351, odo_loss: 3.574016, ine_loss: 0.549024, ref_loss: 0.168311\n",
      "\t[#  720] train_loss: 4.228462, odo_loss: 3.492874, ine_loss: 0.506970, ref_loss: 0.228617\n",
      "\t[#  900] train_loss: 5.262083, odo_loss: 4.451409, ine_loss: 0.618042, ref_loss: 0.192632\n",
      "\ttrain_loss: 4.089891, odo_loss: 3.327998, ine_loss: 0.548503, ref_loss: 0.213390\n",
      "\tval_loss: 4.093169, odo_loss: 3.337179, ine_loss: 0.543493, ref_loss: 0.212497\n",
      "\t*** Personal Best ***\n",
      "Epoch 27/2000\n",
      "\t[#    0] train_loss: 3.258864, odo_loss: 2.464611, ine_loss: 0.567229, ref_loss: 0.227024\n",
      "\t[#  180] train_loss: 4.248851, odo_loss: 3.535503, ine_loss: 0.500107, ref_loss: 0.213242\n",
      "\t[#  360] train_loss: 3.787509, odo_loss: 3.088624, ine_loss: 0.487410, ref_loss: 0.211475\n",
      "\t[#  540] train_loss: 4.884996, odo_loss: 4.101682, ine_loss: 0.566041, ref_loss: 0.217274\n",
      "\t[#  720] train_loss: 5.168022, odo_loss: 4.427512, ine_loss: 0.511887, ref_loss: 0.228623\n",
      "\t[#  900] train_loss: 5.613484, odo_loss: 4.905513, ine_loss: 0.490734, ref_loss: 0.217237\n",
      "\ttrain_loss: 4.328565, odo_loss: 3.569353, ine_loss: 0.545557, ref_loss: 0.213655\n",
      "\tval_loss: 4.815303, odo_loss: 4.053776, ine_loss: 0.540539, ref_loss: 0.220988\n",
      "Epoch 28/2000\n",
      "\t[#    0] train_loss: 3.560099, odo_loss: 2.686067, ine_loss: 0.629531, ref_loss: 0.244501\n",
      "\t[#  180] train_loss: 5.215311, odo_loss: 4.383394, ine_loss: 0.611790, ref_loss: 0.220127\n",
      "\t[#  360] train_loss: 3.954989, odo_loss: 3.209126, ine_loss: 0.538501, ref_loss: 0.207362\n",
      "\t[#  540] train_loss: 4.328205, odo_loss: 3.672982, ine_loss: 0.484920, ref_loss: 0.170304\n",
      "\t[#  720] train_loss: 3.055015, odo_loss: 2.388099, ine_loss: 0.499684, ref_loss: 0.167232\n",
      "\t[#  900] train_loss: 4.059193, odo_loss: 3.246722, ine_loss: 0.594207, ref_loss: 0.218265\n",
      "\ttrain_loss: 4.191395, odo_loss: 3.436658, ine_loss: 0.541942, ref_loss: 0.212795\n",
      "\tval_loss: 3.988597, odo_loss: 3.238395, ine_loss: 0.535263, ref_loss: 0.214939\n",
      "\t*** Personal Best ***\n",
      "Epoch 29/2000\n",
      "\t[#    0] train_loss: 2.913362, odo_loss: 2.350470, ine_loss: 0.382642, ref_loss: 0.180251\n",
      "\t[#  180] train_loss: 4.360992, odo_loss: 3.628974, ine_loss: 0.505920, ref_loss: 0.226098\n",
      "\t[#  360] train_loss: 5.382057, odo_loss: 4.629361, ine_loss: 0.575069, ref_loss: 0.177626\n",
      "\t[#  540] train_loss: 3.622263, odo_loss: 2.752689, ine_loss: 0.624281, ref_loss: 0.245293\n",
      "\t[#  720] train_loss: 3.990699, odo_loss: 3.314109, ine_loss: 0.497384, ref_loss: 0.179206\n",
      "\t[#  900] train_loss: 4.250663, odo_loss: 3.457667, ine_loss: 0.609177, ref_loss: 0.183819\n",
      "\ttrain_loss: 3.993078, odo_loss: 3.244195, ine_loss: 0.537942, ref_loss: 0.210941\n",
      "\tval_loss: 3.873114, odo_loss: 3.122845, ine_loss: 0.537548, ref_loss: 0.212722\n",
      "\t*** Personal Best ***\n",
      "Epoch 30/2000\n",
      "\t[#    0] train_loss: 3.024762, odo_loss: 2.354479, ine_loss: 0.477784, ref_loss: 0.192499\n",
      "\t[#  180] train_loss: 3.210803, odo_loss: 2.500094, ine_loss: 0.494111, ref_loss: 0.216598\n",
      "\t[#  360] train_loss: 4.072649, odo_loss: 3.359577, ine_loss: 0.511969, ref_loss: 0.201103\n",
      "\t[#  540] train_loss: 3.349848, odo_loss: 2.692641, ine_loss: 0.450979, ref_loss: 0.206228\n",
      "\t[#  720] train_loss: 3.317027, odo_loss: 2.574711, ine_loss: 0.565066, ref_loss: 0.177250\n",
      "\t[#  900] train_loss: 5.169974, odo_loss: 4.444390, ine_loss: 0.528165, ref_loss: 0.197419\n",
      "\ttrain_loss: 3.847023, odo_loss: 3.101693, ine_loss: 0.535892, ref_loss: 0.209438\n",
      "\tval_loss: 3.891664, odo_loss: 3.152635, ine_loss: 0.529449, ref_loss: 0.209580\n",
      "Epoch 31/2000\n",
      "\t[#    0] train_loss: 2.640538, odo_loss: 1.919106, ine_loss: 0.524660, ref_loss: 0.196772\n",
      "\t[#  180] train_loss: 3.220237, odo_loss: 2.541997, ine_loss: 0.445685, ref_loss: 0.232554\n",
      "\t[#  360] train_loss: 4.647674, odo_loss: 3.895762, ine_loss: 0.519686, ref_loss: 0.232226\n",
      "\t[#  540] train_loss: 3.087624, odo_loss: 2.432500, ine_loss: 0.451889, ref_loss: 0.203236\n",
      "\t[#  720] train_loss: 4.102224, odo_loss: 3.393641, ine_loss: 0.507604, ref_loss: 0.200978\n",
      "\t[#  900] train_loss: 4.721567, odo_loss: 4.008969, ine_loss: 0.512665, ref_loss: 0.199933\n",
      "\ttrain_loss: 4.137896, odo_loss: 3.394805, ine_loss: 0.533450, ref_loss: 0.209641\n",
      "\tval_loss: 4.822124, odo_loss: 4.067201, ine_loss: 0.536562, ref_loss: 0.218361\n",
      "Epoch 32/2000\n",
      "\t[#    0] train_loss: 4.497593, odo_loss: 3.667881, ine_loss: 0.557833, ref_loss: 0.271878\n",
      "\t[#  180] train_loss: 3.590136, odo_loss: 2.960095, ine_loss: 0.438293, ref_loss: 0.191747\n",
      "\t[#  360] train_loss: 3.474219, odo_loss: 2.757958, ine_loss: 0.505681, ref_loss: 0.210579\n",
      "\t[#  540] train_loss: 5.017135, odo_loss: 4.275510, ine_loss: 0.526677, ref_loss: 0.214948\n",
      "\t[#  720] train_loss: 4.765074, odo_loss: 3.909810, ine_loss: 0.604757, ref_loss: 0.250508\n",
      "\t[#  900] train_loss: 3.326459, odo_loss: 2.687487, ine_loss: 0.470371, ref_loss: 0.168601\n",
      "\ttrain_loss: 3.868081, odo_loss: 3.126521, ine_loss: 0.531826, ref_loss: 0.209734\n",
      "\tval_loss: 3.714389, odo_loss: 2.970277, ine_loss: 0.532889, ref_loss: 0.211223\n",
      "\t*** Personal Best ***\n",
      "Epoch 33/2000\n",
      "\t[#    0] train_loss: 3.012197, odo_loss: 2.221610, ine_loss: 0.568354, ref_loss: 0.222232\n",
      "\t[#  180] train_loss: 2.811625, odo_loss: 2.115338, ine_loss: 0.484985, ref_loss: 0.211303\n",
      "\t[#  360] train_loss: 4.115958, odo_loss: 3.352566, ine_loss: 0.557527, ref_loss: 0.205865\n",
      "\t[#  540] train_loss: 3.308900, odo_loss: 2.607256, ine_loss: 0.505948, ref_loss: 0.195696\n",
      "\t[#  720] train_loss: 3.547136, odo_loss: 2.805261, ine_loss: 0.535129, ref_loss: 0.206746\n",
      "\t[#  900] train_loss: 3.338128, odo_loss: 2.562791, ine_loss: 0.574612, ref_loss: 0.200725\n",
      "\ttrain_loss: 3.642079, odo_loss: 2.904258, ine_loss: 0.530702, ref_loss: 0.207119\n",
      "\tval_loss: 3.615055, odo_loss: 2.880211, ine_loss: 0.526775, ref_loss: 0.208069\n",
      "\t*** Personal Best ***\n",
      "Epoch 34/2000\n",
      "\t[#    0] train_loss: 3.270043, odo_loss: 2.597911, ine_loss: 0.453494, ref_loss: 0.218638\n",
      "\t[#  180] train_loss: 2.524667, odo_loss: 1.903213, ine_loss: 0.401315, ref_loss: 0.220140\n",
      "\t[#  360] train_loss: 3.134987, odo_loss: 2.443372, ine_loss: 0.480053, ref_loss: 0.211563\n",
      "\t[#  540] train_loss: 4.240605, odo_loss: 3.391156, ine_loss: 0.569058, ref_loss: 0.280390\n",
      "\t[#  720] train_loss: 3.422766, odo_loss: 2.613705, ine_loss: 0.616800, ref_loss: 0.192261\n",
      "\t[#  900] train_loss: 4.971028, odo_loss: 4.231754, ine_loss: 0.546610, ref_loss: 0.192664\n",
      "\ttrain_loss: 3.551781, odo_loss: 2.818757, ine_loss: 0.527614, ref_loss: 0.205410\n",
      "\tval_loss: 3.517460, odo_loss: 2.783950, ine_loss: 0.525303, ref_loss: 0.208208\n",
      "\t*** Personal Best ***\n",
      "Epoch 35/2000\n",
      "\t[#    0] train_loss: 4.303907, odo_loss: 3.553552, ine_loss: 0.567076, ref_loss: 0.183280\n",
      "\t[#  180] train_loss: 3.740439, odo_loss: 2.998831, ine_loss: 0.535258, ref_loss: 0.206351\n",
      "\t[#  360] train_loss: 3.794209, odo_loss: 3.110666, ine_loss: 0.490840, ref_loss: 0.192703\n",
      "\t[#  540] train_loss: 3.057843, odo_loss: 2.243830, ine_loss: 0.598418, ref_loss: 0.215594\n",
      "\t[#  720] train_loss: 2.937911, odo_loss: 2.244131, ine_loss: 0.472668, ref_loss: 0.221111\n",
      "\t[#  900] train_loss: 2.934948, odo_loss: 2.177907, ine_loss: 0.571054, ref_loss: 0.185987\n",
      "\ttrain_loss: 3.475874, odo_loss: 2.744863, ine_loss: 0.526592, ref_loss: 0.204419\n",
      "\tval_loss: 3.650464, odo_loss: 2.928696, ine_loss: 0.515117, ref_loss: 0.206651\n",
      "Epoch 36/2000\n",
      "\t[#    0] train_loss: 4.055325, odo_loss: 3.383395, ine_loss: 0.471989, ref_loss: 0.199940\n",
      "\t[#  180] train_loss: 3.464186, odo_loss: 2.807420, ine_loss: 0.481990, ref_loss: 0.174776\n",
      "\t[#  360] train_loss: 3.642109, odo_loss: 2.941633, ine_loss: 0.479375, ref_loss: 0.221101\n",
      "\t[#  540] train_loss: 3.037920, odo_loss: 2.397579, ine_loss: 0.454261, ref_loss: 0.186080\n",
      "\t[#  720] train_loss: 4.961801, odo_loss: 4.094250, ine_loss: 0.662582, ref_loss: 0.204969\n",
      "\t[#  900] train_loss: 3.570643, odo_loss: 2.645150, ine_loss: 0.701956, ref_loss: 0.223538\n",
      "\ttrain_loss: 3.441822, odo_loss: 2.712881, ine_loss: 0.526180, ref_loss: 0.202761\n",
      "\tval_loss: 3.579357, odo_loss: 2.848241, ine_loss: 0.525709, ref_loss: 0.205407\n",
      "Epoch 37/2000\n",
      "\t[#    0] train_loss: 3.941247, odo_loss: 3.127148, ine_loss: 0.599845, ref_loss: 0.214254\n",
      "\t[#  180] train_loss: 9.132352, odo_loss: 8.411183, ine_loss: 0.526585, ref_loss: 0.194584\n",
      "\t[#  360] train_loss: 3.357962, odo_loss: 2.672321, ine_loss: 0.475009, ref_loss: 0.210631\n",
      "\t[#  540] train_loss: 4.008525, odo_loss: 3.278064, ine_loss: 0.512190, ref_loss: 0.218271\n",
      "\t[#  720] train_loss: 3.529905, odo_loss: 2.627802, ine_loss: 0.654931, ref_loss: 0.247171\n",
      "\t[#  900] train_loss: 3.065924, odo_loss: 2.299148, ine_loss: 0.564023, ref_loss: 0.202753\n",
      "\ttrain_loss: 4.140288, odo_loss: 3.409846, ine_loss: 0.524382, ref_loss: 0.206060\n",
      "\tval_loss: 3.492671, odo_loss: 2.764292, ine_loss: 0.521469, ref_loss: 0.206910\n",
      "\t*** Personal Best ***\n",
      "Epoch 38/2000\n",
      "\t[#    0] train_loss: 3.432434, odo_loss: 2.779099, ine_loss: 0.476783, ref_loss: 0.176553\n",
      "\t[#  180] train_loss: 3.094958, odo_loss: 2.399291, ine_loss: 0.529019, ref_loss: 0.166649\n",
      "\t[#  360] train_loss: 3.012967, odo_loss: 2.331747, ine_loss: 0.478779, ref_loss: 0.202441\n",
      "\t[#  540] train_loss: 3.631032, odo_loss: 2.931113, ine_loss: 0.503162, ref_loss: 0.196757\n",
      "\t[#  720] train_loss: 2.873242, odo_loss: 2.164786, ine_loss: 0.456543, ref_loss: 0.251913\n",
      "\t[#  900] train_loss: 3.852143, odo_loss: 3.026450, ine_loss: 0.599482, ref_loss: 0.226212\n",
      "\ttrain_loss: 3.438205, odo_loss: 2.712817, ine_loss: 0.523100, ref_loss: 0.202289\n",
      "\tval_loss: 3.576426, odo_loss: 2.847199, ine_loss: 0.522561, ref_loss: 0.206666\n",
      "Epoch 39/2000\n",
      "\t[#    0] train_loss: 3.307375, odo_loss: 2.667907, ine_loss: 0.435622, ref_loss: 0.203846\n",
      "\t[#  180] train_loss: 3.743680, odo_loss: 2.998472, ine_loss: 0.525963, ref_loss: 0.219245\n",
      "\t[#  360] train_loss: 3.690005, odo_loss: 3.032649, ine_loss: 0.464977, ref_loss: 0.192379\n",
      "\t[#  540] train_loss: 4.221393, odo_loss: 3.511669, ine_loss: 0.504002, ref_loss: 0.205723\n",
      "\t[#  720] train_loss: 3.668894, odo_loss: 2.971983, ine_loss: 0.502387, ref_loss: 0.194524\n",
      "\t[#  900] train_loss: 2.875364, odo_loss: 2.132603, ine_loss: 0.505132, ref_loss: 0.237629\n",
      "\ttrain_loss: 3.350477, odo_loss: 2.626674, ine_loss: 0.522472, ref_loss: 0.201331\n",
      "\tval_loss: 3.292021, odo_loss: 2.572139, ine_loss: 0.514556, ref_loss: 0.205326\n",
      "\t*** Personal Best ***\n",
      "Epoch 40/2000\n",
      "\t[#    0] train_loss: 2.870949, odo_loss: 2.130578, ine_loss: 0.471590, ref_loss: 0.268781\n",
      "\t[#  180] train_loss: 2.744738, odo_loss: 1.983933, ine_loss: 0.568829, ref_loss: 0.191976\n",
      "\t[#  360] train_loss: 2.963168, odo_loss: 2.304773, ine_loss: 0.492115, ref_loss: 0.166279\n",
      "\t[#  540] train_loss: 2.815033, odo_loss: 2.229791, ine_loss: 0.387177, ref_loss: 0.198066\n",
      "\t[#  720] train_loss: 2.802346, odo_loss: 2.042157, ine_loss: 0.552681, ref_loss: 0.207508\n",
      "\t[#  900] train_loss: 4.028965, odo_loss: 3.243703, ine_loss: 0.538861, ref_loss: 0.246402\n",
      "\ttrain_loss: 3.302464, odo_loss: 2.581607, ine_loss: 0.521069, ref_loss: 0.199789\n",
      "\tval_loss: 3.396366, odo_loss: 2.665662, ine_loss: 0.526101, ref_loss: 0.204603\n",
      "Epoch 41/2000\n",
      "\t[#    0] train_loss: 3.216629, odo_loss: 2.429493, ine_loss: 0.564260, ref_loss: 0.222875\n",
      "\t[#  180] train_loss: 3.508414, odo_loss: 2.939981, ine_loss: 0.388988, ref_loss: 0.179444\n",
      "\t[#  360] train_loss: 2.687557, odo_loss: 1.965123, ine_loss: 0.547851, ref_loss: 0.174584\n",
      "\t[#  540] train_loss: 3.201114, odo_loss: 2.453691, ine_loss: 0.504767, ref_loss: 0.242657\n",
      "\t[#  720] train_loss: 2.370136, odo_loss: 1.702517, ine_loss: 0.505292, ref_loss: 0.162327\n",
      "\t[#  900] train_loss: 13.339328, odo_loss: 12.553165, ine_loss: 0.608164, ref_loss: 0.177999\n",
      "\ttrain_loss: 3.495811, odo_loss: 2.774904, ine_loss: 0.521208, ref_loss: 0.199699\n",
      "\tval_loss: 6.329439, odo_loss: 5.591256, ine_loss: 0.530934, ref_loss: 0.207249\n",
      "Epoch 42/2000\n",
      "\t[#    0] train_loss: 3.378731, odo_loss: 2.782416, ine_loss: 0.452896, ref_loss: 0.143419\n",
      "\t[#  180] train_loss: 3.194306, odo_loss: 2.345282, ine_loss: 0.657380, ref_loss: 0.191644\n",
      "\t[#  360] train_loss: 3.339632, odo_loss: 2.523485, ine_loss: 0.613440, ref_loss: 0.202707\n",
      "\t[#  540] train_loss: 4.135360, odo_loss: 3.523427, ine_loss: 0.426983, ref_loss: 0.184949\n",
      "\t[#  720] train_loss: 3.380871, odo_loss: 2.650665, ine_loss: 0.490024, ref_loss: 0.240181\n",
      "\t[#  900] train_loss: 2.548134, odo_loss: 1.903015, ine_loss: 0.466612, ref_loss: 0.178508\n",
      "\ttrain_loss: 3.650969, odo_loss: 2.928265, ine_loss: 0.521530, ref_loss: 0.201174\n",
      "\tval_loss: 3.328691, odo_loss: 2.610439, ine_loss: 0.513897, ref_loss: 0.204354\n",
      "Epoch 43/2000\n",
      "\t[#    0] train_loss: 3.267796, odo_loss: 2.461334, ine_loss: 0.586788, ref_loss: 0.219674\n",
      "\t[#  180] train_loss: 2.855715, odo_loss: 2.180740, ine_loss: 0.468624, ref_loss: 0.206352\n",
      "\t[#  360] train_loss: 3.787489, odo_loss: 3.033686, ine_loss: 0.556222, ref_loss: 0.197581\n",
      "\t[#  540] train_loss: 3.351810, odo_loss: 2.758842, ine_loss: 0.382483, ref_loss: 0.210485\n",
      "\t[#  720] train_loss: 2.798464, odo_loss: 2.123915, ine_loss: 0.499539, ref_loss: 0.175009\n",
      "\t[#  900] train_loss: 3.162312, odo_loss: 2.458156, ine_loss: 0.485859, ref_loss: 0.218297\n",
      "\ttrain_loss: 3.254294, odo_loss: 2.535709, ine_loss: 0.520592, ref_loss: 0.197992\n",
      "\tval_loss: 3.171528, odo_loss: 2.455341, ine_loss: 0.515881, ref_loss: 0.200305\n",
      "\t*** Personal Best ***\n",
      "Epoch 44/2000\n",
      "\t[#    0] train_loss: 3.351712, odo_loss: 2.654177, ine_loss: 0.524144, ref_loss: 0.173391\n",
      "\t[#  180] train_loss: 2.909688, odo_loss: 2.213971, ine_loss: 0.527646, ref_loss: 0.168072\n",
      "\t[#  360] train_loss: 3.918774, odo_loss: 3.137924, ine_loss: 0.573873, ref_loss: 0.206977\n",
      "\t[#  540] train_loss: 3.145501, odo_loss: 2.382182, ine_loss: 0.518572, ref_loss: 0.244748\n",
      "\t[#  720] train_loss: 3.274326, odo_loss: 2.577854, ine_loss: 0.478336, ref_loss: 0.218136\n",
      "\t[#  900] train_loss: 4.056024, odo_loss: 3.355930, ine_loss: 0.498319, ref_loss: 0.201774\n",
      "\ttrain_loss: 3.155654, odo_loss: 2.439855, ine_loss: 0.518949, ref_loss: 0.196850\n",
      "\tval_loss: 3.078129, odo_loss: 2.363905, ine_loss: 0.513846, ref_loss: 0.200378\n",
      "\t*** Personal Best ***\n",
      "Epoch 45/2000\n",
      "\t[#    0] train_loss: 3.271372, odo_loss: 2.610203, ine_loss: 0.501943, ref_loss: 0.159227\n",
      "\t[#  180] train_loss: 2.553430, odo_loss: 1.838874, ine_loss: 0.507083, ref_loss: 0.207473\n",
      "\t[#  360] train_loss: 3.498786, odo_loss: 2.712919, ine_loss: 0.563281, ref_loss: 0.222585\n",
      "\t[#  540] train_loss: 3.338639, odo_loss: 2.601155, ine_loss: 0.534272, ref_loss: 0.203212\n",
      "\t[#  720] train_loss: 3.280883, odo_loss: 2.599463, ine_loss: 0.495556, ref_loss: 0.185864\n",
      "\t[#  900] train_loss: 2.735458, odo_loss: 1.923252, ine_loss: 0.589158, ref_loss: 0.223048\n",
      "\ttrain_loss: 3.142783, odo_loss: 2.429183, ine_loss: 0.518031, ref_loss: 0.195568\n",
      "\tval_loss: 3.134135, odo_loss: 2.414998, ine_loss: 0.516649, ref_loss: 0.202488\n",
      "Epoch 46/2000\n",
      "\t[#    0] train_loss: 3.095213, odo_loss: 2.483559, ine_loss: 0.441838, ref_loss: 0.169817\n",
      "\t[#  180] train_loss: 3.281976, odo_loss: 2.625135, ine_loss: 0.478463, ref_loss: 0.178377\n",
      "\t[#  360] train_loss: 3.317296, odo_loss: 2.613473, ine_loss: 0.533122, ref_loss: 0.170700\n",
      "\t[#  540] train_loss: 3.099091, odo_loss: 2.343073, ine_loss: 0.583866, ref_loss: 0.172151\n",
      "\t[#  720] train_loss: 3.345946, odo_loss: 2.504752, ine_loss: 0.631623, ref_loss: 0.209571\n",
      "\t[#  900] train_loss: 3.500109, odo_loss: 2.917255, ine_loss: 0.409792, ref_loss: 0.173062\n",
      "\ttrain_loss: 3.104088, odo_loss: 2.391223, ine_loss: 0.517937, ref_loss: 0.194928\n",
      "\tval_loss: 3.077217, odo_loss: 2.366417, ine_loss: 0.512027, ref_loss: 0.198773\n",
      "Epoch 47/2000\n",
      "\t[#    0] train_loss: 3.552222, odo_loss: 2.710017, ine_loss: 0.644263, ref_loss: 0.197942\n",
      "\t[#  180] train_loss: 2.788010, odo_loss: 2.122214, ine_loss: 0.457422, ref_loss: 0.208373\n",
      "\t[#  360] train_loss: 3.108178, odo_loss: 2.463698, ine_loss: 0.449933, ref_loss: 0.194546\n",
      "\t[#  540] train_loss: 2.966839, odo_loss: 2.182848, ine_loss: 0.596627, ref_loss: 0.187364\n",
      "\t[#  720] train_loss: 3.110080, odo_loss: 2.511449, ine_loss: 0.410269, ref_loss: 0.188361\n",
      "\t[#  900] train_loss: 3.809982, odo_loss: 2.967620, ine_loss: 0.615798, ref_loss: 0.226563\n",
      "\ttrain_loss: 3.591884, odo_loss: 2.877620, ine_loss: 0.517798, ref_loss: 0.196465\n",
      "\tval_loss: 3.771224, odo_loss: 3.055377, ine_loss: 0.513428, ref_loss: 0.202418\n",
      "Epoch 48/2000\n",
      "\t[#    0] train_loss: 2.826985, odo_loss: 2.100076, ine_loss: 0.523520, ref_loss: 0.203389\n",
      "\t[#  180] train_loss: 6.532152, odo_loss: 5.836670, ine_loss: 0.510324, ref_loss: 0.185157\n",
      "\t[#  360] train_loss: 3.007850, odo_loss: 2.130813, ine_loss: 0.625768, ref_loss: 0.251269\n",
      "\t[#  540] train_loss: 2.993109, odo_loss: 2.263715, ine_loss: 0.550172, ref_loss: 0.179222\n",
      "\t[#  720] train_loss: 2.918382, odo_loss: 2.162508, ine_loss: 0.535846, ref_loss: 0.220028\n",
      "\t[#  900] train_loss: 2.976708, odo_loss: 2.271355, ine_loss: 0.465020, ref_loss: 0.240333\n",
      "\ttrain_loss: 3.330359, odo_loss: 2.616801, ine_loss: 0.517673, ref_loss: 0.195886\n",
      "\tval_loss: 3.216996, odo_loss: 2.497401, ine_loss: 0.517481, ref_loss: 0.202114\n",
      "Epoch 49/2000\n",
      "\t[#    0] train_loss: 3.323666, odo_loss: 2.512326, ine_loss: 0.613626, ref_loss: 0.197714\n",
      "\t[#  180] train_loss: 3.018336, odo_loss: 2.260723, ine_loss: 0.539700, ref_loss: 0.217913\n",
      "\t[#  360] train_loss: 2.880645, odo_loss: 2.213904, ine_loss: 0.471384, ref_loss: 0.195357\n",
      "\t[#  540] train_loss: 2.774921, odo_loss: 2.015738, ine_loss: 0.543595, ref_loss: 0.215588\n",
      "\t[#  720] train_loss: 3.659340, odo_loss: 3.045183, ine_loss: 0.442785, ref_loss: 0.171372\n",
      "\t[#  900] train_loss: 3.330294, odo_loss: 2.668930, ine_loss: 0.489563, ref_loss: 0.171801\n",
      "\ttrain_loss: 3.231234, odo_loss: 2.518700, ine_loss: 0.517088, ref_loss: 0.195446\n",
      "\tval_loss: 3.364332, odo_loss: 2.658411, ine_loss: 0.507057, ref_loss: 0.198864\n",
      "Epoch 50/2000\n",
      "\t[#    0] train_loss: 3.187746, odo_loss: 2.575358, ine_loss: 0.448681, ref_loss: 0.163708\n",
      "\t[#  180] train_loss: 2.789886, odo_loss: 2.138052, ine_loss: 0.446427, ref_loss: 0.205408\n",
      "\t[#  360] train_loss: 2.736581, odo_loss: 2.068784, ine_loss: 0.471516, ref_loss: 0.196280\n",
      "\t[#  540] train_loss: 4.090934, odo_loss: 3.221740, ine_loss: 0.627208, ref_loss: 0.241986\n",
      "\t[#  720] train_loss: 2.899342, odo_loss: 2.288491, ine_loss: 0.448250, ref_loss: 0.162601\n",
      "\t[#  900] train_loss: 3.440676, odo_loss: 2.770815, ine_loss: 0.499570, ref_loss: 0.170291\n",
      "\ttrain_loss: 3.143111, odo_loss: 2.434341, ine_loss: 0.515013, ref_loss: 0.193757\n",
      "\tval_loss: 3.122443, odo_loss: 2.407049, ine_loss: 0.514930, ref_loss: 0.200464\n",
      "Epoch 51/2000\n",
      "\t[#    0] train_loss: 2.691352, odo_loss: 2.011205, ine_loss: 0.489002, ref_loss: 0.191145\n",
      "\t[#  180] train_loss: 2.628491, odo_loss: 1.926269, ine_loss: 0.492698, ref_loss: 0.209524\n",
      "\t[#  360] train_loss: 3.056725, odo_loss: 2.467748, ine_loss: 0.436134, ref_loss: 0.152843\n",
      "\t[#  540] train_loss: 2.681245, odo_loss: 1.985076, ine_loss: 0.520153, ref_loss: 0.176015\n",
      "\t[#  720] train_loss: 3.251175, odo_loss: 2.412044, ine_loss: 0.581756, ref_loss: 0.257375\n",
      "\t[#  900] train_loss: 2.798709, odo_loss: 2.194976, ine_loss: 0.411486, ref_loss: 0.192247\n",
      "\ttrain_loss: 3.039167, odo_loss: 2.331912, ine_loss: 0.514945, ref_loss: 0.192310\n",
      "\tval_loss: 3.029271, odo_loss: 2.317631, ine_loss: 0.512137, ref_loss: 0.199503\n",
      "\t*** Personal Best ***\n",
      "Epoch 52/2000\n",
      "\t[#    0] train_loss: 3.690423, odo_loss: 3.060916, ine_loss: 0.439957, ref_loss: 0.189550\n",
      "\t[#  180] train_loss: 3.289983, odo_loss: 2.649491, ine_loss: 0.442942, ref_loss: 0.197550\n",
      "\t[#  360] train_loss: 2.989833, odo_loss: 2.340278, ine_loss: 0.487282, ref_loss: 0.162272\n",
      "\t[#  540] train_loss: 3.104294, odo_loss: 2.431010, ine_loss: 0.494119, ref_loss: 0.179164\n",
      "\t[#  720] train_loss: 2.774707, odo_loss: 2.142820, ine_loss: 0.443434, ref_loss: 0.188453\n",
      "\t[#  900] train_loss: 3.405944, odo_loss: 2.747417, ine_loss: 0.467762, ref_loss: 0.190765\n",
      "\ttrain_loss: 3.025894, odo_loss: 2.320239, ine_loss: 0.514258, ref_loss: 0.191397\n",
      "\tval_loss: 3.132840, odo_loss: 2.424980, ine_loss: 0.510359, ref_loss: 0.197501\n",
      "Epoch 53/2000\n",
      "\t[#    0] train_loss: 2.922943, odo_loss: 2.209346, ine_loss: 0.523353, ref_loss: 0.190245\n",
      "\t[#  180] train_loss: 3.700325, odo_loss: 2.947126, ine_loss: 0.539664, ref_loss: 0.213535\n",
      "\t[#  360] train_loss: 3.702133, odo_loss: 3.029781, ine_loss: 0.509237, ref_loss: 0.163115\n",
      "\t[#  540] train_loss: 3.496531, odo_loss: 2.764861, ine_loss: 0.519083, ref_loss: 0.212587\n",
      "\t[#  720] train_loss: 3.374793, odo_loss: 2.751134, ine_loss: 0.432506, ref_loss: 0.191153\n",
      "\t[#  900] train_loss: 2.982399, odo_loss: 2.384300, ine_loss: 0.409513, ref_loss: 0.188586\n",
      "\ttrain_loss: 3.392974, odo_loss: 2.687272, ine_loss: 0.513234, ref_loss: 0.192468\n",
      "\tval_loss: 3.160102, odo_loss: 2.445251, ine_loss: 0.515458, ref_loss: 0.199392\n",
      "Epoch 54/2000\n",
      "\t[#    0] train_loss: 3.498185, odo_loss: 2.659985, ine_loss: 0.632919, ref_loss: 0.205280\n",
      "\t[#  180] train_loss: 3.303891, odo_loss: 2.664302, ine_loss: 0.469995, ref_loss: 0.169594\n",
      "\t[#  360] train_loss: 3.264088, odo_loss: 2.421829, ine_loss: 0.647695, ref_loss: 0.194563\n",
      "\t[#  540] train_loss: 2.739136, odo_loss: 2.120990, ine_loss: 0.441500, ref_loss: 0.176646\n",
      "\t[#  720] train_loss: 3.241498, odo_loss: 2.466227, ine_loss: 0.590549, ref_loss: 0.184722\n",
      "\t[#  900] train_loss: 3.479718, odo_loss: 2.653375, ine_loss: 0.648789, ref_loss: 0.177554\n",
      "\ttrain_loss: 3.203552, odo_loss: 2.499070, ine_loss: 0.513475, ref_loss: 0.191008\n",
      "\tval_loss: 3.249050, odo_loss: 2.541486, ine_loss: 0.506979, ref_loss: 0.200585\n",
      "Epoch 55/2000\n",
      "\t[#    0] train_loss: 2.498459, odo_loss: 1.911953, ine_loss: 0.418775, ref_loss: 0.167730\n",
      "\t[#  180] train_loss: 3.658708, odo_loss: 2.975487, ine_loss: 0.501486, ref_loss: 0.181736\n",
      "\t[#  360] train_loss: 2.851559, odo_loss: 2.247330, ine_loss: 0.452163, ref_loss: 0.152066\n",
      "\t[#  540] train_loss: 3.593700, odo_loss: 2.809478, ine_loss: 0.566094, ref_loss: 0.218128\n",
      "\t[#  720] train_loss: 3.120394, odo_loss: 2.324212, ine_loss: 0.613800, ref_loss: 0.182382\n",
      "\t[#  900] train_loss: 2.603825, odo_loss: 1.943607, ine_loss: 0.450491, ref_loss: 0.209726\n",
      "\ttrain_loss: 3.241167, odo_loss: 2.536349, ine_loss: 0.513513, ref_loss: 0.191305\n",
      "\tval_loss: 3.131050, odo_loss: 2.427716, ine_loss: 0.506004, ref_loss: 0.197330\n",
      "Epoch 56/2000\n",
      "\t[#    0] train_loss: 3.228483, odo_loss: 2.536221, ine_loss: 0.508765, ref_loss: 0.183498\n",
      "\t[#  180] train_loss: 3.056567, odo_loss: 2.287052, ine_loss: 0.569009, ref_loss: 0.200506\n",
      "\t[#  360] train_loss: 2.758215, odo_loss: 2.147374, ine_loss: 0.433191, ref_loss: 0.177650\n",
      "\t[#  540] train_loss: 3.149214, odo_loss: 2.324667, ine_loss: 0.605508, ref_loss: 0.219039\n",
      "\t[#  720] train_loss: 2.887364, odo_loss: 2.178462, ine_loss: 0.535992, ref_loss: 0.172911\n",
      "\t[#  900] train_loss: 2.759112, odo_loss: 2.092416, ine_loss: 0.453644, ref_loss: 0.213052\n",
      "\ttrain_loss: 3.022913, odo_loss: 2.320345, ine_loss: 0.512291, ref_loss: 0.190277\n",
      "\tval_loss: 3.095014, odo_loss: 2.388233, ine_loss: 0.510235, ref_loss: 0.196547\n",
      "Epoch 57/2000\n",
      "\t[#    0] train_loss: 2.444541, odo_loss: 1.551862, ine_loss: 0.692236, ref_loss: 0.200443\n",
      "\t[#  180] train_loss: 2.954895, odo_loss: 2.291722, ine_loss: 0.493349, ref_loss: 0.169823\n",
      "\t[#  360] train_loss: 2.882149, odo_loss: 2.300819, ine_loss: 0.423310, ref_loss: 0.158020\n",
      "\t[#  540] train_loss: 2.799883, odo_loss: 2.041906, ine_loss: 0.542142, ref_loss: 0.215835\n",
      "\t[#  720] train_loss: 2.862336, odo_loss: 2.097719, ine_loss: 0.588910, ref_loss: 0.175706\n",
      "\t[#  900] train_loss: 2.758804, odo_loss: 2.117524, ine_loss: 0.446831, ref_loss: 0.194449\n",
      "\ttrain_loss: 2.953959, odo_loss: 2.253481, ine_loss: 0.511940, ref_loss: 0.188537\n",
      "\tval_loss: 2.939476, odo_loss: 2.233215, ine_loss: 0.509800, ref_loss: 0.196462\n",
      "\t*** Personal Best ***\n",
      "Epoch 58/2000\n",
      "\t[#    0] train_loss: 2.583130, odo_loss: 1.957569, ine_loss: 0.422031, ref_loss: 0.203531\n",
      "\t[#  180] train_loss: 3.276538, odo_loss: 2.570121, ine_loss: 0.517159, ref_loss: 0.189257\n",
      "\t[#  360] train_loss: 2.716082, odo_loss: 2.013438, ine_loss: 0.512609, ref_loss: 0.190035\n",
      "\t[#  540] train_loss: 2.648369, odo_loss: 2.030504, ine_loss: 0.447354, ref_loss: 0.170511\n",
      "\t[#  720] train_loss: 3.008926, odo_loss: 2.395671, ine_loss: 0.443040, ref_loss: 0.170216\n",
      "\t[#  900] train_loss: 2.827802, odo_loss: 2.100869, ine_loss: 0.540554, ref_loss: 0.186379\n",
      "\ttrain_loss: 2.933387, odo_loss: 2.235131, ine_loss: 0.510796, ref_loss: 0.187460\n",
      "\tval_loss: 2.933074, odo_loss: 2.229123, ine_loss: 0.510453, ref_loss: 0.193498\n",
      "\t*** Personal Best ***\n",
      "Epoch 59/2000\n",
      "\t[#    0] train_loss: 3.051195, odo_loss: 2.311995, ine_loss: 0.543901, ref_loss: 0.195299\n",
      "\t[#  180] train_loss: 2.670305, odo_loss: 2.056694, ine_loss: 0.429019, ref_loss: 0.184592\n",
      "\t[#  360] train_loss: 2.879468, odo_loss: 2.079428, ine_loss: 0.569691, ref_loss: 0.230349\n",
      "\t[#  540] train_loss: 3.622528, odo_loss: 2.882813, ine_loss: 0.558634, ref_loss: 0.181080\n",
      "\t[#  720] train_loss: 3.219956, odo_loss: 2.482021, ine_loss: 0.561829, ref_loss: 0.176106\n",
      "\t[#  900] train_loss: 3.382734, odo_loss: 2.687332, ine_loss: 0.493117, ref_loss: 0.202284\n",
      "\ttrain_loss: 3.131058, odo_loss: 2.430336, ine_loss: 0.512498, ref_loss: 0.188224\n",
      "\tval_loss: 3.061868, odo_loss: 2.357613, ine_loss: 0.507313, ref_loss: 0.196942\n",
      "Epoch 60/2000\n",
      "\t[#    0] train_loss: 2.851957, odo_loss: 2.222332, ine_loss: 0.421846, ref_loss: 0.207779\n",
      "\t[#  180] train_loss: 3.093012, odo_loss: 2.374765, ine_loss: 0.501093, ref_loss: 0.217153\n",
      "\t[#  360] train_loss: 2.826635, odo_loss: 2.208942, ine_loss: 0.430844, ref_loss: 0.186850\n",
      "\t[#  540] train_loss: 3.116046, odo_loss: 2.294312, ine_loss: 0.635007, ref_loss: 0.186726\n",
      "\t[#  720] train_loss: 2.708884, odo_loss: 2.007642, ine_loss: 0.508154, ref_loss: 0.193087\n",
      "\t[#  900] train_loss: 2.764109, odo_loss: 2.154280, ine_loss: 0.413034, ref_loss: 0.196796\n",
      "\ttrain_loss: 3.060963, odo_loss: 2.363126, ine_loss: 0.510710, ref_loss: 0.187128\n",
      "\tval_loss: 2.948446, odo_loss: 2.248339, ine_loss: 0.506075, ref_loss: 0.194032\n",
      "Epoch 61/2000\n",
      "\t[#    0] train_loss: 2.987616, odo_loss: 2.255286, ine_loss: 0.557567, ref_loss: 0.174763\n",
      "\t[#  180] train_loss: 2.261240, odo_loss: 1.627638, ine_loss: 0.463642, ref_loss: 0.169960\n",
      "\t[#  360] train_loss: 2.694697, odo_loss: 2.107303, ine_loss: 0.408967, ref_loss: 0.178427\n",
      "\t[#  540] train_loss: 3.121521, odo_loss: 2.444473, ine_loss: 0.507028, ref_loss: 0.170021\n",
      "\t[#  720] train_loss: 3.398847, odo_loss: 2.809433, ine_loss: 0.403148, ref_loss: 0.186266\n",
      "\t[#  900] train_loss: 9.533702, odo_loss: 8.930719, ine_loss: 0.439277, ref_loss: 0.163705\n",
      "\ttrain_loss: 3.165512, odo_loss: 2.467836, ine_loss: 0.511083, ref_loss: 0.186594\n",
      "\tval_loss: 3.227548, odo_loss: 2.526088, ine_loss: 0.506215, ref_loss: 0.195244\n",
      "Epoch 62/2000\n",
      "\t[#    0] train_loss: 2.630577, odo_loss: 1.944641, ine_loss: 0.513087, ref_loss: 0.172849\n",
      "\t[#  180] train_loss: 2.743517, odo_loss: 2.150126, ine_loss: 0.386975, ref_loss: 0.206417\n",
      "\t[#  360] train_loss: 2.923637, odo_loss: 2.301341, ine_loss: 0.453087, ref_loss: 0.169209\n",
      "\t[#  540] train_loss: 3.005539, odo_loss: 2.292492, ine_loss: 0.543244, ref_loss: 0.169803\n",
      "\t[#  720] train_loss: 2.985284, odo_loss: 2.098012, ine_loss: 0.659834, ref_loss: 0.227439\n",
      "\t[#  900] train_loss: 3.539279, odo_loss: 2.816732, ine_loss: 0.515856, ref_loss: 0.206691\n",
      "\ttrain_loss: 3.103263, odo_loss: 2.405193, ine_loss: 0.511852, ref_loss: 0.186218\n",
      "\tval_loss: 3.004853, odo_loss: 2.306062, ine_loss: 0.505701, ref_loss: 0.193091\n",
      "Epoch 63/2000\n",
      "\t[#    0] train_loss: 2.901198, odo_loss: 2.287329, ine_loss: 0.453892, ref_loss: 0.159978\n",
      "\t[#  180] train_loss: 2.581746, odo_loss: 1.929808, ine_loss: 0.473712, ref_loss: 0.178226\n",
      "\t[#  360] train_loss: 2.768602, odo_loss: 2.147543, ine_loss: 0.445908, ref_loss: 0.175150\n",
      "\t[#  540] train_loss: 2.936857, odo_loss: 2.271357, ine_loss: 0.484528, ref_loss: 0.180972\n",
      "\t[#  720] train_loss: 2.704913, odo_loss: 2.048904, ine_loss: 0.474274, ref_loss: 0.181735\n",
      "\t[#  900] train_loss: 3.247635, odo_loss: 2.447067, ine_loss: 0.581547, ref_loss: 0.219022\n",
      "\ttrain_loss: 2.903171, odo_loss: 2.207390, ine_loss: 0.511521, ref_loss: 0.184259\n",
      "\tval_loss: 2.906326, odo_loss: 2.210011, ine_loss: 0.505757, ref_loss: 0.190558\n",
      "\t*** Personal Best ***\n",
      "Epoch 64/2000\n",
      "\t[#    0] train_loss: 2.953056, odo_loss: 2.312875, ine_loss: 0.473501, ref_loss: 0.166679\n",
      "\t[#  180] train_loss: 2.568679, odo_loss: 1.864216, ine_loss: 0.525567, ref_loss: 0.178895\n",
      "\t[#  360] train_loss: 2.848796, odo_loss: 2.199016, ine_loss: 0.455868, ref_loss: 0.193912\n",
      "\t[#  540] train_loss: 2.732780, odo_loss: 2.073940, ine_loss: 0.483600, ref_loss: 0.175240\n",
      "\t[#  720] train_loss: 3.030090, odo_loss: 2.317068, ine_loss: 0.523376, ref_loss: 0.189646\n",
      "\t[#  900] train_loss: 2.911656, odo_loss: 2.251042, ine_loss: 0.484324, ref_loss: 0.176291\n",
      "\ttrain_loss: 2.888590, odo_loss: 2.194114, ine_loss: 0.510207, ref_loss: 0.184269\n",
      "\tval_loss: 2.909654, odo_loss: 2.213648, ine_loss: 0.504742, ref_loss: 0.191264\n",
      "Epoch 65/2000\n",
      "\t[#    0] train_loss: 2.645086, odo_loss: 1.859270, ine_loss: 0.612255, ref_loss: 0.173561\n",
      "\t[#  180] train_loss: 2.567582, odo_loss: 1.957864, ine_loss: 0.434864, ref_loss: 0.174854\n",
      "\t[#  360] train_loss: 3.106711, odo_loss: 2.369970, ine_loss: 0.551085, ref_loss: 0.185656\n",
      "\t[#  540] train_loss: 2.937246, odo_loss: 2.184781, ine_loss: 0.546641, ref_loss: 0.205824\n",
      "\t[#  720] train_loss: 3.343925, odo_loss: 2.589626, ine_loss: 0.605313, ref_loss: 0.148986\n",
      "\t[#  900] train_loss: 3.267470, odo_loss: 2.422406, ine_loss: 0.665774, ref_loss: 0.179290\n",
      "\ttrain_loss: 2.858571, odo_loss: 2.165062, ine_loss: 0.510304, ref_loss: 0.183205\n",
      "\tval_loss: 2.867042, odo_loss: 2.167627, ine_loss: 0.508441, ref_loss: 0.190974\n",
      "\t*** Personal Best ***\n",
      "Epoch 66/2000\n",
      "\t[#    0] train_loss: 2.977659, odo_loss: 2.241543, ine_loss: 0.576998, ref_loss: 0.159118\n",
      "\t[#  180] train_loss: 2.653677, odo_loss: 2.052603, ine_loss: 0.406603, ref_loss: 0.194471\n",
      "\t[#  360] train_loss: 3.057615, odo_loss: 2.345478, ine_loss: 0.532124, ref_loss: 0.180013\n",
      "\t[#  540] train_loss: 2.514462, odo_loss: 1.880509, ine_loss: 0.451501, ref_loss: 0.182453\n",
      "\t[#  720] train_loss: 3.165618, odo_loss: 2.441861, ine_loss: 0.568159, ref_loss: 0.155597\n",
      "\t[#  900] train_loss: 2.665361, odo_loss: 2.067431, ine_loss: 0.435835, ref_loss: 0.162095\n",
      "\ttrain_loss: 2.850398, odo_loss: 2.158109, ine_loss: 0.510019, ref_loss: 0.182270\n",
      "\tval_loss: 2.831015, odo_loss: 2.135768, ine_loss: 0.506851, ref_loss: 0.188396\n",
      "\t*** Personal Best ***\n",
      "Epoch 67/2000\n",
      "\t[#    0] train_loss: 3.067614, odo_loss: 2.405543, ine_loss: 0.477531, ref_loss: 0.184540\n",
      "\t[#  180] train_loss: 2.971203, odo_loss: 2.345567, ine_loss: 0.486162, ref_loss: 0.139474\n",
      "\t[#  360] train_loss: 3.223887, odo_loss: 2.549315, ine_loss: 0.491399, ref_loss: 0.183173\n",
      "\t[#  540] train_loss: 3.631853, odo_loss: 2.889186, ine_loss: 0.525417, ref_loss: 0.217249\n",
      "\t[#  720] train_loss: 3.106326, odo_loss: 2.435815, ine_loss: 0.498980, ref_loss: 0.171531\n",
      "\t[#  900] train_loss: 3.047366, odo_loss: 2.403789, ine_loss: 0.487123, ref_loss: 0.156454\n",
      "\ttrain_loss: 3.298519, odo_loss: 2.603875, ine_loss: 0.511263, ref_loss: 0.183381\n",
      "\tval_loss: 3.228548, odo_loss: 2.524951, ine_loss: 0.510240, ref_loss: 0.193356\n",
      "Epoch 68/2000\n",
      "\t[#    0] train_loss: 3.041174, odo_loss: 2.398946, ine_loss: 0.469556, ref_loss: 0.172672\n",
      "\t[#  180] train_loss: 3.125524, odo_loss: 2.416295, ine_loss: 0.495902, ref_loss: 0.213327\n",
      "\t[#  360] train_loss: 3.052523, odo_loss: 2.303378, ine_loss: 0.588908, ref_loss: 0.160237\n",
      "\t[#  540] train_loss: 2.717937, odo_loss: 2.061768, ine_loss: 0.477350, ref_loss: 0.178819\n",
      "\t[#  720] train_loss: 2.524168, odo_loss: 1.784039, ine_loss: 0.547272, ref_loss: 0.192858\n",
      "\t[#  900] train_loss: 3.279788, odo_loss: 2.517966, ine_loss: 0.588690, ref_loss: 0.173132\n",
      "\ttrain_loss: 2.924243, odo_loss: 2.229687, ine_loss: 0.511827, ref_loss: 0.182729\n",
      "\tval_loss: 2.871784, odo_loss: 2.167384, ine_loss: 0.511603, ref_loss: 0.192798\n",
      "Epoch 69/2000\n",
      "\t[#    0] train_loss: 2.726946, odo_loss: 2.048666, ine_loss: 0.482492, ref_loss: 0.195788\n",
      "\t[#  180] train_loss: 2.932211, odo_loss: 2.216713, ine_loss: 0.510296, ref_loss: 0.205202\n",
      "\t[#  360] train_loss: 4.520172, odo_loss: 3.893653, ine_loss: 0.447823, ref_loss: 0.178696\n",
      "\t[#  540] train_loss: 3.133306, odo_loss: 2.409157, ine_loss: 0.528352, ref_loss: 0.195797\n",
      "\t[#  720] train_loss: 2.725106, odo_loss: 1.990331, ine_loss: 0.557176, ref_loss: 0.177598\n",
      "\t[#  900] train_loss: 3.043463, odo_loss: 2.308399, ine_loss: 0.532288, ref_loss: 0.202777\n",
      "\ttrain_loss: 2.891143, odo_loss: 2.199006, ine_loss: 0.511520, ref_loss: 0.180616\n",
      "\tval_loss: 2.902974, odo_loss: 2.197790, ine_loss: 0.516119, ref_loss: 0.189064\n",
      "Epoch 70/2000\n",
      "\t[#    0] train_loss: 2.791107, odo_loss: 2.125962, ine_loss: 0.503362, ref_loss: 0.161782\n",
      "\t[#  180] train_loss: 2.545179, odo_loss: 1.905185, ine_loss: 0.477101, ref_loss: 0.162893\n",
      "\t[#  360] train_loss: 2.862080, odo_loss: 2.084064, ine_loss: 0.548693, ref_loss: 0.229323\n",
      "\t[#  540] train_loss: 3.060521, odo_loss: 2.446859, ine_loss: 0.450052, ref_loss: 0.163611\n",
      "\t[#  720] train_loss: 2.866031, odo_loss: 2.104970, ine_loss: 0.598610, ref_loss: 0.162452\n",
      "\t[#  900] train_loss: 2.482469, odo_loss: 1.821251, ine_loss: 0.457068, ref_loss: 0.204150\n",
      "\ttrain_loss: 2.822378, odo_loss: 2.132215, ine_loss: 0.510510, ref_loss: 0.179653\n",
      "\tval_loss: 2.816474, odo_loss: 2.118416, ine_loss: 0.509949, ref_loss: 0.188109\n",
      "\t*** Personal Best ***\n",
      "Epoch 71/2000\n",
      "\t[#    0] train_loss: 2.874087, odo_loss: 2.160405, ine_loss: 0.505243, ref_loss: 0.208438\n",
      "\t[#  180] train_loss: 2.403371, odo_loss: 1.877067, ine_loss: 0.392144, ref_loss: 0.134159\n",
      "\t[#  360] train_loss: 2.729761, odo_loss: 2.154026, ine_loss: 0.411902, ref_loss: 0.163833\n",
      "\t[#  540] train_loss: 2.838948, odo_loss: 2.244554, ine_loss: 0.424251, ref_loss: 0.170144\n",
      "\t[#  720] train_loss: 2.998331, odo_loss: 2.414101, ine_loss: 0.415179, ref_loss: 0.169052\n",
      "\t[#  900] train_loss: 2.859246, odo_loss: 2.112936, ine_loss: 0.547080, ref_loss: 0.199230\n",
      "\ttrain_loss: 2.982749, odo_loss: 2.292330, ine_loss: 0.510760, ref_loss: 0.179658\n",
      "\tval_loss: 3.023695, odo_loss: 2.319058, ine_loss: 0.515336, ref_loss: 0.189300\n",
      "Epoch 72/2000\n",
      "\t[#    0] train_loss: 2.869963, odo_loss: 2.062591, ine_loss: 0.620266, ref_loss: 0.187106\n",
      "\t[#  180] train_loss: 3.444422, odo_loss: 2.636217, ine_loss: 0.623784, ref_loss: 0.184421\n",
      "\t[#  360] train_loss: 3.033473, odo_loss: 2.255397, ine_loss: 0.571124, ref_loss: 0.206953\n",
      "\t[#  540] train_loss: 2.601774, odo_loss: 1.937100, ine_loss: 0.485952, ref_loss: 0.178721\n",
      "\t[#  720] train_loss: 2.696781, odo_loss: 2.058572, ine_loss: 0.438776, ref_loss: 0.199433\n",
      "\t[#  900] train_loss: 3.209373, odo_loss: 2.483495, ine_loss: 0.556969, ref_loss: 0.168910\n",
      "\ttrain_loss: 2.940648, odo_loss: 2.247916, ine_loss: 0.513463, ref_loss: 0.179269\n",
      "\tval_loss: 2.860954, odo_loss: 2.161022, ine_loss: 0.508857, ref_loss: 0.191075\n",
      "Epoch 73/2000\n",
      "\t[#    0] train_loss: 2.915340, odo_loss: 2.190695, ine_loss: 0.540722, ref_loss: 0.183922\n",
      "\t[#  180] train_loss: 3.228472, odo_loss: 2.508893, ine_loss: 0.532895, ref_loss: 0.186683\n",
      "\t[#  360] train_loss: 2.993327, odo_loss: 2.300270, ine_loss: 0.522873, ref_loss: 0.170184\n",
      "\t[#  540] train_loss: 3.009722, odo_loss: 2.227949, ine_loss: 0.587816, ref_loss: 0.193957\n",
      "\t[#  720] train_loss: 3.282411, odo_loss: 2.295157, ine_loss: 0.763922, ref_loss: 0.223332\n",
      "\t[#  900] train_loss: 2.558180, odo_loss: 1.923276, ine_loss: 0.478643, ref_loss: 0.156261\n",
      "\ttrain_loss: 2.859050, odo_loss: 2.169151, ine_loss: 0.511157, ref_loss: 0.178742\n",
      "\tval_loss: 2.894731, odo_loss: 2.196586, ine_loss: 0.509725, ref_loss: 0.188419\n",
      "Epoch 74/2000\n",
      "\t[#    0] train_loss: 3.112511, odo_loss: 2.399702, ine_loss: 0.534206, ref_loss: 0.178604\n",
      "\t[#  180] train_loss: 2.497068, odo_loss: 1.833823, ine_loss: 0.471796, ref_loss: 0.191450\n",
      "\t[#  360] train_loss: 2.638063, odo_loss: 2.117804, ine_loss: 0.361368, ref_loss: 0.158891\n",
      "\t[#  540] train_loss: 2.858132, odo_loss: 2.099989, ine_loss: 0.576759, ref_loss: 0.181384\n",
      "\t[#  720] train_loss: 2.660665, odo_loss: 1.879833, ine_loss: 0.596917, ref_loss: 0.183915\n",
      "\t[#  900] train_loss: 2.766440, odo_loss: 2.097313, ine_loss: 0.503513, ref_loss: 0.165614\n",
      "\ttrain_loss: 2.831481, odo_loss: 2.143063, ine_loss: 0.511147, ref_loss: 0.177272\n",
      "\tval_loss: 2.904716, odo_loss: 2.207857, ine_loss: 0.507710, ref_loss: 0.189149\n",
      "Epoch 75/2000\n",
      "\t[#    0] train_loss: 2.602372, odo_loss: 1.841921, ine_loss: 0.590053, ref_loss: 0.170398\n",
      "\t[#  180] train_loss: 3.148462, odo_loss: 2.349347, ine_loss: 0.585136, ref_loss: 0.213978\n",
      "\t[#  360] train_loss: 3.070459, odo_loss: 2.339248, ine_loss: 0.517845, ref_loss: 0.213365\n",
      "\t[#  540] train_loss: 2.550610, odo_loss: 1.934920, ine_loss: 0.471569, ref_loss: 0.144121\n",
      "\t[#  720] train_loss: 2.548923, odo_loss: 1.869241, ine_loss: 0.513002, ref_loss: 0.166680\n",
      "\t[#  900] train_loss: 2.873789, odo_loss: 2.068833, ine_loss: 0.617515, ref_loss: 0.187441\n",
      "\ttrain_loss: 2.835076, odo_loss: 2.146418, ine_loss: 0.510961, ref_loss: 0.177697\n",
      "\tval_loss: 2.920043, odo_loss: 2.229256, ine_loss: 0.505764, ref_loss: 0.185023\n",
      "Epoch 76/2000\n",
      "\t[#    0] train_loss: 2.337054, odo_loss: 1.760514, ine_loss: 0.383119, ref_loss: 0.193421\n",
      "\t[#  180] train_loss: 2.724104, odo_loss: 1.977019, ine_loss: 0.562748, ref_loss: 0.184337\n",
      "\t[#  360] train_loss: 5.684035, odo_loss: 5.011550, ine_loss: 0.491987, ref_loss: 0.180498\n",
      "\t[#  540] train_loss: 3.140782, odo_loss: 2.402190, ine_loss: 0.576302, ref_loss: 0.162290\n",
      "\t[#  720] train_loss: 2.970848, odo_loss: 2.316773, ine_loss: 0.447263, ref_loss: 0.206813\n",
      "\t[#  900] train_loss: 3.075832, odo_loss: 2.381858, ine_loss: 0.511644, ref_loss: 0.182331\n",
      "\ttrain_loss: 2.982218, odo_loss: 2.293953, ine_loss: 0.510884, ref_loss: 0.177381\n",
      "\tval_loss: 2.814180, odo_loss: 2.122734, ine_loss: 0.503418, ref_loss: 0.188028\n",
      "Epoch 77/2000\n",
      "\t[#    0] train_loss: 2.598706, odo_loss: 1.916057, ine_loss: 0.493055, ref_loss: 0.189595\n",
      "\t[#  180] train_loss: 2.953379, odo_loss: 2.142514, ine_loss: 0.607591, ref_loss: 0.203275\n",
      "\t[#  360] train_loss: 2.792491, odo_loss: 2.150586, ine_loss: 0.487351, ref_loss: 0.154554\n",
      "\t[#  540] train_loss: 2.512677, odo_loss: 1.893004, ine_loss: 0.425473, ref_loss: 0.194200\n",
      "\t[#  720] train_loss: 2.860859, odo_loss: 2.182312, ine_loss: 0.519394, ref_loss: 0.159153\n",
      "\t[#  900] train_loss: 2.911115, odo_loss: 2.208117, ine_loss: 0.515084, ref_loss: 0.187915\n",
      "\ttrain_loss: 2.813704, odo_loss: 2.127760, ine_loss: 0.509972, ref_loss: 0.175972\n",
      "\tval_loss: 2.845981, odo_loss: 2.153557, ine_loss: 0.506698, ref_loss: 0.185726\n",
      "Epoch 78/2000\n",
      "\t[#    0] train_loss: 3.189550, odo_loss: 2.407000, ine_loss: 0.640291, ref_loss: 0.142259\n",
      "\t[#  180] train_loss: 2.456215, odo_loss: 1.720616, ine_loss: 0.563128, ref_loss: 0.172470\n",
      "\t[#  360] train_loss: 3.006804, odo_loss: 2.334897, ine_loss: 0.502882, ref_loss: 0.169025\n",
      "\t[#  540] train_loss: 2.627820, odo_loss: 1.984603, ine_loss: 0.491433, ref_loss: 0.151785\n",
      "\t[#  720] train_loss: 2.182180, odo_loss: 1.679179, ine_loss: 0.342377, ref_loss: 0.160624\n",
      "\t[#  900] train_loss: 2.586134, odo_loss: 1.928660, ine_loss: 0.439049, ref_loss: 0.218424\n",
      "\ttrain_loss: 2.785453, odo_loss: 2.100048, ine_loss: 0.510924, ref_loss: 0.174481\n",
      "\tval_loss: 2.782190, odo_loss: 2.083257, ine_loss: 0.511017, ref_loss: 0.187916\n",
      "\t*** Personal Best ***\n",
      "Epoch 79/2000\n",
      "\t[#    0] train_loss: 2.547927, odo_loss: 1.924629, ine_loss: 0.432770, ref_loss: 0.190528\n",
      "\t[#  180] train_loss: 2.914167, odo_loss: 2.319669, ine_loss: 0.441004, ref_loss: 0.153494\n",
      "\t[#  360] train_loss: 2.953150, odo_loss: 2.342762, ine_loss: 0.448701, ref_loss: 0.161687\n",
      "\t[#  540] train_loss: 2.893925, odo_loss: 2.011039, ine_loss: 0.674725, ref_loss: 0.208161\n",
      "\t[#  720] train_loss: 2.697214, odo_loss: 2.111630, ine_loss: 0.418436, ref_loss: 0.167149\n",
      "\t[#  900] train_loss: 2.849763, odo_loss: 2.188049, ine_loss: 0.485043, ref_loss: 0.176672\n",
      "\ttrain_loss: 2.806788, odo_loss: 2.122779, ine_loss: 0.509768, ref_loss: 0.174241\n",
      "\tval_loss: 3.027608, odo_loss: 2.334846, ine_loss: 0.509316, ref_loss: 0.183447\n",
      "Epoch 80/2000\n",
      "\t[#    0] train_loss: 2.728384, odo_loss: 2.103189, ine_loss: 0.459232, ref_loss: 0.165964\n",
      "\t[#  180] train_loss: 2.648267, odo_loss: 1.947205, ine_loss: 0.523451, ref_loss: 0.177610\n",
      "\t[#  360] train_loss: 2.685503, odo_loss: 2.090073, ine_loss: 0.430438, ref_loss: 0.164992\n",
      "\t[#  540] train_loss: 2.728980, odo_loss: 1.989398, ine_loss: 0.539756, ref_loss: 0.199826\n",
      "\t[#  720] train_loss: 2.880787, odo_loss: 2.098978, ine_loss: 0.600431, ref_loss: 0.181377\n",
      "\t[#  900] train_loss: 2.527492, odo_loss: 1.982559, ine_loss: 0.383980, ref_loss: 0.160953\n",
      "\ttrain_loss: 3.083649, odo_loss: 2.398761, ine_loss: 0.509528, ref_loss: 0.175360\n",
      "\tval_loss: 2.855434, odo_loss: 2.155804, ine_loss: 0.514747, ref_loss: 0.184882\n",
      "Epoch 81/2000\n",
      "\t[#    0] train_loss: 2.654042, odo_loss: 2.057118, ine_loss: 0.452966, ref_loss: 0.143957\n",
      "\t[#  180] train_loss: 2.369714, odo_loss: 1.817889, ine_loss: 0.382908, ref_loss: 0.168917\n",
      "\t[#  360] train_loss: 3.152349, odo_loss: 2.293624, ine_loss: 0.696175, ref_loss: 0.162551\n",
      "\t[#  540] train_loss: 3.007667, odo_loss: 2.200456, ine_loss: 0.602471, ref_loss: 0.204740\n",
      "\t[#  720] train_loss: 3.321603, odo_loss: 2.517875, ine_loss: 0.636316, ref_loss: 0.167412\n",
      "\t[#  900] train_loss: 2.604654, odo_loss: 1.977183, ine_loss: 0.494468, ref_loss: 0.133003\n",
      "\ttrain_loss: 2.912142, odo_loss: 2.227300, ine_loss: 0.510664, ref_loss: 0.174178\n",
      "\tval_loss: 2.929899, odo_loss: 2.235325, ine_loss: 0.509172, ref_loss: 0.185402\n",
      "Epoch 82/2000\n",
      "\t[#    0] train_loss: 3.021263, odo_loss: 2.354750, ine_loss: 0.517637, ref_loss: 0.148876\n",
      "\t[#  180] train_loss: 2.385271, odo_loss: 1.729711, ine_loss: 0.469898, ref_loss: 0.185662\n",
      "\t[#  360] train_loss: 2.735468, odo_loss: 2.078869, ine_loss: 0.505426, ref_loss: 0.151173\n",
      "\t[#  540] train_loss: 2.790926, odo_loss: 2.109949, ine_loss: 0.528695, ref_loss: 0.152283\n",
      "\t[#  720] train_loss: 3.055534, odo_loss: 2.224595, ine_loss: 0.635553, ref_loss: 0.195386\n",
      "\t[#  900] train_loss: 2.676322, odo_loss: 2.070432, ine_loss: 0.437819, ref_loss: 0.168071\n",
      "\ttrain_loss: 2.852438, odo_loss: 2.167970, ine_loss: 0.510950, ref_loss: 0.173519\n",
      "\tval_loss: 2.829533, odo_loss: 2.139427, ine_loss: 0.505056, ref_loss: 0.185050\n",
      "Epoch 83/2000\n",
      "\t[#    0] train_loss: 2.943030, odo_loss: 2.305787, ine_loss: 0.462059, ref_loss: 0.175184\n",
      "\t[#  180] train_loss: 2.627196, odo_loss: 2.034721, ine_loss: 0.443899, ref_loss: 0.148576\n",
      "\t[#  360] train_loss: 2.779544, odo_loss: 2.085875, ine_loss: 0.498235, ref_loss: 0.195434\n",
      "\t[#  540] train_loss: 2.840442, odo_loss: 2.178455, ine_loss: 0.520043, ref_loss: 0.141945\n",
      "\t[#  720] train_loss: 3.794597, odo_loss: 3.074220, ine_loss: 0.510481, ref_loss: 0.209896\n",
      "\t[#  900] train_loss: 3.283491, odo_loss: 2.562696, ine_loss: 0.570034, ref_loss: 0.150761\n",
      "\ttrain_loss: 2.861759, odo_loss: 2.181300, ine_loss: 0.508211, ref_loss: 0.172247\n",
      "\tval_loss: 2.899434, odo_loss: 2.209555, ine_loss: 0.507409, ref_loss: 0.182470\n",
      "Epoch 84/2000\n",
      "\t[#    0] train_loss: 2.795216, odo_loss: 2.161769, ine_loss: 0.485580, ref_loss: 0.147868\n",
      "\t[#  180] train_loss: 2.577605, odo_loss: 1.976753, ine_loss: 0.443205, ref_loss: 0.157647\n",
      "\t[#  360] train_loss: 2.788372, odo_loss: 2.131698, ine_loss: 0.503003, ref_loss: 0.153671\n",
      "\t[#  540] train_loss: 2.548258, odo_loss: 1.962014, ine_loss: 0.409206, ref_loss: 0.177038\n",
      "\t[#  720] train_loss: 2.703616, odo_loss: 2.014866, ine_loss: 0.505571, ref_loss: 0.183180\n",
      "\t[#  900] train_loss: 2.677207, odo_loss: 2.007589, ine_loss: 0.457070, ref_loss: 0.212548\n",
      "\ttrain_loss: 2.810071, odo_loss: 2.128596, ine_loss: 0.509430, ref_loss: 0.172045\n",
      "\tval_loss: 2.794293, odo_loss: 2.105186, ine_loss: 0.505005, ref_loss: 0.184102\n",
      "Epoch 85/2000\n",
      "\t[#    0] train_loss: 2.726298, odo_loss: 2.070031, ine_loss: 0.497152, ref_loss: 0.159115\n",
      "\t[#  180] train_loss: 2.527575, odo_loss: 1.738827, ine_loss: 0.590650, ref_loss: 0.198098\n",
      "\t[#  360] train_loss: 2.544317, odo_loss: 1.895674, ine_loss: 0.462287, ref_loss: 0.186356\n",
      "\t[#  540] train_loss: 3.032961, odo_loss: 2.491963, ine_loss: 0.398382, ref_loss: 0.142616\n",
      "\t[#  720] train_loss: 2.865966, odo_loss: 2.157233, ine_loss: 0.536527, ref_loss: 0.172206\n",
      "\t[#  900] train_loss: 2.893731, odo_loss: 2.293124, ine_loss: 0.439460, ref_loss: 0.161147\n",
      "\ttrain_loss: 3.037463, odo_loss: 2.356095, ine_loss: 0.508430, ref_loss: 0.172938\n",
      "\tval_loss: 3.185001, odo_loss: 2.493465, ine_loss: 0.509249, ref_loss: 0.182287\n",
      "Epoch 86/2000\n",
      "\t[#    0] train_loss: 2.710655, odo_loss: 2.084884, ine_loss: 0.463195, ref_loss: 0.162575\n",
      "\t[#  180] train_loss: 2.790832, odo_loss: 2.171232, ine_loss: 0.460860, ref_loss: 0.158740\n",
      "\t[#  360] train_loss: 2.958086, odo_loss: 2.323701, ine_loss: 0.465727, ref_loss: 0.168658\n",
      "\t[#  540] train_loss: 2.946738, odo_loss: 2.232321, ine_loss: 0.527412, ref_loss: 0.187004\n",
      "\t[#  720] train_loss: 2.634389, odo_loss: 1.978234, ine_loss: 0.499347, ref_loss: 0.156808\n",
      "\t[#  900] train_loss: 2.633126, odo_loss: 2.051963, ine_loss: 0.406785, ref_loss: 0.174379\n",
      "\ttrain_loss: 2.827481, odo_loss: 2.146421, ine_loss: 0.509045, ref_loss: 0.172015\n",
      "\tval_loss: 2.777764, odo_loss: 2.095294, ine_loss: 0.500500, ref_loss: 0.181969\n",
      "Epoch 87/2000\n",
      "\t[#    0] train_loss: 2.537143, odo_loss: 1.874764, ine_loss: 0.506433, ref_loss: 0.155946\n",
      "\t[#  180] train_loss: 2.905403, odo_loss: 2.121276, ine_loss: 0.569256, ref_loss: 0.214870\n",
      "\t[#  360] train_loss: 2.419915, odo_loss: 1.775273, ine_loss: 0.470445, ref_loss: 0.174197\n",
      "\t[#  540] train_loss: 2.691978, odo_loss: 1.892960, ine_loss: 0.576267, ref_loss: 0.222750\n",
      "\t[#  720] train_loss: 2.693858, odo_loss: 2.079595, ine_loss: 0.467561, ref_loss: 0.146702\n",
      "\t[#  900] train_loss: 2.998455, odo_loss: 2.205526, ine_loss: 0.609611, ref_loss: 0.183317\n",
      "\ttrain_loss: 2.752849, odo_loss: 2.073129, ine_loss: 0.509198, ref_loss: 0.170521\n",
      "\tval_loss: 2.784475, odo_loss: 2.098880, ine_loss: 0.504421, ref_loss: 0.181174\n",
      "Epoch 88/2000\n",
      "\t[#    0] train_loss: 2.746602, odo_loss: 2.092800, ine_loss: 0.501017, ref_loss: 0.152785\n",
      "\t[#  180] train_loss: 2.472981, odo_loss: 1.959594, ine_loss: 0.358502, ref_loss: 0.154885\n",
      "\t[#  360] train_loss: 2.672596, odo_loss: 1.946218, ine_loss: 0.544300, ref_loss: 0.182078\n",
      "\t[#  540] train_loss: 2.384363, odo_loss: 1.813277, ine_loss: 0.400464, ref_loss: 0.170622\n",
      "\t[#  720] train_loss: 2.770573, odo_loss: 2.004970, ine_loss: 0.601808, ref_loss: 0.163795\n",
      "\t[#  900] train_loss: 2.656450, odo_loss: 1.929858, ine_loss: 0.544251, ref_loss: 0.182341\n",
      "\ttrain_loss: 2.732169, odo_loss: 2.053411, ine_loss: 0.508865, ref_loss: 0.169893\n",
      "\tval_loss: 2.739963, odo_loss: 2.052261, ine_loss: 0.505486, ref_loss: 0.182216\n",
      "\t*** Personal Best ***\n",
      "Epoch 89/2000\n",
      "\t[#    0] train_loss: 2.620424, odo_loss: 1.911731, ine_loss: 0.543957, ref_loss: 0.164737\n",
      "\t[#  180] train_loss: 2.973841, odo_loss: 2.256754, ine_loss: 0.574561, ref_loss: 0.142525\n",
      "\t[#  360] train_loss: 3.070670, odo_loss: 2.378005, ine_loss: 0.530039, ref_loss: 0.162626\n",
      "\t[#  540] train_loss: 2.406189, odo_loss: 1.749394, ine_loss: 0.461577, ref_loss: 0.195218\n",
      "\t[#  720] train_loss: 2.685228, odo_loss: 2.088522, ine_loss: 0.426771, ref_loss: 0.169935\n",
      "\t[#  900] train_loss: 2.900915, odo_loss: 2.215389, ine_loss: 0.530459, ref_loss: 0.155067\n",
      "\ttrain_loss: 2.782712, odo_loss: 2.103317, ine_loss: 0.509639, ref_loss: 0.169756\n",
      "\tval_loss: 2.855785, odo_loss: 2.177126, ine_loss: 0.499044, ref_loss: 0.179615\n",
      "Epoch 90/2000\n",
      "\t[#    0] train_loss: 2.961302, odo_loss: 2.277728, ine_loss: 0.546125, ref_loss: 0.137449\n",
      "\t[#  180] train_loss: 2.571666, odo_loss: 1.991867, ine_loss: 0.427839, ref_loss: 0.151960\n",
      "\t[#  360] train_loss: 2.789126, odo_loss: 2.151136, ine_loss: 0.463221, ref_loss: 0.174769\n",
      "\t[#  540] train_loss: 2.850676, odo_loss: 2.130048, ine_loss: 0.565784, ref_loss: 0.154844\n",
      "\t[#  720] train_loss: 2.810556, odo_loss: 2.097466, ine_loss: 0.534402, ref_loss: 0.178688\n",
      "\t[#  900] train_loss: 2.362754, odo_loss: 1.800666, ine_loss: 0.420159, ref_loss: 0.141929\n",
      "\ttrain_loss: 2.764912, odo_loss: 2.084883, ine_loss: 0.510698, ref_loss: 0.169332\n",
      "\tval_loss: 2.775778, odo_loss: 2.087976, ine_loss: 0.508048, ref_loss: 0.179754\n",
      "Epoch 91/2000\n",
      "\t[#    0] train_loss: 2.632204, odo_loss: 1.977745, ine_loss: 0.483925, ref_loss: 0.170534\n",
      "\t[#  180] train_loss: 2.983842, odo_loss: 2.344997, ine_loss: 0.470005, ref_loss: 0.168840\n",
      "\t[#  360] train_loss: 2.524922, odo_loss: 1.921011, ine_loss: 0.435071, ref_loss: 0.168840\n",
      "\t[#  540] train_loss: 2.731385, odo_loss: 1.926837, ine_loss: 0.583861, ref_loss: 0.220686\n",
      "\t[#  720] train_loss: 2.904040, odo_loss: 1.984819, ine_loss: 0.747145, ref_loss: 0.172075\n",
      "\t[#  900] train_loss: 2.853917, odo_loss: 2.124065, ine_loss: 0.580830, ref_loss: 0.149022\n",
      "\ttrain_loss: 2.737211, odo_loss: 2.059106, ine_loss: 0.509595, ref_loss: 0.168510\n",
      "\tval_loss: 2.740857, odo_loss: 2.057659, ine_loss: 0.503249, ref_loss: 0.179948\n",
      "Epoch 92/2000\n",
      "\t[#    0] train_loss: 2.769947, odo_loss: 2.130369, ine_loss: 0.485956, ref_loss: 0.153622\n",
      "\t[#  180] train_loss: 2.806317, odo_loss: 2.122784, ine_loss: 0.502460, ref_loss: 0.181072\n",
      "\t[#  360] train_loss: 2.926931, odo_loss: 2.264234, ine_loss: 0.504396, ref_loss: 0.158301\n",
      "\t[#  540] train_loss: 2.350720, odo_loss: 1.777593, ine_loss: 0.428595, ref_loss: 0.144532\n",
      "\t[#  720] train_loss: 5.490548, odo_loss: 4.639345, ine_loss: 0.676737, ref_loss: 0.174465\n",
      "\t[#  900] train_loss: 2.823455, odo_loss: 2.146739, ine_loss: 0.519835, ref_loss: 0.156881\n",
      "\ttrain_loss: 2.941571, odo_loss: 2.261753, ine_loss: 0.510397, ref_loss: 0.169422\n",
      "\tval_loss: 2.987545, odo_loss: 2.293549, ine_loss: 0.512286, ref_loss: 0.181710\n",
      "Epoch 93/2000\n",
      "\t[#    0] train_loss: 2.914870, odo_loss: 2.235767, ine_loss: 0.502786, ref_loss: 0.176317\n",
      "\t[#  180] train_loss: 2.859138, odo_loss: 2.156477, ine_loss: 0.534181, ref_loss: 0.168480\n",
      "\t[#  360] train_loss: 2.669529, odo_loss: 2.116905, ine_loss: 0.389420, ref_loss: 0.163204\n",
      "\t[#  540] train_loss: 2.750957, odo_loss: 2.170095, ine_loss: 0.400651, ref_loss: 0.180211\n",
      "\t[#  720] train_loss: 2.678081, odo_loss: 2.005637, ine_loss: 0.494239, ref_loss: 0.178204\n",
      "\t[#  900] train_loss: 2.628978, odo_loss: 2.061831, ine_loss: 0.420579, ref_loss: 0.146568\n",
      "\ttrain_loss: 2.998958, odo_loss: 2.319594, ine_loss: 0.509086, ref_loss: 0.170278\n",
      "\tval_loss: 2.774747, odo_loss: 2.085789, ine_loss: 0.507617, ref_loss: 0.181341\n",
      "Epoch 94/2000\n",
      "\t[#    0] train_loss: 2.745978, odo_loss: 2.122246, ine_loss: 0.478995, ref_loss: 0.144737\n",
      "\t[#  180] train_loss: 4.071666, odo_loss: 3.324733, ine_loss: 0.577567, ref_loss: 0.169367\n",
      "\t[#  360] train_loss: 2.588131, odo_loss: 1.938843, ine_loss: 0.484546, ref_loss: 0.164742\n",
      "\t[#  540] train_loss: 2.413052, odo_loss: 1.789091, ine_loss: 0.477735, ref_loss: 0.146226\n",
      "\t[#  720] train_loss: 2.401746, odo_loss: 1.847376, ine_loss: 0.379030, ref_loss: 0.175340\n",
      "\t[#  900] train_loss: 2.770037, odo_loss: 1.972421, ine_loss: 0.634120, ref_loss: 0.163495\n",
      "\ttrain_loss: 2.751040, odo_loss: 2.072269, ine_loss: 0.510275, ref_loss: 0.168496\n",
      "\tval_loss: 2.689453, odo_loss: 1.999817, ine_loss: 0.509775, ref_loss: 0.179861\n",
      "\t*** Personal Best ***\n",
      "Epoch 95/2000\n",
      "\t[#    0] train_loss: 2.918778, odo_loss: 2.277256, ine_loss: 0.493926, ref_loss: 0.147597\n",
      "\t[#  180] train_loss: 2.553647, odo_loss: 1.909289, ine_loss: 0.502014, ref_loss: 0.142344\n",
      "\t[#  360] train_loss: 3.152395, odo_loss: 2.379918, ine_loss: 0.588944, ref_loss: 0.183533\n",
      "\t[#  540] train_loss: 3.003451, odo_loss: 2.334714, ine_loss: 0.481554, ref_loss: 0.187183\n",
      "\t[#  720] train_loss: 2.571370, odo_loss: 1.839608, ine_loss: 0.549394, ref_loss: 0.182367\n",
      "\t[#  900] train_loss: 2.865817, odo_loss: 2.217756, ine_loss: 0.443338, ref_loss: 0.204724\n",
      "\ttrain_loss: 2.761660, odo_loss: 2.082811, ine_loss: 0.511306, ref_loss: 0.167543\n",
      "\tval_loss: 2.816207, odo_loss: 2.125887, ine_loss: 0.510100, ref_loss: 0.180219\n",
      "Epoch 96/2000\n",
      "\t[#    0] train_loss: 2.853455, odo_loss: 2.209462, ine_loss: 0.470018, ref_loss: 0.173975\n",
      "\t[#  180] train_loss: 2.481422, odo_loss: 1.864671, ine_loss: 0.454469, ref_loss: 0.162281\n",
      "\t[#  360] train_loss: 2.917406, odo_loss: 2.168801, ine_loss: 0.577711, ref_loss: 0.170894\n",
      "\t[#  540] train_loss: 2.516026, odo_loss: 1.969359, ine_loss: 0.411218, ref_loss: 0.135449\n",
      "\t[#  720] train_loss: 2.707332, odo_loss: 2.147610, ine_loss: 0.405344, ref_loss: 0.154378\n",
      "\t[#  900] train_loss: 2.744611, odo_loss: 1.994116, ine_loss: 0.586394, ref_loss: 0.164101\n",
      "\ttrain_loss: 2.748786, odo_loss: 2.070141, ine_loss: 0.511658, ref_loss: 0.166986\n",
      "\tval_loss: 2.779714, odo_loss: 2.100159, ine_loss: 0.500359, ref_loss: 0.179197\n",
      "Epoch 97/2000\n",
      "\t[#    0] train_loss: 2.569484, odo_loss: 1.880448, ine_loss: 0.514963, ref_loss: 0.174072\n",
      "\t[#  180] train_loss: 2.235280, odo_loss: 1.667097, ine_loss: 0.410804, ref_loss: 0.157379\n",
      "\t[#  360] train_loss: 2.184849, odo_loss: 1.509268, ine_loss: 0.533964, ref_loss: 0.141617\n",
      "\t[#  540] train_loss: 2.311838, odo_loss: 1.684552, ine_loss: 0.470548, ref_loss: 0.156738\n",
      "\t[#  720] train_loss: 2.531826, odo_loss: 1.942339, ine_loss: 0.433374, ref_loss: 0.156113\n",
      "\t[#  900] train_loss: 2.679435, odo_loss: 1.916675, ine_loss: 0.614631, ref_loss: 0.148128\n",
      "\ttrain_loss: 2.735626, odo_loss: 2.058598, ine_loss: 0.510555, ref_loss: 0.166473\n",
      "\tval_loss: 2.675808, odo_loss: 1.990160, ine_loss: 0.507597, ref_loss: 0.178050\n",
      "\t*** Personal Best ***\n",
      "Epoch 98/2000\n",
      "\t[#    0] train_loss: 2.466628, odo_loss: 1.888467, ine_loss: 0.421745, ref_loss: 0.156416\n",
      "\t[#  180] train_loss: 2.723064, odo_loss: 2.121728, ine_loss: 0.469580, ref_loss: 0.131755\n",
      "\t[#  360] train_loss: 2.674608, odo_loss: 2.021707, ine_loss: 0.481096, ref_loss: 0.171806\n",
      "\t[#  540] train_loss: 2.575070, odo_loss: 1.834832, ine_loss: 0.562145, ref_loss: 0.178093\n",
      "\t[#  720] train_loss: 2.530568, odo_loss: 1.916115, ine_loss: 0.471906, ref_loss: 0.142547\n",
      "\t[#  900] train_loss: 2.906170, odo_loss: 2.266746, ine_loss: 0.473893, ref_loss: 0.165531\n",
      "\ttrain_loss: 2.786815, odo_loss: 2.110115, ine_loss: 0.510284, ref_loss: 0.166416\n",
      "\tval_loss: 2.798534, odo_loss: 2.115002, ine_loss: 0.504564, ref_loss: 0.178968\n",
      "Epoch 99/2000\n",
      "\t[#    0] train_loss: 2.645110, odo_loss: 2.100146, ine_loss: 0.369768, ref_loss: 0.175196\n",
      "\t[#  180] train_loss: 3.126339, odo_loss: 2.343459, ine_loss: 0.574721, ref_loss: 0.208160\n",
      "\t[#  360] train_loss: 2.618476, odo_loss: 1.972160, ine_loss: 0.444877, ref_loss: 0.201439\n",
      "\t[#  540] train_loss: 3.045023, odo_loss: 2.405988, ine_loss: 0.494084, ref_loss: 0.144952\n",
      "\t[#  720] train_loss: 2.365946, odo_loss: 1.647053, ine_loss: 0.507156, ref_loss: 0.211736\n",
      "\t[#  900] train_loss: 2.980419, odo_loss: 2.275533, ine_loss: 0.551974, ref_loss: 0.152913\n",
      "\ttrain_loss: 2.788834, odo_loss: 2.111476, ine_loss: 0.511078, ref_loss: 0.166279\n",
      "\tval_loss: 2.767170, odo_loss: 2.080684, ine_loss: 0.509025, ref_loss: 0.177462\n",
      "Epoch 100/2000\n",
      "\t[#    0] train_loss: 2.945884, odo_loss: 2.255803, ine_loss: 0.498316, ref_loss: 0.191765\n",
      "\t[#  180] train_loss: 2.499657, odo_loss: 1.890258, ine_loss: 0.435998, ref_loss: 0.173402\n",
      "\t[#  360] train_loss: 3.018221, odo_loss: 2.341737, ine_loss: 0.507172, ref_loss: 0.169311\n",
      "\t[#  540] train_loss: 2.577596, odo_loss: 1.962769, ine_loss: 0.449006, ref_loss: 0.165822\n",
      "\t[#  720] train_loss: 2.515466, odo_loss: 1.818400, ine_loss: 0.489138, ref_loss: 0.207928\n",
      "\t[#  900] train_loss: 3.000247, odo_loss: 2.213109, ine_loss: 0.604121, ref_loss: 0.183016\n",
      "\ttrain_loss: 2.766305, odo_loss: 2.089114, ine_loss: 0.511424, ref_loss: 0.165767\n",
      "\tval_loss: 2.892950, odo_loss: 2.208507, ine_loss: 0.507228, ref_loss: 0.177214\n",
      "Epoch 101/2000\n",
      "\t[#    0] train_loss: 2.740065, odo_loss: 2.139312, ine_loss: 0.467461, ref_loss: 0.133292\n",
      "\t[#  180] train_loss: 2.937287, odo_loss: 2.335949, ine_loss: 0.463936, ref_loss: 0.137403\n",
      "\t[#  360] train_loss: 4.725421, odo_loss: 4.039093, ine_loss: 0.523695, ref_loss: 0.162634\n",
      "\t[#  540] train_loss: 3.095712, odo_loss: 2.369917, ine_loss: 0.535421, ref_loss: 0.190374\n",
      "\t[#  720] train_loss: 2.975113, odo_loss: 2.302992, ine_loss: 0.511631, ref_loss: 0.160490\n",
      "\t[#  900] train_loss: 2.513310, odo_loss: 1.858853, ine_loss: 0.471974, ref_loss: 0.182482\n",
      "\ttrain_loss: 2.929441, odo_loss: 2.251143, ine_loss: 0.512293, ref_loss: 0.166005\n",
      "\tval_loss: 2.744316, odo_loss: 2.049837, ine_loss: 0.513550, ref_loss: 0.180929\n",
      "Epoch 102/2000\n",
      "\t[#    0] train_loss: 2.854130, odo_loss: 2.244797, ine_loss: 0.471713, ref_loss: 0.137621\n",
      "\t[#  180] train_loss: 2.534166, odo_loss: 1.926593, ine_loss: 0.454740, ref_loss: 0.152834\n",
      "\t[#  360] train_loss: 2.404764, odo_loss: 1.862308, ine_loss: 0.386419, ref_loss: 0.156037\n",
      "\t[#  540] train_loss: 2.606156, odo_loss: 1.927588, ine_loss: 0.504833, ref_loss: 0.173735\n",
      "\t[#  720] train_loss: 2.856031, odo_loss: 2.102215, ine_loss: 0.582481, ref_loss: 0.171334\n",
      "\t[#  900] train_loss: 2.529526, odo_loss: 1.891221, ine_loss: 0.486014, ref_loss: 0.152291\n",
      "\ttrain_loss: 2.696298, odo_loss: 2.019063, ine_loss: 0.512394, ref_loss: 0.164841\n",
      "\tval_loss: 2.686329, odo_loss: 1.998610, ine_loss: 0.510664, ref_loss: 0.177055\n",
      "Epoch 103/2000\n",
      "\t[#    0] train_loss: 2.534990, odo_loss: 1.828247, ine_loss: 0.536075, ref_loss: 0.170667\n",
      "\t[#  180] train_loss: 2.446897, odo_loss: 1.753010, ine_loss: 0.490341, ref_loss: 0.203547\n",
      "\t[#  360] train_loss: 2.770078, odo_loss: 2.059601, ine_loss: 0.545231, ref_loss: 0.165247\n",
      "\t[#  540] train_loss: 2.908127, odo_loss: 2.090735, ine_loss: 0.648506, ref_loss: 0.168886\n",
      "\t[#  720] train_loss: 3.061738, odo_loss: 2.463923, ine_loss: 0.437935, ref_loss: 0.159881\n",
      "\t[#  900] train_loss: 2.770618, odo_loss: 2.120248, ine_loss: 0.490783, ref_loss: 0.159588\n",
      "\ttrain_loss: 2.822222, odo_loss: 2.144928, ine_loss: 0.513015, ref_loss: 0.164280\n",
      "\tval_loss: 2.916132, odo_loss: 2.220626, ine_loss: 0.515092, ref_loss: 0.180414\n",
      "Epoch 104/2000\n",
      "\t[#    0] train_loss: 2.493659, odo_loss: 1.844332, ine_loss: 0.499523, ref_loss: 0.149804\n",
      "\t[#  180] train_loss: 2.671322, odo_loss: 1.963356, ine_loss: 0.534722, ref_loss: 0.173244\n",
      "\t[#  360] train_loss: 2.508584, odo_loss: 1.831316, ine_loss: 0.501481, ref_loss: 0.175788\n",
      "\t[#  540] train_loss: 2.625452, odo_loss: 1.960057, ine_loss: 0.491312, ref_loss: 0.174083\n",
      "\t[#  720] train_loss: 2.382015, odo_loss: 1.724661, ine_loss: 0.509127, ref_loss: 0.148227\n",
      "\t[#  900] train_loss: 3.102235, odo_loss: 2.411224, ine_loss: 0.536588, ref_loss: 0.154424\n",
      "\ttrain_loss: 2.783080, odo_loss: 2.104710, ine_loss: 0.513649, ref_loss: 0.164721\n",
      "\tval_loss: 2.805505, odo_loss: 2.117187, ine_loss: 0.511412, ref_loss: 0.176906\n",
      "Epoch 105/2000\n",
      "\t[#    0] train_loss: 2.592513, odo_loss: 1.793940, ine_loss: 0.631338, ref_loss: 0.167236\n",
      "\t[#  180] train_loss: 2.476162, odo_loss: 1.807234, ine_loss: 0.513035, ref_loss: 0.155893\n",
      "\t[#  360] train_loss: 2.817921, odo_loss: 2.211906, ine_loss: 0.469111, ref_loss: 0.136904\n",
      "\t[#  540] train_loss: 2.887399, odo_loss: 2.089263, ine_loss: 0.629890, ref_loss: 0.168246\n",
      "\t[#  720] train_loss: 2.373726, odo_loss: 1.697902, ine_loss: 0.505076, ref_loss: 0.170748\n",
      "\t[#  900] train_loss: 2.487304, odo_loss: 1.742151, ine_loss: 0.539541, ref_loss: 0.205612\n",
      "\ttrain_loss: 2.724621, odo_loss: 2.047723, ine_loss: 0.512224, ref_loss: 0.164674\n",
      "\tval_loss: 2.716258, odo_loss: 2.029743, ine_loss: 0.509940, ref_loss: 0.176576\n",
      "Epoch 106/2000\n",
      "\t[#    0] train_loss: 2.899890, odo_loss: 2.179245, ine_loss: 0.578970, ref_loss: 0.141675\n",
      "\t[#  180] train_loss: 2.653626, odo_loss: 2.022287, ine_loss: 0.477327, ref_loss: 0.154012\n",
      "\t[#  360] train_loss: 2.734788, odo_loss: 2.049854, ine_loss: 0.508686, ref_loss: 0.176248\n",
      "\t[#  540] train_loss: 2.527900, odo_loss: 1.846655, ine_loss: 0.498242, ref_loss: 0.183003\n",
      "\t[#  720] train_loss: 2.733218, odo_loss: 2.059598, ine_loss: 0.529736, ref_loss: 0.143883\n",
      "\t[#  900] train_loss: 2.885701, odo_loss: 2.022644, ine_loss: 0.725191, ref_loss: 0.137866\n",
      "\ttrain_loss: 2.699056, odo_loss: 2.020577, ine_loss: 0.514459, ref_loss: 0.164020\n",
      "\tval_loss: 2.678148, odo_loss: 1.993709, ine_loss: 0.508908, ref_loss: 0.175530\n",
      "Epoch 107/2000\n",
      "\t[#    0] train_loss: 2.601676, odo_loss: 1.835196, ine_loss: 0.601783, ref_loss: 0.164696\n",
      "\t[#  180] train_loss: 2.481735, odo_loss: 1.854541, ine_loss: 0.486949, ref_loss: 0.140245\n",
      "\t[#  360] train_loss: 2.602713, odo_loss: 1.863021, ine_loss: 0.522441, ref_loss: 0.217251\n",
      "\t[#  540] train_loss: 2.346257, odo_loss: 1.702507, ine_loss: 0.487092, ref_loss: 0.156658\n",
      "\t[#  720] train_loss: 2.454136, odo_loss: 1.821908, ine_loss: 0.486383, ref_loss: 0.145844\n",
      "\t[#  900] train_loss: 2.386836, odo_loss: 1.791275, ine_loss: 0.442441, ref_loss: 0.153120\n",
      "\ttrain_loss: 2.722842, odo_loss: 2.045354, ine_loss: 0.514371, ref_loss: 0.163117\n",
      "\tval_loss: 2.713741, odo_loss: 2.024040, ine_loss: 0.512309, ref_loss: 0.177392\n",
      "Epoch 108/2000\n",
      "\t[#    0] train_loss: 2.656919, odo_loss: 1.881450, ine_loss: 0.605446, ref_loss: 0.170023\n",
      "\t[#  180] train_loss: 2.451406, odo_loss: 1.685973, ine_loss: 0.607689, ref_loss: 0.157743\n",
      "\t[#  360] train_loss: 2.461131, odo_loss: 1.783381, ine_loss: 0.520474, ref_loss: 0.157276\n",
      "\t[#  540] train_loss: 2.917847, odo_loss: 2.237993, ine_loss: 0.479871, ref_loss: 0.199984\n",
      "\t[#  720] train_loss: 2.922006, odo_loss: 2.143846, ine_loss: 0.596424, ref_loss: 0.181736\n",
      "\t[#  900] train_loss: 2.958976, odo_loss: 2.229131, ine_loss: 0.559208, ref_loss: 0.170637\n",
      "\ttrain_loss: 2.679132, odo_loss: 2.001245, ine_loss: 0.514892, ref_loss: 0.162995\n",
      "\tval_loss: 2.663953, odo_loss: 1.976841, ine_loss: 0.508129, ref_loss: 0.178984\n",
      "\t*** Personal Best ***\n",
      "Epoch 109/2000\n",
      "\t[#    0] train_loss: 2.949084, odo_loss: 2.278541, ine_loss: 0.524009, ref_loss: 0.146534\n",
      "\t[#  180] train_loss: 2.593832, odo_loss: 1.917310, ine_loss: 0.513872, ref_loss: 0.162650\n",
      "\t[#  360] train_loss: 2.890652, odo_loss: 2.186612, ine_loss: 0.545634, ref_loss: 0.158407\n",
      "\t[#  540] train_loss: 2.561091, odo_loss: 1.893627, ine_loss: 0.507321, ref_loss: 0.160143\n",
      "\t[#  720] train_loss: 2.383855, odo_loss: 1.620002, ine_loss: 0.571312, ref_loss: 0.192541\n",
      "\t[#  900] train_loss: 2.644092, odo_loss: 2.005522, ine_loss: 0.485297, ref_loss: 0.153274\n",
      "\ttrain_loss: 2.663939, odo_loss: 1.986078, ine_loss: 0.515207, ref_loss: 0.162654\n",
      "\tval_loss: 2.645959, odo_loss: 1.953769, ine_loss: 0.516477, ref_loss: 0.175713\n",
      "\t*** Personal Best ***\n",
      "Epoch 110/2000\n",
      "\t[#    0] train_loss: 2.663197, odo_loss: 2.041022, ine_loss: 0.465835, ref_loss: 0.156340\n",
      "\t[#  180] train_loss: 2.515449, odo_loss: 1.967545, ine_loss: 0.393411, ref_loss: 0.154493\n",
      "\t[#  360] train_loss: 2.711023, odo_loss: 2.140878, ine_loss: 0.414438, ref_loss: 0.155706\n",
      "\t[#  540] train_loss: 2.701006, odo_loss: 1.845854, ine_loss: 0.665496, ref_loss: 0.189655\n",
      "\t[#  720] train_loss: 3.218628, odo_loss: 2.430140, ine_loss: 0.618605, ref_loss: 0.169883\n",
      "\t[#  900] train_loss: 2.833422, odo_loss: 2.141388, ine_loss: 0.564887, ref_loss: 0.127146\n",
      "\ttrain_loss: 2.629555, odo_loss: 1.949794, ine_loss: 0.517508, ref_loss: 0.162253\n",
      "\tval_loss: 2.674482, odo_loss: 1.979916, ine_loss: 0.518865, ref_loss: 0.175701\n",
      "Epoch 111/2000\n",
      "\t[#    0] train_loss: 2.357293, odo_loss: 1.800287, ine_loss: 0.422429, ref_loss: 0.134577\n",
      "\t[#  180] train_loss: 2.858464, odo_loss: 2.098129, ine_loss: 0.566573, ref_loss: 0.193762\n",
      "\t[#  360] train_loss: 2.653786, odo_loss: 2.041195, ine_loss: 0.454879, ref_loss: 0.157712\n",
      "\t[#  540] train_loss: 2.719372, odo_loss: 1.930794, ine_loss: 0.623031, ref_loss: 0.165547\n",
      "\t[#  720] train_loss: 2.225161, odo_loss: 1.627769, ine_loss: 0.448793, ref_loss: 0.148599\n",
      "\t[#  900] train_loss: 2.434670, odo_loss: 1.841924, ine_loss: 0.441752, ref_loss: 0.150994\n",
      "\ttrain_loss: 2.676537, odo_loss: 1.996482, ine_loss: 0.517674, ref_loss: 0.162382\n",
      "\tval_loss: 3.154020, odo_loss: 2.461742, ine_loss: 0.515539, ref_loss: 0.176739\n",
      "Epoch 112/2000\n",
      "\t[#    0] train_loss: 2.716208, odo_loss: 2.097195, ine_loss: 0.457848, ref_loss: 0.161164\n",
      "\t[#  180] train_loss: 2.398217, odo_loss: 1.657749, ine_loss: 0.610041, ref_loss: 0.130428\n",
      "\t[#  360] train_loss: 2.573251, odo_loss: 2.034818, ine_loss: 0.391355, ref_loss: 0.147078\n",
      "\t[#  540] train_loss: 3.175943, odo_loss: 2.448813, ine_loss: 0.544318, ref_loss: 0.182811\n",
      "\t[#  720] train_loss: 2.600683, odo_loss: 1.886312, ine_loss: 0.555684, ref_loss: 0.158687\n",
      "\t[#  900] train_loss: 2.480498, odo_loss: 1.873431, ine_loss: 0.443849, ref_loss: 0.163217\n",
      "\ttrain_loss: 2.874805, odo_loss: 2.193900, ine_loss: 0.518532, ref_loss: 0.162373\n",
      "\tval_loss: 2.729479, odo_loss: 2.036517, ine_loss: 0.516511, ref_loss: 0.176451\n",
      "Epoch 113/2000\n",
      "\t[#    0] train_loss: 2.832718, odo_loss: 2.139321, ine_loss: 0.526850, ref_loss: 0.166546\n",
      "\t[#  180] train_loss: 2.679258, odo_loss: 2.028105, ine_loss: 0.479967, ref_loss: 0.171186\n",
      "\t[#  360] train_loss: 2.494722, odo_loss: 1.882478, ine_loss: 0.476359, ref_loss: 0.135884\n",
      "\t[#  540] train_loss: 2.484351, odo_loss: 1.830873, ine_loss: 0.491205, ref_loss: 0.162273\n",
      "\t[#  720] train_loss: 2.865095, odo_loss: 2.124636, ine_loss: 0.581171, ref_loss: 0.159288\n",
      "\t[#  900] train_loss: 2.335732, odo_loss: 1.738213, ine_loss: 0.427951, ref_loss: 0.169568\n",
      "\ttrain_loss: 2.624362, odo_loss: 1.940494, ine_loss: 0.522196, ref_loss: 0.161672\n",
      "\tval_loss: 2.639992, odo_loss: 1.946401, ine_loss: 0.515908, ref_loss: 0.177684\n",
      "\t*** Personal Best ***\n",
      "Epoch 114/2000\n",
      "\t[#    0] train_loss: 2.387204, odo_loss: 1.785986, ine_loss: 0.420673, ref_loss: 0.180546\n",
      "\t[#  180] train_loss: 3.186804, odo_loss: 2.507581, ine_loss: 0.525991, ref_loss: 0.153232\n",
      "\t[#  360] train_loss: 2.728035, odo_loss: 2.074586, ine_loss: 0.508688, ref_loss: 0.144760\n",
      "\t[#  540] train_loss: 2.522681, odo_loss: 1.837293, ine_loss: 0.525767, ref_loss: 0.159620\n",
      "\t[#  720] train_loss: 2.728582, odo_loss: 1.934023, ine_loss: 0.603562, ref_loss: 0.190997\n",
      "\t[#  900] train_loss: 2.691846, odo_loss: 2.098555, ine_loss: 0.456441, ref_loss: 0.136850\n",
      "\ttrain_loss: 2.684802, odo_loss: 1.999791, ine_loss: 0.523608, ref_loss: 0.161402\n",
      "\tval_loss: 2.816504, odo_loss: 2.124928, ine_loss: 0.514673, ref_loss: 0.176903\n",
      "Epoch 115/2000\n",
      "\t[#    0] train_loss: 2.602706, odo_loss: 1.984537, ine_loss: 0.479625, ref_loss: 0.138544\n",
      "\t[#  180] train_loss: 2.545247, odo_loss: 1.845208, ine_loss: 0.548313, ref_loss: 0.151726\n",
      "\t[#  360] train_loss: 2.714333, odo_loss: 2.087751, ine_loss: 0.451582, ref_loss: 0.175000\n",
      "\t[#  540] train_loss: 2.843048, odo_loss: 2.168350, ine_loss: 0.495635, ref_loss: 0.179064\n",
      "\t[#  720] train_loss: 2.279102, odo_loss: 1.671361, ine_loss: 0.446601, ref_loss: 0.161140\n",
      "\t[#  900] train_loss: 2.683136, odo_loss: 2.029745, ine_loss: 0.512127, ref_loss: 0.141264\n",
      "\ttrain_loss: 2.683971, odo_loss: 1.997917, ine_loss: 0.524786, ref_loss: 0.161267\n",
      "\tval_loss: 2.603193, odo_loss: 1.903863, ine_loss: 0.523093, ref_loss: 0.176237\n",
      "\t*** Personal Best ***\n",
      "Epoch 116/2000\n",
      "\t[#    0] train_loss: 2.461895, odo_loss: 1.847449, ine_loss: 0.451928, ref_loss: 0.162518\n",
      "\t[#  180] train_loss: 2.516837, odo_loss: 1.824036, ine_loss: 0.526988, ref_loss: 0.165813\n",
      "\t[#  360] train_loss: 2.794942, odo_loss: 2.138043, ine_loss: 0.517555, ref_loss: 0.139345\n",
      "\t[#  540] train_loss: 3.314830, odo_loss: 2.494457, ine_loss: 0.645592, ref_loss: 0.174780\n",
      "\t[#  720] train_loss: 2.195582, odo_loss: 1.533661, ine_loss: 0.534638, ref_loss: 0.127282\n",
      "\t[#  900] train_loss: 2.324778, odo_loss: 1.677387, ine_loss: 0.506151, ref_loss: 0.141240\n",
      "\ttrain_loss: 2.627285, odo_loss: 1.939246, ine_loss: 0.526670, ref_loss: 0.161369\n",
      "\tval_loss: 2.605906, odo_loss: 1.905458, ine_loss: 0.523758, ref_loss: 0.176690\n",
      "Epoch 117/2000\n",
      "\t[#    0] train_loss: 2.881432, odo_loss: 2.116970, ine_loss: 0.608761, ref_loss: 0.155701\n",
      "\t[#  180] train_loss: 2.497551, odo_loss: 1.809514, ine_loss: 0.506513, ref_loss: 0.181523\n",
      "\t[#  360] train_loss: 2.092191, odo_loss: 1.429147, ine_loss: 0.509788, ref_loss: 0.153256\n",
      "\t[#  540] train_loss: 2.417262, odo_loss: 1.836511, ine_loss: 0.420403, ref_loss: 0.160349\n",
      "\t[#  720] train_loss: 2.941632, odo_loss: 2.209571, ine_loss: 0.552619, ref_loss: 0.179442\n",
      "\t[#  900] train_loss: 2.731827, odo_loss: 1.975720, ine_loss: 0.613392, ref_loss: 0.142714\n",
      "\ttrain_loss: 2.566250, odo_loss: 1.875296, ine_loss: 0.530241, ref_loss: 0.160713\n",
      "\tval_loss: 2.566154, odo_loss: 1.867072, ine_loss: 0.524859, ref_loss: 0.174224\n",
      "\t*** Personal Best ***\n",
      "Epoch 118/2000\n",
      "\t[#    0] train_loss: 2.623112, odo_loss: 1.906550, ine_loss: 0.551119, ref_loss: 0.165443\n",
      "\t[#  180] train_loss: 2.180042, odo_loss: 1.515359, ine_loss: 0.505374, ref_loss: 0.159309\n",
      "\t[#  360] train_loss: 2.741521, odo_loss: 2.002416, ine_loss: 0.613785, ref_loss: 0.125320\n",
      "\t[#  540] train_loss: 2.736494, odo_loss: 2.015195, ine_loss: 0.576250, ref_loss: 0.145048\n",
      "\t[#  720] train_loss: 2.705327, odo_loss: 1.957697, ine_loss: 0.564142, ref_loss: 0.183488\n",
      "\t[#  900] train_loss: 2.344231, odo_loss: 1.631663, ine_loss: 0.569671, ref_loss: 0.142897\n",
      "\ttrain_loss: 2.547832, odo_loss: 1.856095, ine_loss: 0.531507, ref_loss: 0.160230\n",
      "\tval_loss: 2.502859, odo_loss: 1.797054, ine_loss: 0.532288, ref_loss: 0.173516\n",
      "\t*** Personal Best ***\n",
      "Epoch 119/2000\n",
      "\t[#    0] train_loss: 2.470196, odo_loss: 1.808749, ine_loss: 0.522190, ref_loss: 0.139258\n",
      "\t[#  180] train_loss: 2.457841, odo_loss: 1.725401, ine_loss: 0.559669, ref_loss: 0.172771\n",
      "\t[#  360] train_loss: 2.288990, odo_loss: 1.728449, ine_loss: 0.422703, ref_loss: 0.137838\n",
      "\t[#  540] train_loss: 2.545314, odo_loss: 1.927563, ine_loss: 0.435189, ref_loss: 0.182563\n",
      "\t[#  720] train_loss: 2.517067, odo_loss: 1.773632, ine_loss: 0.557199, ref_loss: 0.186236\n",
      "\t[#  900] train_loss: 2.652191, odo_loss: 1.978329, ine_loss: 0.512659, ref_loss: 0.161203\n",
      "\ttrain_loss: 2.512255, odo_loss: 1.818289, ine_loss: 0.534196, ref_loss: 0.159770\n",
      "\tval_loss: 2.521694, odo_loss: 1.818533, ine_loss: 0.527272, ref_loss: 0.175889\n",
      "Epoch 120/2000\n",
      "\t[#    0] train_loss: 2.255744, odo_loss: 1.630909, ine_loss: 0.482907, ref_loss: 0.141927\n",
      "\t[#  180] train_loss: 2.179540, odo_loss: 1.560835, ine_loss: 0.499726, ref_loss: 0.118979\n",
      "\t[#  360] train_loss: 2.434843, odo_loss: 1.651471, ine_loss: 0.607845, ref_loss: 0.175528\n",
      "\t[#  540] train_loss: 2.929779, odo_loss: 2.310273, ine_loss: 0.463324, ref_loss: 0.156182\n",
      "\t[#  720] train_loss: 2.785962, odo_loss: 2.142078, ine_loss: 0.499857, ref_loss: 0.144027\n",
      "\t[#  900] train_loss: 2.522132, odo_loss: 1.807261, ine_loss: 0.571284, ref_loss: 0.143587\n",
      "\ttrain_loss: 2.514884, odo_loss: 1.821766, ine_loss: 0.533608, ref_loss: 0.159509\n",
      "\tval_loss: 2.512228, odo_loss: 1.805869, ine_loss: 0.530330, ref_loss: 0.176029\n",
      "Epoch 121/2000\n",
      "\t[#    0] train_loss: 2.777043, odo_loss: 2.027315, ine_loss: 0.602852, ref_loss: 0.146875\n",
      "\t[#  180] train_loss: 2.912724, odo_loss: 2.017557, ine_loss: 0.709677, ref_loss: 0.185490\n",
      "\t[#  360] train_loss: 2.365220, odo_loss: 1.683213, ine_loss: 0.531825, ref_loss: 0.150182\n",
      "\t[#  540] train_loss: 2.906324, odo_loss: 2.029115, ine_loss: 0.718726, ref_loss: 0.158484\n",
      "\t[#  720] train_loss: 2.234444, odo_loss: 1.461819, ine_loss: 0.613491, ref_loss: 0.159134\n",
      "\t[#  900] train_loss: 2.373942, odo_loss: 1.794956, ine_loss: 0.453047, ref_loss: 0.125939\n",
      "\ttrain_loss: 2.499692, odo_loss: 1.806709, ine_loss: 0.533637, ref_loss: 0.159347\n",
      "\tval_loss: 2.516305, odo_loss: 1.812492, ine_loss: 0.531693, ref_loss: 0.172120\n",
      "Epoch 122/2000\n",
      "\t[#    0] train_loss: 2.763321, odo_loss: 2.053675, ine_loss: 0.522715, ref_loss: 0.186932\n",
      "\t[#  180] train_loss: 2.414409, odo_loss: 1.814354, ine_loss: 0.444056, ref_loss: 0.155999\n",
      "\t[#  360] train_loss: 2.645689, odo_loss: 1.966852, ine_loss: 0.520470, ref_loss: 0.158367\n",
      "\t[#  540] train_loss: 2.656548, odo_loss: 2.020484, ine_loss: 0.488358, ref_loss: 0.147706\n",
      "\t[#  720] train_loss: 2.056216, odo_loss: 1.475598, ine_loss: 0.440769, ref_loss: 0.139849\n",
      "\t[#  900] train_loss: 2.525033, odo_loss: 1.831420, ine_loss: 0.530021, ref_loss: 0.163592\n",
      "\ttrain_loss: 2.566760, odo_loss: 1.874431, ine_loss: 0.533235, ref_loss: 0.159094\n",
      "\tval_loss: 2.595283, odo_loss: 1.886351, ine_loss: 0.535287, ref_loss: 0.173644\n",
      "Epoch 123/2000\n",
      "\t[#    0] train_loss: 2.416100, odo_loss: 1.781991, ine_loss: 0.466680, ref_loss: 0.167428\n",
      "\t[#  180] train_loss: 2.401704, odo_loss: 1.704641, ine_loss: 0.555763, ref_loss: 0.141299\n",
      "\t[#  360] train_loss: 2.814435, odo_loss: 2.072397, ine_loss: 0.608921, ref_loss: 0.133118\n",
      "\t[#  540] train_loss: 2.348278, odo_loss: 1.623288, ine_loss: 0.564297, ref_loss: 0.160692\n",
      "\t[#  720] train_loss: 3.757054, odo_loss: 3.019718, ine_loss: 0.589394, ref_loss: 0.147942\n",
      "\t[#  900] train_loss: 2.215870, odo_loss: 1.468049, ine_loss: 0.573399, ref_loss: 0.174422\n",
      "\ttrain_loss: 2.570250, odo_loss: 1.878375, ine_loss: 0.532870, ref_loss: 0.159006\n",
      "\tval_loss: 2.600846, odo_loss: 1.897561, ine_loss: 0.527778, ref_loss: 0.175507\n",
      "Epoch 124/2000\n",
      "\t[#    0] train_loss: 2.730943, odo_loss: 1.980514, ine_loss: 0.594743, ref_loss: 0.155686\n",
      "\t[#  180] train_loss: 2.376215, odo_loss: 1.693717, ine_loss: 0.504805, ref_loss: 0.177693\n",
      "\t[#  360] train_loss: 2.645322, odo_loss: 1.910539, ine_loss: 0.558215, ref_loss: 0.176568\n",
      "\t[#  540] train_loss: 2.232643, odo_loss: 1.475942, ine_loss: 0.590149, ref_loss: 0.166552\n",
      "\t[#  720] train_loss: 2.513227, odo_loss: 1.875987, ine_loss: 0.493956, ref_loss: 0.143284\n",
      "\t[#  900] train_loss: 2.479006, odo_loss: 1.797774, ine_loss: 0.518297, ref_loss: 0.162935\n",
      "\ttrain_loss: 2.599737, odo_loss: 1.907671, ine_loss: 0.532747, ref_loss: 0.159319\n",
      "\tval_loss: 2.587284, odo_loss: 1.886707, ine_loss: 0.525220, ref_loss: 0.175356\n",
      "Epoch 125/2000\n",
      "\t[#    0] train_loss: 2.319756, odo_loss: 1.649659, ine_loss: 0.529582, ref_loss: 0.140514\n",
      "\t[#  180] train_loss: 2.705762, odo_loss: 2.074959, ine_loss: 0.439186, ref_loss: 0.191617\n",
      "\t[#  360] train_loss: 2.162957, odo_loss: 1.469835, ine_loss: 0.523055, ref_loss: 0.170067\n",
      "\t[#  540] train_loss: 2.620760, odo_loss: 1.850108, ine_loss: 0.575028, ref_loss: 0.195625\n",
      "\t[#  720] train_loss: 2.416208, odo_loss: 1.816212, ine_loss: 0.434974, ref_loss: 0.165022\n",
      "\t[#  900] train_loss: 2.710459, odo_loss: 1.967533, ine_loss: 0.582915, ref_loss: 0.160011\n",
      "\ttrain_loss: 2.542157, odo_loss: 1.852287, ine_loss: 0.531307, ref_loss: 0.158563\n",
      "\tval_loss: 2.499566, odo_loss: 1.801578, ine_loss: 0.523952, ref_loss: 0.174035\n",
      "Epoch 126/2000\n",
      "\t[#    0] train_loss: 2.456421, odo_loss: 1.718575, ine_loss: 0.618576, ref_loss: 0.119270\n",
      "\t[#  180] train_loss: 2.568654, odo_loss: 1.800781, ine_loss: 0.589452, ref_loss: 0.178421\n",
      "\t[#  360] train_loss: 2.651484, odo_loss: 1.995362, ine_loss: 0.509351, ref_loss: 0.146771\n",
      "\t[#  540] train_loss: 2.307959, odo_loss: 1.635666, ine_loss: 0.515167, ref_loss: 0.157126\n",
      "\t[#  720] train_loss: 2.358081, odo_loss: 1.685877, ine_loss: 0.518266, ref_loss: 0.153938\n",
      "\t[#  900] train_loss: 2.657103, odo_loss: 1.870716, ine_loss: 0.640930, ref_loss: 0.145456\n",
      "\ttrain_loss: 2.508153, odo_loss: 1.817834, ine_loss: 0.531599, ref_loss: 0.158720\n",
      "\tval_loss: 2.520357, odo_loss: 1.816167, ine_loss: 0.528844, ref_loss: 0.175347\n",
      "Epoch 127/2000\n",
      "\t[#    0] train_loss: 2.789864, odo_loss: 1.956823, ine_loss: 0.646269, ref_loss: 0.186772\n",
      "\t[#  180] train_loss: 2.257496, odo_loss: 1.620986, ine_loss: 0.494616, ref_loss: 0.141894\n",
      "\t[#  360] train_loss: 4.626208, odo_loss: 3.849043, ine_loss: 0.615706, ref_loss: 0.161459\n",
      "\t[#  540] train_loss: 2.807190, odo_loss: 2.124163, ine_loss: 0.522971, ref_loss: 0.160055\n",
      "\t[#  720] train_loss: 2.935433, odo_loss: 2.257962, ine_loss: 0.534699, ref_loss: 0.142772\n",
      "\t[#  900] train_loss: 2.712804, odo_loss: 1.941451, ine_loss: 0.596914, ref_loss: 0.174439\n",
      "\ttrain_loss: 2.610075, odo_loss: 1.921871, ine_loss: 0.529761, ref_loss: 0.158443\n",
      "\tval_loss: 2.455348, odo_loss: 1.752760, ine_loss: 0.529175, ref_loss: 0.173413\n",
      "\t*** Personal Best ***\n",
      "Epoch 128/2000\n",
      "\t[#    0] train_loss: 2.312067, odo_loss: 1.645544, ine_loss: 0.499146, ref_loss: 0.167378\n",
      "\t[#  180] train_loss: 2.604481, odo_loss: 1.920077, ine_loss: 0.522827, ref_loss: 0.161577\n",
      "\t[#  360] train_loss: 2.402354, odo_loss: 1.710773, ine_loss: 0.526728, ref_loss: 0.164853\n",
      "\t[#  540] train_loss: 2.169527, odo_loss: 1.571909, ine_loss: 0.440213, ref_loss: 0.157405\n",
      "\t[#  720] train_loss: 2.811696, odo_loss: 2.041985, ine_loss: 0.593483, ref_loss: 0.176228\n",
      "\t[#  900] train_loss: 2.657111, odo_loss: 1.953918, ine_loss: 0.515482, ref_loss: 0.187711\n",
      "\ttrain_loss: 2.426428, odo_loss: 1.737134, ine_loss: 0.531158, ref_loss: 0.158136\n",
      "\tval_loss: 2.364762, odo_loss: 1.664220, ine_loss: 0.524844, ref_loss: 0.175698\n",
      "\t*** Personal Best ***\n",
      "Epoch 129/2000\n",
      "\t[#    0] train_loss: 2.345659, odo_loss: 1.677218, ine_loss: 0.531652, ref_loss: 0.136789\n",
      "\t[#  180] train_loss: 2.293178, odo_loss: 1.652514, ine_loss: 0.492499, ref_loss: 0.148165\n",
      "\t[#  360] train_loss: 2.598005, odo_loss: 1.933288, ine_loss: 0.523654, ref_loss: 0.141063\n",
      "\t[#  540] train_loss: 2.274487, odo_loss: 1.623485, ine_loss: 0.475240, ref_loss: 0.175762\n",
      "\t[#  720] train_loss: 2.039446, odo_loss: 1.356164, ine_loss: 0.517895, ref_loss: 0.165387\n",
      "\t[#  900] train_loss: 2.364188, odo_loss: 1.710557, ine_loss: 0.489753, ref_loss: 0.163879\n",
      "\ttrain_loss: 2.420623, odo_loss: 1.733142, ine_loss: 0.530069, ref_loss: 0.157412\n",
      "\tval_loss: 2.495482, odo_loss: 1.796501, ine_loss: 0.524372, ref_loss: 0.174609\n",
      "Epoch 130/2000\n",
      "\t[#    0] train_loss: 2.967724, odo_loss: 2.339240, ine_loss: 0.473918, ref_loss: 0.154566\n",
      "\t[#  180] train_loss: 2.310346, odo_loss: 1.600159, ine_loss: 0.556109, ref_loss: 0.154079\n",
      "\t[#  360] train_loss: 2.989988, odo_loss: 2.256052, ine_loss: 0.573934, ref_loss: 0.160002\n",
      "\t[#  540] train_loss: 2.575308, odo_loss: 1.802131, ine_loss: 0.596315, ref_loss: 0.176863\n",
      "\t[#  720] train_loss: 2.214703, odo_loss: 1.515019, ine_loss: 0.515249, ref_loss: 0.184436\n",
      "\t[#  900] train_loss: 2.848184, odo_loss: 2.137421, ine_loss: 0.556310, ref_loss: 0.154453\n",
      "\ttrain_loss: 2.417743, odo_loss: 1.730232, ine_loss: 0.529806, ref_loss: 0.157704\n",
      "\tval_loss: 2.439988, odo_loss: 1.744045, ine_loss: 0.523044, ref_loss: 0.172900\n",
      "Epoch 131/2000\n",
      "\t[#    0] train_loss: 2.469852, odo_loss: 1.849840, ine_loss: 0.451655, ref_loss: 0.168357\n",
      "\t[#  180] train_loss: 2.718081, odo_loss: 2.078984, ine_loss: 0.488584, ref_loss: 0.150512\n",
      "\t[#  360] train_loss: 3.426448, odo_loss: 2.583786, ine_loss: 0.691243, ref_loss: 0.151419\n",
      "\t[#  540] train_loss: 2.165912, odo_loss: 1.529357, ine_loss: 0.490691, ref_loss: 0.145865\n",
      "\t[#  720] train_loss: 2.550527, odo_loss: 1.911114, ine_loss: 0.497692, ref_loss: 0.141721\n",
      "\t[#  900] train_loss: 2.462458, odo_loss: 1.777949, ine_loss: 0.492921, ref_loss: 0.191588\n",
      "\ttrain_loss: 2.593043, odo_loss: 1.906786, ine_loss: 0.528524, ref_loss: 0.157733\n",
      "\tval_loss: 2.609684, odo_loss: 1.907372, ine_loss: 0.530463, ref_loss: 0.171849\n",
      "Epoch 132/2000\n",
      "\t[#    0] train_loss: 2.393941, odo_loss: 1.615042, ine_loss: 0.624650, ref_loss: 0.154249\n",
      "\t[#  180] train_loss: 2.468192, odo_loss: 1.704245, ine_loss: 0.621810, ref_loss: 0.142138\n",
      "\t[#  360] train_loss: 2.613686, odo_loss: 1.796143, ine_loss: 0.664643, ref_loss: 0.152900\n",
      "\t[#  540] train_loss: 2.396263, odo_loss: 1.719764, ine_loss: 0.548162, ref_loss: 0.128337\n",
      "\t[#  720] train_loss: 2.522513, odo_loss: 1.880298, ine_loss: 0.470380, ref_loss: 0.171835\n",
      "\t[#  900] train_loss: 2.262671, odo_loss: 1.647673, ine_loss: 0.447831, ref_loss: 0.167167\n",
      "\ttrain_loss: 2.443081, odo_loss: 1.755384, ine_loss: 0.530053, ref_loss: 0.157645\n",
      "\tval_loss: 2.467555, odo_loss: 1.764286, ine_loss: 0.531471, ref_loss: 0.171798\n",
      "Epoch 133/2000\n",
      "\t[#    0] train_loss: 2.457483, odo_loss: 1.777268, ine_loss: 0.517185, ref_loss: 0.163030\n",
      "\t[#  180] train_loss: 2.226633, odo_loss: 1.612412, ine_loss: 0.446666, ref_loss: 0.167555\n",
      "\t[#  360] train_loss: 2.182844, odo_loss: 1.516906, ine_loss: 0.479832, ref_loss: 0.186106\n",
      "\t[#  540] train_loss: 2.199440, odo_loss: 1.616518, ine_loss: 0.440288, ref_loss: 0.142633\n",
      "\t[#  720] train_loss: 2.663410, odo_loss: 1.910129, ine_loss: 0.590454, ref_loss: 0.162827\n",
      "\t[#  900] train_loss: 2.448411, odo_loss: 1.675292, ine_loss: 0.609832, ref_loss: 0.163287\n",
      "\ttrain_loss: 2.389759, odo_loss: 1.703409, ine_loss: 0.529683, ref_loss: 0.156667\n",
      "\tval_loss: 2.353555, odo_loss: 1.657509, ine_loss: 0.524595, ref_loss: 0.171451\n",
      "\t*** Personal Best ***\n",
      "Epoch 134/2000\n",
      "\t[#    0] train_loss: 1.871662, odo_loss: 1.228894, ine_loss: 0.496302, ref_loss: 0.146465\n",
      "\t[#  180] train_loss: 2.322783, odo_loss: 1.687076, ine_loss: 0.474955, ref_loss: 0.160752\n",
      "\t[#  360] train_loss: 2.376417, odo_loss: 1.717428, ine_loss: 0.525451, ref_loss: 0.133538\n",
      "\t[#  540] train_loss: 2.394972, odo_loss: 1.678301, ine_loss: 0.538049, ref_loss: 0.178623\n",
      "\t[#  720] train_loss: 2.430021, odo_loss: 1.791973, ine_loss: 0.486844, ref_loss: 0.151204\n",
      "\t[#  900] train_loss: 2.145813, odo_loss: 1.544339, ine_loss: 0.457820, ref_loss: 0.143653\n",
      "\ttrain_loss: 2.374967, odo_loss: 1.690197, ine_loss: 0.528300, ref_loss: 0.156470\n",
      "\tval_loss: 2.377001, odo_loss: 1.676837, ine_loss: 0.526767, ref_loss: 0.173397\n",
      "Epoch 135/2000\n",
      "\t[#    0] train_loss: 2.480328, odo_loss: 1.812965, ine_loss: 0.516142, ref_loss: 0.151222\n",
      "\t[#  180] train_loss: 2.276597, odo_loss: 1.632458, ine_loss: 0.492485, ref_loss: 0.151654\n",
      "\t[#  360] train_loss: 2.581256, odo_loss: 1.900911, ine_loss: 0.514112, ref_loss: 0.166233\n",
      "\t[#  540] train_loss: 2.674606, odo_loss: 1.969406, ine_loss: 0.562498, ref_loss: 0.142703\n",
      "\t[#  720] train_loss: 2.226454, odo_loss: 1.685052, ine_loss: 0.384284, ref_loss: 0.157118\n",
      "\t[#  900] train_loss: 2.070947, odo_loss: 1.440040, ine_loss: 0.470421, ref_loss: 0.160486\n",
      "\ttrain_loss: 2.680119, odo_loss: 1.995078, ine_loss: 0.527454, ref_loss: 0.157587\n",
      "\tval_loss: 2.696577, odo_loss: 2.000539, ine_loss: 0.519030, ref_loss: 0.177009\n",
      "Epoch 136/2000\n",
      "\t[#    0] train_loss: 2.531068, odo_loss: 1.816839, ine_loss: 0.535674, ref_loss: 0.178555\n",
      "\t[#  180] train_loss: 2.575887, odo_loss: 1.869287, ine_loss: 0.544581, ref_loss: 0.162019\n",
      "\t[#  360] train_loss: 2.538082, odo_loss: 1.904412, ine_loss: 0.499193, ref_loss: 0.134477\n",
      "\t[#  540] train_loss: 2.162538, odo_loss: 1.513838, ine_loss: 0.505429, ref_loss: 0.143271\n",
      "\t[#  720] train_loss: 2.506400, odo_loss: 1.873563, ine_loss: 0.492200, ref_loss: 0.140637\n",
      "\t[#  900] train_loss: 2.216416, odo_loss: 1.614172, ine_loss: 0.492026, ref_loss: 0.110218\n",
      "\ttrain_loss: 2.437389, odo_loss: 1.751260, ine_loss: 0.529466, ref_loss: 0.156663\n",
      "\tval_loss: 2.381500, odo_loss: 1.684983, ine_loss: 0.524044, ref_loss: 0.172473\n",
      "Epoch 137/2000\n",
      "\t[#    0] train_loss: 2.510385, odo_loss: 1.885617, ine_loss: 0.475864, ref_loss: 0.148904\n",
      "\t[#  180] train_loss: 2.573766, odo_loss: 1.910068, ine_loss: 0.517683, ref_loss: 0.146015\n",
      "\t[#  360] train_loss: 2.397317, odo_loss: 1.675271, ine_loss: 0.585728, ref_loss: 0.136318\n",
      "\t[#  540] train_loss: 2.444843, odo_loss: 1.720717, ine_loss: 0.556706, ref_loss: 0.167420\n",
      "\t[#  720] train_loss: 2.270888, odo_loss: 1.666485, ine_loss: 0.441543, ref_loss: 0.162859\n",
      "\t[#  900] train_loss: 2.263099, odo_loss: 1.641576, ine_loss: 0.437351, ref_loss: 0.184172\n",
      "\ttrain_loss: 2.346502, odo_loss: 1.663966, ine_loss: 0.526788, ref_loss: 0.155748\n",
      "\tval_loss: 2.389967, odo_loss: 1.692610, ine_loss: 0.524521, ref_loss: 0.172836\n",
      "Epoch 138/2000\n",
      "\t[#    0] train_loss: 2.453267, odo_loss: 1.679595, ine_loss: 0.595464, ref_loss: 0.178209\n",
      "\t[#  180] train_loss: 2.064432, odo_loss: 1.435625, ine_loss: 0.478906, ref_loss: 0.149901\n",
      "\t[#  360] train_loss: 2.277634, odo_loss: 1.529608, ine_loss: 0.592229, ref_loss: 0.155798\n",
      "\t[#  540] train_loss: 2.209354, odo_loss: 1.550475, ine_loss: 0.506381, ref_loss: 0.152498\n",
      "\t[#  720] train_loss: 2.839123, odo_loss: 2.091922, ine_loss: 0.581346, ref_loss: 0.165855\n",
      "\t[#  900] train_loss: 2.266711, odo_loss: 1.570797, ine_loss: 0.530357, ref_loss: 0.165557\n",
      "\ttrain_loss: 2.456981, odo_loss: 1.773992, ine_loss: 0.527238, ref_loss: 0.155751\n",
      "\tval_loss: 2.435255, odo_loss: 1.737269, ine_loss: 0.523865, ref_loss: 0.174121\n",
      "Epoch 139/2000\n",
      "\t[#    0] train_loss: 2.223597, odo_loss: 1.440481, ine_loss: 0.642850, ref_loss: 0.140265\n",
      "\t[#  180] train_loss: 2.483582, odo_loss: 1.803491, ine_loss: 0.547548, ref_loss: 0.132544\n",
      "\t[#  360] train_loss: 2.187700, odo_loss: 1.556449, ine_loss: 0.488664, ref_loss: 0.142587\n",
      "\t[#  540] train_loss: 2.488585, odo_loss: 1.845298, ine_loss: 0.471017, ref_loss: 0.172270\n",
      "\t[#  720] train_loss: 2.515604, odo_loss: 1.866975, ine_loss: 0.510836, ref_loss: 0.137793\n",
      "\t[#  900] train_loss: 2.575976, odo_loss: 1.878178, ine_loss: 0.540159, ref_loss: 0.157638\n",
      "\ttrain_loss: 2.386973, odo_loss: 1.702458, ine_loss: 0.527762, ref_loss: 0.156752\n",
      "\tval_loss: 2.366735, odo_loss: 1.667160, ine_loss: 0.527401, ref_loss: 0.172174\n",
      "Epoch 140/2000\n",
      "\t[#    0] train_loss: 2.093390, odo_loss: 1.328950, ine_loss: 0.604542, ref_loss: 0.159898\n",
      "\t[#  180] train_loss: 2.331765, odo_loss: 1.576410, ine_loss: 0.582317, ref_loss: 0.173038\n",
      "\t[#  360] train_loss: 2.731412, odo_loss: 2.004053, ine_loss: 0.582210, ref_loss: 0.145149\n",
      "\t[#  540] train_loss: 2.260309, odo_loss: 1.591942, ine_loss: 0.527421, ref_loss: 0.140946\n",
      "\t[#  720] train_loss: 2.344317, odo_loss: 1.710541, ine_loss: 0.451187, ref_loss: 0.182590\n",
      "\t[#  900] train_loss: 2.452903, odo_loss: 1.633287, ine_loss: 0.653491, ref_loss: 0.166124\n",
      "\ttrain_loss: 2.363197, odo_loss: 1.680268, ine_loss: 0.527302, ref_loss: 0.155627\n",
      "\tval_loss: 2.405122, odo_loss: 1.707515, ine_loss: 0.525326, ref_loss: 0.172281\n",
      "Epoch 141/2000\n",
      "\t[#    0] train_loss: 2.161038, odo_loss: 1.405204, ine_loss: 0.595036, ref_loss: 0.160798\n",
      "\t[#  180] train_loss: 2.423458, odo_loss: 1.767725, ine_loss: 0.507445, ref_loss: 0.148288\n",
      "\t[#  360] train_loss: 2.156312, odo_loss: 1.330752, ine_loss: 0.648285, ref_loss: 0.177276\n",
      "\t[#  540] train_loss: 2.379455, odo_loss: 1.658440, ine_loss: 0.538099, ref_loss: 0.182917\n",
      "\t[#  720] train_loss: 6.154733, odo_loss: 5.478466, ine_loss: 0.513855, ref_loss: 0.162412\n",
      "\t[#  900] train_loss: 2.352727, odo_loss: 1.732813, ine_loss: 0.448462, ref_loss: 0.171451\n",
      "\ttrain_loss: 2.377029, odo_loss: 1.695033, ine_loss: 0.526913, ref_loss: 0.155083\n",
      "\tval_loss: 2.542668, odo_loss: 1.847316, ine_loss: 0.522224, ref_loss: 0.173128\n",
      "Epoch 142/2000\n",
      "\t[#    0] train_loss: 2.384464, odo_loss: 1.742052, ine_loss: 0.500120, ref_loss: 0.142291\n",
      "\t[#  180] train_loss: 2.032074, odo_loss: 1.426000, ine_loss: 0.461928, ref_loss: 0.144146\n",
      "\t[#  360] train_loss: 2.401782, odo_loss: 1.703944, ine_loss: 0.488380, ref_loss: 0.209457\n",
      "\t[#  540] train_loss: 2.336231, odo_loss: 1.765277, ine_loss: 0.426373, ref_loss: 0.144580\n",
      "\t[#  720] train_loss: 1.818920, odo_loss: 1.280992, ine_loss: 0.390935, ref_loss: 0.146993\n",
      "\t[#  900] train_loss: 2.680715, odo_loss: 1.891964, ine_loss: 0.640616, ref_loss: 0.148135\n",
      "\ttrain_loss: 2.441879, odo_loss: 1.757943, ine_loss: 0.528339, ref_loss: 0.155596\n",
      "\tval_loss: 2.444472, odo_loss: 1.748306, ine_loss: 0.525541, ref_loss: 0.170625\n",
      "Epoch 143/2000\n",
      "\t[#    0] train_loss: 2.367639, odo_loss: 1.707363, ine_loss: 0.524863, ref_loss: 0.135413\n",
      "\t[#  180] train_loss: 2.437730, odo_loss: 1.765574, ine_loss: 0.508732, ref_loss: 0.163425\n",
      "\t[#  360] train_loss: 2.232321, odo_loss: 1.582462, ine_loss: 0.462845, ref_loss: 0.187013\n",
      "\t[#  540] train_loss: 2.367064, odo_loss: 1.675242, ine_loss: 0.536387, ref_loss: 0.155435\n",
      "\t[#  720] train_loss: 2.129924, odo_loss: 1.481300, ine_loss: 0.503446, ref_loss: 0.145177\n",
      "\t[#  900] train_loss: 8.927900, odo_loss: 8.316002, ine_loss: 0.449693, ref_loss: 0.162205\n",
      "\ttrain_loss: 2.337596, odo_loss: 1.655336, ine_loss: 0.527111, ref_loss: 0.155149\n",
      "\tval_loss: 2.767596, odo_loss: 2.071203, ine_loss: 0.525070, ref_loss: 0.171323\n",
      "Epoch 144/2000\n",
      "\t[#    0] train_loss: 2.214655, odo_loss: 1.461032, ine_loss: 0.618139, ref_loss: 0.135484\n",
      "\t[#  180] train_loss: 2.449019, odo_loss: 1.913738, ine_loss: 0.384514, ref_loss: 0.150767\n",
      "\t[#  360] train_loss: 2.552445, odo_loss: 1.955317, ine_loss: 0.456404, ref_loss: 0.140724\n",
      "\t[#  540] train_loss: 2.583501, odo_loss: 1.861281, ine_loss: 0.539845, ref_loss: 0.182374\n",
      "\t[#  720] train_loss: 2.312693, odo_loss: 1.686088, ine_loss: 0.454408, ref_loss: 0.172196\n",
      "\t[#  900] train_loss: 2.255831, odo_loss: 1.606954, ine_loss: 0.489776, ref_loss: 0.159101\n",
      "\ttrain_loss: 2.421517, odo_loss: 1.740371, ine_loss: 0.525910, ref_loss: 0.155235\n",
      "\tval_loss: 2.329094, odo_loss: 1.634019, ine_loss: 0.522548, ref_loss: 0.172527\n",
      "\t*** Personal Best ***\n",
      "Epoch 145/2000\n",
      "\t[#    0] train_loss: 4.212381, odo_loss: 3.500763, ine_loss: 0.582164, ref_loss: 0.129454\n",
      "\t[#  180] train_loss: 2.320273, odo_loss: 1.609656, ine_loss: 0.551334, ref_loss: 0.159283\n",
      "\t[#  360] train_loss: 2.217244, odo_loss: 1.546138, ine_loss: 0.534198, ref_loss: 0.136908\n",
      "\t[#  540] train_loss: 2.404343, odo_loss: 1.700732, ine_loss: 0.560697, ref_loss: 0.142914\n",
      "\t[#  720] train_loss: 2.293718, odo_loss: 1.638495, ine_loss: 0.502290, ref_loss: 0.152933\n",
      "\t[#  900] train_loss: 2.052813, odo_loss: 1.453589, ine_loss: 0.448095, ref_loss: 0.151128\n",
      "\ttrain_loss: 2.306703, odo_loss: 1.625877, ine_loss: 0.526068, ref_loss: 0.154757\n",
      "\tval_loss: 2.279271, odo_loss: 1.582662, ine_loss: 0.524037, ref_loss: 0.172572\n",
      "\t*** Personal Best ***\n",
      "Epoch 146/2000\n",
      "\t[#    0] train_loss: 2.360293, odo_loss: 1.714587, ine_loss: 0.525710, ref_loss: 0.119996\n",
      "\t[#  180] train_loss: 2.947164, odo_loss: 2.135700, ine_loss: 0.641498, ref_loss: 0.169967\n",
      "\t[#  360] train_loss: 2.473438, odo_loss: 1.666530, ine_loss: 0.660164, ref_loss: 0.146744\n",
      "\t[#  540] train_loss: 2.149248, odo_loss: 1.419408, ine_loss: 0.563225, ref_loss: 0.166614\n",
      "\t[#  720] train_loss: 2.465399, odo_loss: 1.806262, ine_loss: 0.520423, ref_loss: 0.138714\n",
      "\t[#  900] train_loss: 2.696324, odo_loss: 2.011094, ine_loss: 0.534614, ref_loss: 0.150616\n",
      "\ttrain_loss: 2.340043, odo_loss: 1.659034, ine_loss: 0.526380, ref_loss: 0.154630\n",
      "\tval_loss: 2.471286, odo_loss: 1.772117, ine_loss: 0.526209, ref_loss: 0.172960\n",
      "Epoch 147/2000\n",
      "\t[#    0] train_loss: 2.295873, odo_loss: 1.677543, ine_loss: 0.457652, ref_loss: 0.160679\n",
      "\t[#  180] train_loss: 2.435928, odo_loss: 1.747382, ine_loss: 0.533758, ref_loss: 0.154788\n",
      "\t[#  360] train_loss: 2.079503, odo_loss: 1.445636, ine_loss: 0.504694, ref_loss: 0.129174\n",
      "\t[#  540] train_loss: 2.053605, odo_loss: 1.408233, ine_loss: 0.512687, ref_loss: 0.132685\n",
      "\t[#  720] train_loss: 2.420109, odo_loss: 1.580506, ine_loss: 0.649068, ref_loss: 0.190534\n",
      "\t[#  900] train_loss: 2.493285, odo_loss: 1.743509, ine_loss: 0.582890, ref_loss: 0.166886\n",
      "\ttrain_loss: 2.326169, odo_loss: 1.646043, ine_loss: 0.525942, ref_loss: 0.154184\n",
      "\tval_loss: 2.345400, odo_loss: 1.652755, ine_loss: 0.521791, ref_loss: 0.170853\n",
      "Epoch 148/2000\n",
      "\t[#    0] train_loss: 2.267437, odo_loss: 1.397738, ine_loss: 0.682913, ref_loss: 0.186786\n",
      "\t[#  180] train_loss: 2.115192, odo_loss: 1.362442, ine_loss: 0.607181, ref_loss: 0.145569\n",
      "\t[#  360] train_loss: 2.140203, odo_loss: 1.517445, ine_loss: 0.459805, ref_loss: 0.162953\n",
      "\t[#  540] train_loss: 2.163560, odo_loss: 1.467046, ine_loss: 0.529505, ref_loss: 0.167009\n",
      "\t[#  720] train_loss: 2.407763, odo_loss: 1.583447, ine_loss: 0.644604, ref_loss: 0.179712\n",
      "\t[#  900] train_loss: 2.209800, odo_loss: 1.532746, ine_loss: 0.500570, ref_loss: 0.176485\n",
      "\ttrain_loss: 2.294090, odo_loss: 1.615332, ine_loss: 0.524724, ref_loss: 0.154034\n",
      "\tval_loss: 2.366725, odo_loss: 1.676401, ine_loss: 0.521202, ref_loss: 0.169122\n",
      "Epoch 149/2000\n",
      "\t[#    0] train_loss: 2.425827, odo_loss: 1.699619, ine_loss: 0.588697, ref_loss: 0.137510\n",
      "\t[#  180] train_loss: 2.055301, odo_loss: 1.410921, ine_loss: 0.489439, ref_loss: 0.154940\n",
      "\t[#  360] train_loss: 2.651081, odo_loss: 2.020427, ine_loss: 0.482070, ref_loss: 0.148583\n",
      "\t[#  540] train_loss: 2.564617, odo_loss: 1.821007, ine_loss: 0.587660, ref_loss: 0.155949\n",
      "\t[#  720] train_loss: 1.913646, odo_loss: 1.368163, ine_loss: 0.394915, ref_loss: 0.150567\n",
      "\t[#  900] train_loss: 2.476217, odo_loss: 1.689149, ine_loss: 0.598309, ref_loss: 0.188759\n",
      "\ttrain_loss: 2.630370, odo_loss: 1.950704, ine_loss: 0.524303, ref_loss: 0.155363\n",
      "\tval_loss: 2.683647, odo_loss: 1.988697, ine_loss: 0.522198, ref_loss: 0.172752\n",
      "Epoch 150/2000\n",
      "\t[#    0] train_loss: 2.514380, odo_loss: 1.804098, ine_loss: 0.557100, ref_loss: 0.153182\n",
      "\t[#  180] train_loss: 2.585248, odo_loss: 1.806144, ine_loss: 0.637142, ref_loss: 0.141961\n",
      "\t[#  360] train_loss: 2.700351, odo_loss: 1.998097, ine_loss: 0.545026, ref_loss: 0.157228\n",
      "\t[#  540] train_loss: 2.020835, odo_loss: 1.425552, ine_loss: 0.436133, ref_loss: 0.159150\n",
      "\t[#  720] train_loss: 2.265681, odo_loss: 1.511971, ine_loss: 0.598881, ref_loss: 0.154829\n",
      "\t[#  900] train_loss: 2.184161, odo_loss: 1.597738, ine_loss: 0.454191, ref_loss: 0.132232\n",
      "\ttrain_loss: 2.408301, odo_loss: 1.729853, ine_loss: 0.523880, ref_loss: 0.154568\n",
      "\tval_loss: 2.418426, odo_loss: 1.724345, ine_loss: 0.520446, ref_loss: 0.173635\n",
      "Epoch 151/2000\n",
      "\t[#    0] train_loss: 2.414569, odo_loss: 1.620399, ine_loss: 0.631679, ref_loss: 0.162491\n",
      "\t[#  180] train_loss: 2.265169, odo_loss: 1.692011, ine_loss: 0.437542, ref_loss: 0.135617\n",
      "\t[#  360] train_loss: 2.047353, odo_loss: 1.408826, ine_loss: 0.472382, ref_loss: 0.166145\n",
      "\t[#  540] train_loss: 2.493058, odo_loss: 1.749998, ine_loss: 0.555904, ref_loss: 0.187156\n",
      "\t[#  720] train_loss: 1.937928, odo_loss: 1.365542, ine_loss: 0.438934, ref_loss: 0.133453\n",
      "\t[#  900] train_loss: 2.338266, odo_loss: 1.629690, ine_loss: 0.569348, ref_loss: 0.139227\n",
      "\ttrain_loss: 2.347844, odo_loss: 1.669773, ine_loss: 0.523799, ref_loss: 0.154272\n",
      "\tval_loss: 2.447092, odo_loss: 1.750641, ine_loss: 0.524521, ref_loss: 0.171930\n",
      "Epoch 152/2000\n",
      "\t[#    0] train_loss: 2.361466, odo_loss: 1.617242, ine_loss: 0.597620, ref_loss: 0.146603\n",
      "\t[#  180] train_loss: 2.035676, odo_loss: 1.391537, ine_loss: 0.504745, ref_loss: 0.139394\n",
      "\t[#  360] train_loss: 2.052724, odo_loss: 1.424003, ine_loss: 0.465754, ref_loss: 0.162968\n",
      "\t[#  540] train_loss: 2.241442, odo_loss: 1.607739, ine_loss: 0.494924, ref_loss: 0.138779\n",
      "\t[#  720] train_loss: 2.710573, odo_loss: 2.002107, ine_loss: 0.551817, ref_loss: 0.156649\n",
      "\t[#  900] train_loss: 2.109416, odo_loss: 1.481855, ine_loss: 0.444311, ref_loss: 0.183250\n",
      "\ttrain_loss: 2.291755, odo_loss: 1.613852, ine_loss: 0.524139, ref_loss: 0.153765\n",
      "\tval_loss: 2.242440, odo_loss: 1.547262, ine_loss: 0.522926, ref_loss: 0.172251\n",
      "\t*** Personal Best ***\n",
      "Epoch 153/2000\n",
      "\t[#    0] train_loss: 2.097687, odo_loss: 1.419310, ine_loss: 0.541210, ref_loss: 0.137167\n",
      "\t[#  180] train_loss: 2.059354, odo_loss: 1.305283, ine_loss: 0.561216, ref_loss: 0.192855\n",
      "\t[#  360] train_loss: 2.659714, odo_loss: 1.969492, ine_loss: 0.524766, ref_loss: 0.165456\n",
      "\t[#  540] train_loss: 2.442112, odo_loss: 1.676262, ine_loss: 0.608180, ref_loss: 0.157671\n",
      "\t[#  720] train_loss: 2.219795, odo_loss: 1.512083, ine_loss: 0.532498, ref_loss: 0.175214\n",
      "\t[#  900] train_loss: 2.508364, odo_loss: 1.901555, ine_loss: 0.460237, ref_loss: 0.146572\n",
      "\ttrain_loss: 2.360572, odo_loss: 1.683658, ine_loss: 0.523027, ref_loss: 0.153887\n",
      "\tval_loss: 2.586445, odo_loss: 1.894672, ine_loss: 0.519277, ref_loss: 0.172497\n",
      "Epoch 154/2000\n",
      "\t[#    0] train_loss: 2.225405, odo_loss: 1.460860, ine_loss: 0.601772, ref_loss: 0.162772\n",
      "\t[#  180] train_loss: 2.041641, odo_loss: 1.375147, ine_loss: 0.505003, ref_loss: 0.161490\n",
      "\t[#  360] train_loss: 1.801400, odo_loss: 1.229928, ine_loss: 0.421333, ref_loss: 0.150140\n",
      "\t[#  540] train_loss: 2.009810, odo_loss: 1.368787, ine_loss: 0.485831, ref_loss: 0.155192\n",
      "\t[#  720] train_loss: 2.081308, odo_loss: 1.500603, ine_loss: 0.445924, ref_loss: 0.134781\n",
      "\t[#  900] train_loss: 2.069871, odo_loss: 1.439699, ine_loss: 0.504811, ref_loss: 0.125361\n",
      "\ttrain_loss: 2.409949, odo_loss: 1.733710, ine_loss: 0.521880, ref_loss: 0.154359\n",
      "\tval_loss: 2.284218, odo_loss: 1.591557, ine_loss: 0.520081, ref_loss: 0.172580\n",
      "Epoch 155/2000\n",
      "\t[#    0] train_loss: 2.471642, odo_loss: 1.877655, ine_loss: 0.446808, ref_loss: 0.147179\n",
      "\t[#  180] train_loss: 2.320264, odo_loss: 1.586011, ine_loss: 0.586925, ref_loss: 0.147328\n",
      "\t[#  360] train_loss: 2.241468, odo_loss: 1.549381, ine_loss: 0.548764, ref_loss: 0.143323\n",
      "\t[#  540] train_loss: 2.220926, odo_loss: 1.544558, ine_loss: 0.508934, ref_loss: 0.167434\n",
      "\t[#  720] train_loss: 2.413803, odo_loss: 1.702237, ine_loss: 0.586270, ref_loss: 0.125296\n",
      "\t[#  900] train_loss: 2.285164, odo_loss: 1.578948, ine_loss: 0.551435, ref_loss: 0.154781\n",
      "\ttrain_loss: 2.305805, odo_loss: 1.629901, ine_loss: 0.522538, ref_loss: 0.153366\n",
      "\tval_loss: 2.332852, odo_loss: 1.638891, ine_loss: 0.522644, ref_loss: 0.171318\n",
      "Epoch 156/2000\n",
      "\t[#    0] train_loss: 2.247417, odo_loss: 1.570842, ine_loss: 0.515522, ref_loss: 0.161054\n",
      "\t[#  180] train_loss: 1.956585, odo_loss: 1.388894, ine_loss: 0.409470, ref_loss: 0.158221\n",
      "\t[#  360] train_loss: 2.038647, odo_loss: 1.445087, ine_loss: 0.457224, ref_loss: 0.136335\n",
      "\t[#  540] train_loss: 2.017896, odo_loss: 1.378487, ine_loss: 0.476435, ref_loss: 0.162974\n",
      "\t[#  720] train_loss: 2.056110, odo_loss: 1.545817, ine_loss: 0.383154, ref_loss: 0.127139\n",
      "\t[#  900] train_loss: 2.068743, odo_loss: 1.422514, ine_loss: 0.497229, ref_loss: 0.149001\n",
      "\ttrain_loss: 2.257942, odo_loss: 1.581832, ine_loss: 0.523040, ref_loss: 0.153070\n",
      "\tval_loss: 2.278140, odo_loss: 1.587934, ine_loss: 0.518602, ref_loss: 0.171605\n",
      "Epoch 157/2000\n",
      "\t[#    0] train_loss: 2.402443, odo_loss: 1.752432, ine_loss: 0.477291, ref_loss: 0.172720\n",
      "\t[#  180] train_loss: 2.366059, odo_loss: 1.529974, ine_loss: 0.658129, ref_loss: 0.177957\n",
      "\t[#  360] train_loss: 2.173916, odo_loss: 1.520868, ine_loss: 0.501875, ref_loss: 0.151172\n",
      "\t[#  540] train_loss: 2.252174, odo_loss: 1.532892, ine_loss: 0.520598, ref_loss: 0.198684\n",
      "\t[#  720] train_loss: 2.301218, odo_loss: 1.538451, ine_loss: 0.584300, ref_loss: 0.178466\n",
      "\t[#  900] train_loss: 2.258937, odo_loss: 1.644704, ine_loss: 0.489290, ref_loss: 0.124943\n",
      "\ttrain_loss: 2.253560, odo_loss: 1.578742, ine_loss: 0.522043, ref_loss: 0.152775\n",
      "\tval_loss: 2.236460, odo_loss: 1.547163, ine_loss: 0.518990, ref_loss: 0.170307\n",
      "\t*** Personal Best ***\n",
      "Epoch 158/2000\n",
      "\t[#    0] train_loss: 2.365628, odo_loss: 1.762691, ine_loss: 0.473531, ref_loss: 0.129406\n",
      "\t[#  180] train_loss: 2.051238, odo_loss: 1.364549, ine_loss: 0.545997, ref_loss: 0.140692\n",
      "\t[#  360] train_loss: 2.291693, odo_loss: 1.595474, ine_loss: 0.529552, ref_loss: 0.166667\n",
      "\t[#  540] train_loss: 2.925859, odo_loss: 2.195552, ine_loss: 0.549606, ref_loss: 0.180701\n",
      "\t[#  720] train_loss: 2.041916, odo_loss: 1.413497, ine_loss: 0.479502, ref_loss: 0.148917\n",
      "\t[#  900] train_loss: 2.467190, odo_loss: 1.702480, ine_loss: 0.616450, ref_loss: 0.148260\n",
      "\ttrain_loss: 2.248934, odo_loss: 1.574809, ine_loss: 0.521425, ref_loss: 0.152700\n",
      "\tval_loss: 2.303345, odo_loss: 1.613675, ine_loss: 0.517522, ref_loss: 0.172147\n",
      "Epoch 159/2000\n",
      "\t[#    0] train_loss: 2.294818, odo_loss: 1.604513, ine_loss: 0.551004, ref_loss: 0.139301\n",
      "\t[#  180] train_loss: 2.669291, odo_loss: 1.882576, ine_loss: 0.644094, ref_loss: 0.142621\n",
      "\t[#  360] train_loss: 3.238990, odo_loss: 2.561706, ine_loss: 0.552204, ref_loss: 0.125079\n",
      "\t[#  540] train_loss: 2.766617, odo_loss: 1.927818, ine_loss: 0.647528, ref_loss: 0.191270\n",
      "\t[#  720] train_loss: 2.744225, odo_loss: 2.102398, ine_loss: 0.517712, ref_loss: 0.124115\n",
      "\t[#  900] train_loss: 2.962947, odo_loss: 2.287278, ine_loss: 0.507532, ref_loss: 0.168137\n",
      "\ttrain_loss: 2.462288, odo_loss: 1.788032, ine_loss: 0.521313, ref_loss: 0.152943\n",
      "\tval_loss: 2.729053, odo_loss: 2.037724, ine_loss: 0.518644, ref_loss: 0.172684\n",
      "Epoch 160/2000\n",
      "\t[#    0] train_loss: 2.208226, odo_loss: 1.640544, ine_loss: 0.426648, ref_loss: 0.141034\n",
      "\t[#  180] train_loss: 2.000405, odo_loss: 1.419433, ine_loss: 0.430877, ref_loss: 0.150095\n",
      "\t[#  360] train_loss: 2.249780, odo_loss: 1.618146, ine_loss: 0.499372, ref_loss: 0.132262\n",
      "\t[#  540] train_loss: 2.322414, odo_loss: 1.665582, ine_loss: 0.486862, ref_loss: 0.169970\n",
      "\t[#  720] train_loss: 2.324557, odo_loss: 1.686819, ine_loss: 0.494979, ref_loss: 0.142759\n",
      "\t[#  900] train_loss: 2.292491, odo_loss: 1.729748, ine_loss: 0.407143, ref_loss: 0.155601\n",
      "\ttrain_loss: 2.328748, odo_loss: 1.654507, ine_loss: 0.521346, ref_loss: 0.152895\n",
      "\tval_loss: 2.401098, odo_loss: 1.709180, ine_loss: 0.520224, ref_loss: 0.171694\n",
      "Epoch 161/2000\n",
      "\t[#    0] train_loss: 2.845440, odo_loss: 2.041366, ine_loss: 0.654233, ref_loss: 0.149841\n",
      "\t[#  180] train_loss: 2.169161, odo_loss: 1.438745, ine_loss: 0.578888, ref_loss: 0.151528\n",
      "\t[#  360] train_loss: 2.009528, odo_loss: 1.282751, ine_loss: 0.557526, ref_loss: 0.169251\n",
      "\t[#  540] train_loss: 2.242019, odo_loss: 1.624813, ine_loss: 0.465544, ref_loss: 0.151663\n",
      "\t[#  720] train_loss: 2.174013, odo_loss: 1.543449, ine_loss: 0.451419, ref_loss: 0.179144\n",
      "\t[#  900] train_loss: 2.301064, odo_loss: 1.644660, ine_loss: 0.493325, ref_loss: 0.163078\n",
      "\ttrain_loss: 2.276328, odo_loss: 1.603281, ine_loss: 0.520389, ref_loss: 0.152658\n",
      "\tval_loss: 2.397040, odo_loss: 1.713724, ine_loss: 0.512077, ref_loss: 0.171239\n",
      "Epoch 162/2000\n",
      "\t[#    0] train_loss: 2.312366, odo_loss: 1.574461, ine_loss: 0.594917, ref_loss: 0.142988\n",
      "\t[#  180] train_loss: 2.255030, odo_loss: 1.525405, ine_loss: 0.528699, ref_loss: 0.200926\n",
      "\t[#  360] train_loss: 2.607583, odo_loss: 1.900909, ine_loss: 0.553497, ref_loss: 0.153177\n",
      "\t[#  540] train_loss: 2.225003, odo_loss: 1.577401, ine_loss: 0.484297, ref_loss: 0.163305\n",
      "\t[#  720] train_loss: 2.323941, odo_loss: 1.786778, ine_loss: 0.401577, ref_loss: 0.135586\n",
      "\t[#  900] train_loss: 2.316967, odo_loss: 1.692045, ine_loss: 0.482098, ref_loss: 0.142824\n",
      "\ttrain_loss: 2.273581, odo_loss: 1.601630, ine_loss: 0.519801, ref_loss: 0.152150\n",
      "\tval_loss: 2.449790, odo_loss: 1.766431, ine_loss: 0.512352, ref_loss: 0.171006\n",
      "Epoch 163/2000\n",
      "\t[#    0] train_loss: 2.284926, odo_loss: 1.727079, ine_loss: 0.417648, ref_loss: 0.140200\n",
      "\t[#  180] train_loss: 1.980829, odo_loss: 1.334740, ine_loss: 0.496284, ref_loss: 0.149805\n",
      "\t[#  360] train_loss: 2.351758, odo_loss: 1.767425, ine_loss: 0.414774, ref_loss: 0.169560\n",
      "\t[#  540] train_loss: 2.091927, odo_loss: 1.341445, ine_loss: 0.591330, ref_loss: 0.159152\n",
      "\t[#  720] train_loss: 2.317992, odo_loss: 1.609690, ine_loss: 0.537522, ref_loss: 0.170780\n",
      "\t[#  900] train_loss: 2.390065, odo_loss: 1.663343, ine_loss: 0.583356, ref_loss: 0.143366\n",
      "\ttrain_loss: 2.309042, odo_loss: 1.638369, ine_loss: 0.518133, ref_loss: 0.152540\n",
      "\tval_loss: 2.271111, odo_loss: 1.585669, ine_loss: 0.513609, ref_loss: 0.171833\n",
      "Epoch 164/2000\n",
      "\t[#    0] train_loss: 2.037948, odo_loss: 1.430171, ine_loss: 0.479386, ref_loss: 0.128390\n",
      "\t[#  180] train_loss: 2.451795, odo_loss: 1.772657, ine_loss: 0.514258, ref_loss: 0.164879\n",
      "\t[#  360] train_loss: 2.164460, odo_loss: 1.526861, ine_loss: 0.512757, ref_loss: 0.124842\n",
      "\t[#  540] train_loss: 2.038291, odo_loss: 1.484114, ine_loss: 0.393767, ref_loss: 0.160411\n",
      "\t[#  720] train_loss: 2.280828, odo_loss: 1.592276, ine_loss: 0.510614, ref_loss: 0.177938\n",
      "\t[#  900] train_loss: 2.042182, odo_loss: 1.359988, ine_loss: 0.546611, ref_loss: 0.135583\n",
      "\ttrain_loss: 2.344046, odo_loss: 1.674670, ine_loss: 0.516530, ref_loss: 0.152846\n",
      "\tval_loss: 2.399500, odo_loss: 1.710095, ine_loss: 0.517759, ref_loss: 0.171645\n",
      "Epoch 165/2000\n",
      "\t[#    0] train_loss: 2.628117, odo_loss: 1.896832, ine_loss: 0.581857, ref_loss: 0.149428\n",
      "\t[#  180] train_loss: 2.207589, odo_loss: 1.563463, ine_loss: 0.497614, ref_loss: 0.146512\n",
      "\t[#  360] train_loss: 2.153492, odo_loss: 1.487782, ine_loss: 0.525362, ref_loss: 0.140348\n",
      "\t[#  540] train_loss: 2.396209, odo_loss: 1.768180, ine_loss: 0.478743, ref_loss: 0.149286\n",
      "\t[#  720] train_loss: 2.179716, odo_loss: 1.539129, ine_loss: 0.461214, ref_loss: 0.179372\n",
      "\t[#  900] train_loss: 2.640631, odo_loss: 1.918343, ine_loss: 0.573616, ref_loss: 0.148672\n",
      "\ttrain_loss: 2.262343, odo_loss: 1.591543, ine_loss: 0.518174, ref_loss: 0.152627\n",
      "\tval_loss: 2.282095, odo_loss: 1.598171, ine_loss: 0.514824, ref_loss: 0.169100\n",
      "Epoch 166/2000\n",
      "\t[#    0] train_loss: 2.635255, odo_loss: 1.829234, ine_loss: 0.645306, ref_loss: 0.160715\n",
      "\t[#  180] train_loss: 2.221081, odo_loss: 1.592842, ine_loss: 0.486361, ref_loss: 0.141878\n",
      "\t[#  360] train_loss: 2.181295, odo_loss: 1.427572, ine_loss: 0.565354, ref_loss: 0.188369\n",
      "\t[#  540] train_loss: 2.530285, odo_loss: 1.909904, ine_loss: 0.492990, ref_loss: 0.127392\n",
      "\t[#  720] train_loss: 2.523822, odo_loss: 1.830018, ine_loss: 0.529824, ref_loss: 0.163981\n",
      "\t[#  900] train_loss: 2.519525, odo_loss: 1.831501, ine_loss: 0.535232, ref_loss: 0.152792\n",
      "\ttrain_loss: 2.242198, odo_loss: 1.571242, ine_loss: 0.519098, ref_loss: 0.151858\n",
      "\tval_loss: 2.235385, odo_loss: 1.552657, ine_loss: 0.514740, ref_loss: 0.167988\n",
      "Epoch 167/2000\n",
      "\t[#    0] train_loss: 2.421518, odo_loss: 1.828629, ine_loss: 0.475979, ref_loss: 0.116910\n",
      "\t[#  180] train_loss: 2.030860, odo_loss: 1.399978, ine_loss: 0.478517, ref_loss: 0.152365\n",
      "\t[#  360] train_loss: 1.905112, odo_loss: 1.213246, ine_loss: 0.513765, ref_loss: 0.178102\n",
      "\t[#  540] train_loss: 2.271757, odo_loss: 1.488896, ine_loss: 0.612843, ref_loss: 0.170018\n",
      "\t[#  720] train_loss: 1.861778, odo_loss: 1.292114, ine_loss: 0.422632, ref_loss: 0.147032\n",
      "\t[#  900] train_loss: 2.282433, odo_loss: 1.660939, ine_loss: 0.482893, ref_loss: 0.138602\n",
      "\ttrain_loss: 2.270694, odo_loss: 1.601359, ine_loss: 0.516920, ref_loss: 0.152415\n",
      "\tval_loss: 3.796853, odo_loss: 3.115709, ine_loss: 0.510494, ref_loss: 0.170650\n",
      "Epoch 168/2000\n",
      "\t[#    0] train_loss: 2.230661, odo_loss: 1.581787, ine_loss: 0.477443, ref_loss: 0.171431\n",
      "\t[#  180] train_loss: 2.223475, odo_loss: 1.568598, ine_loss: 0.489700, ref_loss: 0.165177\n",
      "\t[#  360] train_loss: 2.433019, odo_loss: 1.709651, ine_loss: 0.539834, ref_loss: 0.183534\n",
      "\t[#  540] train_loss: 2.386369, odo_loss: 1.575966, ine_loss: 0.611536, ref_loss: 0.198868\n",
      "\t[#  720] train_loss: 2.621916, odo_loss: 1.875782, ine_loss: 0.595403, ref_loss: 0.150730\n",
      "\t[#  900] train_loss: 2.504545, odo_loss: 1.849360, ine_loss: 0.514015, ref_loss: 0.141169\n",
      "\ttrain_loss: 2.464459, odo_loss: 1.794878, ine_loss: 0.516257, ref_loss: 0.153324\n",
      "\tval_loss: 2.329033, odo_loss: 1.647405, ine_loss: 0.510591, ref_loss: 0.171037\n",
      "Epoch 169/2000\n",
      "\t[#    0] train_loss: 2.126060, odo_loss: 1.570042, ine_loss: 0.427542, ref_loss: 0.128475\n",
      "\t[#  180] train_loss: 2.452224, odo_loss: 1.811864, ine_loss: 0.504408, ref_loss: 0.135953\n",
      "\t[#  360] train_loss: 1.849006, odo_loss: 1.337790, ine_loss: 0.371999, ref_loss: 0.139217\n",
      "\t[#  540] train_loss: 2.071845, odo_loss: 1.514968, ine_loss: 0.399192, ref_loss: 0.157684\n",
      "\t[#  720] train_loss: 2.526255, odo_loss: 1.916256, ine_loss: 0.473279, ref_loss: 0.136720\n",
      "\t[#  900] train_loss: 2.377265, odo_loss: 1.742508, ine_loss: 0.474238, ref_loss: 0.160519\n",
      "\ttrain_loss: 2.305143, odo_loss: 1.637434, ine_loss: 0.515007, ref_loss: 0.152701\n",
      "\tval_loss: 2.341972, odo_loss: 1.657165, ine_loss: 0.513320, ref_loss: 0.171487\n",
      "Epoch 170/2000\n",
      "\t[#    0] train_loss: 2.216598, odo_loss: 1.596009, ine_loss: 0.466216, ref_loss: 0.154373\n",
      "\t[#  180] train_loss: 1.947225, odo_loss: 1.355593, ine_loss: 0.444556, ref_loss: 0.147077\n",
      "\t[#  360] train_loss: 2.255690, odo_loss: 1.573548, ine_loss: 0.529623, ref_loss: 0.152519\n",
      "\t[#  540] train_loss: 2.430310, odo_loss: 1.794696, ine_loss: 0.490212, ref_loss: 0.145402\n",
      "\t[#  720] train_loss: 2.425705, odo_loss: 1.742997, ine_loss: 0.553840, ref_loss: 0.128867\n",
      "\t[#  900] train_loss: 2.326735, odo_loss: 1.667480, ine_loss: 0.516328, ref_loss: 0.142927\n",
      "\ttrain_loss: 2.308830, odo_loss: 1.639802, ine_loss: 0.515988, ref_loss: 0.153040\n",
      "\tval_loss: 2.381016, odo_loss: 1.696477, ine_loss: 0.514544, ref_loss: 0.169995\n",
      "Epoch 171/2000\n",
      "\t[#    0] train_loss: 2.462456, odo_loss: 1.607936, ine_loss: 0.693077, ref_loss: 0.161443\n",
      "\t[#  180] train_loss: 2.447362, odo_loss: 1.711096, ine_loss: 0.546324, ref_loss: 0.189943\n",
      "\t[#  360] train_loss: 2.035050, odo_loss: 1.436696, ine_loss: 0.439982, ref_loss: 0.158373\n",
      "\t[#  540] train_loss: 2.047223, odo_loss: 1.493622, ine_loss: 0.402080, ref_loss: 0.151521\n",
      "\t[#  720] train_loss: 2.229747, odo_loss: 1.585034, ine_loss: 0.515950, ref_loss: 0.128763\n",
      "\t[#  900] train_loss: 2.799069, odo_loss: 1.998349, ine_loss: 0.637148, ref_loss: 0.163571\n",
      "\ttrain_loss: 2.243211, odo_loss: 1.575643, ine_loss: 0.515166, ref_loss: 0.152402\n",
      "\tval_loss: 2.336001, odo_loss: 1.654442, ine_loss: 0.511880, ref_loss: 0.169678\n",
      "Epoch 172/2000\n",
      "\t[#    0] train_loss: 2.485271, odo_loss: 1.836527, ine_loss: 0.489399, ref_loss: 0.159345\n",
      "\t[#  180] train_loss: 2.065808, odo_loss: 1.414338, ine_loss: 0.505169, ref_loss: 0.146301\n",
      "\t[#  360] train_loss: 2.577984, odo_loss: 1.880338, ine_loss: 0.534422, ref_loss: 0.163224\n",
      "\t[#  540] train_loss: 2.387190, odo_loss: 1.816827, ine_loss: 0.442310, ref_loss: 0.128053\n",
      "\t[#  720] train_loss: 1.662509, odo_loss: 1.103364, ine_loss: 0.417480, ref_loss: 0.141665\n",
      "\t[#  900] train_loss: 2.750866, odo_loss: 2.058712, ine_loss: 0.516886, ref_loss: 0.175267\n",
      "\ttrain_loss: 2.257261, odo_loss: 1.589489, ine_loss: 0.515512, ref_loss: 0.152260\n",
      "\tval_loss: 2.470345, odo_loss: 1.784794, ine_loss: 0.513189, ref_loss: 0.172362\n",
      "Epoch 173/2000\n",
      "\t[#    0] train_loss: 2.105388, odo_loss: 1.544529, ine_loss: 0.427018, ref_loss: 0.133841\n",
      "\t[#  180] train_loss: 2.063159, odo_loss: 1.419081, ine_loss: 0.489615, ref_loss: 0.154462\n",
      "\t[#  360] train_loss: 2.364977, odo_loss: 1.675624, ine_loss: 0.536471, ref_loss: 0.152882\n",
      "\t[#  540] train_loss: 2.141905, odo_loss: 1.524769, ine_loss: 0.474534, ref_loss: 0.142602\n",
      "\t[#  720] train_loss: 2.308856, odo_loss: 1.558891, ine_loss: 0.588905, ref_loss: 0.161060\n",
      "\t[#  900] train_loss: 2.546058, odo_loss: 1.916254, ine_loss: 0.455373, ref_loss: 0.174431\n",
      "\ttrain_loss: 2.272813, odo_loss: 1.604327, ine_loss: 0.515861, ref_loss: 0.152625\n",
      "\tval_loss: 2.224267, odo_loss: 1.541983, ine_loss: 0.509516, ref_loss: 0.172768\n",
      "\t*** Personal Best ***\n",
      "Epoch 174/2000\n",
      "\t[#    0] train_loss: 2.242508, odo_loss: 1.467996, ine_loss: 0.603216, ref_loss: 0.171296\n",
      "\t[#  180] train_loss: 2.164462, odo_loss: 1.609500, ine_loss: 0.406965, ref_loss: 0.147997\n",
      "\t[#  360] train_loss: 1.955020, odo_loss: 1.212872, ine_loss: 0.606970, ref_loss: 0.135178\n",
      "\t[#  540] train_loss: 2.328387, odo_loss: 1.628281, ine_loss: 0.554621, ref_loss: 0.145486\n",
      "\t[#  720] train_loss: 2.373520, odo_loss: 1.684531, ine_loss: 0.541036, ref_loss: 0.147952\n",
      "\t[#  900] train_loss: 2.245779, odo_loss: 1.604180, ine_loss: 0.477109, ref_loss: 0.164490\n",
      "\ttrain_loss: 2.210653, odo_loss: 1.542876, ine_loss: 0.515432, ref_loss: 0.152345\n",
      "\tval_loss: 2.223349, odo_loss: 1.537281, ine_loss: 0.514006, ref_loss: 0.172062\n",
      "\t*** Personal Best ***\n",
      "Epoch 175/2000\n",
      "\t[#    0] train_loss: 2.141470, odo_loss: 1.468165, ine_loss: 0.515365, ref_loss: 0.157941\n",
      "\t[#  180] train_loss: 2.082280, odo_loss: 1.422015, ine_loss: 0.503673, ref_loss: 0.156592\n",
      "\t[#  360] train_loss: 2.202920, odo_loss: 1.543282, ine_loss: 0.522900, ref_loss: 0.136739\n",
      "\t[#  540] train_loss: 1.876580, odo_loss: 1.246105, ine_loss: 0.479244, ref_loss: 0.151231\n",
      "\t[#  720] train_loss: 2.187060, odo_loss: 1.447605, ine_loss: 0.589784, ref_loss: 0.149670\n",
      "\t[#  900] train_loss: 2.246952, odo_loss: 1.686117, ine_loss: 0.432871, ref_loss: 0.127963\n",
      "\ttrain_loss: 2.301095, odo_loss: 1.634883, ine_loss: 0.514312, ref_loss: 0.151900\n",
      "\tval_loss: 2.415928, odo_loss: 1.735094, ine_loss: 0.509517, ref_loss: 0.171316\n",
      "Epoch 176/2000\n",
      "\t[#    0] train_loss: 2.338973, odo_loss: 1.498681, ine_loss: 0.680634, ref_loss: 0.159657\n",
      "\t[#  180] train_loss: 2.862987, odo_loss: 2.227783, ine_loss: 0.468450, ref_loss: 0.166754\n",
      "\t[#  360] train_loss: 2.274507, odo_loss: 1.464115, ine_loss: 0.666946, ref_loss: 0.143445\n",
      "\t[#  540] train_loss: 2.472331, odo_loss: 1.732584, ine_loss: 0.570255, ref_loss: 0.169491\n",
      "\t[#  720] train_loss: 2.595604, odo_loss: 1.856450, ine_loss: 0.597817, ref_loss: 0.141336\n",
      "\t[#  900] train_loss: 2.681567, odo_loss: 1.974463, ine_loss: 0.534916, ref_loss: 0.172188\n",
      "\ttrain_loss: 2.245551, odo_loss: 1.579138, ine_loss: 0.514076, ref_loss: 0.152336\n",
      "\tval_loss: 2.306775, odo_loss: 1.620389, ine_loss: 0.515001, ref_loss: 0.171386\n",
      "Epoch 177/2000\n",
      "\t[#    0] train_loss: 2.289548, odo_loss: 1.562772, ine_loss: 0.574048, ref_loss: 0.152728\n",
      "\t[#  180] train_loss: 2.179782, odo_loss: 1.572578, ine_loss: 0.457259, ref_loss: 0.149945\n",
      "\t[#  360] train_loss: 1.946253, odo_loss: 1.349995, ine_loss: 0.443478, ref_loss: 0.152780\n",
      "\t[#  540] train_loss: 2.462577, odo_loss: 1.793251, ine_loss: 0.529202, ref_loss: 0.140125\n",
      "\t[#  720] train_loss: 2.325583, odo_loss: 1.598602, ine_loss: 0.604826, ref_loss: 0.122155\n",
      "\t[#  900] train_loss: 2.564742, odo_loss: 1.869164, ine_loss: 0.565415, ref_loss: 0.130163\n",
      "\ttrain_loss: 2.293937, odo_loss: 1.627475, ine_loss: 0.514783, ref_loss: 0.151678\n",
      "\tval_loss: 2.404938, odo_loss: 1.721041, ine_loss: 0.511676, ref_loss: 0.172221\n",
      "Epoch 178/2000\n",
      "\t[#    0] train_loss: 4.361572, odo_loss: 3.667782, ine_loss: 0.544825, ref_loss: 0.148966\n",
      "\t[#  180] train_loss: 2.293590, odo_loss: 1.650002, ine_loss: 0.500850, ref_loss: 0.142738\n",
      "\t[#  360] train_loss: 1.817203, odo_loss: 1.094824, ine_loss: 0.576587, ref_loss: 0.145792\n",
      "\t[#  540] train_loss: 2.142740, odo_loss: 1.513956, ine_loss: 0.479927, ref_loss: 0.148857\n",
      "\t[#  720] train_loss: 2.237677, odo_loss: 1.534101, ine_loss: 0.560183, ref_loss: 0.143393\n",
      "\t[#  900] train_loss: 2.077396, odo_loss: 1.472145, ine_loss: 0.452600, ref_loss: 0.152652\n",
      "\ttrain_loss: 2.383007, odo_loss: 1.717592, ine_loss: 0.512852, ref_loss: 0.152564\n",
      "\tval_loss: 2.268147, odo_loss: 1.592488, ine_loss: 0.504633, ref_loss: 0.171026\n",
      "Epoch 179/2000\n",
      "\t[#    0] train_loss: 2.071564, odo_loss: 1.409859, ine_loss: 0.517798, ref_loss: 0.143907\n",
      "\t[#  180] train_loss: 2.003487, odo_loss: 1.348824, ine_loss: 0.500174, ref_loss: 0.154489\n",
      "\t[#  360] train_loss: 2.405919, odo_loss: 1.696228, ine_loss: 0.559710, ref_loss: 0.149982\n",
      "\t[#  540] train_loss: 2.161677, odo_loss: 1.517832, ine_loss: 0.505872, ref_loss: 0.137974\n",
      "\t[#  720] train_loss: 2.373638, odo_loss: 1.703237, ine_loss: 0.518641, ref_loss: 0.151761\n",
      "\t[#  900] train_loss: 2.520981, odo_loss: 1.814255, ine_loss: 0.546317, ref_loss: 0.160409\n",
      "\ttrain_loss: 2.207968, odo_loss: 1.543549, ine_loss: 0.512616, ref_loss: 0.151803\n",
      "\tval_loss: 2.261171, odo_loss: 1.579997, ine_loss: 0.508859, ref_loss: 0.172315\n",
      "Epoch 180/2000\n",
      "\t[#    0] train_loss: 2.273892, odo_loss: 1.536117, ine_loss: 0.575874, ref_loss: 0.161902\n",
      "\t[#  180] train_loss: 2.367232, odo_loss: 1.511796, ine_loss: 0.670199, ref_loss: 0.185237\n",
      "\t[#  360] train_loss: 1.936869, odo_loss: 1.350337, ine_loss: 0.448812, ref_loss: 0.137720\n",
      "\t[#  540] train_loss: 2.354913, odo_loss: 1.729761, ine_loss: 0.480183, ref_loss: 0.144969\n",
      "\t[#  720] train_loss: 1.853423, odo_loss: 1.215046, ine_loss: 0.493963, ref_loss: 0.144415\n",
      "\t[#  900] train_loss: 2.277968, odo_loss: 1.448122, ine_loss: 0.668734, ref_loss: 0.161112\n",
      "\ttrain_loss: 2.182302, odo_loss: 1.516558, ine_loss: 0.513673, ref_loss: 0.152071\n",
      "\tval_loss: 2.217020, odo_loss: 1.537116, ine_loss: 0.508365, ref_loss: 0.171538\n",
      "\t*** Personal Best ***\n",
      "Epoch 181/2000\n",
      "\t[#    0] train_loss: 2.249251, odo_loss: 1.616022, ine_loss: 0.470191, ref_loss: 0.163039\n",
      "\t[#  180] train_loss: 2.108510, odo_loss: 1.430022, ine_loss: 0.540229, ref_loss: 0.138259\n",
      "\t[#  360] train_loss: 2.299214, odo_loss: 1.664114, ine_loss: 0.474534, ref_loss: 0.160566\n",
      "\t[#  540] train_loss: 2.337992, odo_loss: 1.712179, ine_loss: 0.480837, ref_loss: 0.144976\n",
      "\t[#  720] train_loss: 2.412184, odo_loss: 1.736900, ine_loss: 0.529660, ref_loss: 0.145624\n",
      "\t[#  900] train_loss: 2.813136, odo_loss: 2.061718, ine_loss: 0.580063, ref_loss: 0.171354\n",
      "\ttrain_loss: 2.185824, odo_loss: 1.521538, ine_loss: 0.513013, ref_loss: 0.151273\n",
      "\tval_loss: 2.232065, odo_loss: 1.548541, ine_loss: 0.512822, ref_loss: 0.170702\n",
      "Epoch 182/2000\n",
      "\t[#    0] train_loss: 3.464357, odo_loss: 2.755643, ine_loss: 0.548661, ref_loss: 0.160054\n",
      "\t[#  180] train_loss: 2.224917, odo_loss: 1.570179, ine_loss: 0.519365, ref_loss: 0.135373\n",
      "\t[#  360] train_loss: 2.120139, odo_loss: 1.283024, ine_loss: 0.661670, ref_loss: 0.175444\n",
      "\t[#  540] train_loss: 2.482586, odo_loss: 1.739804, ine_loss: 0.571225, ref_loss: 0.171557\n",
      "\t[#  720] train_loss: 2.186474, odo_loss: 1.508697, ine_loss: 0.509085, ref_loss: 0.168691\n",
      "\t[#  900] train_loss: 2.582443, odo_loss: 1.890360, ine_loss: 0.546543, ref_loss: 0.145541\n",
      "\ttrain_loss: 2.193228, odo_loss: 1.529243, ine_loss: 0.513144, ref_loss: 0.150842\n",
      "\tval_loss: 2.245901, odo_loss: 1.558985, ine_loss: 0.514684, ref_loss: 0.172231\n",
      "Epoch 183/2000\n",
      "\t[#    0] train_loss: 2.549387, odo_loss: 1.737310, ine_loss: 0.657600, ref_loss: 0.154477\n",
      "\t[#  180] train_loss: 2.210526, odo_loss: 1.576677, ine_loss: 0.456494, ref_loss: 0.177355\n",
      "\t[#  360] train_loss: 2.213532, odo_loss: 1.505208, ine_loss: 0.540524, ref_loss: 0.167800\n",
      "\t[#  540] train_loss: 2.446090, odo_loss: 1.795007, ine_loss: 0.514907, ref_loss: 0.136176\n",
      "\t[#  720] train_loss: 2.472111, odo_loss: 1.769725, ine_loss: 0.557119, ref_loss: 0.145267\n",
      "\t[#  900] train_loss: 2.463787, odo_loss: 1.772277, ine_loss: 0.514206, ref_loss: 0.177304\n",
      "\ttrain_loss: 2.193941, odo_loss: 1.529618, ine_loss: 0.512755, ref_loss: 0.151568\n",
      "\tval_loss: 2.237896, odo_loss: 1.560764, ine_loss: 0.505869, ref_loss: 0.171264\n",
      "Epoch 184/2000\n",
      "\t[#    0] train_loss: 2.366514, odo_loss: 1.675193, ine_loss: 0.524642, ref_loss: 0.166679\n",
      "\t[#  180] train_loss: 1.969711, odo_loss: 1.408672, ine_loss: 0.424097, ref_loss: 0.136943\n",
      "\t[#  360] train_loss: 2.132308, odo_loss: 1.418704, ine_loss: 0.562267, ref_loss: 0.151338\n",
      "\t[#  540] train_loss: 1.817616, odo_loss: 1.234240, ine_loss: 0.454759, ref_loss: 0.128617\n",
      "\t[#  720] train_loss: 1.670400, odo_loss: 1.067847, ine_loss: 0.449152, ref_loss: 0.153401\n",
      "\t[#  900] train_loss: 1.982042, odo_loss: 1.260469, ine_loss: 0.552971, ref_loss: 0.168602\n",
      "\ttrain_loss: 2.217929, odo_loss: 1.554196, ine_loss: 0.512699, ref_loss: 0.151034\n",
      "\tval_loss: 2.187969, odo_loss: 1.510259, ine_loss: 0.507244, ref_loss: 0.170466\n",
      "\t*** Personal Best ***\n",
      "Epoch 185/2000\n",
      "\t[#    0] train_loss: 2.157901, odo_loss: 1.494365, ine_loss: 0.533776, ref_loss: 0.129759\n",
      "\t[#  180] train_loss: 2.095193, odo_loss: 1.440935, ine_loss: 0.504388, ref_loss: 0.149870\n",
      "\t[#  360] train_loss: 2.165615, odo_loss: 1.512615, ine_loss: 0.518986, ref_loss: 0.134014\n",
      "\t[#  540] train_loss: 2.173961, odo_loss: 1.505708, ine_loss: 0.527950, ref_loss: 0.140303\n",
      "\t[#  720] train_loss: 2.313904, odo_loss: 1.695189, ine_loss: 0.501501, ref_loss: 0.117213\n",
      "\t[#  900] train_loss: 2.529633, odo_loss: 1.835439, ine_loss: 0.550635, ref_loss: 0.143559\n",
      "\ttrain_loss: 2.274077, odo_loss: 1.611484, ine_loss: 0.511878, ref_loss: 0.150715\n",
      "\tval_loss: 2.255603, odo_loss: 1.575919, ine_loss: 0.509292, ref_loss: 0.170392\n",
      "Epoch 186/2000\n",
      "\t[#    0] train_loss: 2.175955, odo_loss: 1.466292, ine_loss: 0.545716, ref_loss: 0.163947\n",
      "\t[#  180] train_loss: 2.240752, odo_loss: 1.617347, ine_loss: 0.469901, ref_loss: 0.153504\n",
      "\t[#  360] train_loss: 1.979564, odo_loss: 1.325418, ine_loss: 0.508883, ref_loss: 0.145263\n",
      "\t[#  540] train_loss: 2.252224, odo_loss: 1.570846, ine_loss: 0.533710, ref_loss: 0.147667\n",
      "\t[#  720] train_loss: 2.142298, odo_loss: 1.345241, ine_loss: 0.653422, ref_loss: 0.143636\n",
      "\t[#  900] train_loss: 2.067575, odo_loss: 1.438516, ine_loss: 0.486310, ref_loss: 0.142749\n",
      "\ttrain_loss: 2.215201, odo_loss: 1.552763, ine_loss: 0.511469, ref_loss: 0.150969\n",
      "\tval_loss: 2.215314, odo_loss: 1.533432, ine_loss: 0.512049, ref_loss: 0.169834\n",
      "Epoch 187/2000\n",
      "\t[#    0] train_loss: 2.175783, odo_loss: 1.321453, ine_loss: 0.693380, ref_loss: 0.160950\n",
      "\t[#  180] train_loss: 2.606776, odo_loss: 1.881541, ine_loss: 0.598481, ref_loss: 0.126754\n",
      "\t[#  360] train_loss: 2.611112, odo_loss: 1.872437, ine_loss: 0.570497, ref_loss: 0.168178\n",
      "\t[#  540] train_loss: 2.005830, odo_loss: 1.323607, ine_loss: 0.521872, ref_loss: 0.160351\n",
      "\t[#  720] train_loss: 2.063579, odo_loss: 1.391800, ine_loss: 0.510925, ref_loss: 0.160853\n",
      "\t[#  900] train_loss: 2.275547, odo_loss: 1.607955, ine_loss: 0.519428, ref_loss: 0.148164\n",
      "\ttrain_loss: 2.192140, odo_loss: 1.529722, ine_loss: 0.511928, ref_loss: 0.150490\n",
      "\tval_loss: 2.195409, odo_loss: 1.515120, ine_loss: 0.511591, ref_loss: 0.168699\n",
      "Epoch 188/2000\n",
      "\t[#    0] train_loss: 1.920335, odo_loss: 1.243752, ine_loss: 0.512509, ref_loss: 0.164074\n",
      "\t[#  180] train_loss: 2.489986, odo_loss: 1.833831, ine_loss: 0.505051, ref_loss: 0.151103\n",
      "\t[#  360] train_loss: 1.947300, odo_loss: 1.230880, ine_loss: 0.565349, ref_loss: 0.151070\n",
      "\t[#  540] train_loss: 2.009516, odo_loss: 1.426069, ine_loss: 0.441045, ref_loss: 0.142402\n",
      "\t[#  720] train_loss: 2.107710, odo_loss: 1.511606, ine_loss: 0.449942, ref_loss: 0.146162\n",
      "\t[#  900] train_loss: 2.058221, odo_loss: 1.470765, ine_loss: 0.462812, ref_loss: 0.124644\n",
      "\ttrain_loss: 2.228758, odo_loss: 1.566554, ine_loss: 0.511413, ref_loss: 0.150790\n",
      "\tval_loss: 2.267915, odo_loss: 1.583379, ine_loss: 0.513934, ref_loss: 0.170601\n",
      "Epoch 189/2000\n",
      "\t[#    0] train_loss: 2.485286, odo_loss: 1.847335, ine_loss: 0.483753, ref_loss: 0.154198\n",
      "\t[#  180] train_loss: 2.222212, odo_loss: 1.542010, ine_loss: 0.545922, ref_loss: 0.134280\n",
      "\t[#  360] train_loss: 2.252619, odo_loss: 1.491795, ine_loss: 0.607597, ref_loss: 0.153226\n",
      "\t[#  540] train_loss: 2.095039, odo_loss: 1.408814, ine_loss: 0.497481, ref_loss: 0.188743\n",
      "\t[#  720] train_loss: 2.348327, odo_loss: 1.731099, ine_loss: 0.426680, ref_loss: 0.190548\n",
      "\t[#  900] train_loss: 1.733296, odo_loss: 1.112749, ine_loss: 0.483526, ref_loss: 0.137020\n",
      "\ttrain_loss: 2.190554, odo_loss: 1.528678, ine_loss: 0.511470, ref_loss: 0.150406\n",
      "\tval_loss: 2.161362, odo_loss: 1.483451, ine_loss: 0.508784, ref_loss: 0.169127\n",
      "\t*** Personal Best ***\n",
      "Epoch 190/2000\n",
      "\t[#    0] train_loss: 1.832594, odo_loss: 1.183855, ine_loss: 0.525445, ref_loss: 0.123294\n",
      "\t[#  180] train_loss: 2.573590, odo_loss: 1.888305, ine_loss: 0.562020, ref_loss: 0.123265\n",
      "\t[#  360] train_loss: 2.339465, odo_loss: 1.645452, ine_loss: 0.548893, ref_loss: 0.145120\n",
      "\t[#  540] train_loss: 2.751325, odo_loss: 2.065642, ine_loss: 0.541678, ref_loss: 0.144006\n",
      "\t[#  720] train_loss: 1.936896, odo_loss: 1.325030, ine_loss: 0.439631, ref_loss: 0.172235\n",
      "\t[#  900] train_loss: 2.217990, odo_loss: 1.401316, ine_loss: 0.676910, ref_loss: 0.139764\n",
      "\ttrain_loss: 2.207010, odo_loss: 1.545840, ine_loss: 0.510821, ref_loss: 0.150349\n",
      "\tval_loss: 2.188232, odo_loss: 1.509579, ine_loss: 0.509417, ref_loss: 0.169235\n",
      "Epoch 191/2000\n",
      "\t[#    0] train_loss: 2.147010, odo_loss: 1.589759, ine_loss: 0.427447, ref_loss: 0.129804\n",
      "\t[#  180] train_loss: 2.090000, odo_loss: 1.486340, ine_loss: 0.474409, ref_loss: 0.129251\n",
      "\t[#  360] train_loss: 2.292457, odo_loss: 1.458677, ine_loss: 0.663327, ref_loss: 0.170453\n",
      "\t[#  540] train_loss: 2.089452, odo_loss: 1.383364, ine_loss: 0.572514, ref_loss: 0.133573\n",
      "\t[#  720] train_loss: 2.411060, odo_loss: 1.774183, ine_loss: 0.490025, ref_loss: 0.146852\n",
      "\t[#  900] train_loss: 2.213153, odo_loss: 1.558797, ine_loss: 0.501100, ref_loss: 0.153256\n",
      "\ttrain_loss: 2.195801, odo_loss: 1.534729, ine_loss: 0.510855, ref_loss: 0.150217\n",
      "\tval_loss: 2.179339, odo_loss: 1.499125, ine_loss: 0.508292, ref_loss: 0.171921\n",
      "Epoch 192/2000\n",
      "\t[#    0] train_loss: 2.429488, odo_loss: 1.585905, ine_loss: 0.633722, ref_loss: 0.209861\n",
      "\t[#  180] train_loss: 2.530426, odo_loss: 1.777573, ine_loss: 0.600805, ref_loss: 0.152048\n",
      "\t[#  360] train_loss: 1.798008, odo_loss: 1.113458, ine_loss: 0.539272, ref_loss: 0.145278\n",
      "\t[#  540] train_loss: 1.858264, odo_loss: 1.290985, ine_loss: 0.421587, ref_loss: 0.145691\n",
      "\t[#  720] train_loss: 2.190282, odo_loss: 1.472431, ine_loss: 0.560345, ref_loss: 0.157506\n",
      "\t[#  900] train_loss: 2.398089, odo_loss: 1.757219, ine_loss: 0.494486, ref_loss: 0.146384\n",
      "\ttrain_loss: 2.167810, odo_loss: 1.507354, ine_loss: 0.510146, ref_loss: 0.150310\n",
      "\tval_loss: 2.237675, odo_loss: 1.563939, ine_loss: 0.503071, ref_loss: 0.170666\n",
      "Epoch 193/2000\n",
      "\t[#    0] train_loss: 1.991580, odo_loss: 1.411472, ine_loss: 0.442079, ref_loss: 0.138029\n",
      "\t[#  180] train_loss: 2.010590, odo_loss: 1.439871, ine_loss: 0.430013, ref_loss: 0.140706\n",
      "\t[#  360] train_loss: 2.092841, odo_loss: 1.369776, ine_loss: 0.551769, ref_loss: 0.171297\n",
      "\t[#  540] train_loss: 2.215020, odo_loss: 1.521719, ine_loss: 0.524029, ref_loss: 0.169271\n",
      "\t[#  720] train_loss: 2.127972, odo_loss: 1.476753, ine_loss: 0.516087, ref_loss: 0.135132\n",
      "\t[#  900] train_loss: 2.071512, odo_loss: 1.495091, ine_loss: 0.444547, ref_loss: 0.131875\n",
      "\ttrain_loss: 2.155525, odo_loss: 1.495363, ine_loss: 0.509974, ref_loss: 0.150188\n",
      "\tval_loss: 2.287668, odo_loss: 1.614624, ine_loss: 0.500622, ref_loss: 0.172422\n",
      "Epoch 194/2000\n",
      "\t[#    0] train_loss: 2.235854, odo_loss: 1.565486, ine_loss: 0.525591, ref_loss: 0.144777\n",
      "\t[#  180] train_loss: 2.068218, odo_loss: 1.420781, ine_loss: 0.489738, ref_loss: 0.157698\n",
      "\t[#  360] train_loss: 2.295827, odo_loss: 1.663384, ine_loss: 0.498147, ref_loss: 0.134296\n",
      "\t[#  540] train_loss: 1.882508, odo_loss: 1.181649, ine_loss: 0.526942, ref_loss: 0.173917\n",
      "\t[#  720] train_loss: 2.220926, odo_loss: 1.668410, ine_loss: 0.386286, ref_loss: 0.166230\n",
      "\t[#  900] train_loss: 1.842247, odo_loss: 1.307998, ine_loss: 0.368021, ref_loss: 0.166228\n",
      "\ttrain_loss: 2.171272, odo_loss: 1.511084, ine_loss: 0.510333, ref_loss: 0.149855\n",
      "\tval_loss: 2.134714, odo_loss: 1.456812, ine_loss: 0.508799, ref_loss: 0.169103\n",
      "\t*** Personal Best ***\n",
      "Epoch 195/2000\n",
      "\t[#    0] train_loss: 2.327490, odo_loss: 1.627725, ine_loss: 0.544928, ref_loss: 0.154837\n",
      "\t[#  180] train_loss: 2.396448, odo_loss: 1.736401, ine_loss: 0.521376, ref_loss: 0.138670\n",
      "\t[#  360] train_loss: 2.470129, odo_loss: 1.749978, ine_loss: 0.549309, ref_loss: 0.170841\n",
      "\t[#  540] train_loss: 2.207812, odo_loss: 1.473481, ine_loss: 0.573938, ref_loss: 0.160393\n",
      "\t[#  720] train_loss: 2.112906, odo_loss: 1.504726, ine_loss: 0.468447, ref_loss: 0.139733\n",
      "\t[#  900] train_loss: 2.052275, odo_loss: 1.575770, ine_loss: 0.336956, ref_loss: 0.139549\n",
      "\ttrain_loss: 2.170912, odo_loss: 1.511346, ine_loss: 0.509546, ref_loss: 0.150020\n",
      "\tval_loss: 2.206660, odo_loss: 1.528223, ine_loss: 0.506292, ref_loss: 0.172145\n",
      "Epoch 196/2000\n",
      "\t[#    0] train_loss: 2.144222, odo_loss: 1.534383, ine_loss: 0.464828, ref_loss: 0.145010\n",
      "\t[#  180] train_loss: 2.091858, odo_loss: 1.437876, ine_loss: 0.498628, ref_loss: 0.155355\n",
      "\t[#  360] train_loss: 2.489426, odo_loss: 1.881272, ine_loss: 0.428291, ref_loss: 0.179862\n",
      "\t[#  540] train_loss: 1.739335, odo_loss: 1.185884, ine_loss: 0.405029, ref_loss: 0.148423\n",
      "\t[#  720] train_loss: 2.146170, odo_loss: 1.376745, ine_loss: 0.641792, ref_loss: 0.127633\n",
      "\t[#  900] train_loss: 2.514456, odo_loss: 1.773259, ine_loss: 0.550463, ref_loss: 0.190733\n",
      "\ttrain_loss: 2.218312, odo_loss: 1.558019, ine_loss: 0.510305, ref_loss: 0.149988\n",
      "\tval_loss: 2.306215, odo_loss: 1.631408, ine_loss: 0.504121, ref_loss: 0.170687\n",
      "Epoch 197/2000\n",
      "\t[#    0] train_loss: 2.238634, odo_loss: 1.512141, ine_loss: 0.583417, ref_loss: 0.143076\n",
      "\t[#  180] train_loss: 2.036674, odo_loss: 1.440674, ine_loss: 0.459316, ref_loss: 0.136685\n",
      "\t[#  360] train_loss: 2.228213, odo_loss: 1.622040, ine_loss: 0.463410, ref_loss: 0.142763\n",
      "\t[#  540] train_loss: 2.425287, odo_loss: 1.757113, ine_loss: 0.516652, ref_loss: 0.151522\n",
      "\t[#  720] train_loss: 2.205352, odo_loss: 1.544291, ine_loss: 0.480647, ref_loss: 0.180414\n",
      "\t[#  900] train_loss: 2.519877, odo_loss: 1.856940, ine_loss: 0.497333, ref_loss: 0.165604\n",
      "\ttrain_loss: 2.186555, odo_loss: 1.526983, ine_loss: 0.509772, ref_loss: 0.149801\n",
      "\tval_loss: 2.290888, odo_loss: 1.608774, ine_loss: 0.513608, ref_loss: 0.168506\n",
      "Epoch 198/2000\n",
      "\t[#    0] train_loss: 1.815947, odo_loss: 1.250716, ine_loss: 0.426621, ref_loss: 0.138610\n",
      "\t[#  180] train_loss: 2.024525, odo_loss: 1.374323, ine_loss: 0.510994, ref_loss: 0.139208\n",
      "\t[#  360] train_loss: 2.217686, odo_loss: 1.590915, ine_loss: 0.492920, ref_loss: 0.133851\n",
      "\t[#  540] train_loss: 2.202039, odo_loss: 1.580240, ine_loss: 0.470641, ref_loss: 0.151158\n",
      "\t[#  720] train_loss: 7.766967, odo_loss: 7.085723, ine_loss: 0.527648, ref_loss: 0.153596\n",
      "\t[#  900] train_loss: 2.528314, odo_loss: 1.770881, ine_loss: 0.595886, ref_loss: 0.161548\n",
      "\ttrain_loss: 2.221792, odo_loss: 1.562660, ine_loss: 0.508960, ref_loss: 0.150172\n",
      "\tval_loss: 2.310233, odo_loss: 1.637551, ine_loss: 0.502991, ref_loss: 0.169690\n",
      "Epoch 199/2000\n",
      "\t[#    0] train_loss: 2.406429, odo_loss: 1.889244, ine_loss: 0.382526, ref_loss: 0.134659\n",
      "\t[#  180] train_loss: 2.384473, odo_loss: 1.863549, ine_loss: 0.401111, ref_loss: 0.119813\n",
      "\t[#  360] train_loss: 2.150504, odo_loss: 1.452146, ine_loss: 0.560755, ref_loss: 0.137602\n",
      "\t[#  540] train_loss: 2.193546, odo_loss: 1.559012, ine_loss: 0.481898, ref_loss: 0.152637\n",
      "\t[#  720] train_loss: 2.110148, odo_loss: 1.459062, ine_loss: 0.536286, ref_loss: 0.114800\n",
      "\t[#  900] train_loss: 2.454078, odo_loss: 1.795505, ine_loss: 0.495784, ref_loss: 0.162789\n",
      "\ttrain_loss: 2.179002, odo_loss: 1.519704, ine_loss: 0.509351, ref_loss: 0.149947\n",
      "\tval_loss: 2.179140, odo_loss: 1.503443, ine_loss: 0.506731, ref_loss: 0.168967\n",
      "Epoch 200/2000\n",
      "\t[#    0] train_loss: 1.997514, odo_loss: 1.433906, ine_loss: 0.428369, ref_loss: 0.135238\n",
      "\t[#  180] train_loss: 2.171431, odo_loss: 1.590623, ine_loss: 0.444613, ref_loss: 0.136196\n",
      "\t[#  360] train_loss: 2.346380, odo_loss: 1.778405, ine_loss: 0.455075, ref_loss: 0.112900\n",
      "\t[#  540] train_loss: 2.022481, odo_loss: 1.390374, ine_loss: 0.477049, ref_loss: 0.155059\n",
      "\t[#  720] train_loss: 2.255188, odo_loss: 1.553371, ine_loss: 0.544399, ref_loss: 0.157417\n",
      "\t[#  900] train_loss: 2.375655, odo_loss: 1.724668, ine_loss: 0.505176, ref_loss: 0.145811\n",
      "\ttrain_loss: 2.234473, odo_loss: 1.576084, ine_loss: 0.508220, ref_loss: 0.150170\n",
      "\tval_loss: 2.320459, odo_loss: 1.644358, ine_loss: 0.507004, ref_loss: 0.169096\n",
      "Epoch 201/2000\n",
      "\t[#    0] train_loss: 2.099849, odo_loss: 1.502439, ine_loss: 0.464978, ref_loss: 0.132432\n",
      "\t[#  180] train_loss: 2.004868, odo_loss: 1.228600, ine_loss: 0.626961, ref_loss: 0.149307\n",
      "\t[#  360] train_loss: 2.481663, odo_loss: 1.873337, ine_loss: 0.434569, ref_loss: 0.173757\n",
      "\t[#  540] train_loss: 2.130585, odo_loss: 1.537021, ine_loss: 0.449562, ref_loss: 0.144002\n",
      "\t[#  720] train_loss: 1.774779, odo_loss: 1.165252, ine_loss: 0.441480, ref_loss: 0.168047\n",
      "\t[#  900] train_loss: 2.044561, odo_loss: 1.381380, ine_loss: 0.525400, ref_loss: 0.137781\n",
      "\ttrain_loss: 2.219861, odo_loss: 1.560383, ine_loss: 0.509054, ref_loss: 0.150424\n",
      "\tval_loss: 2.254977, odo_loss: 1.583121, ine_loss: 0.500770, ref_loss: 0.171086\n",
      "Epoch 202/2000\n",
      "\t[#    0] train_loss: 2.469742, odo_loss: 1.806667, ine_loss: 0.524054, ref_loss: 0.139021\n",
      "\t[#  180] train_loss: 2.338804, odo_loss: 1.670862, ine_loss: 0.470406, ref_loss: 0.197535\n",
      "\t[#  360] train_loss: 2.181269, odo_loss: 1.557329, ine_loss: 0.462660, ref_loss: 0.161280\n",
      "\t[#  540] train_loss: 2.027012, odo_loss: 1.482137, ine_loss: 0.416206, ref_loss: 0.128668\n",
      "\t[#  720] train_loss: 2.683521, odo_loss: 2.017592, ine_loss: 0.518006, ref_loss: 0.147923\n",
      "\t[#  900] train_loss: 1.971299, odo_loss: 1.328340, ine_loss: 0.479556, ref_loss: 0.163402\n",
      "\ttrain_loss: 2.171342, odo_loss: 1.513524, ine_loss: 0.508540, ref_loss: 0.149279\n",
      "\tval_loss: 2.197322, odo_loss: 1.523615, ine_loss: 0.505073, ref_loss: 0.168634\n",
      "Epoch 203/2000\n",
      "\t[#    0] train_loss: 2.344140, odo_loss: 1.542753, ine_loss: 0.651311, ref_loss: 0.150076\n",
      "\t[#  180] train_loss: 2.077123, odo_loss: 1.384351, ine_loss: 0.546876, ref_loss: 0.145896\n",
      "\t[#  360] train_loss: 2.241115, odo_loss: 1.527240, ine_loss: 0.568759, ref_loss: 0.145116\n",
      "\t[#  540] train_loss: 2.053014, odo_loss: 1.334796, ine_loss: 0.531571, ref_loss: 0.186647\n",
      "\t[#  720] train_loss: 1.785897, odo_loss: 1.246174, ine_loss: 0.408333, ref_loss: 0.131390\n",
      "\t[#  900] train_loss: 2.092650, odo_loss: 1.285469, ine_loss: 0.655738, ref_loss: 0.151443\n",
      "\ttrain_loss: 2.145269, odo_loss: 1.486840, ine_loss: 0.509022, ref_loss: 0.149408\n",
      "\tval_loss: 2.273106, odo_loss: 1.598398, ine_loss: 0.506104, ref_loss: 0.168603\n",
      "Epoch 204/2000\n",
      "\t[#    0] train_loss: 2.348877, odo_loss: 1.675267, ine_loss: 0.500084, ref_loss: 0.173526\n",
      "\t[#  180] train_loss: 2.244306, odo_loss: 1.599146, ine_loss: 0.512621, ref_loss: 0.132539\n",
      "\t[#  360] train_loss: 2.763184, odo_loss: 2.142644, ine_loss: 0.466552, ref_loss: 0.153988\n",
      "\t[#  540] train_loss: 2.334051, odo_loss: 1.499771, ine_loss: 0.677315, ref_loss: 0.156964\n",
      "\t[#  720] train_loss: 2.120170, odo_loss: 1.508511, ine_loss: 0.441469, ref_loss: 0.170190\n",
      "\t[#  900] train_loss: 2.231373, odo_loss: 1.594625, ine_loss: 0.493405, ref_loss: 0.143343\n",
      "\ttrain_loss: 2.249906, odo_loss: 1.591287, ine_loss: 0.509005, ref_loss: 0.149614\n",
      "\tval_loss: 2.208514, odo_loss: 1.533048, ine_loss: 0.506260, ref_loss: 0.169206\n",
      "Epoch 205/2000\n",
      "\t[#    0] train_loss: 2.173169, odo_loss: 1.461340, ine_loss: 0.587694, ref_loss: 0.124135\n",
      "\t[#  180] train_loss: 2.070529, odo_loss: 1.361411, ine_loss: 0.576951, ref_loss: 0.132168\n",
      "\t[#  360] train_loss: 2.256680, odo_loss: 1.562733, ine_loss: 0.541546, ref_loss: 0.152400\n",
      "\t[#  540] train_loss: 2.347250, odo_loss: 1.662436, ine_loss: 0.505897, ref_loss: 0.178918\n",
      "\t[#  720] train_loss: 2.479197, odo_loss: 1.764033, ine_loss: 0.560897, ref_loss: 0.154267\n",
      "\t[#  900] train_loss: 2.073857, odo_loss: 1.341991, ine_loss: 0.578378, ref_loss: 0.153489\n",
      "\ttrain_loss: 2.160249, odo_loss: 1.501577, ine_loss: 0.509796, ref_loss: 0.148876\n",
      "\tval_loss: 2.240109, odo_loss: 1.565871, ine_loss: 0.504588, ref_loss: 0.169649\n",
      "Epoch 206/2000\n",
      "\t[#    0] train_loss: 2.066201, odo_loss: 1.444519, ine_loss: 0.481943, ref_loss: 0.139738\n",
      "\t[#  180] train_loss: 1.740317, odo_loss: 1.063087, ine_loss: 0.487959, ref_loss: 0.189270\n",
      "\t[#  360] train_loss: 1.955657, odo_loss: 1.323619, ine_loss: 0.461618, ref_loss: 0.170420\n",
      "\t[#  540] train_loss: 1.924647, odo_loss: 1.268702, ine_loss: 0.489857, ref_loss: 0.166087\n",
      "\t[#  720] train_loss: 2.145885, odo_loss: 1.517183, ine_loss: 0.461233, ref_loss: 0.167468\n",
      "\t[#  900] train_loss: 2.322702, odo_loss: 1.684838, ine_loss: 0.448504, ref_loss: 0.189360\n",
      "\ttrain_loss: 2.190881, odo_loss: 1.531982, ine_loss: 0.509734, ref_loss: 0.149165\n",
      "\tval_loss: 2.185675, odo_loss: 1.515941, ine_loss: 0.501275, ref_loss: 0.168459\n",
      "Epoch 207/2000\n",
      "\t[#    0] train_loss: 2.113069, odo_loss: 1.289545, ine_loss: 0.677970, ref_loss: 0.145554\n",
      "\t[#  180] train_loss: 1.853943, odo_loss: 1.193887, ine_loss: 0.517760, ref_loss: 0.142295\n",
      "\t[#  360] train_loss: 2.033005, odo_loss: 1.297065, ine_loss: 0.562328, ref_loss: 0.173612\n",
      "\t[#  540] train_loss: 2.077950, odo_loss: 1.351702, ine_loss: 0.561692, ref_loss: 0.164556\n",
      "\t[#  720] train_loss: 2.312064, odo_loss: 1.629852, ine_loss: 0.540641, ref_loss: 0.141571\n",
      "\t[#  900] train_loss: 1.909385, odo_loss: 1.316730, ine_loss: 0.474863, ref_loss: 0.117792\n",
      "\ttrain_loss: 2.155819, odo_loss: 1.497931, ine_loss: 0.508652, ref_loss: 0.149236\n",
      "\tval_loss: 2.143358, odo_loss: 1.469432, ine_loss: 0.505259, ref_loss: 0.168667\n",
      "Epoch 208/2000\n",
      "\t[#    0] train_loss: 1.992886, odo_loss: 1.381989, ine_loss: 0.489616, ref_loss: 0.121280\n",
      "\t[#  180] train_loss: 2.036242, odo_loss: 1.449494, ine_loss: 0.455669, ref_loss: 0.131079\n",
      "\t[#  360] train_loss: 2.039037, odo_loss: 1.420575, ine_loss: 0.483974, ref_loss: 0.134488\n",
      "\t[#  540] train_loss: 2.144720, odo_loss: 1.349162, ine_loss: 0.615177, ref_loss: 0.180381\n",
      "\t[#  720] train_loss: 2.105391, odo_loss: 1.457187, ine_loss: 0.474432, ref_loss: 0.173771\n",
      "\t[#  900] train_loss: 2.416437, odo_loss: 1.809322, ine_loss: 0.489280, ref_loss: 0.117835\n",
      "\ttrain_loss: 2.204409, odo_loss: 1.545917, ine_loss: 0.509160, ref_loss: 0.149331\n",
      "\tval_loss: 2.252206, odo_loss: 1.581138, ine_loss: 0.502717, ref_loss: 0.168351\n",
      "Epoch 209/2000\n",
      "\t[#    0] train_loss: 2.084289, odo_loss: 1.379795, ine_loss: 0.585294, ref_loss: 0.119200\n",
      "\t[#  180] train_loss: 2.221158, odo_loss: 1.433550, ine_loss: 0.616921, ref_loss: 0.170686\n",
      "\t[#  360] train_loss: 2.092174, odo_loss: 1.448234, ine_loss: 0.491362, ref_loss: 0.152577\n",
      "\t[#  540] train_loss: 2.180452, odo_loss: 1.383168, ine_loss: 0.622960, ref_loss: 0.174324\n",
      "\t[#  720] train_loss: 2.266746, odo_loss: 1.624635, ine_loss: 0.510593, ref_loss: 0.131518\n",
      "\t[#  900] train_loss: 2.138355, odo_loss: 1.392442, ine_loss: 0.595911, ref_loss: 0.150002\n",
      "\ttrain_loss: 2.156560, odo_loss: 1.498281, ine_loss: 0.509389, ref_loss: 0.148890\n",
      "\tval_loss: 2.277100, odo_loss: 1.599704, ine_loss: 0.507927, ref_loss: 0.169469\n",
      "Epoch 210/2000\n",
      "\t[#    0] train_loss: 2.136822, odo_loss: 1.457025, ine_loss: 0.509607, ref_loss: 0.170190\n",
      "\t[#  180] train_loss: 1.981568, odo_loss: 1.325809, ine_loss: 0.520090, ref_loss: 0.135669\n",
      "\t[#  360] train_loss: 1.961962, odo_loss: 1.405564, ine_loss: 0.433232, ref_loss: 0.123165\n",
      "\t[#  540] train_loss: 1.923651, odo_loss: 1.255175, ine_loss: 0.526475, ref_loss: 0.142001\n",
      "\t[#  720] train_loss: 2.315334, odo_loss: 1.629727, ine_loss: 0.533843, ref_loss: 0.151763\n",
      "\t[#  900] train_loss: 2.604433, odo_loss: 1.823364, ine_loss: 0.600516, ref_loss: 0.180553\n",
      "\ttrain_loss: 2.143411, odo_loss: 1.485220, ine_loss: 0.509097, ref_loss: 0.149093\n",
      "\tval_loss: 2.359002, odo_loss: 1.681346, ine_loss: 0.508569, ref_loss: 0.169087\n",
      "Epoch 211/2000\n",
      "\t[#    0] train_loss: 2.340311, odo_loss: 1.444809, ine_loss: 0.730017, ref_loss: 0.165485\n",
      "\t[#  180] train_loss: 2.134385, odo_loss: 1.524227, ine_loss: 0.443311, ref_loss: 0.166848\n",
      "\t[#  360] train_loss: 2.278695, odo_loss: 1.501764, ine_loss: 0.625868, ref_loss: 0.151062\n",
      "\t[#  540] train_loss: 2.259037, odo_loss: 1.648654, ine_loss: 0.483617, ref_loss: 0.126766\n",
      "\t[#  720] train_loss: 2.266127, odo_loss: 1.628833, ine_loss: 0.489364, ref_loss: 0.147929\n",
      "\t[#  900] train_loss: 4.885027, odo_loss: 4.216177, ine_loss: 0.494516, ref_loss: 0.174335\n",
      "\ttrain_loss: 2.152349, odo_loss: 1.494909, ine_loss: 0.508106, ref_loss: 0.149334\n",
      "\tval_loss: 2.402908, odo_loss: 1.733862, ine_loss: 0.501861, ref_loss: 0.167185\n",
      "Epoch 212/2000\n",
      "\t[#    0] train_loss: 2.360159, odo_loss: 1.640628, ine_loss: 0.579280, ref_loss: 0.140251\n",
      "\t[#  180] train_loss: 2.770244, odo_loss: 2.001629, ine_loss: 0.603194, ref_loss: 0.165422\n",
      "\t[#  360] train_loss: 2.045357, odo_loss: 1.379314, ine_loss: 0.500540, ref_loss: 0.165503\n",
      "\t[#  540] train_loss: 2.090941, odo_loss: 1.440193, ine_loss: 0.477990, ref_loss: 0.172759\n",
      "\t[#  720] train_loss: 2.283399, odo_loss: 1.628822, ine_loss: 0.507579, ref_loss: 0.146998\n",
      "\t[#  900] train_loss: 2.099875, odo_loss: 1.387228, ine_loss: 0.534835, ref_loss: 0.177813\n",
      "\ttrain_loss: 2.168707, odo_loss: 1.512446, ine_loss: 0.507477, ref_loss: 0.148784\n",
      "\tval_loss: 2.194517, odo_loss: 1.519553, ine_loss: 0.502324, ref_loss: 0.172640\n",
      "Epoch 213/2000\n",
      "\t[#    0] train_loss: 1.966565, odo_loss: 1.445770, ine_loss: 0.393330, ref_loss: 0.127464\n",
      "\t[#  180] train_loss: 2.500121, odo_loss: 1.890474, ine_loss: 0.473854, ref_loss: 0.135792\n",
      "\t[#  360] train_loss: 2.059941, odo_loss: 1.469778, ine_loss: 0.430827, ref_loss: 0.159336\n",
      "\t[#  540] train_loss: 1.806753, odo_loss: 1.336874, ine_loss: 0.343130, ref_loss: 0.126749\n",
      "\t[#  720] train_loss: 1.937161, odo_loss: 1.314867, ine_loss: 0.467602, ref_loss: 0.154693\n",
      "\t[#  900] train_loss: 1.810414, odo_loss: 1.203858, ine_loss: 0.462893, ref_loss: 0.143663\n",
      "\ttrain_loss: 2.282075, odo_loss: 1.625428, ine_loss: 0.507568, ref_loss: 0.149079\n",
      "\tval_loss: 2.224279, odo_loss: 1.548646, ine_loss: 0.506749, ref_loss: 0.168885\n",
      "Epoch 214/2000\n",
      "\t[#    0] train_loss: 2.423818, odo_loss: 1.728448, ine_loss: 0.547505, ref_loss: 0.147866\n",
      "\t[#  180] train_loss: 2.287208, odo_loss: 1.579237, ine_loss: 0.585696, ref_loss: 0.122275\n",
      "\t[#  360] train_loss: 2.291833, odo_loss: 1.767350, ine_loss: 0.403963, ref_loss: 0.120521\n",
      "\t[#  540] train_loss: 2.200064, odo_loss: 1.447900, ine_loss: 0.617778, ref_loss: 0.134386\n",
      "\t[#  720] train_loss: 2.519671, odo_loss: 1.734848, ine_loss: 0.632051, ref_loss: 0.152772\n",
      "\t[#  900] train_loss: 2.259798, odo_loss: 1.581816, ine_loss: 0.506651, ref_loss: 0.171331\n",
      "\ttrain_loss: 2.182969, odo_loss: 1.524640, ine_loss: 0.509078, ref_loss: 0.149251\n",
      "\tval_loss: 2.147025, odo_loss: 1.474690, ine_loss: 0.502484, ref_loss: 0.169850\n",
      "Epoch 215/2000\n",
      "\t[#    0] train_loss: 2.380351, odo_loss: 1.783153, ine_loss: 0.430642, ref_loss: 0.166556\n",
      "\t[#  180] train_loss: 2.231545, odo_loss: 1.460320, ine_loss: 0.623166, ref_loss: 0.148059\n",
      "\t[#  360] train_loss: 2.614022, odo_loss: 1.918972, ine_loss: 0.507266, ref_loss: 0.187784\n",
      "\t[#  540] train_loss: 2.576218, odo_loss: 1.949664, ine_loss: 0.456370, ref_loss: 0.170185\n",
      "\t[#  720] train_loss: 2.304729, odo_loss: 1.573236, ine_loss: 0.573097, ref_loss: 0.158396\n",
      "\t[#  900] train_loss: 2.543937, odo_loss: 1.811010, ine_loss: 0.572449, ref_loss: 0.160479\n",
      "\ttrain_loss: 2.247061, odo_loss: 1.590359, ine_loss: 0.507156, ref_loss: 0.149546\n",
      "\tval_loss: 2.212762, odo_loss: 1.538205, ine_loss: 0.503915, ref_loss: 0.170643\n",
      "\n",
      "\tStopped by  early stopping!\n"
     ]
    }
   ],
   "source": [
    "model = InertialNet2().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "h_loss_train = []\n",
    "h_loss_val = []\n",
    "\n",
    "early_stopping = {\"epoch\":0, \"best\":10**3, \"epoch_threshold\":EARLY_STOPPING}\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(f\"Epoch {epoch}/{EPOCHS}\")\n",
    "\n",
    "    _, loss_train, _, _ = train(model, device, train_loader, optimizer, epoch)\n",
    "    _, loss_val, _, _ = validation(model, device, val_loader, epoch)\n",
    "\n",
    "    #populating the history of the loss\n",
    "    h_loss_train.append(loss_train)\n",
    "    h_loss_val.append(loss_val)\n",
    "\n",
    "    # early stopping\n",
    "    if loss_val < early_stopping[\"best\"]:\n",
    "        early_stopping[\"best\"] = loss_val\n",
    "        early_stopping[\"epoch\"] = epoch\n",
    "        print(\"\\t*** Personal Best ***\")\n",
    "\n",
    "    if epoch - early_stopping[\"epoch\"] > early_stopping[\"epoch_threshold\"]:\n",
    "        print(\"\\n\\tStopped by  early stopping!\")\n",
    "        break\n",
    "\n",
    "np.savez(f\"train_loss_{EPOCHS}\", h_loss_train)\n",
    "np.savez(f\"val_loss_{EPOCHS}\", h_loss_val)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(h_loss_train, label=\"train\")\n",
    "plt.plot(h_loss_val, label=\"validation\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zoomed plot (last 30 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(h_loss_train)[-100:], label=\"train\")\n",
    "plt.plot(np.array(h_loss_val)[-100:], label=\"validation\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a60a9521ac24e310983a613c26989eaf1fc2b3e1d7e934fda12fd60cebe70c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
